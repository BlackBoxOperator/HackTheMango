parameter = [0.47615826222934565, 0.6302190543188851, 0.40396096956847294, 0.9200240126763269, 0.01685162040226995, 0.9876105507362524]
Training loss = 0.043472129947372845
step = 0, Training Accuracy: 0.42
Validation Accuracy: 0.4375
Training loss = 0.04005867423755782
step = 1, Training Accuracy: 0.4719642857142857
Training loss = 0.03953099313591208
step = 2, Training Accuracy: 0.4789285714285714
Training loss = 0.03871874563395977
step = 3, Training Accuracy: 0.48839285714285713
Training loss = 0.03824070019381387
step = 4, Training Accuracy: 0.5282142857142857
Training loss = 0.036784777673227444
step = 5, Training Accuracy: 0.5521428571428572
Training loss = 0.03556188514190061
step = 6, Training Accuracy: 0.5798214285714286
Training loss = 0.034777285499232154
step = 7, Training Accuracy: 0.5982142857142857
Training loss = 0.03446152394371373
step = 8, Training Accuracy: 0.5975
Training loss = 0.03349937325077398
step = 9, Training Accuracy: 0.6089285714285714
Training loss = 0.033153271153569225
step = 10, Training Accuracy: 0.6117857142857143
Training loss = 0.032056787077869686
step = 11, Training Accuracy: 0.6328571428571429
Training loss = 0.032121281634484015
step = 12, Training Accuracy: 0.6307142857142857
Training loss = 0.031704634417380605
step = 13, Training Accuracy: 0.6428571428571429
Training loss = 0.030260991331722054
step = 14, Training Accuracy: 0.6555357142857143
Training loss = 0.02975102789167847
step = 15, Training Accuracy: 0.6683928571428571
Training loss = 0.029483703449368476
step = 16, Training Accuracy: 0.6617857142857143
Training loss = 0.02882568364696843
step = 17, Training Accuracy: 0.6683928571428571
Training loss = 0.028600662004734788
step = 18, Training Accuracy: 0.6753571428571429
Training loss = 0.02828102382166045
step = 19, Training Accuracy: 0.6796428571428571
Validation Accuracy: 0.74625
parameter = [0.1474309569583241, 0.8613314138109517, 0.44003630577221464, 0.7212885992572478, 0.08366591038506865, 0.679464779137179]
Training loss = 0.02840807790202754
step = 0, Training Accuracy: 0.6866071428571429
Validation Accuracy: 0.75125
Training loss = 0.028118351096553463
step = 1, Training Accuracy: 0.68625
Training loss = 0.027563601253288134
step = 2, Training Accuracy: 0.6857142857142857
Training loss = 0.027262782050030573
step = 3, Training Accuracy: 0.6985714285714286
Training loss = 0.027035217439489705
step = 4, Training Accuracy: 0.6980357142857143
Training loss = 0.0268375659893666
step = 5, Training Accuracy: 0.7008928571428571
Training loss = 0.02663521898644311
step = 6, Training Accuracy: 0.7067857142857142
Training loss = 0.02668016916407006
step = 7, Training Accuracy: 0.6985714285714286
Training loss = 0.02624203783060823
step = 8, Training Accuracy: 0.7083928571428572
Training loss = 0.02561036681490285
step = 9, Training Accuracy: 0.7132142857142857
Training loss = 0.025845443095479693
step = 10, Training Accuracy: 0.715
Training loss = 0.025394252070358822
step = 11, Training Accuracy: 0.7121428571428572
Training loss = 0.02552632690540382
step = 12, Training Accuracy: 0.71375
Training loss = 0.025543103995067734
step = 13, Training Accuracy: 0.7180357142857143
Training loss = 0.025338107592293196
step = 14, Training Accuracy: 0.7239285714285715
Training loss = 0.024862670398184232
step = 15, Training Accuracy: 0.7223214285714286
Training loss = 0.02524116045662335
step = 16, Training Accuracy: 0.7135714285714285
Training loss = 0.02519283250506435
step = 17, Training Accuracy: 0.7230357142857143
Training loss = 0.024616121053695678
step = 18, Training Accuracy: 0.7283928571428572
Training loss = 0.024334321479712213
step = 19, Training Accuracy: 0.7383928571428572
Validation Accuracy: 0.79375
parameter = [0.19673746145383764, 0.8149524482305617, 0.7696797658382238, 0.39701291838018926, 0.2137573979486891, 0.7423923323846316]
Training loss = 0.026343249396554063
step = 0, Training Accuracy: 0.7003571428571429
Validation Accuracy: 0.78125
Training loss = 0.025358282662928104
step = 1, Training Accuracy: 0.71625
Training loss = 0.02502957433462143
step = 2, Training Accuracy: 0.7157142857142857
Training loss = 0.024951242272342956
step = 3, Training Accuracy: 0.7210714285714286
Training loss = 0.02458690228738955
step = 4, Training Accuracy: 0.7278571428571429
Training loss = 0.024605515689722128
step = 5, Training Accuracy: 0.7276785714285714
Training loss = 0.024610975150551113
step = 6, Training Accuracy: 0.7321428571428571
Training loss = 0.024648049920797346
step = 7, Training Accuracy: 0.7273214285714286
Training loss = 0.02478612907230854
step = 8, Training Accuracy: 0.7294642857142857
Training loss = 0.023989727411951337
step = 9, Training Accuracy: 0.7325
Training loss = 0.023951231076249056
step = 10, Training Accuracy: 0.7376785714285714
Training loss = 0.024799311868846416
step = 11, Training Accuracy: 0.7248214285714286
Training loss = 0.024247631191142968
step = 12, Training Accuracy: 0.7326785714285714
Training loss = 0.024192299598029682
step = 13, Training Accuracy: 0.7330357142857142
Training loss = 0.02389942099473306
step = 14, Training Accuracy: 0.7271428571428571
Training loss = 0.023763312537755286
step = 15, Training Accuracy: 0.74125
Training loss = 0.023583463808255538
step = 16, Training Accuracy: 0.7403571428571428
Training loss = 0.02412899437759604
step = 17, Training Accuracy: 0.7282142857142857
Training loss = 0.0235124190098473
step = 18, Training Accuracy: 0.7448214285714285
Training loss = 0.023842657900282314
step = 19, Training Accuracy: 0.7328571428571429
Validation Accuracy: 0.81125
parameter = [0.0016410517036646866, 0.4654349622200482, 0.21349210455755507, 0.05598080636124514, 0.2807600588893786, 0.6727775726121318]
Training loss = 0.02670237741300038
step = 0, Training Accuracy: 0.6996428571428571
Validation Accuracy: 0.76
Training loss = 0.02566364601254463
step = 1, Training Accuracy: 0.7173214285714286
Training loss = 0.02547532943742616
step = 2, Training Accuracy: 0.72
Training loss = 0.025200324606682572
step = 3, Training Accuracy: 0.72
Training loss = 0.024747203668313365
step = 4, Training Accuracy: 0.73
Training loss = 0.024629013229693686
step = 5, Training Accuracy: 0.7264285714285714
Training loss = 0.024649453493101256
step = 6, Training Accuracy: 0.7253571428571428
Training loss = 0.02452931580266782
step = 7, Training Accuracy: 0.7278571428571429
Training loss = 0.024942897611430714
step = 8, Training Accuracy: 0.725
Training loss = 0.024404780300600188
step = 9, Training Accuracy: 0.7335714285714285
Training loss = 0.02451518999678748
step = 10, Training Accuracy: 0.7342857142857143
Training loss = 0.024510964463864054
step = 11, Training Accuracy: 0.7276785714285714
Training loss = 0.024372029905872686
step = 12, Training Accuracy: 0.7228571428571429
Training loss = 0.024444419273308347
step = 13, Training Accuracy: 0.7273214285714286
Training loss = 0.02397775926760265
step = 14, Training Accuracy: 0.74
Training loss = 0.023859676952872957
step = 15, Training Accuracy: 0.73625
Training loss = 0.023952090772134917
step = 16, Training Accuracy: 0.74125
Training loss = 0.02369677170046738
step = 17, Training Accuracy: 0.7375
Training loss = 0.024220832623541355
step = 18, Training Accuracy: 0.7289285714285715
Training loss = 0.023862898993705
step = 19, Training Accuracy: 0.7307142857142858
Validation Accuracy: 0.78875
gen	nevals	avg  	std      	min    	max    
0  	4     	0.785	0.0238812	0.74625	0.81125
parameter = [0.15687593637536246, 0.8316686516823, 0.5831338908498166, 0.687370651320018, 0.09867448919758273, 0.6771803377593855]
Training loss = 0.02555213908531836
step = 0, Training Accuracy: 0.7125
Validation Accuracy: 0.79125
Training loss = 0.024212810572768962
step = 1, Training Accuracy: 0.7326785714285714
Training loss = 0.02410533524517502
step = 2, Training Accuracy: 0.7314285714285714
Training loss = 0.023818241363125187
step = 3, Training Accuracy: 0.7367857142857143
Training loss = 0.024211074214960847
step = 4, Training Accuracy: 0.7317857142857143
Training loss = 0.02417119981987136
step = 5, Training Accuracy: 0.7351785714285715
Training loss = 0.023565170222095082
step = 6, Training Accuracy: 0.7414285714285714
Training loss = 0.023645887800625393
step = 7, Training Accuracy: 0.7405357142857143
Training loss = 0.023421832237924847
step = 8, Training Accuracy: 0.7355357142857143
Training loss = 0.02365510422204222
step = 9, Training Accuracy: 0.74125
Training loss = 0.02347232227878911
step = 10, Training Accuracy: 0.7423214285714286
Training loss = 0.023734538171972547
step = 11, Training Accuracy: 0.7408928571428571
Training loss = 0.023537790035562854
step = 12, Training Accuracy: 0.74625
Training loss = 0.02360899824116911
step = 13, Training Accuracy: 0.7416071428571429
Training loss = 0.02364879247333322
step = 14, Training Accuracy: 0.7383928571428572
Training loss = 0.0229161376239998
step = 15, Training Accuracy: 0.7521428571428571
Training loss = 0.023506309730666024
step = 16, Training Accuracy: 0.7446428571428572
Training loss = 0.022979376773749078
step = 17, Training Accuracy: 0.7451785714285715
Training loss = 0.023462276166038853
step = 18, Training Accuracy: 0.7401785714285715
Training loss = 0.02357759169702019
step = 19, Training Accuracy: 0.7408928571428571
Validation Accuracy: 0.80625
parameter = [0.9937351930880042, 0.6999774952670302, 0.4506417252015659, 0.23635548700778367, 0.07663879046228922, 0.6776228457941125]
Training loss = 0.024124899958925587
step = 0, Training Accuracy: 0.73625
Validation Accuracy: 0.78375
Training loss = 0.024197098511670317
step = 1, Training Accuracy: 0.7332142857142857
Training loss = 0.023382853402623107
step = 2, Training Accuracy: 0.7428571428571429
Training loss = 0.023357075569885116
step = 3, Training Accuracy: 0.7419642857142857
Training loss = 0.02364380202123097
step = 4, Training Accuracy: 0.7375
Training loss = 0.023297690280846186
step = 5, Training Accuracy: 0.7451785714285715
Training loss = 0.023787044563463755
step = 6, Training Accuracy: 0.7391071428571429
Training loss = 0.02371780438082559
step = 7, Training Accuracy: 0.7398214285714285
Training loss = 0.023347045933561666
step = 8, Training Accuracy: 0.745
Training loss = 0.02344294883310795
step = 9, Training Accuracy: 0.7425
Training loss = 0.023080073206552438
step = 10, Training Accuracy: 0.7448214285714285
Training loss = 0.02335448975807854
step = 11, Training Accuracy: 0.7430357142857142
Training loss = 0.022981732290770326
step = 12, Training Accuracy: 0.75
Training loss = 0.022820177099534444
step = 13, Training Accuracy: 0.75
Training loss = 0.023381481383528028
step = 14, Training Accuracy: 0.7441071428571429
Training loss = 0.02284806640552623
step = 15, Training Accuracy: 0.7494642857142857
Training loss = 0.023396211032356534
step = 16, Training Accuracy: 0.7414285714285714
Training loss = 0.0231228203486119
step = 17, Training Accuracy: 0.7485714285714286
Training loss = 0.023013584496719496
step = 18, Training Accuracy: 0.7503571428571428
Training loss = 0.022852414580328124
step = 19, Training Accuracy: 0.7539285714285714
Validation Accuracy: 0.805
parameter = [0.3940613559015593, 0.6401459843393509, 0.5372383179830428, 0.7102268361227105, 0.2168612171567833, 0.8314766151043855]
Training loss = 0.02496641001531056
step = 0, Training Accuracy: 0.7248214285714286
Validation Accuracy: 0.78625
Training loss = 0.024220663074936186
step = 1, Training Accuracy: 0.7289285714285715
Training loss = 0.023584890205945286
step = 2, Training Accuracy: 0.7426785714285714
Training loss = 0.023703977944595472
step = 3, Training Accuracy: 0.7355357142857143
Training loss = 0.0233659347945026
step = 4, Training Accuracy: 0.745
Training loss = 0.02338386695832014
step = 5, Training Accuracy: 0.7439285714285714
Training loss = 0.023346425529037203
step = 6, Training Accuracy: 0.7389285714285714
Training loss = 0.02370945564338139
step = 7, Training Accuracy: 0.7414285714285714
Training loss = 0.023934533633291722
step = 8, Training Accuracy: 0.74125
Training loss = 0.023391905991094454
step = 9, Training Accuracy: 0.7435714285714285
Training loss = 0.023388309228633133
step = 10, Training Accuracy: 0.7473214285714286
Training loss = 0.023415882103145123
step = 11, Training Accuracy: 0.7394642857142857
Training loss = 0.02348500534359898
step = 12, Training Accuracy: 0.73875
Training loss = 0.02351700504443475
step = 13, Training Accuracy: 0.7414285714285714
Training loss = 0.02304475202624287
step = 14, Training Accuracy: 0.7416071428571429
Training loss = 0.023265722819737027
step = 15, Training Accuracy: 0.7432142857142857
Training loss = 0.023254803312676292
step = 16, Training Accuracy: 0.7426785714285714
Training loss = 0.02306254637560674
step = 17, Training Accuracy: 0.7475
Training loss = 0.022993623151310854
step = 18, Training Accuracy: 0.74625
Training loss = 0.023226067210946763
step = 19, Training Accuracy: 0.7408928571428571
Validation Accuracy: 0.80875
parameter = [0.13453700546169453, 0.5329841124023544, 0.36514687429424186, 0.09777823707646693, 0.1930550135372103, 0.6778001918730293]
Training loss = 0.025295656461800847
step = 0, Training Accuracy: 0.7146428571428571
Validation Accuracy: 0.75625
Training loss = 0.025051564957414355
step = 1, Training Accuracy: 0.7183928571428572
Training loss = 0.024644092151096888
step = 2, Training Accuracy: 0.7241071428571428
Training loss = 0.024140622333756516
step = 3, Training Accuracy: 0.7316071428571429
Training loss = 0.02445903188415936
step = 4, Training Accuracy: 0.7214285714285714
Training loss = 0.023869931751063892
step = 5, Training Accuracy: 0.7385714285714285
Training loss = 0.024284075695489134
step = 6, Training Accuracy: 0.7296428571428571
Training loss = 0.02363114084516253
step = 7, Training Accuracy: 0.73375
Training loss = 0.023702390816594872
step = 8, Training Accuracy: 0.7444642857142857
Training loss = 0.02416777483586754
step = 9, Training Accuracy: 0.7233928571428572
Training loss = 0.024039012672645705
step = 10, Training Accuracy: 0.7376785714285714
Training loss = 0.023852691783436707
step = 11, Training Accuracy: 0.7367857142857143
Training loss = 0.024062412386494023
step = 12, Training Accuracy: 0.7341071428571428
Training loss = 0.02392884162919862
step = 13, Training Accuracy: 0.7364285714285714
Training loss = 0.024230886484895433
step = 14, Training Accuracy: 0.7325
Training loss = 0.024052858224936895
step = 15, Training Accuracy: 0.7378571428571429
Training loss = 0.023906224982014723
step = 16, Training Accuracy: 0.7339285714285714
Training loss = 0.023910519581820285
step = 17, Training Accuracy: 0.7355357142857143
Training loss = 0.024170253702572413
step = 18, Training Accuracy: 0.73875
Training loss = 0.02378697409693684
step = 19, Training Accuracy: 0.7342857142857143
Validation Accuracy: 0.785
parameter = [0.47615826222934565, 0.6302190543188851, 0.40396096956847294, 0.9200240126763269, 0.01685162040226995, 0.9876105507362524]
Training loss = 0.03376608677208424
step = 0, Training Accuracy: 0.61625
Validation Accuracy: 0.6725
Training loss = 0.032748789404119766
step = 1, Training Accuracy: 0.6280357142857143
Training loss = 0.03236515963183982
step = 2, Training Accuracy: 0.6273214285714286
Training loss = 0.031084452931370053
step = 3, Training Accuracy: 0.6416071428571428
Training loss = 0.03131196667041097
step = 4, Training Accuracy: 0.6410714285714286
Training loss = 0.03061386940202543
step = 5, Training Accuracy: 0.6532142857142857
Training loss = 0.03074468380638531
step = 6, Training Accuracy: 0.6510714285714285
Training loss = 0.03013606883585453
step = 7, Training Accuracy: 0.6585714285714286
Training loss = 0.030519312002829143
step = 8, Training Accuracy: 0.6566071428571428
Training loss = 0.029886957822101455
step = 9, Training Accuracy: 0.6589285714285714
Training loss = 0.029511327759495803
step = 10, Training Accuracy: 0.6589285714285714
Training loss = 0.029571846973683154
step = 11, Training Accuracy: 0.6671428571428571
Training loss = 0.029414979996425766
step = 12, Training Accuracy: 0.6616071428571428
Training loss = 0.029309974083943025
step = 13, Training Accuracy: 0.6680357142857143
Training loss = 0.02898610895765679
step = 14, Training Accuracy: 0.6644642857142857
Training loss = 0.028549305056887013
step = 15, Training Accuracy: 0.6769642857142857
Training loss = 0.029274413527122567
step = 16, Training Accuracy: 0.6667857142857143
Training loss = 0.02897948475288493
step = 17, Training Accuracy: 0.6664285714285715
Training loss = 0.02886455746633666
step = 18, Training Accuracy: 0.6726785714285715
Training loss = 0.029025925105171543
step = 19, Training Accuracy: 0.6642857142857143
Validation Accuracy: 0.72375
parameter = [0.19673746145383764, 0.8149524482305617, 0.7696797658382238, 0.6972661645183106, 0.2137573979486891, 0.7423923323846316]
Training loss = 0.024220328799315863
step = 0, Training Accuracy: 0.7305357142857143
Validation Accuracy: 0.7975
Training loss = 0.02418117224637951
step = 1, Training Accuracy: 0.7335714285714285
Training loss = 0.024035813143210752
step = 2, Training Accuracy: 0.7326785714285714
Training loss = 0.024299821688660555
step = 3, Training Accuracy: 0.7267857142857143
Training loss = 0.024363926665059158
step = 4, Training Accuracy: 0.7275
Training loss = 0.024046114890703133
step = 5, Training Accuracy: 0.7369642857142857
Training loss = 0.023967946278197424
step = 6, Training Accuracy: 0.7339285714285714
Training loss = 0.023822773875934736
step = 7, Training Accuracy: 0.7396428571428572
Training loss = 0.0240762190840074
step = 8, Training Accuracy: 0.7319642857142857
Training loss = 0.023818457068077156
step = 9, Training Accuracy: 0.7455357142857143
Training loss = 0.02406435623764992
step = 10, Training Accuracy: 0.7339285714285714
Training loss = 0.02418027820863894
step = 11, Training Accuracy: 0.7298214285714286
Training loss = 0.023972623348236084
step = 12, Training Accuracy: 0.73375
Training loss = 0.024381585898143904
step = 13, Training Accuracy: 0.7244642857142857
Training loss = 0.023657100253871508
step = 14, Training Accuracy: 0.7380357142857142
Training loss = 0.023950171146009648
step = 15, Training Accuracy: 0.7426785714285714
Training loss = 0.024209573348718032
step = 16, Training Accuracy: 0.7301785714285715
Training loss = 0.02408958364278078
step = 17, Training Accuracy: 0.735
Training loss = 0.023671404431973186
step = 18, Training Accuracy: 0.7389285714285714
Training loss = 0.023873897663184575
step = 19, Training Accuracy: 0.7375
Validation Accuracy: 0.79875
parameter = [0.47465039059345376, 0.5106320358925561, 0.3021175557983387, 0.5021652319960087, 0.023487723016207065, 0.8136031524665036]
Training loss = 0.026302276120654174
step = 0, Training Accuracy: 0.7067857142857142
Validation Accuracy: 0.76125
Training loss = 0.026529861454452786
step = 1, Training Accuracy: 0.70625
Training loss = 0.026207703426480294
step = 2, Training Accuracy: 0.7019642857142857
Training loss = 0.02598531658095973
step = 3, Training Accuracy: 0.7141071428571428
Training loss = 0.026324309983423777
step = 4, Training Accuracy: 0.6942857142857143
Training loss = 0.025988877032484328
step = 5, Training Accuracy: 0.7035714285714286
Training loss = 0.025987578704953194
step = 6, Training Accuracy: 0.7091071428571428
Training loss = 0.026262107544711658
step = 7, Training Accuracy: 0.7035714285714286
Training loss = 0.026428592056035996
step = 8, Training Accuracy: 0.6998214285714286
Training loss = 0.02612198834972722
step = 9, Training Accuracy: 0.7121428571428572
Training loss = 0.026168343563164984
step = 10, Training Accuracy: 0.7132142857142857
Training loss = 0.026193580398602145
step = 11, Training Accuracy: 0.7008928571428571
Training loss = 0.025985648536256383
step = 12, Training Accuracy: 0.7055357142857143
Training loss = 0.02619610090340887
step = 13, Training Accuracy: 0.7073214285714285
Training loss = 0.02567904184971537
step = 14, Training Accuracy: 0.7101785714285714
Training loss = 0.02595889661461115
step = 15, Training Accuracy: 0.7116071428571429
Training loss = 0.025558632026825633
step = 16, Training Accuracy: 0.7189285714285715
Training loss = 0.02603196763566562
step = 17, Training Accuracy: 0.7096428571428571
Training loss = 0.026191586761602333
step = 18, Training Accuracy: 0.7101785714285714
Training loss = 0.026141744075076922
step = 19, Training Accuracy: 0.7139285714285715
Validation Accuracy: 0.76
1  	7     	0.805	0.00649519	0.79375	0.80875
parameter = [0.3940613559015593, 0.6401459843393509, 0.5372383179830428, 0.7102268361227105, 0.21686121715678333, 0.8314766151043855]
Training loss = 0.02365418285663639
step = 0, Training Accuracy: 0.7335714285714285
Validation Accuracy: 0.79625
Training loss = 0.02368342983403376
step = 1, Training Accuracy: 0.7348214285714286
Training loss = 0.02395545210157122
step = 2, Training Accuracy: 0.735
Training loss = 0.02341986236827714
step = 3, Training Accuracy: 0.7428571428571429
Training loss = 0.023591335006058214
step = 4, Training Accuracy: 0.7389285714285714
Training loss = 0.023252187365932125
step = 5, Training Accuracy: 0.7392857142857143
Training loss = 0.02335596292678799
step = 6, Training Accuracy: 0.7405357142857143
Training loss = 0.023832190797797272
step = 7, Training Accuracy: 0.7419642857142857
Training loss = 0.023379608371428082
step = 8, Training Accuracy: 0.7439285714285714
Training loss = 0.023748050246919904
step = 9, Training Accuracy: 0.7385714285714285
Training loss = 0.0231226720181959
step = 10, Training Accuracy: 0.7464285714285714
Training loss = 0.02378072143665382
step = 11, Training Accuracy: 0.7360714285714286
Training loss = 0.023954667880066803
step = 12, Training Accuracy: 0.7407142857142858
Training loss = 0.023829278291336128
step = 13, Training Accuracy: 0.7392857142857143
Training loss = 0.02370460247354848
step = 14, Training Accuracy: 0.7398214285714285
Training loss = 0.02360956089305026
step = 15, Training Accuracy: 0.7475
Training loss = 0.024240820785718306
step = 16, Training Accuracy: 0.7308928571428571
Training loss = 0.02342898804428322
step = 17, Training Accuracy: 0.7419642857142857
Training loss = 0.023294139584260326
step = 18, Training Accuracy: 0.7394642857142857
Training loss = 0.023472875974008014
step = 19, Training Accuracy: 0.7382142857142857
Validation Accuracy: 0.7975
parameter = [0.3940613559015592, 0.6401459843393509, 0.5372383179830428, 0.7102268361227105, 0.2168612171567833, 0.8314766151043855]
Training loss = 0.02351120587970529
step = 0, Training Accuracy: 0.7405357142857143
Validation Accuracy: 0.78875
Training loss = 0.02320029698844467
step = 1, Training Accuracy: 0.745
Training loss = 0.023750111450042043
step = 2, Training Accuracy: 0.7375
Training loss = 0.023883707629782813
step = 3, Training Accuracy: 0.7394642857142857
Training loss = 0.02364010479301214
step = 4, Training Accuracy: 0.7407142857142858
Training loss = 0.02344621336885861
step = 5, Training Accuracy: 0.7394642857142857
Training loss = 0.02364278859858002
step = 6, Training Accuracy: 0.7408928571428571
Training loss = 0.023574694166226047
step = 7, Training Accuracy: 0.7473214285714286
Training loss = 0.023641734767173017
step = 8, Training Accuracy: 0.7391071428571429
Training loss = 0.023813453566815173
step = 9, Training Accuracy: 0.7366071428571429
Training loss = 0.023827002367803028
step = 10, Training Accuracy: 0.7408928571428571
Training loss = 0.02366484968257802
step = 11, Training Accuracy: 0.7446428571428572
Training loss = 0.023375563150537865
step = 12, Training Accuracy: 0.7433928571428572
Training loss = 0.023634924795478584
step = 13, Training Accuracy: 0.73625
Training loss = 0.0230704490840435
step = 14, Training Accuracy: 0.7430357142857142
Training loss = 0.02378822131880692
step = 15, Training Accuracy: 0.7401785714285715
Training loss = 0.02398682413888829
step = 16, Training Accuracy: 0.7351785714285715
Training loss = 0.02394458336489541
step = 17, Training Accuracy: 0.7392857142857143
Training loss = 0.023736221838210312
step = 18, Training Accuracy: 0.7326785714285714
Training loss = 0.023554819550897395
step = 19, Training Accuracy: 0.7375
Validation Accuracy: 0.79375
parameter = [0.3035246434028148, 0.7563237534420104, 0.5229166421860715, 0.7094423506939381, 0.19213965654522408, 0.7115313486712231]
Training loss = 0.023538331048829214
step = 0, Training Accuracy: 0.74125
Validation Accuracy: 0.7975
Training loss = 0.023605042972734996
step = 1, Training Accuracy: 0.7419642857142857
Training loss = 0.023768760732242038
step = 2, Training Accuracy: 0.7333928571428572
Training loss = 0.02325886104788099
step = 3, Training Accuracy: 0.7435714285714285
Training loss = 0.023326184047119957
step = 4, Training Accuracy: 0.7385714285714285
Training loss = 0.02394415498844215
step = 5, Training Accuracy: 0.7308928571428571
Training loss = 0.023475999417049545
step = 6, Training Accuracy: 0.74
Training loss = 0.02349491680839232
step = 7, Training Accuracy: 0.7373214285714286
Training loss = 0.023947965502738953
step = 8, Training Accuracy: 0.7335714285714285
Training loss = 0.023991223743983676
step = 9, Training Accuracy: 0.7373214285714286
Training loss = 0.02352992560714483
step = 10, Training Accuracy: 0.7405357142857143
Training loss = 0.023427544491631643
step = 11, Training Accuracy: 0.7416071428571429
Training loss = 0.023660046186830316
step = 12, Training Accuracy: 0.7457142857142857
Training loss = 0.023784491518246277
step = 13, Training Accuracy: 0.7376785714285714
Training loss = 0.023359914837138993
step = 14, Training Accuracy: 0.7366071428571429
Training loss = 0.023852008900472097
step = 15, Training Accuracy: 0.7375
Training loss = 0.02381318553750004
step = 16, Training Accuracy: 0.7467857142857143
Training loss = 0.02359234155820949
step = 17, Training Accuracy: 0.7425
Training loss = 0.02401962434872985
step = 18, Training Accuracy: 0.7333928571428572
Training loss = 0.023787512465247088
step = 19, Training Accuracy: 0.7464285714285714
Validation Accuracy: 0.7975
parameter = [0.39632834178970733, 0.821667985330363, 0.4589848009281148, 0.7103616783638494, 0.15245090927554703, 0.6945850010918602]
Training loss = 0.023722197775329863
step = 0, Training Accuracy: 0.7371428571428571
Validation Accuracy: 0.7975
Training loss = 0.023590168016297475
step = 1, Training Accuracy: 0.7364285714285714
Training loss = 0.02331788647653801
step = 2, Training Accuracy: 0.7466071428571428
Training loss = 0.023714183175138064
step = 3, Training Accuracy: 0.7423214285714286
Training loss = 0.023660131224564142
step = 4, Training Accuracy: 0.7373214285714286
Training loss = 0.023516352655632157
step = 5, Training Accuracy: 0.7373214285714286
Training loss = 0.023910099762891022
step = 6, Training Accuracy: 0.7325
Training loss = 0.02328192312536495
step = 7, Training Accuracy: 0.7457142857142857
Training loss = 0.023783371075987814
step = 8, Training Accuracy: 0.7421428571428571
Training loss = 0.02334768591714757
step = 9, Training Accuracy: 0.7482142857142857
Training loss = 0.02354022391140461
step = 10, Training Accuracy: 0.7364285714285714
Training loss = 0.023796620023037705
step = 11, Training Accuracy: 0.7346428571428572
Training loss = 0.02351745351084641
step = 12, Training Accuracy: 0.7453571428571428
Training loss = 0.023450258411467074
step = 13, Training Accuracy: 0.7419642857142857
Training loss = 0.023455638640693256
step = 14, Training Accuracy: 0.7430357142857142
Training loss = 0.023871633873454163
step = 15, Training Accuracy: 0.7419642857142857
Training loss = 0.023905005848833493
step = 16, Training Accuracy: 0.7275
Training loss = 0.023660789957003932
step = 17, Training Accuracy: 0.7378571428571429
Training loss = 0.023525997272559575
step = 18, Training Accuracy: 0.7416071428571429
Training loss = 0.0241075379720756
step = 19, Training Accuracy: 0.73
Validation Accuracy: 0.7925
parameter = [0.3940613559015593, 0.6401459843393509, 0.5372383179830428, 0.7102268361227105, 0.2168612171567833, 0.8314766151043855]
Training loss = 0.023237090946308204
step = 0, Training Accuracy: 0.7432142857142857
Validation Accuracy: 0.79875
Training loss = 0.023673521099346024
step = 1, Training Accuracy: 0.7439285714285714
Training loss = 0.02364250968077353
step = 2, Training Accuracy: 0.7366071428571429
Training loss = 0.023687842105116163
step = 3, Training Accuracy: 0.7416071428571429
Training loss = 0.023495304062962533
step = 4, Training Accuracy: 0.7389285714285714
Training loss = 0.023903143656040942
step = 5, Training Accuracy: 0.7375
Training loss = 0.023494745391820157
step = 6, Training Accuracy: 0.74125
Training loss = 0.02340051491345678
step = 7, Training Accuracy: 0.7491071428571429
Training loss = 0.023589098661073615
step = 8, Training Accuracy: 0.7385714285714285
Training loss = 0.023579209010515894
step = 9, Training Accuracy: 0.7385714285714285
Training loss = 0.023420023008116655
step = 10, Training Accuracy: 0.74125
Training loss = 0.023414223116955585
step = 11, Training Accuracy: 0.7366071428571429
Training loss = 0.023843841733677047
step = 12, Training Accuracy: 0.7425
Training loss = 0.02339018587555204
step = 13, Training Accuracy: 0.7453571428571428
Training loss = 0.02338055610124554
step = 14, Training Accuracy: 0.7373214285714286
Training loss = 0.0233341829638396
step = 15, Training Accuracy: 0.7455357142857143
Training loss = 0.02357851125832115
step = 16, Training Accuracy: 0.7417857142857143
Training loss = 0.023746649074767315
step = 17, Training Accuracy: 0.7392857142857143
Training loss = 0.023647703230381012
step = 18, Training Accuracy: 0.74125
Training loss = 0.023664898723363876
step = 19, Training Accuracy: 0.7326785714285714
Validation Accuracy: 0.78875
parameter = [0.3940613559015593, 0.6401459843393509, 0.5372383179830428, 0.7102268361227104, 0.2168612171567833, 0.8314766151043855]
Training loss = 0.023779111238462585
step = 0, Training Accuracy: 0.7408928571428571
Validation Accuracy: 0.795
Training loss = 0.023790928428726536
step = 1, Training Accuracy: 0.7380357142857142
Training loss = 0.023521066462355
step = 2, Training Accuracy: 0.745
Training loss = 0.023374119342437813
step = 3, Training Accuracy: 0.7346428571428572
Training loss = 0.023781976981886794
step = 4, Training Accuracy: 0.7360714285714286
Training loss = 0.023595204880195005
step = 5, Training Accuracy: 0.7383928571428572
Training loss = 0.02319785606648241
step = 6, Training Accuracy: 0.7428571428571429
Training loss = 0.02362083881561245
step = 7, Training Accuracy: 0.7385714285714285
Training loss = 0.023566066989941258
step = 8, Training Accuracy: 0.7439285714285714
Training loss = 0.023887351139315536
step = 9, Training Accuracy: 0.7441071428571429
Training loss = 0.023300198529447827
step = 10, Training Accuracy: 0.7403571428571428
Training loss = 0.023550801702908106
step = 11, Training Accuracy: 0.7371428571428571
Training loss = 0.02357263779533761
step = 12, Training Accuracy: 0.7426785714285714
Training loss = 0.023230427519551344
step = 13, Training Accuracy: 0.7407142857142858
Training loss = 0.024068128801882267
step = 14, Training Accuracy: 0.7319642857142857
Training loss = 0.023809923231601714
step = 15, Training Accuracy: 0.7423214285714286
Training loss = 0.02385885553168399
step = 16, Training Accuracy: 0.7401785714285715
Training loss = 0.023588011573467935
step = 17, Training Accuracy: 0.7367857142857143
Training loss = 0.02382666353136301
step = 18, Training Accuracy: 0.7369642857142857
Training loss = 0.02343500345413174
step = 19, Training Accuracy: 0.745
Validation Accuracy: 0.79625
parameter = [0.3940613559015593, 0.6401459843393509, 0.5372383179830428, 0.7102268361227105, 0.2168612171567833, 0.8314766151043855]
Training loss = 0.023370196553213256
step = 0, Training Accuracy: 0.7425
Validation Accuracy: 0.8
Training loss = 0.023817947405789578
step = 1, Training Accuracy: 0.7376785714285714
Training loss = 0.024499672928026746
step = 2, Training Accuracy: 0.73125
Training loss = 0.02397428280540875
step = 3, Training Accuracy: 0.7426785714285714
Training loss = 0.023781244637710707
step = 4, Training Accuracy: 0.7398214285714285
Training loss = 0.02321374223168407
step = 5, Training Accuracy: 0.7401785714285715
Training loss = 0.023557414769061973
step = 6, Training Accuracy: 0.7389285714285714
Training loss = 0.023225608090204852
step = 7, Training Accuracy: 0.7441071428571429
Training loss = 0.023896312404956137
step = 8, Training Accuracy: 0.7323214285714286
Training loss = 0.023631284939391272
step = 9, Training Accuracy: 0.7383928571428572
Training loss = 0.023794597424566747
step = 10, Training Accuracy: 0.73875
Training loss = 0.023423280918172428
step = 11, Training Accuracy: 0.7407142857142858
Training loss = 0.023723137293543136
step = 12, Training Accuracy: 0.7448214285714285
Training loss = 0.023801230362483432
step = 13, Training Accuracy: 0.7369642857142857
Training loss = 0.023285511450043747
step = 14, Training Accuracy: 0.7451785714285715
Training loss = 0.023647071894790445
step = 15, Training Accuracy: 0.7433928571428572
Training loss = 0.023269414507916995
step = 16, Training Accuracy: 0.7428571428571429
Training loss = 0.024207951171057566
step = 17, Training Accuracy: 0.7326785714285714
Training loss = 0.023562242654817444
step = 18, Training Accuracy: 0.7355357142857143
Training loss = 0.023844983290348735
step = 19, Training Accuracy: 0.7339285714285714
Validation Accuracy: 0.79125
2  	7     	0.801875	0.00709864	0.7925 	0.80875
parameter = [0.3940613559015593, 0.6401459843393509, 0.5372383179830428, 0.7102268361227106, 0.2168612171567833, 0.8314766151043855]
Training loss = 0.02356666699051857
step = 0, Training Accuracy: 0.7428571428571429
Validation Accuracy: 0.8
