pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.046244535048802694
step = 0, Training Accuracy: 0.3433333333333333
Validation Accuracy: 0.33
Training loss = 0.03873733619848887
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.03458924869696299
step = 2, Training Accuracy: 0.5
Training loss = 0.03388761758804321
step = 3, Training Accuracy: 0.5133333333333333
Training loss = 0.031067036986351014
step = 4, Training Accuracy: 0.5666666666666667
Training loss = 0.027291130324204764
step = 5, Training Accuracy: 0.5833333333333334
Validation Accuracy: 0.5325
Training loss = 0.0227157195409139
step = 6, Training Accuracy: 0.7133333333333334
Training loss = 0.022690369486808776
step = 7, Training Accuracy: 0.6933333333333334
Training loss = 0.024703442454338073
step = 8, Training Accuracy: 0.67
Training loss = 0.020865789353847503
step = 9, Training Accuracy: 0.7166666666666667
Training loss = 0.018671510418256123
step = 10, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.5375
Training loss = 0.016996732652187346
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.016899443864822387
step = 12, Training Accuracy: 0.82
Training loss = 0.020785725216070812
step = 13, Training Accuracy: 0.78
Training loss = 0.015667955080668133
step = 14, Training Accuracy: 0.82
Validation Accuracy: 0.5
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03527201573053996
step = 0, Training Accuracy: 0.5833333333333334
Validation Accuracy: 0.51125
Training loss = 0.029199954072634378
step = 1, Training Accuracy: 0.56
Training loss = 0.02448150287071864
step = 2, Training Accuracy: 0.66
Training loss = 0.023537199298540753
step = 3, Training Accuracy: 0.7033333333333334
Training loss = 0.023290639718373616
step = 4, Training Accuracy: 0.68
Training loss = 0.02041352500518163
step = 5, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.58125
Training loss = 0.019729562302430472
step = 6, Training Accuracy: 0.76
Training loss = 0.016958495279153187
step = 7, Training Accuracy: 0.8233333333333334
Training loss = 0.014315916697184244
step = 8, Training Accuracy: 0.8
Training loss = 0.015934593876202902
step = 9, Training Accuracy: 0.8166666666666667
Training loss = 0.01431222915649414
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.46875
Training loss = 0.020622775157292685
step = 11, Training Accuracy: 0.74
Training loss = 0.013876148263613382
step = 12, Training Accuracy: 0.8466666666666667
Training loss = 0.010845770736535391
step = 13, Training Accuracy: 0.8766666666666667
Training loss = 0.008476732522249222
step = 14, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.58875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.041864500244458515
step = 0, Training Accuracy: 0.5433333333333333
Validation Accuracy: 0.5625
Training loss = 0.02581902503967285
step = 1, Training Accuracy: 0.62
Training loss = 0.022965712149937947
step = 2, Training Accuracy: 0.6766666666666666
Training loss = 0.023341036438941955
step = 3, Training Accuracy: 0.7166666666666667
Training loss = 0.01959811250368754
step = 4, Training Accuracy: 0.7433333333333333
Training loss = 0.01973700354496638
step = 5, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.60375
Training loss = 0.014340872764587403
step = 6, Training Accuracy: 0.8166666666666667
Training loss = 0.012609120508035023
step = 7, Training Accuracy: 0.86
Training loss = 0.009752796789010365
step = 8, Training Accuracy: 0.89
Training loss = 0.007761601035793622
step = 9, Training Accuracy: 0.9266666666666666
Training loss = 0.006524947633345921
step = 10, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.5425
Training loss = 0.003769211918115616
step = 11, Training Accuracy: 0.97
Training loss = 0.0025306975344816843
step = 12, Training Accuracy: 0.9866666666666667
Training loss = 0.003655179925262928
step = 13, Training Accuracy: 0.97
Training loss = 0.0027287199720740316
step = 14, Training Accuracy: 0.9733333333333334
Validation Accuracy: 0.54
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04662792126337687
step = 0, Training Accuracy: 0.6333333333333333
Validation Accuracy: 0.5075
Training loss = 0.028512412309646608
step = 1, Training Accuracy: 0.6766666666666666
Training loss = 0.022695935666561126
step = 2, Training Accuracy: 0.72
Training loss = 0.020217511355876922
step = 3, Training Accuracy: 0.7333333333333333
Training loss = 0.017502557237943014
step = 4, Training Accuracy: 0.81
Training loss = 0.013176063199838002
step = 5, Training Accuracy: 0.87
Validation Accuracy: 0.615
Training loss = 0.011319057643413543
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.00860270435611407
step = 7, Training Accuracy: 0.9266666666666666
Training loss = 0.006422674680749575
step = 8, Training Accuracy: 0.94
Training loss = 0.004522914290428162
step = 9, Training Accuracy: 0.9533333333333334
Training loss = 0.003735959579547246
step = 10, Training Accuracy: 0.9733333333333334
Validation Accuracy: 0.61625
Training loss = 0.002784729575117429
step = 11, Training Accuracy: 0.98
Training loss = 0.0037698819860816
step = 12, Training Accuracy: 0.9766666666666667
Training loss = 0.0025952275966604553
step = 13, Training Accuracy: 0.98
Training loss = 0.0014611043967306613
step = 14, Training Accuracy: 0.99
Validation Accuracy: 0.53875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04626710911591848
step = 0, Training Accuracy: 0.66
Validation Accuracy: 0.585
Training loss = 0.02069842576980591
step = 1, Training Accuracy: 0.7633333333333333
Training loss = 0.016152058243751526
step = 2, Training Accuracy: 0.83
Training loss = 0.009278290073076885
step = 3, Training Accuracy: 0.9133333333333333
Training loss = 0.006196410345534483
step = 4, Training Accuracy: 0.95
Training loss = 0.00304566482702891
step = 5, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.61375
Training loss = 0.0021603854559361937
step = 6, Training Accuracy: 0.9833333333333333
Training loss = 0.00122815294812123
step = 7, Training Accuracy: 0.9933333333333333
Training loss = 0.0009693413476149241
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.000985093464454015
step = 9, Training Accuracy: 0.99
Training loss = 0.0009080041944980621
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.585
Training loss = 0.000950749988357226
step = 11, Training Accuracy: 0.9933333333333333
Training loss = 0.0003919656745468577
step = 12, Training Accuracy: 1.0
Training loss = 0.0005184145426998536
step = 13, Training Accuracy: 0.9966666666666667
Training loss = 0.0007075953856110573
step = 14, Training Accuracy: 0.99
Validation Accuracy: 0.59625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04975181758403778
step = 0, Training Accuracy: 0.62
Validation Accuracy: 0.3625
Training loss = 0.02363051732381185
step = 1, Training Accuracy: 0.6933333333333334
Training loss = 0.01871873199939728
step = 2, Training Accuracy: 0.7766666666666666
Training loss = 0.016030177573362985
step = 3, Training Accuracy: 0.8066666666666666
Training loss = 0.010942240407069525
step = 4, Training Accuracy: 0.8566666666666667
Training loss = 0.008198378384113312
step = 5, Training Accuracy: 0.91
Validation Accuracy: 0.63625
Training loss = 0.0045250421638290085
step = 6, Training Accuracy: 0.9633333333333334
Training loss = 0.003327372558414936
step = 7, Training Accuracy: 0.9833333333333333
Training loss = 0.0024941896523038545
step = 8, Training Accuracy: 0.99
Training loss = 0.0026668593287467956
step = 9, Training Accuracy: 0.97
Training loss = 0.001788232500354449
step = 10, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.5825
Training loss = 0.0018439425652225813
step = 11, Training Accuracy: 0.9833333333333333
Training loss = 0.0011252819498380024
step = 12, Training Accuracy: 0.9933333333333333
Training loss = 0.0006772205400435875
step = 13, Training Accuracy: 0.9966666666666667
Training loss = 0.0005580232129432261
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.60125
gen	nevals	Avg     	Std      	Min	Max    
0  	6     	0.560833	0.0371698	0.5	0.60125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03504323005676269
step = 0, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.55
Training loss = 0.01998323028286298
step = 1, Training Accuracy: 0.7833333333333333
Training loss = 0.01461213340361913
step = 2, Training Accuracy: 0.84
Training loss = 0.009942396357655526
step = 3, Training Accuracy: 0.8733333333333333
Training loss = 0.005956714500983556
step = 4, Training Accuracy: 0.9333333333333333
Training loss = 0.0032323598489165306
step = 5, Training Accuracy: 0.98
Validation Accuracy: 0.66125
Training loss = 0.0018243038343886534
step = 6, Training Accuracy: 0.9866666666666667
Training loss = 0.0009593510751922925
step = 7, Training Accuracy: 0.9933333333333333
Training loss = 0.0006037680339068174
step = 8, Training Accuracy: 1.0
Training loss = 0.0004529232904314995
step = 9, Training Accuracy: 1.0
Training loss = 0.0006312970165163279
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.64625
Training loss = 0.0003193935193121433
step = 11, Training Accuracy: 1.0
Training loss = 0.00031899362492064637
step = 12, Training Accuracy: 1.0
Training loss = 0.00012776729146329066
step = 13, Training Accuracy: 1.0
Training loss = 0.0002137858544786771
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.63
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03981652537981669
step = 0, Training Accuracy: 0.6833333333333333
Validation Accuracy: 0.49125
Training loss = 0.02165383577346802
step = 1, Training Accuracy: 0.75
Training loss = 0.016636540790398915
step = 2, Training Accuracy: 0.8066666666666666
Training loss = 0.012370565434296927
step = 3, Training Accuracy: 0.8466666666666667
Training loss = 0.008338144421577454
step = 4, Training Accuracy: 0.9233333333333333
Training loss = 0.004436643682420254
step = 5, Training Accuracy: 0.9666666666666667
Validation Accuracy: 0.6225
Training loss = 0.0031616203859448433
step = 6, Training Accuracy: 0.97
Training loss = 0.0017585901791850726
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.0016917650277415912
step = 8, Training Accuracy: 0.99
Training loss = 0.001255147981767853
step = 9, Training Accuracy: 0.9866666666666667
Training loss = 0.0009159870135287444
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.60125
Training loss = 0.0010150104761123657
step = 11, Training Accuracy: 0.9933333333333333
Training loss = 0.0007834760514864078
step = 12, Training Accuracy: 0.9933333333333333
Training loss = 0.0007148775706688563
step = 13, Training Accuracy: 0.9966666666666667
Training loss = 0.00047332734490434326
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.63375
1  	2     	0.610625	0.0151683	0.59625	0.63375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.039453654289245604
step = 0, Training Accuracy: 0.6633333333333333
Validation Accuracy: 0.61625
Training loss = 0.01738787829875946
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.014048708602786064
step = 2, Training Accuracy: 0.8366666666666667
Training loss = 0.009732074936230977
step = 3, Training Accuracy: 0.9066666666666666
Training loss = 0.006558630267779033
step = 4, Training Accuracy: 0.9166666666666666
Training loss = 0.0031065369521578153
step = 5, Training Accuracy: 0.99
Validation Accuracy: 0.66125
Training loss = 0.001766020357608795
step = 6, Training Accuracy: 0.99
Training loss = 0.000930910762399435
step = 7, Training Accuracy: 0.9933333333333333
Training loss = 0.0009081055844823519
step = 8, Training Accuracy: 0.9933333333333333
Training loss = 0.0004118907575805982
step = 9, Training Accuracy: 1.0
Training loss = 0.000531706636150678
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.665
Training loss = 0.0006091792074342569
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 0.00030371690013756354
step = 12, Training Accuracy: 0.9966666666666667
Training loss = 0.00037698787947495777
step = 13, Training Accuracy: 1.0
Training loss = 0.00033012583230932553
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.65125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0430669230222702
step = 0, Training Accuracy: 0.6766666666666666
Validation Accuracy: 0.5
Training loss = 0.017403897543748218
step = 1, Training Accuracy: 0.7866666666666666
Training loss = 0.012699526101350785
step = 2, Training Accuracy: 0.84
Training loss = 0.009425484041372934
step = 3, Training Accuracy: 0.9
Training loss = 0.0053806707883874575
step = 4, Training Accuracy: 0.9466666666666667
Training loss = 0.004123562922080358
step = 5, Training Accuracy: 0.9733333333333334
Validation Accuracy: 0.64875
Training loss = 0.0023723699152469633
step = 6, Training Accuracy: 0.98
Training loss = 0.001270023596783479
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.000932228999833266
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.0006585559574887156
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.0004464833810925484
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.635
Training loss = 0.00044495597947388885
step = 11, Training Accuracy: 1.0
Training loss = 0.00026063775449680784
step = 12, Training Accuracy: 1.0
Training loss = 0.00028520503391822176
step = 13, Training Accuracy: 1.0
Training loss = 0.0001981584851940473
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.63375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.038377809524536136
step = 0, Training Accuracy: 0.7266666666666667
Validation Accuracy: 0.52375
Training loss = 0.017409043113390605
step = 1, Training Accuracy: 0.8066666666666666
Training loss = 0.01234462320804596
step = 2, Training Accuracy: 0.8533333333333334
Training loss = 0.008947745909293493
step = 3, Training Accuracy: 0.9166666666666666
Training loss = 0.005399520148833593
step = 4, Training Accuracy: 0.9533333333333334
Training loss = 0.001848114983489116
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6425
Training loss = 0.0011780190033217272
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 0.001200668973227342
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.0005615559034049511
step = 8, Training Accuracy: 1.0
Training loss = 0.0005787816767891249
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.0003351328056305647
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.61875
Training loss = 0.00030721501136819524
step = 11, Training Accuracy: 1.0
Training loss = 0.00017481389145056406
step = 12, Training Accuracy: 1.0
Training loss = 0.00018531038891524078
step = 13, Training Accuracy: 1.0
Training loss = 0.00021805391957362494
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6475
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03587134952346484
step = 0, Training Accuracy: 0.7166666666666667
Validation Accuracy: 0.575
Training loss = 0.013111433188120525
step = 1, Training Accuracy: 0.87
Training loss = 0.008285834540923437
step = 2, Training Accuracy: 0.9233333333333333
Training loss = 0.005664787168304125
step = 3, Training Accuracy: 0.97
Training loss = 0.002975237083931764
step = 4, Training Accuracy: 0.98
Training loss = 0.0029476181417703627
step = 5, Training Accuracy: 0.98
Validation Accuracy: 0.67125
Training loss = 0.0014264847834904988
step = 6, Training Accuracy: 0.99
Training loss = 0.0011823117174208165
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.0004828698622683684
step = 8, Training Accuracy: 1.0
Training loss = 0.00036589721217751504
step = 9, Training Accuracy: 1.0
Training loss = 0.0004883801937103271
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.64625
Training loss = 0.00030605471382538475
step = 11, Training Accuracy: 1.0
Training loss = 0.000209257237923642
step = 12, Training Accuracy: 1.0
Training loss = 0.0002239558690538009
step = 13, Training Accuracy: 1.0
Training loss = 0.000499755988518397
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.66875
2  	4     	0.639375	0.0207634	0.60125	0.66875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03286264657974243
step = 0, Training Accuracy: 0.7033333333333334
Validation Accuracy: 0.59875
Training loss = 0.016827039817969004
step = 1, Training Accuracy: 0.81
Training loss = 0.009886193523804347
step = 2, Training Accuracy: 0.9166666666666666
Training loss = 0.005973775548239549
step = 3, Training Accuracy: 0.9666666666666667
Training loss = 0.0019249006640166045
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0013090726857384045
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.65375
Training loss = 0.0005390491398672263
step = 6, Training Accuracy: 1.0
Training loss = 0.0004561015218496323
step = 7, Training Accuracy: 1.0
Training loss = 0.0003858945146203041
step = 8, Training Accuracy: 1.0
Training loss = 0.00029427329466367763
step = 9, Training Accuracy: 1.0
Training loss = 0.0002612886531278491
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67
Training loss = 0.00013718030919941763
step = 11, Training Accuracy: 1.0
Training loss = 0.00016960525264342625
step = 12, Training Accuracy: 1.0
Training loss = 0.00019283208608006437
step = 13, Training Accuracy: 1.0
Training loss = 0.00014811240951530634
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.665
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02964424471060435
step = 0, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.66625
Training loss = 0.013331970125436783
step = 1, Training Accuracy: 0.9
Training loss = 0.008986781984567642
step = 2, Training Accuracy: 0.8966666666666666
Training loss = 0.004185041598975659
step = 3, Training Accuracy: 0.9866666666666667
Training loss = 0.0018531067793567976
step = 4, Training Accuracy: 0.9866666666666667
Training loss = 0.0012203692613790432
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6675
Training loss = 0.00046907453487316766
step = 6, Training Accuracy: 1.0
Training loss = 0.0004414231912232935
step = 7, Training Accuracy: 1.0
Training loss = 0.000231420331595776
step = 8, Training Accuracy: 1.0
Training loss = 0.0002798263852794965
step = 9, Training Accuracy: 1.0
Training loss = 0.0002930748245368401
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.665
Training loss = 0.00015348727504412333
step = 11, Training Accuracy: 1.0
Training loss = 0.00021534824511036278
step = 12, Training Accuracy: 1.0
Training loss = 0.000836176797747612
step = 13, Training Accuracy: 0.9933333333333333
Training loss = 0.0002141903837521871
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.655
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03337105393409729
step = 0, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.5575
Training loss = 0.014965387582778931
step = 1, Training Accuracy: 0.85
Training loss = 0.01000170479218165
step = 2, Training Accuracy: 0.9
Training loss = 0.005064452315370242
step = 3, Training Accuracy: 0.9466666666666667
Training loss = 0.0029604100063443184
step = 4, Training Accuracy: 0.99
Training loss = 0.0012901738844811916
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.69125
Training loss = 0.0007759850099682808
step = 6, Training Accuracy: 1.0
Training loss = 0.0007042145356535911
step = 7, Training Accuracy: 1.0
Training loss = 0.0003884739490846793
step = 8, Training Accuracy: 1.0
Training loss = 0.0004609505304445823
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.00018518978419403235
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6875
Training loss = 0.00019007069369157155
step = 11, Training Accuracy: 1.0
Training loss = 0.00014788548927754163
step = 12, Training Accuracy: 1.0
Training loss = 0.00025306463552018005
step = 13, Training Accuracy: 1.0
Training loss = 0.00018034729718541105
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03186720569928487
step = 0, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.66875
Training loss = 0.009207532157500585
step = 1, Training Accuracy: 0.9066666666666666
Training loss = 0.00475135458012422
step = 2, Training Accuracy: 0.97
Training loss = 0.002764143676807483
step = 3, Training Accuracy: 0.9833333333333333
Training loss = 0.0012896566155056158
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0010319176192084948
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67375
Training loss = 0.0012553125744064648
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.0007657013794717689
step = 7, Training Accuracy: 0.99
Training loss = 0.0006477152835577726
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.0008550235132376353
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.00023010000974560779
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 0.0005832868752380212
step = 11, Training Accuracy: 0.9933333333333333
Training loss = 0.0004914721287786961
step = 12, Training Accuracy: 1.0
Training loss = 0.0004905673954635858
step = 13, Training Accuracy: 0.9933333333333333
Training loss = 0.00017635791252056758
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.675
3  	4     	0.665   	0.0108733	0.6475 	0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03360475540161133
step = 0, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.61
Training loss = 0.011045317326982816
step = 1, Training Accuracy: 0.87
Training loss = 0.007701973666747411
step = 2, Training Accuracy: 0.95
Training loss = 0.003508324089149634
step = 3, Training Accuracy: 0.9766666666666667
Training loss = 0.0018391242312888305
step = 4, Training Accuracy: 0.99
Training loss = 0.0010552503215149045
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6675
Training loss = 0.00041662990193193155
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.00040101713190476097
step = 7, Training Accuracy: 1.0
Training loss = 0.0002622179811199506
step = 8, Training Accuracy: 1.0
Training loss = 0.00018668916542083025
step = 9, Training Accuracy: 1.0
Training loss = 0.00016723283488924304
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.00012063949485309422
step = 11, Training Accuracy: 1.0
Training loss = 0.00010572829206163684
step = 12, Training Accuracy: 1.0
Training loss = 0.00020609195033709208
step = 13, Training Accuracy: 1.0
Training loss = 9.495094418525696e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03574047744274139
step = 0, Training Accuracy: 0.71
Validation Accuracy: 0.52375
Training loss = 0.013700101574261983
step = 1, Training Accuracy: 0.8466666666666667
Training loss = 0.008120078643163045
step = 2, Training Accuracy: 0.9433333333333334
Training loss = 0.00569902241230011
step = 3, Training Accuracy: 0.9566666666666667
Training loss = 0.002395470328629017
step = 4, Training Accuracy: 0.99
Training loss = 0.001821620042125384
step = 5, Training Accuracy: 0.99
Validation Accuracy: 0.68375
Training loss = 0.0009823370228211085
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 0.0006877942212546865
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.0008893264861156543
step = 8, Training Accuracy: 0.99
Training loss = 0.0003852031333371997
step = 9, Training Accuracy: 1.0
Training loss = 0.00023152398876845836
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6575
Training loss = 0.00020932328421622515
step = 11, Training Accuracy: 1.0
Training loss = 0.00020752858370542526
step = 12, Training Accuracy: 1.0
Training loss = 0.00027482991417249045
step = 13, Training Accuracy: 1.0
Training loss = 0.00013009371032239868
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02697776640454928
step = 0, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.65
Training loss = 0.008072725733121237
step = 1, Training Accuracy: 0.91
Training loss = 0.0040474586312969525
step = 2, Training Accuracy: 0.9633333333333334
Training loss = 0.0017038590833544731
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0010377677778402965
step = 4, Training Accuracy: 1.0
Training loss = 0.0005045079486444593
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.0003241874192220469
step = 6, Training Accuracy: 1.0
Training loss = 0.00025040308168778816
step = 7, Training Accuracy: 1.0
Training loss = 0.0002455728454515338
step = 8, Training Accuracy: 1.0
Training loss = 0.00011258367875901361
step = 9, Training Accuracy: 1.0
Training loss = 0.00019500654578829806
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 0.0001259225692289571
step = 11, Training Accuracy: 1.0
Training loss = 0.00015256747603416442
step = 12, Training Accuracy: 1.0
Training loss = 0.00013046137988567352
step = 13, Training Accuracy: 1.0
Training loss = 0.0001942544151097536
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67875
4  	3     	0.674375	0.00419263	0.66875	0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.037603076299031576
step = 0, Training Accuracy: 0.7433333333333333
Validation Accuracy: 0.56
Training loss = 0.015835576951503755
step = 1, Training Accuracy: 0.83
Training loss = 0.008866642862558364
step = 2, Training Accuracy: 0.93
Training loss = 0.005218345398704211
step = 3, Training Accuracy: 0.9733333333333334
Training loss = 0.003422476090490818
step = 4, Training Accuracy: 0.9733333333333334
Training loss = 0.0034027876580754917
step = 5, Training Accuracy: 0.99
Validation Accuracy: 0.66875
Training loss = 0.0014814684291680653
step = 6, Training Accuracy: 0.99
Training loss = 0.0010138405673205853
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.0006788829372574885
step = 8, Training Accuracy: 0.9933333333333333
Training loss = 0.0004747660209735235
step = 9, Training Accuracy: 1.0
Training loss = 0.000338081947217385
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 0.000165748397509257
step = 11, Training Accuracy: 1.0
Training loss = 0.00022452338288227717
step = 12, Training Accuracy: 1.0
Training loss = 0.00010375132939467827
step = 13, Training Accuracy: 1.0
Training loss = 9.649763504664103e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.029444162448247272
step = 0, Training Accuracy: 0.74
Validation Accuracy: 0.54125
Training loss = 0.012829152842362721
step = 1, Training Accuracy: 0.87
Training loss = 0.006238022285203139
step = 2, Training Accuracy: 0.95
Training loss = 0.003277077948053678
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0012668524123728275
step = 4, Training Accuracy: 1.0
Training loss = 0.0008287949301302433
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68625
Training loss = 0.00046701294835656883
step = 6, Training Accuracy: 1.0
Training loss = 0.0006717517537375292
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.00033542694756761194
step = 8, Training Accuracy: 1.0
Training loss = 0.0003714784731467565
step = 9, Training Accuracy: 1.0
Training loss = 0.00023737455407778422
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.665
Training loss = 0.0002028106317933028
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 0.0002575687815745672
step = 12, Training Accuracy: 1.0
Training loss = 0.0003017873751620452
step = 13, Training Accuracy: 0.9966666666666667
Training loss = 9.848800798257192e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.030023636519908904
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.64
Training loss = 0.011021554470062256
step = 1, Training Accuracy: 0.91
Training loss = 0.006434629013140996
step = 2, Training Accuracy: 0.9333333333333333
Training loss = 0.0035803332428137463
step = 3, Training Accuracy: 0.97
Training loss = 0.003265031122912963
step = 4, Training Accuracy: 0.9833333333333333
Training loss = 0.0009902885121603807
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67
Training loss = 0.0015218278641502062
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 0.0006000149374206861
step = 7, Training Accuracy: 1.0
Training loss = 0.00037131405901163816
step = 8, Training Accuracy: 1.0
Training loss = 0.00032311860471963884
step = 9, Training Accuracy: 1.0
Training loss = 0.00020871486825247605
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6625
Training loss = 0.0002538315330942472
step = 11, Training Accuracy: 1.0
Training loss = 0.00011304563920324047
step = 12, Training Accuracy: 1.0
Training loss = 0.00014188968886931738
step = 13, Training Accuracy: 1.0
Training loss = 0.00026387828091780345
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6675
5  	3     	0.673542	0.00502165	0.66625	0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02493243306875229
step = 0, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.66375
Training loss = 0.01019531970222791
step = 1, Training Accuracy: 0.9
Training loss = 0.005217678224047025
step = 2, Training Accuracy: 0.9433333333333334
Training loss = 0.002498005380233129
step = 3, Training Accuracy: 0.9866666666666667
Training loss = 0.0014227999995152156
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0011867877220114072
step = 5, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.6875
Training loss = 0.0006842403983076413
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.00025934057543054224
step = 7, Training Accuracy: 1.0
Training loss = 0.0002450212991485993
step = 8, Training Accuracy: 1.0
Training loss = 0.00022145096523066361
step = 9, Training Accuracy: 1.0
Training loss = 0.00028803362200657525
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 0.00013449644902721047
step = 11, Training Accuracy: 1.0
Training loss = 0.0005412515749533971
step = 12, Training Accuracy: 0.9966666666666667
Training loss = 0.00012157198449131102
step = 13, Training Accuracy: 1.0
Training loss = 0.0001067964150570333
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02992535173892975
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.62875
Training loss = 0.011101173907518387
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.005860597963134448
step = 2, Training Accuracy: 0.9366666666666666
Training loss = 0.002754189632833004
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0023336058482527735
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0007936344482004642
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.0023380396515130996
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 0.0009737408036986987
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.0007530376315116882
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.00055995079378287
step = 9, Training Accuracy: 1.0
Training loss = 0.0003291547220821182
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.64875
Training loss = 0.0005749821519323936
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 0.00020559442540009817
step = 12, Training Accuracy: 1.0
Training loss = 0.00026668199648459753
step = 13, Training Accuracy: 1.0
Training loss = 0.0001565630982319514
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.65
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.029679763515790304
step = 0, Training Accuracy: 0.7333333333333333
Validation Accuracy: 0.69125
Training loss = 0.010490585962931315
step = 1, Training Accuracy: 0.8966666666666666
Training loss = 0.005070869140326977
step = 2, Training Accuracy: 0.9433333333333334
Training loss = 0.0028397464628020924
step = 3, Training Accuracy: 0.99
Training loss = 0.0010732989199459552
step = 4, Training Accuracy: 1.0
Training loss = 0.0008425373459855715
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.65875
Training loss = 0.0007430590797836582
step = 6, Training Accuracy: 1.0
Training loss = 0.00027892063915108643
step = 7, Training Accuracy: 1.0
Training loss = 0.00023524840672810873
step = 8, Training Accuracy: 1.0
Training loss = 0.00030058478315671283
step = 9, Training Accuracy: 1.0
Training loss = 0.0002053253600994746
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66625
Training loss = 0.0001160688364567856
step = 11, Training Accuracy: 1.0
Training loss = 0.00011766910941029589
step = 12, Training Accuracy: 1.0
Training loss = 0.00013003345190857848
step = 13, Training Accuracy: 1.0
Training loss = 0.00022285775126268465
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.023707809348901113
step = 0, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.655
Training loss = 0.00641891082127889
step = 1, Training Accuracy: 0.9333333333333333
Training loss = 0.0041891901443401975
step = 2, Training Accuracy: 0.9766666666666667
Training loss = 0.0016074184887111187
step = 3, Training Accuracy: 0.99
Training loss = 0.001427547112107277
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0006664779409766197
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67375
Training loss = 0.0007291645680864652
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 0.00046949319541454313
step = 7, Training Accuracy: 1.0
Training loss = 0.0002834714844357222
step = 8, Training Accuracy: 1.0
Training loss = 0.00038214740188171465
step = 9, Training Accuracy: 1.0
Training loss = 0.00018670900724828242
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 0.00015103002816128233
step = 11, Training Accuracy: 1.0
Training loss = 0.00013158763448397319
step = 12, Training Accuracy: 1.0
Training loss = 0.00012407438519100347
step = 13, Training Accuracy: 1.0
Training loss = 0.00010050614674886068
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.024874721964200337
step = 0, Training Accuracy: 0.8
Validation Accuracy: 0.64
Training loss = 0.00803023137152195
step = 1, Training Accuracy: 0.93
Training loss = 0.004013003557920456
step = 2, Training Accuracy: 0.97
Training loss = 0.001868081254263719
step = 3, Training Accuracy: 0.99
Training loss = 0.0012610009436806043
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0015886563683549563
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.64125
Training loss = 0.0006291949337658783
step = 6, Training Accuracy: 1.0
Training loss = 0.0002578772682075699
step = 7, Training Accuracy: 1.0
Training loss = 0.00032302509993314743
step = 8, Training Accuracy: 1.0
Training loss = 0.0002754581967989604
step = 9, Training Accuracy: 1.0
Training loss = 0.0002659304253757
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6475
Training loss = 0.00012394619484742484
step = 11, Training Accuracy: 1.0
Training loss = 0.00015297455868373315
step = 12, Training Accuracy: 1.0
Training loss = 0.00014720093148450056
step = 13, Training Accuracy: 1.0
Training loss = 0.00010060432056585948
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.64875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.026606609324614207
step = 0, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.66375
Training loss = 0.010120353102684021
step = 1, Training Accuracy: 0.8833333333333333
Training loss = 0.007627836739023526
step = 2, Training Accuracy: 0.9166666666666666
Training loss = 0.0035897323302924635
step = 3, Training Accuracy: 0.97
Training loss = 0.0019194842502474785
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0007766875127951304
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 0.0005736107317109903
step = 6, Training Accuracy: 1.0
Training loss = 0.00034570835530757906
step = 7, Training Accuracy: 1.0
Training loss = 0.00038228153716772794
step = 8, Training Accuracy: 1.0
Training loss = 0.00018107723056649168
step = 9, Training Accuracy: 1.0
Training loss = 0.0003615842014551163
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.685
Training loss = 0.00019273817151164015
step = 11, Training Accuracy: 1.0
Training loss = 0.00023855387543638548
step = 12, Training Accuracy: 1.0
Training loss = 0.00018233692273497581
step = 13, Training Accuracy: 1.0
Training loss = 0.00015730977873317897
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6825
6  	6     	0.666667	0.0138193 	0.64875	0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021613814433415732
step = 0, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.68875
Training loss = 0.0062996649245421095
step = 1, Training Accuracy: 0.93
Training loss = 0.002284839687248071
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0013322098925709724
step = 3, Training Accuracy: 1.0
Training loss = 0.0007589153448740641
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0005064754855508605
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68875
Training loss = 0.00036113224923610686
step = 6, Training Accuracy: 1.0
Training loss = 0.00026759448771675426
step = 7, Training Accuracy: 1.0
Training loss = 0.00019768708695967993
step = 8, Training Accuracy: 1.0
Training loss = 0.00015182843625855943
step = 9, Training Accuracy: 1.0
Training loss = 0.00020279576381047567
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 0.00013174694458333155
step = 11, Training Accuracy: 1.0
Training loss = 0.0001195632751720647
step = 12, Training Accuracy: 1.0
Training loss = 0.00014762835344299673
step = 13, Training Accuracy: 1.0
Training loss = 0.00011583219903210799
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03212486306826274
step = 0, Training Accuracy: 0.78
Validation Accuracy: 0.70125
Training loss = 0.009894226938486099
step = 1, Training Accuracy: 0.9133333333333333
Training loss = 0.004971028889218966
step = 2, Training Accuracy: 0.9566666666666667
Training loss = 0.0026471204807360965
step = 3, Training Accuracy: 0.9833333333333333
Training loss = 0.0015135800186544656
step = 4, Training Accuracy: 0.9866666666666667
Training loss = 0.0009322845128675301
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.0008762106702973445
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.0003522486689810952
step = 7, Training Accuracy: 1.0
Training loss = 0.0004244709697862466
step = 8, Training Accuracy: 1.0
Training loss = 0.00022014946055908997
step = 9, Training Accuracy: 1.0
Training loss = 0.0002540636761114001
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6875
Training loss = 0.0002758125999631981
step = 11, Training Accuracy: 1.0
Training loss = 0.00021076961498086653
step = 12, Training Accuracy: 1.0
Training loss = 0.00011833201666983465
step = 13, Training Accuracy: 1.0
Training loss = 9.9601149559021e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.025146078169345856
step = 0, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.665
Training loss = 0.007829257672031721
step = 1, Training Accuracy: 0.9266666666666666
Training loss = 0.003466938349107901
step = 2, Training Accuracy: 0.9733333333333334
Training loss = 0.002484611372152964
step = 3, Training Accuracy: 0.9866666666666667
Training loss = 0.0012230763956904412
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0005068944208323955
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 0.0005227201059460639
step = 6, Training Accuracy: 1.0
Training loss = 0.000582075243194898
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.00028278506516168515
step = 8, Training Accuracy: 1.0
Training loss = 0.000224250095585982
step = 9, Training Accuracy: 1.0
Training loss = 0.0002574560015151898
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6925
Training loss = 0.000208427628967911
step = 11, Training Accuracy: 1.0
Training loss = 0.0002359380821386973
step = 12, Training Accuracy: 1.0
Training loss = 0.00018695860247438154
step = 13, Training Accuracy: 1.0
Training loss = 0.00011853069998323917
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021720215578873953
step = 0, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.635
Training loss = 0.007260393301645914
step = 1, Training Accuracy: 0.9433333333333334
Training loss = 0.0028569363926847775
step = 2, Training Accuracy: 0.9766666666666667
Training loss = 0.0012086066727836928
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0009441885072737932
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0006199548207223416
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.66875
Training loss = 0.0004094430214414994
step = 6, Training Accuracy: 1.0
Training loss = 0.00024248873814940451
step = 7, Training Accuracy: 1.0
Training loss = 0.0002281506856282552
step = 8, Training Accuracy: 1.0
Training loss = 0.00019363337972511848
step = 9, Training Accuracy: 1.0
Training loss = 0.00017966464161872864
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66875
Training loss = 0.00015513186653455099
step = 11, Training Accuracy: 1.0
Training loss = 0.00014505544871402283
step = 12, Training Accuracy: 1.0
Training loss = 0.0001094503285518537
step = 13, Training Accuracy: 1.0
Training loss = 7.627522786303113e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6675
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02018391529719035
step = 0, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.68375
Training loss = 0.005584882361193498
step = 1, Training Accuracy: 0.9433333333333334
Training loss = 0.002113049328327179
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0008825631936391194
step = 3, Training Accuracy: 1.0
Training loss = 0.0006478458146254221
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0005702951077061394
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.66875
Training loss = 0.0003134703341250618
step = 6, Training Accuracy: 1.0
Training loss = 0.0002263583242893219
step = 7, Training Accuracy: 1.0
Training loss = 0.00043359071637193364
step = 8, Training Accuracy: 1.0
Training loss = 0.00021304832771420478
step = 9, Training Accuracy: 1.0
Training loss = 0.0001900266110897064
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66625
Training loss = 9.558393736369908e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.660271405863265e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.00013474772684276103
step = 13, Training Accuracy: 1.0
Training loss = 0.0001745374108819912
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66625
7  	5     	0.68125 	0.0109211 	0.66625	0.69625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020513204634189607
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.65375
Training loss = 0.005669286971290906
step = 1, Training Accuracy: 0.9466666666666667
Training loss = 0.0023368502408266066
step = 2, Training Accuracy: 0.98
Training loss = 0.0010139549399415652
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00085102296123902
step = 4, Training Accuracy: 1.0
Training loss = 0.0004527800856158137
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.66625
Training loss = 0.0003190172587831815
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.0005000172679622968
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.00023565676373740038
step = 8, Training Accuracy: 1.0
Training loss = 0.00031455882204075653
step = 9, Training Accuracy: 1.0
Training loss = 0.00023202535385886828
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6375
Training loss = 0.00019459743867628277
step = 11, Training Accuracy: 1.0
Training loss = 0.0003903459594585001
step = 12, Training Accuracy: 0.9966666666666667
Training loss = 9.491574484854937e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00013753444383231303
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02045236239830653
step = 0, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.66
Training loss = 0.005641928513844808
step = 1, Training Accuracy: 0.9533333333333334
Training loss = 0.0021961858309805394
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0012690053569773833
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0007944640913046897
step = 4, Training Accuracy: 1.0
Training loss = 0.0004836722835898399
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 0.0005266233781973521
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.0003538443800061941
step = 7, Training Accuracy: 1.0
Training loss = 0.0001846565391557912
step = 8, Training Accuracy: 1.0
Training loss = 0.0002474352282782396
step = 9, Training Accuracy: 1.0
Training loss = 0.00014137255648771923
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 0.000129947563012441
step = 11, Training Accuracy: 1.0
Training loss = 0.00016785723467667898
step = 12, Training Accuracy: 1.0
Training loss = 0.00013289730219791333
step = 13, Training Accuracy: 1.0
Training loss = 0.0001673072079817454
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6925
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012340573420127232
step = 0, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.6975
Training loss = 0.00381860659768184
step = 1, Training Accuracy: 0.9633333333333334
Training loss = 0.0018314962089061738
step = 2, Training Accuracy: 0.99
Training loss = 0.0009039238312592109
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0005499728644887607
step = 4, Training Accuracy: 1.0
Training loss = 0.00032764712038139504
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.705
Training loss = 0.00023260047814498345
step = 6, Training Accuracy: 1.0
Training loss = 0.000185561482309519
step = 7, Training Accuracy: 1.0
Training loss = 0.0001677954119319717
step = 8, Training Accuracy: 1.0
Training loss = 0.0003513686110575994
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.0006476282700896264
step = 10, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.695
Training loss = 0.0001362037565559149
step = 11, Training Accuracy: 1.0
Training loss = 0.00017347737836341062
step = 12, Training Accuracy: 1.0
Training loss = 0.00017020723472038906
step = 13, Training Accuracy: 1.0
Training loss = 0.00022887085874875388
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021360497872034707
step = 0, Training Accuracy: 0.86
Validation Accuracy: 0.68875
Training loss = 0.006264664853612582
step = 1, Training Accuracy: 0.93
Training loss = 0.00375415349068741
step = 2, Training Accuracy: 0.9733333333333334
Training loss = 0.0012512283896406492
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0007847680027286212
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0004350667322675387
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69625
Training loss = 0.0002420304389670491
step = 6, Training Accuracy: 1.0
Training loss = 0.0004156833328306675
step = 7, Training Accuracy: 1.0
Training loss = 0.00022177455791582665
step = 8, Training Accuracy: 1.0
Training loss = 0.0003124796513778468
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.0001605984770382444
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69875
Training loss = 0.00014628184338410694
step = 11, Training Accuracy: 1.0
Training loss = 0.00011861357420760517
step = 12, Training Accuracy: 1.0
Training loss = 0.00014374869565169016
step = 13, Training Accuracy: 1.0
Training loss = 0.0001211441308259964
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.023700610299905143
step = 0, Training Accuracy: 0.83
Validation Accuracy: 0.69375
Training loss = 0.00663593544314305
step = 1, Training Accuracy: 0.9366666666666666
Training loss = 0.0026674560829997064
step = 2, Training Accuracy: 0.9766666666666667
Training loss = 0.0012896038716038068
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.002075610818962256
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0004996980105837186
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.0008184398928036292
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 0.00024220072974761328
step = 7, Training Accuracy: 1.0
Training loss = 0.0003093678938845793
step = 8, Training Accuracy: 1.0
Training loss = 0.00021840737317688764
step = 9, Training Accuracy: 1.0
Training loss = 0.0001584085232267777
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68875
Training loss = 0.0001551405464609464
step = 11, Training Accuracy: 1.0
Training loss = 0.00014732233326261244
step = 12, Training Accuracy: 1.0
Training loss = 0.00013839377944047253
step = 13, Training Accuracy: 1.0
Training loss = 8.263045689091086e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6825
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02104778106013934
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.69375
Training loss = 0.011175600637992222
step = 1, Training Accuracy: 0.9266666666666666
Training loss = 0.0025998256852229435
step = 2, Training Accuracy: 0.98
Training loss = 0.001980104011793931
step = 3, Training Accuracy: 0.9866666666666667
Training loss = 0.0009808254862825076
step = 4, Training Accuracy: 1.0
Training loss = 0.0006446380975345771
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6925
Training loss = 0.0006357172876596451
step = 6, Training Accuracy: 1.0
Training loss = 0.0004096062853932381
step = 7, Training Accuracy: 1.0
Training loss = 0.00021689865738153458
step = 8, Training Accuracy: 1.0
Training loss = 0.00020445005347331365
step = 9, Training Accuracy: 1.0
Training loss = 0.0001841521969375511
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.7025
Training loss = 0.00013480687281116843
step = 11, Training Accuracy: 1.0
Training loss = 0.00015051445302863915
step = 12, Training Accuracy: 1.0
Training loss = 0.00016594497797389824
step = 13, Training Accuracy: 1.0
Training loss = 0.00012561654904857277
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6975
8  	6     	0.681875	0.0204092 	0.6375 	0.6975 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01759853422641754
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.68125
Training loss = 0.004303951738402248
step = 1, Training Accuracy: 0.9666666666666667
Training loss = 0.0017191067431122065
step = 2, Training Accuracy: 0.99
Training loss = 0.001062509020169576
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0005682725210984548
step = 4, Training Accuracy: 1.0
Training loss = 0.00040117474272847173
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.00042328253388404844
step = 6, Training Accuracy: 1.0
Training loss = 0.00024640125998606283
step = 7, Training Accuracy: 1.0
Training loss = 0.0005410940696795782
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.0003110240896542867
step = 9, Training Accuracy: 1.0
Training loss = 0.00012360009908055265
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6675
Training loss = 0.00012480321029822032
step = 11, Training Accuracy: 1.0
Training loss = 0.00012527176877483726
step = 12, Training Accuracy: 1.0
Training loss = 0.00017047569155693055
step = 13, Training Accuracy: 1.0
Training loss = 0.00010340312340607246
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018698779940605162
step = 0, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.66125
Training loss = 0.004793070269127687
step = 1, Training Accuracy: 0.9666666666666667
Training loss = 0.002105518231789271
step = 2, Training Accuracy: 0.9833333333333333
Training loss = 0.001116320074846347
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0006369136460125446
step = 4, Training Accuracy: 1.0
Training loss = 0.0004114946722984314
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.00033604162745177747
step = 6, Training Accuracy: 1.0
Training loss = 0.0006135546912749609
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.0003573214883605639
step = 8, Training Accuracy: 1.0
Training loss = 0.00044929942737023036
step = 9, Training Accuracy: 1.0
Training loss = 0.0001888231762374441
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 0.00018334442128737768
step = 11, Training Accuracy: 1.0
Training loss = 0.00026678525532285375
step = 12, Training Accuracy: 1.0
Training loss = 0.00013412576479216416
step = 13, Training Accuracy: 1.0
Training loss = 0.00011821072859068711
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6725
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017234439589083196
step = 0, Training Accuracy: 0.85
Validation Accuracy: 0.67375
Training loss = 0.00511672184492151
step = 1, Training Accuracy: 0.96
Training loss = 0.001898403192559878
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0022764620122810203
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.000609279361863931
step = 4, Training Accuracy: 1.0
Training loss = 0.00037753050914034246
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.655
Training loss = 0.00029371041338890794
step = 6, Training Accuracy: 1.0
Training loss = 0.00021182250541945297
step = 7, Training Accuracy: 1.0
Training loss = 0.00022862536211808523
step = 8, Training Accuracy: 1.0
Training loss = 0.00015208943009686966
step = 9, Training Accuracy: 1.0
Training loss = 0.00013698806753382087
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66
Training loss = 0.00013113601366057992
step = 11, Training Accuracy: 1.0
Training loss = 0.00011051803012378514
step = 12, Training Accuracy: 1.0
Training loss = 8.253654697909952e-05
step = 13, Training Accuracy: 1.0
Training loss = 7.942607412890841e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.65875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015458322167396545
step = 0, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.635
Training loss = 0.003901780992746353
step = 1, Training Accuracy: 0.96
Training loss = 0.0017873422180612881
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0009691843887170156
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0004662745197614034
step = 4, Training Accuracy: 1.0
Training loss = 0.0003767849442859491
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.66
Training loss = 0.00017795620718970894
step = 6, Training Accuracy: 1.0
Training loss = 0.0002726045964906613
step = 7, Training Accuracy: 1.0
Training loss = 0.00016599795936296383
step = 8, Training Accuracy: 1.0
Training loss = 0.000244938259323438
step = 9, Training Accuracy: 1.0
Training loss = 0.00018350650866826376
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.65125
Training loss = 0.00012123958052446445
step = 11, Training Accuracy: 1.0
Training loss = 0.00013308767636772246
step = 12, Training Accuracy: 1.0
Training loss = 8.988431732480724e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00010663809060739975
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6575
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012766552865505218
step = 0, Training Accuracy: 0.89
Validation Accuracy: 0.66125
Training loss = 0.004237015669544538
step = 1, Training Accuracy: 0.9466666666666667
Training loss = 0.0010633107569689552
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0009832656880219778
step = 3, Training Accuracy: 0.99
Training loss = 0.00038783649603525797
step = 4, Training Accuracy: 1.0
Training loss = 0.00032845523208379745
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6575
Training loss = 0.00021562959688405196
step = 6, Training Accuracy: 1.0
Training loss = 0.00021453670381257932
step = 7, Training Accuracy: 1.0
Training loss = 0.00014190816165258487
step = 8, Training Accuracy: 1.0
Training loss = 0.00011460623393456141
step = 9, Training Accuracy: 1.0
Training loss = 0.00013837218284606934
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 8.591064562400182e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.0002721213921904564
step = 12, Training Accuracy: 1.0
Training loss = 6.678329567269733e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00012906042238076528
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.665
9  	5     	0.670833	0.0134177 	0.6575 	0.6975 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015947090089321138
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.6525
Training loss = 0.0054792266214887305
step = 1, Training Accuracy: 0.96
Training loss = 0.0026104903717835744
step = 2, Training Accuracy: 0.9833333333333333
Training loss = 0.0015154285604755083
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0005582248171170553
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00037656412770350773
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.65875
Training loss = 0.0003098593388373653
step = 6, Training Accuracy: 1.0
Training loss = 0.00028514751931652427
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.00010528384824283421
step = 8, Training Accuracy: 1.0
Training loss = 0.0001783561291328321
step = 9, Training Accuracy: 1.0
Training loss = 0.00014664008282124996
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.665
Training loss = 0.00014582532768448193
step = 11, Training Accuracy: 1.0
Training loss = 0.00013239261577837168
step = 12, Training Accuracy: 1.0
Training loss = 5.8260700752725826e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.0001014100678730756
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012246041527638833
step = 0, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.6425
Training loss = 0.00453389889250199
step = 1, Training Accuracy: 0.9566666666666667
Training loss = 0.004682678567866485
step = 2, Training Accuracy: 0.9733333333333334
Training loss = 0.0007184966374188662
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00087099795229733
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0005091477620104949
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6525
Training loss = 0.0003437058037767808
step = 6, Training Accuracy: 1.0
Training loss = 0.00029785419969509044
step = 7, Training Accuracy: 1.0
Training loss = 0.00013061030923078459
step = 8, Training Accuracy: 1.0
Training loss = 0.0001351433821643392
step = 9, Training Accuracy: 1.0
Training loss = 0.00018432370387017728
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.65875
Training loss = 0.00011096614102522532
step = 11, Training Accuracy: 1.0
Training loss = 0.00012631213602920372
step = 12, Training Accuracy: 1.0
Training loss = 0.00014131985604763032
step = 13, Training Accuracy: 1.0
Training loss = 0.00010721311904489995
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6725
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014206262131532033
step = 0, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.66375
Training loss = 0.007261891129116217
step = 1, Training Accuracy: 0.9466666666666667
Training loss = 0.0019880678753058114
step = 2, Training Accuracy: 0.98
Training loss = 0.0011792725697159767
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0006275955339272817
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0003564831614494324
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67
Training loss = 0.0002474781288765371
step = 6, Training Accuracy: 1.0
Training loss = 0.00038921516388654707
step = 7, Training Accuracy: 1.0
Training loss = 0.00020645962795242667
step = 8, Training Accuracy: 1.0
Training loss = 0.00021241176097343365
step = 9, Training Accuracy: 1.0
Training loss = 0.0001284193410538137
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.665
Training loss = 8.916975736307601e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00012772702611982823
step = 12, Training Accuracy: 1.0
Training loss = 7.27687116401891e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00010626831868042548
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0185693754752477
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.66625
Training loss = 0.004396542714287837
step = 1, Training Accuracy: 0.9633333333333334
Training loss = 0.0013742528607447943
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0005856403149664402
step = 3, Training Accuracy: 1.0
Training loss = 0.00044765463719765344
step = 4, Training Accuracy: 1.0
Training loss = 0.00027171581673125425
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.66125
Training loss = 0.00025320251006633043
step = 6, Training Accuracy: 1.0
Training loss = 0.00029259173820416135
step = 7, Training Accuracy: 1.0
Training loss = 0.0001884043465058009
step = 8, Training Accuracy: 1.0
Training loss = 0.000167618819201986
step = 9, Training Accuracy: 1.0
Training loss = 8.511629382458825e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66
Training loss = 0.00018896519749735794
step = 11, Training Accuracy: 1.0
Training loss = 0.00018043681668738525
step = 12, Training Accuracy: 1.0
Training loss = 0.0001338721765205264
step = 13, Training Accuracy: 1.0
Training loss = 0.00013054038087526956
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.65625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020475156356890997
step = 0, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.69
Training loss = 0.007120550709466139
step = 1, Training Accuracy: 0.94
Training loss = 0.0015079626813530923
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0009522880365451177
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0006613503148158391
step = 4, Training Accuracy: 1.0
Training loss = 0.0004578549539049466
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 0.0003194119113807877
step = 6, Training Accuracy: 1.0
Training loss = 0.00023650966274241608
step = 7, Training Accuracy: 1.0
Training loss = 0.0001539024873636663
step = 8, Training Accuracy: 1.0
Training loss = 0.00021623119090994199
step = 9, Training Accuracy: 1.0
Training loss = 0.0002041148270169894
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66875
Training loss = 0.00019897120073437692
step = 11, Training Accuracy: 1.0
Training loss = 0.00025398748616377515
step = 12, Training Accuracy: 1.0
Training loss = 0.00012244627655794222
step = 13, Training Accuracy: 1.0
Training loss = 0.00012139158517432709
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66625
10 	5     	0.665208	0.00592561	0.65625	0.6725 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013625602747003238
step = 0, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.67875
Training loss = 0.0034642349804441135
step = 1, Training Accuracy: 0.9666666666666667
Training loss = 0.0014056206867098808
step = 2, Training Accuracy: 0.99
Training loss = 0.0006833692205448945
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0003902443591505289
step = 4, Training Accuracy: 1.0
Training loss = 0.0007011431579788525
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.69625
Training loss = 0.0003086335336168607
step = 6, Training Accuracy: 1.0
Training loss = 0.0003812074661254883
step = 7, Training Accuracy: 1.0
Training loss = 0.00015572139682869116
step = 8, Training Accuracy: 1.0
Training loss = 0.000200385603432854
step = 9, Training Accuracy: 1.0
Training loss = 0.00021121518686413764
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.7
Training loss = 9.289435188596447e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00017659261395844321
step = 12, Training Accuracy: 1.0
Training loss = 0.00010316592563564579
step = 13, Training Accuracy: 1.0
Training loss = 0.00016115042885454992
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014634597897529602
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.68375
Training loss = 0.004704515971243381
step = 1, Training Accuracy: 0.96
Training loss = 0.0024099759571254253
step = 2, Training Accuracy: 0.9833333333333333
Training loss = 0.001617681843539079
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0008979858830571175
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0014583627755443255
step = 5, Training Accuracy: 0.99
Validation Accuracy: 0.68375
Training loss = 0.0003594981071849664
step = 6, Training Accuracy: 1.0
Training loss = 0.00027348654344677925
step = 7, Training Accuracy: 1.0
Training loss = 0.00016681151775022347
step = 8, Training Accuracy: 1.0
Training loss = 0.00019461052880312006
step = 9, Training Accuracy: 1.0
Training loss = 0.00047886313249667487
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6725
Training loss = 0.00018111634999513627
step = 11, Training Accuracy: 1.0
Training loss = 0.00019453682315846284
step = 12, Training Accuracy: 1.0
Training loss = 0.00016084255650639534
step = 13, Training Accuracy: 1.0
Training loss = 0.00012629294981403896
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.675
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012830898550649485
step = 0, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.68375
Training loss = 0.0035602006192008654
step = 1, Training Accuracy: 0.9733333333333334
Training loss = 0.0018766545255978902
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0010639544250443578
step = 3, Training Accuracy: 0.9866666666666667
Training loss = 0.0005764573067426681
step = 4, Training Accuracy: 1.0
Training loss = 0.000571506271759669
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67625
Training loss = 0.0002719192043878138
step = 6, Training Accuracy: 1.0
Training loss = 0.000320029358069102
step = 7, Training Accuracy: 1.0
Training loss = 0.0002289537666365504
step = 8, Training Accuracy: 1.0
Training loss = 0.00020109152421355248
step = 9, Training Accuracy: 1.0
Training loss = 0.00010960561533768972
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.00012867058743722736
step = 11, Training Accuracy: 1.0
Training loss = 0.00020062113801638286
step = 12, Training Accuracy: 1.0
Training loss = 0.00012059374712407589
step = 13, Training Accuracy: 1.0
Training loss = 8.014534910519918e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010445038508623838
step = 0, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.695
Training loss = 0.002996454757327835
step = 1, Training Accuracy: 0.98
Training loss = 0.0017647028714418412
step = 2, Training Accuracy: 0.9833333333333333
Training loss = 0.0007175465362767379
step = 3, Training Accuracy: 1.0
Training loss = 0.000513737068977207
step = 4, Training Accuracy: 1.0
Training loss = 0.0003133770365578433
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.0001885608397424221
step = 6, Training Accuracy: 1.0
Training loss = 0.0001758780291614433
step = 7, Training Accuracy: 1.0
Training loss = 0.00022627522237598897
step = 8, Training Accuracy: 1.0
Training loss = 0.00012988713569939137
step = 9, Training Accuracy: 1.0
Training loss = 7.944974582642317e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.0001445831769766907
step = 11, Training Accuracy: 1.0
Training loss = 0.00015006546551982563
step = 12, Training Accuracy: 1.0
Training loss = 7.546751061454415e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.736920991291603e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011269697199265162
step = 0, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.69
Training loss = 0.0030859729399283727
step = 1, Training Accuracy: 0.9733333333333334
Training loss = 0.0008094739417235056
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0005116156705965598
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0006084869879608353
step = 4, Training Accuracy: 0.99
Training loss = 0.000618815707663695
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68625
Training loss = 0.0002776599178711573
step = 6, Training Accuracy: 1.0
Training loss = 9.352883518052598e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.00013708049237417679
step = 8, Training Accuracy: 1.0
Training loss = 0.0001674698945134878
step = 9, Training Accuracy: 1.0
Training loss = 0.00017591020305796217
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 9.878752132256826e-05
step = 11, Training Accuracy: 1.0
Training loss = 9.705291866945724e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.00014255103150693078
step = 13, Training Accuracy: 1.0
Training loss = 9.689787169918418e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66875
11 	5     	0.67875 	0.00835414	0.66875	0.69375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013434078109761079
step = 0, Training Accuracy: 0.9
Validation Accuracy: 0.66125
Training loss = 0.0026740435883402824
step = 1, Training Accuracy: 0.9866666666666667
Training loss = 0.0014048492908477783
step = 2, Training Accuracy: 0.99
Training loss = 0.0005884597923917075
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0002491625150044759
step = 4, Training Accuracy: 1.0
Training loss = 0.00016130434504399698
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 0.00019018567632883787
step = 6, Training Accuracy: 1.0
Training loss = 0.00016261763017003735
step = 7, Training Accuracy: 1.0
Training loss = 0.00015033496698985498
step = 8, Training Accuracy: 1.0
Training loss = 0.000180042227730155
step = 9, Training Accuracy: 1.0
Training loss = 0.00011635332251898945
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.00011017584552367528
step = 11, Training Accuracy: 1.0
Training loss = 7.492978513861696e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.28018617661049e-05
step = 13, Training Accuracy: 1.0
Training loss = 7.369638323628654e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010963872497280439
step = 0, Training Accuracy: 0.9
Validation Accuracy: 0.68875
Training loss = 0.002918715576330821
step = 1, Training Accuracy: 0.96
Training loss = 0.00112334539492925
step = 2, Training Accuracy: 0.99
Training loss = 0.0006951763418813546
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.00028145802517731987
step = 4, Training Accuracy: 1.0
Training loss = 0.000343774501234293
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.685
Training loss = 0.0003553642084201177
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.000266402008322378
step = 7, Training Accuracy: 1.0
Training loss = 0.00012053717742674052
step = 8, Training Accuracy: 1.0
Training loss = 0.0001713802417119344
step = 9, Training Accuracy: 1.0
Training loss = 0.00013444946069891253
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 9.90837897794942e-05
step = 11, Training Accuracy: 1.0
Training loss = 8.537593821529299e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.81991038719813e-05
step = 13, Training Accuracy: 1.0
Training loss = 8.059471845626831e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014190965530773004
step = 0, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.6675
Training loss = 0.004767383510867754
step = 1, Training Accuracy: 0.9366666666666666
Training loss = 0.001490680236990253
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0006578996777534485
step = 3, Training Accuracy: 1.0
Training loss = 0.00038527796044945717
step = 4, Training Accuracy: 1.0
Training loss = 0.00038946562446653846
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67125
Training loss = 0.00013870947839071353
step = 6, Training Accuracy: 1.0
Training loss = 0.00010651046216177444
step = 7, Training Accuracy: 1.0
Training loss = 8.096867939457298e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00010306573569929848
step = 9, Training Accuracy: 1.0
Training loss = 0.00014653522133206326
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.00010874840120474497
step = 11, Training Accuracy: 1.0
Training loss = 0.0001430067668358485
step = 12, Training Accuracy: 1.0
Training loss = 9.727738797664643e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.3582311073939e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010013372798760732
step = 0, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.68625
Training loss = 0.002584493054697911
step = 1, Training Accuracy: 0.9766666666666667
Training loss = 0.0010356955540676911
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.000652015528952082
step = 3, Training Accuracy: 0.99
Training loss = 0.00026317767410849533
step = 4, Training Accuracy: 1.0
Training loss = 0.0005503655721743901
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67875
Training loss = 0.0003052866420087715
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.00018302241961161295
step = 7, Training Accuracy: 1.0
Training loss = 0.0002418946185692524
step = 8, Training Accuracy: 1.0
Training loss = 0.0001054660975933075
step = 9, Training Accuracy: 1.0
Training loss = 0.0001861800750096639
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.00021976600401103498
step = 11, Training Accuracy: 1.0
Training loss = 7.817278305689494e-05
step = 12, Training Accuracy: 1.0
Training loss = 6.633690635984142e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00011830027680844069
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014094471757610638
step = 0, Training Accuracy: 0.9
Validation Accuracy: 0.6625
Training loss = 0.004431528486311436
step = 1, Training Accuracy: 0.97
Training loss = 0.0013646664967139563
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0008315730219086011
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0011769501492381097
step = 4, Training Accuracy: 0.99
Training loss = 0.00032085498174031575
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67
Training loss = 0.0002226737809057037
step = 6, Training Accuracy: 1.0
Training loss = 0.0009207060684760411
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.00019647214154247194
step = 8, Training Accuracy: 1.0
Training loss = 0.0002098042517900467
step = 9, Training Accuracy: 1.0
Training loss = 0.00020137796178460121
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.0002698842226527631
step = 11, Training Accuracy: 1.0
Training loss = 0.00011635057628154754
step = 12, Training Accuracy: 1.0
Training loss = 0.00011858876406525572
step = 13, Training Accuracy: 1.0
Training loss = 9.87026592095693e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6725
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00970069020986557
step = 0, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.68125
Training loss = 0.004858908218642076
step = 1, Training Accuracy: 0.9766666666666667
Training loss = 0.0021164551004767417
step = 2, Training Accuracy: 0.99
Training loss = 0.0011817314848303795
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0004222464499374231
step = 4, Training Accuracy: 1.0
Training loss = 0.0005070153747995694
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.66
Training loss = 0.000489861307044824
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.00033934576126436395
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.00022539198864251375
step = 8, Training Accuracy: 1.0
Training loss = 0.0002634115082522233
step = 9, Training Accuracy: 1.0
Training loss = 0.00021011225879192353
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 0.0001032640621997416
step = 11, Training Accuracy: 1.0
Training loss = 0.0001386857529481252
step = 12, Training Accuracy: 1.0
Training loss = 0.00011179258426030477
step = 13, Training Accuracy: 1.0
Training loss = 0.00014248813192049663
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66625
12 	6     	0.6725  	0.00353553	0.66625	0.67625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00787281317015489
step = 0, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.6675
Training loss = 0.00204072634379069
step = 1, Training Accuracy: 0.9833333333333333
Training loss = 0.001611611011127631
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0003710745197410385
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.001059599444270134
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0002920401142910123
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.65375
Training loss = 0.0004549747457106908
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.00019782327969248097
step = 7, Training Accuracy: 1.0
Training loss = 0.00010582334478385746
step = 8, Training Accuracy: 1.0
Training loss = 0.00013712983888884386
step = 9, Training Accuracy: 1.0
Training loss = 0.00010184246658657988
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66375
Training loss = 0.0002295118197798729
step = 11, Training Accuracy: 1.0
Training loss = 0.00010452917078509927
step = 12, Training Accuracy: 1.0
Training loss = 8.286145438129704e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.0381309885997325e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011322313360869885
step = 0, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.6675
Training loss = 0.0017321891880904634
step = 1, Training Accuracy: 0.9833333333333333
Training loss = 0.0012914486477772396
step = 2, Training Accuracy: 0.99
Training loss = 0.00035423984130223595
step = 3, Training Accuracy: 1.0
Training loss = 0.0006848097592592239
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0002081374078989029
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6675
Training loss = 0.0001882929028943181
step = 6, Training Accuracy: 1.0
Training loss = 0.00021842955611646176
step = 7, Training Accuracy: 1.0
Training loss = 0.0006529025981823603
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.00017334263461331526
step = 9, Training Accuracy: 1.0
Training loss = 0.00031669873744249343
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.655
Training loss = 0.00028762944256110736
step = 11, Training Accuracy: 1.0
Training loss = 0.00010018311440944672
step = 12, Training Accuracy: 1.0
Training loss = 9.426549077033997e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00011749347050984701
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.655
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007800552522142728
step = 0, Training Accuracy: 0.92
Validation Accuracy: 0.6575
Training loss = 0.0015778708333770435
step = 1, Training Accuracy: 0.9866666666666667
Training loss = 0.0005529184670497974
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0002777458851536115
step = 3, Training Accuracy: 1.0
Training loss = 0.0002847041996816794
step = 4, Training Accuracy: 1.0
Training loss = 0.00018758021295070648
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.655
Training loss = 0.00019184663891792298
step = 6, Training Accuracy: 1.0
Training loss = 0.0003365558634201686
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 0.00014012916944921016
step = 8, Training Accuracy: 1.0
Training loss = 0.00015742517386873564
step = 9, Training Accuracy: 1.0
Training loss = 9.526985775058468e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.65625
Training loss = 0.00012660551505784193
step = 11, Training Accuracy: 1.0
Training loss = 0.00011741148928801218
step = 12, Training Accuracy: 1.0
Training loss = 8.003219962120056e-05
step = 13, Training Accuracy: 1.0
Training loss = 8.870131491372982e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007449003222088019
step = 0, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.65625
Training loss = 0.0029812036827206612
step = 1, Training Accuracy: 0.98
Training loss = 0.000871714868893226
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.00021564540375644962
step = 3, Training Accuracy: 1.0
Training loss = 0.0004053201113129035
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0001609467303690811
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.66
Training loss = 0.00013545230419064562
step = 6, Training Accuracy: 1.0
Training loss = 9.43127398689588e-05
step = 7, Training Accuracy: 1.0
Training loss = 9.484829225887855e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.0001573437141875426
step = 9, Training Accuracy: 1.0
Training loss = 8.115864475257694e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66
Training loss = 0.0001379140136608233
step = 11, Training Accuracy: 1.0
Training loss = 8.606745939080914e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.235108534184595e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.046860585532461e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6625
13 	4     	0.666042	0.00775325	0.655  	0.67625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.006379325051481525
step = 0, Training Accuracy: 0.9366666666666666
Validation Accuracy: 0.6675
Training loss = 0.0027387198184927303
step = 1, Training Accuracy: 0.9866666666666667
Training loss = 0.001655166062215964
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0003615007712505758
step = 3, Training Accuracy: 1.0
Training loss = 0.00033013947308063507
step = 4, Training Accuracy: 1.0
Training loss = 0.0002677019351782898
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.645
Training loss = 0.0002013124121973912
step = 6, Training Accuracy: 1.0
Training loss = 0.0001597906400760015
step = 7, Training Accuracy: 1.0
Training loss = 0.0006173730020721754
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.00010835619449305037
step = 9, Training Accuracy: 1.0
Training loss = 7.143449465123316e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.65375
Training loss = 0.00012987794975439707
step = 11, Training Accuracy: 1.0
Training loss = 6.390748332099368e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.210239311059316e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00010788453121980031
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.65875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008648390571276346
step = 0, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.6675
Training loss = 0.001685891505330801
step = 1, Training Accuracy: 0.9766666666666667
Training loss = 0.0006088482006452977
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.00018490962276700883
step = 3, Training Accuracy: 1.0
Training loss = 0.00026677036037047705
step = 4, Training Accuracy: 1.0
Training loss = 0.0001460315256069104
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6525
Training loss = 0.0001457031195362409
step = 6, Training Accuracy: 1.0
Training loss = 0.00013593516390149793
step = 7, Training Accuracy: 1.0
Training loss = 7.691746373893694e-05
step = 8, Training Accuracy: 1.0
Training loss = 9.327346303810676e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.00012395688235604515
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66625
Training loss = 7.889838578800361e-05
step = 11, Training Accuracy: 1.0
Training loss = 9.217543731210754e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.0003732766459385554
step = 13, Training Accuracy: 1.0
Training loss = 0.00011786711247016986
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6575
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009985093995928764
step = 0, Training Accuracy: 0.92
Validation Accuracy: 0.66125
Training loss = 0.0023599361131588616
step = 1, Training Accuracy: 0.9866666666666667
Training loss = 0.0011448273186882337
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0005119265243411065
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00027053408324718476
step = 4, Training Accuracy: 1.0
Training loss = 0.00019108990828196207
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 0.0002496969016889731
step = 6, Training Accuracy: 1.0
Training loss = 0.00017906029204217097
step = 7, Training Accuracy: 1.0
Training loss = 0.0002153553068637848
step = 8, Training Accuracy: 1.0
Training loss = 0.00016041051596403123
step = 9, Training Accuracy: 1.0
Training loss = 8.743768751931688e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 5.063489079475403e-05
step = 11, Training Accuracy: 1.0
Training loss = 8.929462055675685e-05
step = 12, Training Accuracy: 1.0
Training loss = 5.830945253061752e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.0007279504214723905
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009548575412482023
step = 0, Training Accuracy: 0.93
Validation Accuracy: 0.68375
Training loss = 0.0027048502241571746
step = 1, Training Accuracy: 0.9766666666666667
Training loss = 0.0016701044095680118
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0006706565183897813
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0009063872943321864
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.0006345899356529117
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.69125
Training loss = 0.0006290944914023081
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 0.0014443807614346346
step = 7, Training Accuracy: 0.9933333333333333
Training loss = 0.00047310383369525275
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.00037419707824786505
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.0002209848208197703
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69375
Training loss = 0.00015238992404192686
step = 11, Training Accuracy: 1.0
Training loss = 0.00012752084682385127
step = 12, Training Accuracy: 1.0
Training loss = 9.260451615167161e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00012491604934136073
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.006662236141661803
step = 0, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.6725
Training loss = 0.0011600566655397416
step = 1, Training Accuracy: 0.9866666666666667
Training loss = 0.0009402249349902074
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0009156187996268272
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0005868483831485112
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00044272021080056826
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.685
Training loss = 0.00019488828567167124
step = 6, Training Accuracy: 1.0
Training loss = 0.00012701245645682017
step = 7, Training Accuracy: 1.0
Training loss = 0.0003002055734395981
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 0.00022122668490434687
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.0007129221739402662
step = 10, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.69
Training loss = 0.0001557303675993656
step = 11, Training Accuracy: 1.0
Training loss = 9.711970060986156e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.863526862114668e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00011655364806453387
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011867573137084643
step = 0, Training Accuracy: 0.92
Validation Accuracy: 0.6875
Training loss = 0.004952448473777622
step = 1, Training Accuracy: 0.9666666666666667
Training loss = 0.0025396172826488814
step = 2, Training Accuracy: 0.9833333333333333
Training loss = 0.0004115231242030859
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.000382847897708416
step = 4, Training Accuracy: 1.0
Training loss = 0.0003694677686629196
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6825
Training loss = 0.00037616748983661333
step = 6, Training Accuracy: 1.0
Training loss = 0.00012208970884482065
step = 7, Training Accuracy: 1.0
Training loss = 0.00015315776069959005
step = 8, Training Accuracy: 1.0
Training loss = 0.00020811854551235835
step = 9, Training Accuracy: 1.0
Training loss = 9.574770151327053e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 0.00011406823216627041
step = 11, Training Accuracy: 1.0
Training loss = 8.154629826700935e-05
step = 12, Training Accuracy: 1.0
Training loss = 7.820057372252147e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00012339731891794752
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
14 	6     	0.674375	0.011875  	0.6575 	0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00587812011440595
step = 0, Training Accuracy: 0.94
Validation Accuracy: 0.69
Training loss = 0.0013317416111628215
step = 1, Training Accuracy: 0.98
Training loss = 0.0004498373515283068
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00038837092618147534
step = 3, Training Accuracy: 1.0
Training loss = 0.00031698316956559817
step = 4, Training Accuracy: 1.0
Training loss = 0.0002248814950386683
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.70375
Training loss = 0.0001421939410890142
step = 6, Training Accuracy: 1.0
Training loss = 0.00011685722410523643
step = 7, Training Accuracy: 1.0
Training loss = 8.533743520577749e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00012157842516899109
step = 9, Training Accuracy: 1.0
Training loss = 0.0001249322462050865
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.70375
Training loss = 6.139470458341142e-05
step = 11, Training Accuracy: 1.0
Training loss = 6.183681388696035e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.044149338578184e-05
step = 13, Training Accuracy: 1.0
Training loss = 4.7175313035647074e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.70625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.004470468976845344
step = 0, Training Accuracy: 0.9566666666666667
Validation Accuracy: 0.7075
Training loss = 0.0019231248605259073
step = 1, Training Accuracy: 0.9833333333333333
Training loss = 0.000510086469973127
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0007664899279673894
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.0002818656495461861
step = 4, Training Accuracy: 1.0
Training loss = 0.00019869983196258546
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69875
Training loss = 0.00015932500129565598
step = 6, Training Accuracy: 1.0
Training loss = 0.00010283943653727571
step = 7, Training Accuracy: 1.0
Training loss = 0.0001554672916730245
step = 8, Training Accuracy: 1.0
Training loss = 0.00021998651325702667
step = 9, Training Accuracy: 1.0
Training loss = 7.540148993333181e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69625
Training loss = 0.00013628275870966415
step = 11, Training Accuracy: 1.0
Training loss = 0.00011413010458151499
step = 12, Training Accuracy: 1.0
Training loss = 7.077977837373813e-05
step = 13, Training Accuracy: 1.0
Training loss = 8.725345134735107e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6975
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.004762759571895004
step = 0, Training Accuracy: 0.9566666666666667
Validation Accuracy: 0.7075
Training loss = 0.001439727668960889
step = 1, Training Accuracy: 0.98
Training loss = 0.0005662939324975014
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00028756536543369295
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0004400287941098213
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00023956983039776484
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 0.00030061226182927686
step = 6, Training Accuracy: 1.0
Training loss = 0.00015231133283426365
step = 7, Training Accuracy: 1.0
Training loss = 0.00018369144866786275
step = 8, Training Accuracy: 1.0
Training loss = 8.332733452940981e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.240847667058309e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6925
Training loss = 9.240210832407077e-05
step = 11, Training Accuracy: 1.0
Training loss = 9.129544875274102e-05
step = 12, Training Accuracy: 1.0
Training loss = 7.499370258301497e-05
step = 13, Training Accuracy: 1.0
Training loss = 7.120057940483093e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007286174719532331
step = 0, Training Accuracy: 0.94
Validation Accuracy: 0.7025
Training loss = 0.0008156258799135685
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.0013392552485068639
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0009553973832710956
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00032434756867587565
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00024113866422946254
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 0.0002239077992271632
step = 6, Training Accuracy: 1.0
Training loss = 0.00023332312703132628
step = 7, Training Accuracy: 1.0
Training loss = 0.00011923419505668183
step = 8, Training Accuracy: 1.0
Training loss = 8.831199646616975e-05
step = 9, Training Accuracy: 1.0
Training loss = 8.15473993619283e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68875
Training loss = 8.343299229939779e-05
step = 11, Training Accuracy: 1.0
Training loss = 8.648347963268558e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.00011048261483665556
step = 13, Training Accuracy: 1.0
Training loss = 0.0012880664318799973
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008217035954197248
step = 0, Training Accuracy: 0.95
Validation Accuracy: 0.68125
Training loss = 0.003819454039136569
step = 1, Training Accuracy: 0.98
Training loss = 0.00045534967755277953
step = 2, Training Accuracy: 1.0
Training loss = 0.00036553113410870233
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0010136852040886879
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.00019964891602285205
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69375
Training loss = 0.0001424144053210815
step = 6, Training Accuracy: 1.0
Training loss = 0.00015162371875097354
step = 7, Training Accuracy: 1.0
Training loss = 0.00011361639946699142
step = 8, Training Accuracy: 1.0
Training loss = 0.00012796370079740883
step = 9, Training Accuracy: 1.0
Training loss = 0.00018603325705043972
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.69125
Training loss = 0.00011913234988848369
step = 11, Training Accuracy: 1.0
Training loss = 9.69928332294027e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.30916982764999e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.0002001536823809147
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
15 	5     	0.69125 	0.00938194	0.68125	0.70625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.005950262546539306
step = 0, Training Accuracy: 0.9566666666666667
Validation Accuracy: 0.6825
Training loss = 0.001695948780203859
step = 1, Training Accuracy: 0.9866666666666667
Training loss = 0.00047018878938009343
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0003294632708032926
step = 3, Training Accuracy: 1.0
Training loss = 0.00035424377769231795
step = 4, Training Accuracy: 1.0
Training loss = 0.00016452535171993077
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 0.00015853141744931538
step = 6, Training Accuracy: 1.0
Training loss = 0.0001501761625210444
step = 7, Training Accuracy: 1.0
Training loss = 5.651801824569702e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00012248640259106955
step = 9, Training Accuracy: 1.0
Training loss = 0.00010349405308564503
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 4.707106292092552e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00013739901284376781
step = 12, Training Accuracy: 1.0
Training loss = 7.852314660946528e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00011590844214272996
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.002912595335704585
step = 0, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.675
Training loss = 0.0008607101533561945
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.0004949282358090082
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00013121055245089033
step = 3, Training Accuracy: 1.0
Training loss = 0.00014570949405121308
step = 4, Training Accuracy: 1.0
Training loss = 0.00021616173287232718
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6875
Training loss = 0.00012651077626893916
step = 6, Training Accuracy: 1.0
Training loss = 4.7980604867916555e-05
step = 7, Training Accuracy: 1.0
Training loss = 7.869722942511241e-05
step = 8, Training Accuracy: 1.0
Training loss = 6.547927856445312e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.0008833696569005648
step = 10, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.68375
Training loss = 6.990935226591925e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00010347596369683743
step = 12, Training Accuracy: 1.0
Training loss = 0.00013183577141414086
step = 13, Training Accuracy: 1.0
Training loss = 6.471131384993593e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0027362430181043845
step = 0, Training Accuracy: 0.9733333333333334
Validation Accuracy: 0.68375
Training loss = 0.0008687671273946762
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.00019312897076209385
step = 2, Training Accuracy: 1.0
Training loss = 0.00017771554489930472
step = 3, Training Accuracy: 1.0
Training loss = 0.00011207844673966367
step = 4, Training Accuracy: 1.0
Training loss = 0.00011499706655740738
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 7.388050823161999e-05
step = 6, Training Accuracy: 1.0
Training loss = 8.237194696751734e-05
step = 7, Training Accuracy: 1.0
Training loss = 7.848572451621294e-05
step = 8, Training Accuracy: 1.0
Training loss = 4.2639639771853885e-05
step = 9, Training Accuracy: 1.0
Training loss = 6.299962600072224e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 5.4809484475602705e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.075242698192596e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.026433487733206e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.084800999611616e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.004586884258314967
step = 0, Training Accuracy: 0.9666666666666667
Validation Accuracy: 0.68875
Training loss = 0.0037384426966309546
step = 1, Training Accuracy: 0.9833333333333333
Training loss = 0.0022992647811770437
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.000924988806558152
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0004268312950929006
step = 4, Training Accuracy: 1.0
Training loss = 0.00034482823063929877
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 0.00023132423559824624
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 7.732649644215901e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.00012358743386964004
step = 8, Training Accuracy: 1.0
Training loss = 0.0002450834090511004
step = 9, Training Accuracy: 1.0
Training loss = 8.56031064176932e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 0.0001085835105429093
step = 11, Training Accuracy: 1.0
Training loss = 4.9335534373919166e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.8698716952155034e-05
step = 13, Training Accuracy: 1.0
Training loss = 4.483914216204236e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6925
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00513303759197394
step = 0, Training Accuracy: 0.9566666666666667
Validation Accuracy: 0.67875
Training loss = 0.001364678479731083
step = 1, Training Accuracy: 0.99
Training loss = 0.0004800494302374621
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00030254590014616646
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00026223665724198024
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00013743285400172073
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.0001555810331289346
step = 6, Training Accuracy: 1.0
Training loss = 6.96533340184639e-05
step = 7, Training Accuracy: 1.0
Training loss = 6.936059226669992e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00012876691102671126
step = 9, Training Accuracy: 1.0
Training loss = 6.192208112527927e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 4.670452733989805e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00020317716524004937
step = 12, Training Accuracy: 1.0
Training loss = 0.0011012575154503187
step = 13, Training Accuracy: 0.9966666666666667
Training loss = 0.00012402042746543885
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67375
16 	5     	0.687292	0.0100627 	0.67375	0.70625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.005445102324398855
step = 0, Training Accuracy: 0.9533333333333334
Validation Accuracy: 0.67375
Training loss = 0.001495882362748186
step = 1, Training Accuracy: 0.98
Training loss = 0.0005898389716943105
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00021358351688832044
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 9.620511283477148e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.00030648265965282917
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68
Training loss = 0.00015243968615929286
step = 6, Training Accuracy: 1.0
Training loss = 7.713055441854521e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.0006968319167693456
step = 8, Training Accuracy: 0.99
Training loss = 6.200734060257673e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.0002805965269605319
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69375
Training loss = 0.00011605880339629948
step = 11, Training Accuracy: 1.0
Training loss = 6.785864631334941e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.0001178527291631326
step = 13, Training Accuracy: 1.0
Training loss = 6.542390416143462e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.006897467163701852
step = 0, Training Accuracy: 0.9633333333333334
Validation Accuracy: 0.69625
Training loss = 0.0006290536125500997
step = 1, Training Accuracy: 0.99
Training loss = 0.0005757184990216047
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00032219987362623213
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00013703514200945696
step = 4, Training Accuracy: 1.0
Training loss = 0.00014795219836135707
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6975
Training loss = 0.000287832443912824
step = 6, Training Accuracy: 1.0
Training loss = 0.00011310049332678318
step = 7, Training Accuracy: 1.0
Training loss = 0.0001842558430507779
step = 8, Training Accuracy: 1.0
Training loss = 9.88670108684649e-05
step = 9, Training Accuracy: 1.0
Training loss = 9.913807928872606e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69375
Training loss = 0.0001056188220779101
step = 11, Training Accuracy: 1.0
Training loss = 0.00010698553174734115
step = 12, Training Accuracy: 1.0
Training loss = 0.00016007830699284873
step = 13, Training Accuracy: 1.0
Training loss = 0.00010116741061210632
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.005469085238873958
step = 0, Training Accuracy: 0.98
Validation Accuracy: 0.69375
Training loss = 0.0010499784598747889
step = 1, Training Accuracy: 0.99
Training loss = 0.001333180417617162
step = 2, Training Accuracy: 0.99
Training loss = 0.00022482035875630876
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00019215258873979716
step = 4, Training Accuracy: 1.0
Training loss = 0.0001694685137287403
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 0.00022653323908646903
step = 6, Training Accuracy: 1.0
Training loss = 0.0001541706422964732
step = 7, Training Accuracy: 1.0
Training loss = 8.634823064009348e-05
step = 8, Training Accuracy: 1.0
Training loss = 9.711866577466329e-05
step = 9, Training Accuracy: 1.0
Training loss = 6.238680332899094e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6875
Training loss = 0.00011961941917737325
step = 11, Training Accuracy: 1.0
Training loss = 6.98754769594719e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.999554207548499e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00025845074832128983
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6825
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0024943845191349586
step = 0, Training Accuracy: 0.98
Validation Accuracy: 0.68875
Training loss = 0.0017340861260890961
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.0007140291482210159
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0009157910446325937
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 0.00025128792971372603
step = 4, Training Accuracy: 1.0
Training loss = 0.0005250929028261453
step = 5, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.69125
Training loss = 0.00016719361146291098
step = 6, Training Accuracy: 1.0
Training loss = 0.00027161901195844017
step = 7, Training Accuracy: 1.0
Training loss = 6.795417109970003e-05
step = 8, Training Accuracy: 1.0
Training loss = 5.889095366001129e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.00011483484258254369
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 4.1394167540905374e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.9393077691396075e-05
step = 12, Training Accuracy: 1.0
Training loss = 9.62515757419169e-05
step = 13, Training Accuracy: 1.0
Training loss = 4.933859726103643e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0037263141510387263
step = 0, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.68875
Training loss = 0.00033758225967176256
step = 1, Training Accuracy: 1.0
Training loss = 0.0009586233956118425
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.00028749045915901664
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0001816496563454469
step = 4, Training Accuracy: 1.0
Training loss = 0.00011321613875528177
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 0.0009573793783783913
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.00012863731399799386
step = 7, Training Accuracy: 1.0
Training loss = 0.00013720507015629361
step = 8, Training Accuracy: 1.0
Training loss = 5.800163567376633e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.00010403826832771302
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.0002941171328226725
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 0.0001257802996163567
step = 12, Training Accuracy: 1.0
Training loss = 0.00011659650752941767
step = 13, Training Accuracy: 1.0
Training loss = 4.880770187204083e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.006621719470325236
step = 0, Training Accuracy: 0.9366666666666666
Validation Accuracy: 0.6825
Training loss = 0.00205562461555625
step = 1, Training Accuracy: 0.9733333333333334
Training loss = 0.000857495553791523
step = 2, Training Accuracy: 0.99
Training loss = 0.0002478869305923581
step = 3, Training Accuracy: 1.0
Training loss = 0.0003408563509583473
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00023027030130227407
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 7.062302688912799e-05
step = 6, Training Accuracy: 1.0
Training loss = 8.966513802685464e-05
step = 7, Training Accuracy: 1.0
Training loss = 5.635340183895702e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00021685654506048497
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 7.411568115154903e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 0.0001101589161650433
step = 11, Training Accuracy: 1.0
Training loss = 3.723159432411194e-05
step = 12, Training Accuracy: 1.0
Training loss = 5.297017594178518e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.9237083692569284e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68375
17 	6     	0.685625	0.00431507	0.67875	0.69125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.004270965221027533
step = 0, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.6825
Training loss = 0.0006871740147471428
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.00044449165851498645
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0002717213953534762
step = 3, Training Accuracy: 1.0
Training loss = 0.0005949059004584948
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00010875733414043983
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69
Training loss = 0.0001577360392548144
step = 6, Training Accuracy: 1.0
Training loss = 0.00011718973517417908
step = 7, Training Accuracy: 1.0
Training loss = 7.859039586037397e-05
step = 8, Training Accuracy: 1.0
Training loss = 7.855163654312492e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.0001485172084843119
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 0.0003005240112543106
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 9.145748258257906e-05
step = 12, Training Accuracy: 1.0
Training loss = 9.110848108927409e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.9739914936944845e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.7
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.005582089349627495
step = 0, Training Accuracy: 0.9633333333333334
Validation Accuracy: 0.7
Training loss = 0.0024733195127919316
step = 1, Training Accuracy: 0.9733333333333334
Training loss = 0.0007479212728018562
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.00013015277683734895
step = 3, Training Accuracy: 1.0
Training loss = 0.00012698497235154112
step = 4, Training Accuracy: 1.0
Training loss = 6.162193914254506e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.70125
Training loss = 0.00031123191739122074
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 7.97174870967865e-05
step = 7, Training Accuracy: 1.0
Training loss = 7.805423655857642e-05
step = 8, Training Accuracy: 1.0
Training loss = 7.16865889262408e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.49258291721344e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.70125
Training loss = 4.474903146425883e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.090659320354462e-05
step = 12, Training Accuracy: 1.0
Training loss = 5.273938993923366e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.918720245361328e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.7025
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0031526206682125726
step = 0, Training Accuracy: 0.9733333333333334
Validation Accuracy: 0.705
Training loss = 0.0013466221342484156
step = 1, Training Accuracy: 0.9833333333333333
Training loss = 0.00011643456916014354
step = 2, Training Accuracy: 1.0
Training loss = 0.00010634208718935649
step = 3, Training Accuracy: 1.0
Training loss = 9.143561978513995e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.00010336100628289084
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.70375
Training loss = 0.00027931318094488234
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 0.00012133033325274786
step = 7, Training Accuracy: 1.0
Training loss = 0.0006276124302530661
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 7.205680788805088e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.00011993960399801533
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.70625
Training loss = 0.00010129698435775935
step = 11, Training Accuracy: 1.0
Training loss = 0.00014179786356786886
step = 12, Training Accuracy: 1.0
Training loss = 8.298444251219432e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.806903859289984e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.7025
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0039325385789076486
step = 0, Training Accuracy: 0.9733333333333334
Validation Accuracy: 0.70375
Training loss = 0.0006492636104424794
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.0004511731117963791
step = 2, Training Accuracy: 0.99
Training loss = 0.00018752793005357186
step = 3, Training Accuracy: 1.0
Training loss = 0.0002454926942785581
step = 4, Training Accuracy: 1.0
Training loss = 0.000196869894862175
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6875
Training loss = 0.00013618231440583865
step = 6, Training Accuracy: 1.0
Training loss = 0.00010875696937243143
step = 7, Training Accuracy: 1.0
Training loss = 0.00012107214890420436
step = 8, Training Accuracy: 1.0
Training loss = 0.00015253434578577676
step = 9, Training Accuracy: 1.0
Training loss = 4.741841713742664e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.695
Training loss = 0.00015191525647727152
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 0.00015192724764347078
step = 12, Training Accuracy: 1.0
Training loss = 7.570866922227046e-05
step = 13, Training Accuracy: 1.0
Training loss = 7.870680652558803e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6975
18 	4     	0.6975  	0.00473242	0.69125	0.7025 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0029004724696278573
step = 0, Training Accuracy: 0.99
Validation Accuracy: 0.70625
Training loss = 0.0036356415723760925
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.0011624300976594288
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00040024546285470327
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00011989411354685824
step = 4, Training Accuracy: 1.0
Training loss = 0.0002497595507884398
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.7
Training loss = 0.00010946633061394095
step = 6, Training Accuracy: 1.0
Training loss = 0.00011858881373579303
step = 7, Training Accuracy: 1.0
Training loss = 0.0001244320720434189
step = 8, Training Accuracy: 1.0
Training loss = 4.4163092970848085e-05
step = 9, Training Accuracy: 1.0
Training loss = 4.392842451731364e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.7
Training loss = 9.838904797409972e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.441345194820315e-05
step = 12, Training Accuracy: 1.0
Training loss = 6.032607595746716e-05
step = 13, Training Accuracy: 1.0
Training loss = 4.198300341765086e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.705
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.002792437858879566
step = 0, Training Accuracy: 0.99
Validation Accuracy: 0.69375
Training loss = 0.0011231932540734608
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.00025696565319473545
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00046458474438016616
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00035133025919397673
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 0.00010467440821230411
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69
Training loss = 8.911827792568753e-05
step = 6, Training Accuracy: 1.0
Training loss = 0.00021373418470223746
step = 7, Training Accuracy: 1.0
Training loss = 0.00017469841055572032
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 9.44420361580948e-05
step = 9, Training Accuracy: 1.0
Training loss = 7.568575441837311e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 7.095191239689787e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.006070693023503e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.5430416464805605e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.427279780230795e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6975
19 	2     	0.70125 	0.00239357	0.6975 	0.705  
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0017836566682672128
step = 0, Training Accuracy: 0.9866666666666667
Validation Accuracy: 0.69375
Training loss = 0.00019174323315382936
step = 1, Training Accuracy: 1.0
Training loss = 0.00018968870242436726
step = 2, Training Accuracy: 1.0
Training loss = 0.00018256028066389264
step = 3, Training Accuracy: 1.0
Training loss = 9.638824422533314e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.00011490003943132858
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 4.9875924984614056e-05
step = 6, Training Accuracy: 1.0
Training loss = 6.164028386895856e-05
step = 7, Training Accuracy: 1.0
Training loss = 6.260275840759277e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.0001105709249774615
step = 9, Training Accuracy: 1.0
Training loss = 4.880752826769215e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 7.302851416170597e-05
step = 11, Training Accuracy: 1.0
Training loss = 5.397775094024837e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.4402282303223425e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.7363014271249995e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0012430085327165823
step = 0, Training Accuracy: 0.9866666666666667
Validation Accuracy: 0.68875
Training loss = 0.0002482697078570103
step = 1, Training Accuracy: 1.0
Training loss = 0.0001661449996754527
step = 2, Training Accuracy: 1.0
Training loss = 9.294040908571333e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.0001850402479370435
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 5.240177114804586e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.685
Training loss = 5.3799243469256906e-05
step = 6, Training Accuracy: 1.0
Training loss = 3.761569658915202e-05
step = 7, Training Accuracy: 1.0
Training loss = 7.927671074867249e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.721944134061535e-05
step = 9, Training Accuracy: 1.0
Training loss = 7.233454535404841e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 2.8589434126236787e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.8586586316426596e-05
step = 12, Training Accuracy: 1.0
Training loss = 6.316670061399539e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.166802227497101e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6825
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.002713180842498938
step = 0, Training Accuracy: 0.9833333333333333
Validation Accuracy: 0.6825
Training loss = 0.00213137519856294
step = 1, Training Accuracy: 0.99
Training loss = 0.0006562642815212408
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.0001825860577325026
step = 3, Training Accuracy: 1.0
Training loss = 0.0007530586669842402
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00014905089512467384
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 0.00015125599379340807
step = 6, Training Accuracy: 1.0
Training loss = 0.0001624506339430809
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 7.42452343304952e-05
step = 8, Training Accuracy: 1.0
Training loss = 6.97703038652738e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.5601149797439574e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 0.00011529796640388667
step = 11, Training Accuracy: 1.0
Training loss = 6.307138343496869e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.801379303292682e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.257813841026897e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0039739549284180005
step = 0, Training Accuracy: 0.97
Validation Accuracy: 0.6775
Training loss = 0.0014138476550579072
step = 1, Training Accuracy: 0.98
Training loss = 0.0002533775482637187
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 5.104400217533112e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00015069171786308289
step = 4, Training Accuracy: 1.0
Training loss = 9.80753117861847e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 5.165784697358807e-05
step = 6, Training Accuracy: 1.0
Training loss = 8.923557431747516e-05
step = 7, Training Accuracy: 1.0
Training loss = 5.80973094717289e-05
step = 8, Training Accuracy: 1.0
Training loss = 7.171951234340668e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.2073390979785475e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 5.330301821231842e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.91600759839639e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.483093818028768e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.0001435189259548982
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0025053715209166208
step = 0, Training Accuracy: 0.97
Validation Accuracy: 0.6925
Training loss = 0.0006148093399436523
step = 1, Training Accuracy: 0.99
Training loss = 0.0011544172962506612
step = 2, Training Accuracy: 0.9866666666666667
Training loss = 0.0002692771287790189
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00013700406687955062
step = 4, Training Accuracy: 1.0
Training loss = 0.00010244593024253845
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 4.0435476427470956e-05
step = 6, Training Accuracy: 1.0
Training loss = 9.395059624997278e-05
step = 7, Training Accuracy: 1.0
Training loss = 9.984110482037068e-05
step = 8, Training Accuracy: 1.0
Training loss = 6.151301592277984e-05
step = 9, Training Accuracy: 1.0
Training loss = 4.243584970633189e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 2.821650782910486e-05
step = 11, Training Accuracy: 1.0
Training loss = 8.374846656806767e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.3326637543117006e-05
step = 13, Training Accuracy: 1.0
Training loss = 8.904971182346343e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0018781163461972028
step = 0, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.68
Training loss = 0.00014538514583061139
step = 1, Training Accuracy: 1.0
Training loss = 0.0003376569521302978
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0006008327503999074
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 6.989498933156332e-05
step = 4, Training Accuracy: 1.0
Training loss = 7.886016935420533e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 4.628578006910781e-05
step = 6, Training Accuracy: 1.0
Training loss = 5.22233130565534e-05
step = 7, Training Accuracy: 1.0
Training loss = 6.375828563856581e-05
step = 8, Training Accuracy: 1.0
Training loss = 5.59966101233537e-05
step = 9, Training Accuracy: 1.0
Training loss = 6.728531637539466e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 5.1228677233060204e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.3204302589098616e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.544578492641449e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.9630358417828875e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
20 	6     	0.685   	0.00408248	0.67875	0.69125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0009203847823664546
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67875
Training loss = 0.00011138263624161483
step = 1, Training Accuracy: 1.0
Training loss = 9.735115726167957e-05
step = 2, Training Accuracy: 1.0
Training loss = 8.802698731111984e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00011693285467724006
step = 4, Training Accuracy: 1.0
Training loss = 6.986601486763296e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 5.6196161446374995e-05
step = 6, Training Accuracy: 1.0
Training loss = 0.00022367550681034725
step = 7, Training Accuracy: 1.0
Training loss = 0.00012712387368083
step = 8, Training Accuracy: 1.0
Training loss = 0.0002930270880460739
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 0.00010663582322498163
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 4.257587948814035e-05
step = 11, Training Accuracy: 1.0
Training loss = 5.6120678782463076e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.00014587756867210071
step = 13, Training Accuracy: 1.0
Training loss = 0.00034923826654752096
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6775
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0005391578913743918
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.675
Training loss = 0.00028278028383889857
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 6.712333221609394e-05
step = 2, Training Accuracy: 1.0
Training loss = 0.0005178664500514667
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0001453801803290844
step = 4, Training Accuracy: 1.0
Training loss = 0.0001670526920740182
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.66875
Training loss = 3.5904596249262495e-05
step = 6, Training Accuracy: 1.0
Training loss = 9.142197668552399e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.00016114686305324238
step = 8, Training Accuracy: 1.0
Training loss = 9.3039704952389e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.7778976558086774e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 2.122120737719039e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.327702859882265e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.258851986378431e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.9132213395399352e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0004981272543470065
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.6775
Training loss = 0.00014847177184492465
step = 1, Training Accuracy: 1.0
Training loss = 0.0007313282042741776
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 9.492688269043963e-05
step = 3, Training Accuracy: 1.0
Training loss = 4.631020943634212e-05
step = 4, Training Accuracy: 1.0
Training loss = 3.5825967788696286e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 0.00011753530241549016
step = 6, Training Accuracy: 1.0
Training loss = 5.242577858249812e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.957921882625669e-05
step = 8, Training Accuracy: 1.0
Training loss = 4.890601616352796e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.9178763031959535e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 3.428002198537191e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.9540737072626748e-05
step = 12, Training Accuracy: 1.0
Training loss = 6.782980014880498e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.0026514927546184e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0014883018574861732
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.68
Training loss = 0.0012252239220833872
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.0007452917761232432
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0002749058852593104
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.0002889910254937907
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 6.929287066062292e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 0.00039944558508674767
step = 6, Training Accuracy: 0.9933333333333333
Training loss = 7.355626260202068e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.8521294395128887e-05
step = 8, Training Accuracy: 1.0
Training loss = 4.368464152018229e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.3695288497644166e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 5.7521189252535505e-05
step = 11, Training Accuracy: 1.0
Training loss = 5.705018003936857e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.6060027778148654e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.3826363534123326e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0010935363670190176
step = 0, Training Accuracy: 0.9866666666666667
Validation Accuracy: 0.67875
Training loss = 0.0002315649390220642
step = 1, Training Accuracy: 1.0
Training loss = 0.000220732515056928
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 6.920832752560576e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00014402875676751138
step = 4, Training Accuracy: 1.0
Training loss = 5.2839542428652444e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6875
Training loss = 4.3675046569357316e-05
step = 6, Training Accuracy: 1.0
Training loss = 4.236575604105989e-05
step = 7, Training Accuracy: 1.0
Training loss = 3.427329162756602e-05
step = 8, Training Accuracy: 1.0
Training loss = 6.007164716720581e-05
step = 9, Training Accuracy: 1.0
Training loss = 3.581632345837231e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6875
Training loss = 2.0512276193282257e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.479500154654185e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.7923459808031717e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.2059118946393334e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69125
21 	5     	0.683958	0.00651187	0.6775 	0.69125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.001233296977976958
step = 0, Training Accuracy: 0.99
Validation Accuracy: 0.6925
Training loss = 0.0007286969987520327
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.000170699010292689
step = 2, Training Accuracy: 1.0
Training loss = 0.0001740668589870135
step = 3, Training Accuracy: 1.0
Training loss = 8.56382316366459e-05
step = 4, Training Accuracy: 1.0
Training loss = 6.017858783404033e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.685
Training loss = 8.215039968490601e-05
step = 6, Training Accuracy: 1.0
Training loss = 3.725547731543581e-05
step = 7, Training Accuracy: 1.0
Training loss = 5.563711941552659e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00012162350118160248
step = 9, Training Accuracy: 1.0
Training loss = 0.00014643423880139988
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 5.80465296904246e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00014921457409703483
step = 12, Training Accuracy: 1.0
Training loss = 2.9092600768005166e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.7874124847973385e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6825
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0023458619539936383
step = 0, Training Accuracy: 0.9866666666666667
Validation Accuracy: 0.67875
Training loss = 0.0001982963209350904
step = 1, Training Accuracy: 1.0
Training loss = 0.00017647892236709594
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0001163532833258311
step = 3, Training Accuracy: 1.0
Training loss = 7.226920065780481e-05
step = 4, Training Accuracy: 1.0
Training loss = 6.82150029266874e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.00017103989094418163
step = 6, Training Accuracy: 1.0
Training loss = 5.532273814120951e-05
step = 7, Training Accuracy: 1.0
Training loss = 8.4784470188121e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00020707336564858755
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 8.953838715873038e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 6.327481629947821e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.8419440883832674e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.9041125973065695e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.455705423528949e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0011402317136526108
step = 0, Training Accuracy: 0.9833333333333333
Validation Accuracy: 0.68875
Training loss = 0.0006528708007923948
step = 1, Training Accuracy: 0.99
Training loss = 7.047506670157115e-05
step = 2, Training Accuracy: 1.0
Training loss = 0.0005100021720863879
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00010355989962893849
step = 4, Training Accuracy: 1.0
Training loss = 0.000190766757975022
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6975
Training loss = 8.724731703599294e-05
step = 6, Training Accuracy: 1.0
Training loss = 0.0001216732244938612
step = 7, Training Accuracy: 1.0
Training loss = 2.181785802046458e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00013749756384640933
step = 9, Training Accuracy: 1.0
Training loss = 3.320756057898203e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6975
Training loss = 3.45321084993581e-05
step = 11, Training Accuracy: 1.0
Training loss = 6.594397127628327e-05
step = 12, Training Accuracy: 1.0
Training loss = 7.159366388805211e-05
step = 13, Training Accuracy: 1.0
Training loss = 4.9504985411961874e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.70375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.001684056267986307
step = 0, Training Accuracy: 0.99
Validation Accuracy: 0.69
Training loss = 0.0013129593349488762
step = 1, Training Accuracy: 0.9866666666666667
Training loss = 0.00042097994029366724
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 5.131998824557134e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00047129554053147634
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00018206221361955006
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6575
Training loss = 0.00019077591598033904
step = 6, Training Accuracy: 1.0
Training loss = 3.674691737008591e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.747485200719287e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.6462148923892528e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.6058529814084373e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.66375
Training loss = 7.327117646733919e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.960065267980099e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.313252580681971e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.00012293773392836252
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6675
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.002035279960837215
step = 0, Training Accuracy: 0.99
Validation Accuracy: 0.67125
Training loss = 0.0009165085025597364
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.00034671052048603694
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 7.26995167012016e-05
step = 3, Training Accuracy: 1.0
Training loss = 5.975138808328969e-05
step = 4, Training Accuracy: 1.0
Training loss = 2.0229990283648173e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 0.00010237978564570464
step = 6, Training Accuracy: 1.0
Training loss = 3.46695797634311e-05
step = 7, Training Accuracy: 1.0
Training loss = 9.662591949260484e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.1360955288400872e-05
step = 9, Training Accuracy: 1.0
Training loss = 7.258319198930016e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 4.054424663384756e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.3752364417693267e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.8660057335703944e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.386901100787024e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69125
22 	5     	0.686042	0.0112596 	0.6675 	0.70375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0026857665098456588
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.6925
Training loss = 0.0013962611245612302
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.0007587782458479827
step = 2, Training Accuracy: 0.9933333333333333
Training loss = 0.00018195745016176564
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 6.676461959917409e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.000132472962141037
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 6.174592514677595e-05
step = 6, Training Accuracy: 1.0
Training loss = 3.302796850524222e-05
step = 7, Training Accuracy: 1.0
Training loss = 5.384149262681604e-05
step = 8, Training Accuracy: 1.0
Training loss = 6.038126846154531e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.0320009983455142e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 3.67111215988795e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.207644283771515e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.5974959135055543e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.2257314374437555e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0003012300365420136
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6825
Training loss = 0.00047827365083018475
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.00025202336410681407
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0006224044660727183
step = 3, Training Accuracy: 0.9933333333333333
Training loss = 6.545281251116345e-05
step = 4, Training Accuracy: 1.0
Training loss = 4.956338554620743e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 6.770638128121695e-05
step = 6, Training Accuracy: 1.0
Training loss = 6.485054056004931e-05
step = 7, Training Accuracy: 1.0
Training loss = 8.072723120373364e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.7986980276182292e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.8411356906872244e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 7.81139483054479e-05
step = 11, Training Accuracy: 1.0
Training loss = 3.967143595218658e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.361938272874492e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.0951728026072184e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0003212286283572515
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67375
Training loss = 0.0001454977753261725
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 3.058681885401408e-05
step = 2, Training Accuracy: 1.0
Training loss = 2.392981614927218e-05
step = 3, Training Accuracy: 1.0
Training loss = 3.757855127332732e-05
step = 4, Training Accuracy: 1.0
Training loss = 2.665284613613039e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 4.1425683399817595e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.8674610269566378e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.0003868662317593892
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 1.346185803413391e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.3812656203905742e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 4.017320772012075e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.241284508878986e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.4887120996718295e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.8648219692210358e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 6.131507456302643e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 2.2910957535107932e-05
step = 1, Training Accuracy: 1.0
Training loss = 4.859555900717775e-05
step = 2, Training Accuracy: 1.0
Training loss = 0.00011176841954390208
step = 3, Training Accuracy: 1.0
Training loss = 2.2294711864863833e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.54531995455424e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 1.7165798284016394e-05
step = 6, Training Accuracy: 1.0
Training loss = 9.062510604659716e-05
step = 7, Training Accuracy: 1.0
Training loss = 9.365074336528778e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.4139985044797261e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.7332865099888294e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68875
Training loss = 2.3569415012995402e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.245960334936777e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.9797690187697296e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.631977537026008e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 8.377676208813985e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 0.00022460063298543293
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.00014058349033196766
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0004976671437422434
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 7.059599738568068e-05
step = 4, Training Accuracy: 1.0
Training loss = 4.40163747407496e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69375
Training loss = 6.348636408802121e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.9413013010829066e-05
step = 7, Training Accuracy: 1.0
Training loss = 3.4561629096666975e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.589924467126063e-05
step = 9, Training Accuracy: 1.0
Training loss = 3.475814228295349e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69875
Training loss = 4.229228526431446e-05
step = 11, Training Accuracy: 1.0
Training loss = 8.73167688647906e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.00011482556660970052
step = 13, Training Accuracy: 1.0
Training loss = 8.269231349307423e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6925
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00036773217221101125
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.68875
Training loss = 7.707151273886362e-05
step = 1, Training Accuracy: 1.0
Training loss = 0.00012146184007481983
step = 2, Training Accuracy: 1.0
Training loss = 3.075355460168794e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00017634076997637748
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0029361589998006823
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.685
Training loss = 0.000160931121208705
step = 6, Training Accuracy: 1.0
Training loss = 2.3872355620066324e-05
step = 7, Training Accuracy: 1.0
Training loss = 3.5416525206528605e-05
step = 8, Training Accuracy: 1.0
Training loss = 6.323134759441018e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.539258862573964e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 6.840205649496057e-05
step = 11, Training Accuracy: 1.0
Training loss = 3.8976516176868854e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.6647787963156587e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.7671969583025202e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
23 	6     	0.683958	0.0054685 	0.67625	0.6925 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.001008676029741764
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.68625
Training loss = 6.692509690765291e-05
step = 1, Training Accuracy: 1.0
Training loss = 0.00016110692585546833
step = 2, Training Accuracy: 1.0
Training loss = 0.00018433435926757131
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 7.378882825529824e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.8752333126030863e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.69
Training loss = 5.775054295857747e-05
step = 6, Training Accuracy: 1.0
Training loss = 6.48498193671306e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.8050566713015238e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.7180061998563664e-05
step = 9, Training Accuracy: 1.0
Training loss = 6.828558010359605e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 3.092451215100785e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.4181269604402283e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.0971243977546694e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.7191840460291134e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6925
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0011786279786610975
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68875
Training loss = 0.00011022551192581887
step = 1, Training Accuracy: 1.0
Training loss = 9.615943243261427e-05
step = 2, Training Accuracy: 1.0
Training loss = 7.89756245406655e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00020917584498723348
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 2.318689366802573e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.685
Training loss = 1.5209846994063507e-05
step = 6, Training Accuracy: 1.0
Training loss = 5.432385951280594e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.00021760576715071996
step = 8, Training Accuracy: 1.0
Training loss = 5.6053292428259735e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.8342294594428192e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 4.6779877739027146e-05
step = 11, Training Accuracy: 1.0
Training loss = 3.571130335330963e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.1011224986674886e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.080316664030154e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.002546151764690876
step = 0, Training Accuracy: 0.99
Validation Accuracy: 0.67875
Training loss = 0.00011566188574458162
step = 1, Training Accuracy: 1.0
Training loss = 0.000100855752825737
step = 2, Training Accuracy: 1.0
Training loss = 0.00024846159697820743
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00015265585233767827
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.000162632887562116
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 4.834873815222333e-05
step = 6, Training Accuracy: 1.0
Training loss = 3.5146309273841324e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.633830726457139e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.0524710416793825e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.955148249786968e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 1.4080943365115673e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.789379452626842e-05
step = 12, Training Accuracy: 1.0
Training loss = 6.33754829565684e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.8252780040105185e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 1.9802128275235494e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 3.711283206939697e-05
step = 1, Training Accuracy: 1.0
Training loss = 1.3330313959158956e-05
step = 2, Training Accuracy: 1.0
Training loss = 3.178077856622015e-05
step = 3, Training Accuracy: 1.0
Training loss = 2.8387399215716868e-05
step = 4, Training Accuracy: 1.0
Training loss = 2.035660882635663e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.00011583518654030437
step = 6, Training Accuracy: 1.0
Training loss = 1.2181293665586661e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.0716699883535814e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.8408762213463584e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.951380749233067e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 1.2983563889671738e-05
step = 11, Training Accuracy: 1.0
Training loss = 3.8305769364039104e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.9068237816100008e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.098575234413147e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0018377649202011527
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.6725
Training loss = 0.0013870349443459418
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.00021423038922269673
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 3.3611191902309656e-05
step = 3, Training Accuracy: 1.0
Training loss = 3.858248392740885e-05
step = 4, Training Accuracy: 1.0
Training loss = 5.061923628090881e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 3.305657044014272e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.7532938121197123e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.0877826415623227e-05
step = 8, Training Accuracy: 1.0
Training loss = 4.7522154127364046e-05
step = 9, Training Accuracy: 1.0
Training loss = 4.8878764112790425e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 2.255573868751526e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.609168118496503e-05
step = 12, Training Accuracy: 1.0
Training loss = 0.0005220800017317136
step = 13, Training Accuracy: 0.9933333333333333
Training loss = 1.633131663159778e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
24 	5     	0.682917	0.00571305	0.6775 	0.6925 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0004021525796755062
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.67375
Training loss = 0.00011416002293117344
step = 1, Training Accuracy: 1.0
Training loss = 1.9390607873598736e-05
step = 2, Training Accuracy: 1.0
Training loss = 5.5082606074089806e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00010416158373118379
step = 4, Training Accuracy: 1.0
Training loss = 5.1143790284792585e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.66875
Training loss = 4.73525541019626e-05
step = 6, Training Accuracy: 1.0
Training loss = 0.0006891284137964249
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 1.585633377544582e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.8549346259533193e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.5074170231819155e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.665
Training loss = 3.080565094326933e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.705874542395274e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.612690587838491e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.535225242453938e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0008963693511517098
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67375
Training loss = 0.00020914906014998753
step = 1, Training Accuracy: 1.0
Training loss = 0.000133343655616045
step = 2, Training Accuracy: 1.0
Training loss = 0.00017426783063759406
step = 3, Training Accuracy: 1.0
Training loss = 2.0997590521195283e-05
step = 4, Training Accuracy: 1.0
Training loss = 3.342085414563674e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 2.7193162241019307e-05
step = 6, Training Accuracy: 1.0
Training loss = 4.095709986965327e-05
step = 7, Training Accuracy: 1.0
Training loss = 7.474240323062986e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.4910329120757524e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.3960997263590494e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 2.080678939819336e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.591575926800336e-05
step = 12, Training Accuracy: 1.0
Training loss = 7.952683505815609e-06
step = 13, Training Accuracy: 1.0
Training loss = 2.921560546383262e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0007672090083360672
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.66875
Training loss = 3.587414820988973e-05
step = 1, Training Accuracy: 1.0
Training loss = 4.5548876126607256e-05
step = 2, Training Accuracy: 1.0
Training loss = 4.613765437776844e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.000650172159075737
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.00045932347575823465
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67375
Training loss = 6.23964269955953e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.27047089235081e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.1967470248540243e-05
step = 8, Training Accuracy: 1.0
Training loss = 4.338869204123815e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.2324406430319262e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 5.3679404954891653e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.5817466701264492e-05
step = 12, Training Accuracy: 1.0
Training loss = 5.962530771891276e-05
step = 13, Training Accuracy: 1.0
Training loss = 4.0424581772337354e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.675
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00011284800037780467
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 3.77349058787028e-05
step = 1, Training Accuracy: 1.0
Training loss = 6.732881903493155e-05
step = 2, Training Accuracy: 1.0
Training loss = 2.5949386957411963e-05
step = 3, Training Accuracy: 1.0
Training loss = 3.573018630656103e-05
step = 4, Training Accuracy: 1.0
Training loss = 4.2795306847741205e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.665
Training loss = 7.399185871084531e-05
step = 6, Training Accuracy: 1.0
Training loss = 0.0003548626104990641
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 7.171541452407837e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.9652561944288514e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.9955477764597162e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.00010388845345005393
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 3.618419170379639e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.394508073649679e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.225220501112441e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6725
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 6.554075410046305e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 2.0973864399517575e-05
step = 1, Training Accuracy: 1.0
Training loss = 1.8769196273448567e-05
step = 2, Training Accuracy: 1.0
Training loss = 1.6680434346199035e-05
step = 3, Training Accuracy: 1.0
Training loss = 2.289183437824249e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.814577316205638e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 2.5239148089895026e-05
step = 6, Training Accuracy: 1.0
Training loss = 9.255272646745046e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.00010508028169473013
step = 8, Training Accuracy: 1.0
Training loss = 1.2183272240993878e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.132954325536654e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 5.322561502301445e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.1103972792625427e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.8451131084778655e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.387978455672662e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6825
25 	5     	0.677083	0.00648181	0.67   	0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.001700079929499528
step = 0, Training Accuracy: 0.9866666666666667
Validation Accuracy: 0.6875
Training loss = 0.00016808649757876992
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 5.2512105903588235e-05
step = 2, Training Accuracy: 1.0
Training loss = 9.022751619340852e-05
step = 3, Training Accuracy: 1.0
Training loss = 5.317798815667629e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.0001328604482114315
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 3.861045257508522e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.141189247292156e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.0018760021775960922
step = 8, Training Accuracy: 0.9966666666666667
Training loss = 2.019380529721578e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.917726462124847e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 0.0001824142535527547
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 3.634822035868031e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.1954812556117153e-05
step = 13, Training Accuracy: 1.0
Training loss = 8.080482070605892e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 7.567132920182e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 5.158699221283314e-05
step = 1, Training Accuracy: 1.0
Training loss = 3.4028217196464536e-05
step = 2, Training Accuracy: 1.0
Training loss = 4.916087617554391e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.00021359759072462717
step = 4, Training Accuracy: 1.0
Training loss = 3.383999884439011e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 6.787954984853665e-05
step = 6, Training Accuracy: 1.0
Training loss = 4.304293957829941e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.926442364696413e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.978977600733439e-05
step = 9, Training Accuracy: 1.0
Training loss = 3.80012559859703e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.0003385798881451289
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 2.3865840509339858e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.8927789923424522e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.1947721640268963e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6825
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0006227399990893901
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.68375
Training loss = 0.00044010512530803683
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.00018564875703305005
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0003228404621283213
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 2.5921724736690523e-05
step = 4, Training Accuracy: 1.0
Training loss = 7.031658043464025e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 3.0766982429971294e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.4630531271298727e-05
step = 7, Training Accuracy: 1.0
Training loss = 6.417703193922838e-05
step = 8, Training Accuracy: 1.0
Training loss = 5.630013843377431e-05
step = 9, Training Accuracy: 1.0
Training loss = 4.1311412254193176e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 2.2994221944827585e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.8478035926818847e-05
step = 12, Training Accuracy: 1.0
Training loss = 7.624008188334604e-05
step = 13, Training Accuracy: 1.0
Training loss = 8.287504315376281e-06
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0001542207272723317
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 5.5389867884514385e-05
step = 1, Training Accuracy: 1.0
Training loss = 6.420513822376961e-05
step = 2, Training Accuracy: 1.0
Training loss = 9.691437085469564e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.0002009892463684082
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 5.134280353862171e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6925
Training loss = 1.851864974014461e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.539255181948344e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.6119814974663315e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.6974698305130004e-05
step = 9, Training Accuracy: 1.0
Training loss = 4.56801219843328e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 3.4237106641133625e-05
step = 11, Training Accuracy: 1.0
Training loss = 3.4998187572152044e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.119286697668333e-06
step = 13, Training Accuracy: 1.0
Training loss = 4.987048188922927e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.69
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0031298092007637024
step = 0, Training Accuracy: 0.9866666666666667
Validation Accuracy: 0.6925
Training loss = 0.000367951297921536
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 2.214614716649521e-05
step = 2, Training Accuracy: 1.0
Training loss = 5.286460121472677e-05
step = 3, Training Accuracy: 1.0
Training loss = 0.0004173265438779102
step = 4, Training Accuracy: 0.9933333333333333
Training loss = 3.32355085023058e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.685
Training loss = 2.2690461737511213e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.7298518020349245e-05
step = 7, Training Accuracy: 1.0
Training loss = 3.567472100257874e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.7626388667461774e-05
step = 9, Training Accuracy: 1.0
Training loss = 8.027867297641934e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69125
Training loss = 2.9537868686020373e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.3605674505233766e-05
step = 12, Training Accuracy: 1.0
Training loss = 4.019430954940617e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.8728546525041264e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 4.678309378505219e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 6.246012533665635e-05
step = 1, Training Accuracy: 1.0
Training loss = 4.05469536781311e-05
step = 2, Training Accuracy: 1.0
Training loss = 3.203888734181722e-05
step = 3, Training Accuracy: 1.0
Training loss = 1.9202083349227907e-05
step = 4, Training Accuracy: 1.0
Training loss = 4.836723208427429e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 2.6230886578559876e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.8249195485016874e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.192947601239818e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.6375664199586026e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.405902564836045e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 6.435269897338003e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.839885566373899e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.468433186450663e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.0330617426273724e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68125
26 	6     	0.68375 	0.00395285	0.6775 	0.69   
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 2.6914187668201824e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 0.0013151189684867859
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 2.322655578609556e-05
step = 2, Training Accuracy: 1.0
Training loss = 0.0003253197173277537
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00030780677994092303
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 0.0002850980187455813
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68625
Training loss = 2.130849480939408e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.840781835198868e-05
step = 7, Training Accuracy: 1.0
Training loss = 0.00012994845397770404
step = 8, Training Accuracy: 1.0
Training loss = 3.986265044659376e-05
step = 9, Training Accuracy: 1.0
Training loss = 0.0007914018630981446
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6775
Training loss = 0.0002784984807173411
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 2.4277584549660485e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.7337484496238176e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.869481566051643e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0013624556445332322
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68625
Training loss = 0.0012157689531644186
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.0009684383124113083
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0002793431282043457
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 0.00024510420030613507
step = 4, Training Accuracy: 0.9966666666666667
Training loss = 4.551632543249677e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.00014522991647633414
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 5.1196556887589396e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.8076536133691357e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.5771894007533166e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.3470292029184446e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 3.939575622401511e-05
step = 11, Training Accuracy: 1.0
Training loss = 5.9145631062165195e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.7621760964393615e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.3122442663492014e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 1.530192792415619e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 6.330072045481453e-05
step = 1, Training Accuracy: 1.0
Training loss = 2.8267304102579753e-05
step = 2, Training Accuracy: 1.0
Training loss = 2.3969742954553416e-05
step = 3, Training Accuracy: 1.0
Training loss = 8.574243014057478e-05
step = 4, Training Accuracy: 1.0
Training loss = 5.6575627919907374e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 1.3526620144451347e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.8504613373267298e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.8212683070402514e-05
step = 8, Training Accuracy: 1.0
Training loss = 5.6727835908532145e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.7478416363398235e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68625
Training loss = 1.1105115214983622e-05
step = 11, Training Accuracy: 1.0
Training loss = 7.212683558464051e-06
step = 12, Training Accuracy: 1.0
Training loss = 0.00010088746746381124
step = 13, Training Accuracy: 0.9966666666666667
Training loss = 6.100825121393427e-06
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0005205688873926799
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.69125
Training loss = 2.091017035127152e-05
step = 1, Training Accuracy: 1.0
Training loss = 0.00011037453179596924
step = 2, Training Accuracy: 1.0
Training loss = 2.7471606930096945e-05
step = 3, Training Accuracy: 1.0
Training loss = 1.6298972914228214e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.3145804405212403e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6925
Training loss = 3.866493284779911e-05
step = 6, Training Accuracy: 1.0
Training loss = 4.156827097176574e-05
step = 7, Training Accuracy: 1.0
Training loss = 8.824391600986322e-05
step = 8, Training Accuracy: 1.0
Training loss = 9.090395445430962e-06
step = 9, Training Accuracy: 1.0
Training loss = 9.578226211791238e-06
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68875
Training loss = 1.237070396503744e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.4750642906922924e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.074941622694799e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.5204610501532443e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6925
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 9.23477194737643e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.0006065769990285238
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 2.0144465767468016e-05
step = 2, Training Accuracy: 1.0
Training loss = 8.280906411528121e-05
step = 3, Training Accuracy: 1.0
Training loss = 1.8569537399647136e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.00013081640005111695
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 4.528610190997521e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.6312135606616115e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.8098437115744068e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.123573134265219e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.8801469306927173e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 3.997446736320853e-05
step = 11, Training Accuracy: 1.0
Training loss = 3.138067821661631e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.1522190470714122e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.7360805068165063e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66875
27 	5     	0.684375	0.00745647	0.66875	0.6925 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 4.8539183189859614e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 5.601394611100356e-05
step = 1, Training Accuracy: 1.0
Training loss = 0.0006936817367871603
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00015192500005165735
step = 3, Training Accuracy: 1.0
Training loss = 1.6968448956807455e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.729146499807636e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 3.6182420153636485e-05
step = 6, Training Accuracy: 1.0
Training loss = 7.786908914567902e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.3519128163655599e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.919377207135161e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.931018300335078e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.69
Training loss = 3.8138694192942543e-06
step = 11, Training Accuracy: 1.0
Training loss = 9.826065773571221e-06
step = 12, Training Accuracy: 1.0
Training loss = 1.6242381583045548e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.2285419506952166e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00019152744776874898
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.685
Training loss = 0.00011901457276204989
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.0017543093115091324
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.0001539045406752848
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 5.5361852670709295e-05
step = 4, Training Accuracy: 1.0
Training loss = 4.607686559514453e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 2.1996688495467727e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.1986357072213044e-05
step = 7, Training Accuracy: 1.0
Training loss = 5.4304103056589765e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.566870341775939e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.2723227739334107e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 0.00010390749201178551
step = 11, Training Accuracy: 1.0
Training loss = 2.434960682876408e-05
step = 12, Training Accuracy: 1.0
Training loss = 5.2238015681117155e-05
step = 13, Training Accuracy: 1.0
Training loss = 9.295762206117312e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 5.511168802816731e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 0.0002520189185937246
step = 1, Training Accuracy: 1.0
Training loss = 4.711127122088025e-05
step = 2, Training Accuracy: 1.0
Training loss = 0.0007438364128271739
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 1.9178340832392374e-05
step = 4, Training Accuracy: 1.0
Training loss = 7.296297078331311e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 1.126173468946945e-05
step = 6, Training Accuracy: 1.0
Training loss = 5.030938268949588e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.4679779609044393e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.6510312755902607e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.2036946490212964e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 3.4299343824386596e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.2429294040193783e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.3149612544414897e-05
step = 13, Training Accuracy: 1.0
Training loss = 0.0005860003332297007
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.69
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00023285221308469773
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.68375
Training loss = 0.0006423110432418374
step = 1, Training Accuracy: 0.9933333333333333
Training loss = 0.00010160009478568099
step = 2, Training Accuracy: 1.0
Training loss = 0.0002550983553131421
step = 3, Training Accuracy: 0.9966666666666667
Training loss = 3.320268432920178e-05
step = 4, Training Accuracy: 1.0
Training loss = 3.4858128832032286e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 2.734295196205494e-05
step = 6, Training Accuracy: 1.0
Training loss = 5.937159886040414e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.3400142391522725e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.4334312739568607e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.0115951299667358e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 1.051633725486075e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00011176311721404394
step = 12, Training Accuracy: 0.9966666666666667
Training loss = 1.136648987691539e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.602094193610052e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 1.3834867228676255e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 3.075547904397051e-05
step = 1, Training Accuracy: 1.0
Training loss = 8.135873358696699e-05
step = 2, Training Accuracy: 1.0
Training loss = 5.375958135118708e-06
step = 3, Training Accuracy: 1.0
Training loss = 4.647137364372611e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.5546737446735886e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68875
Training loss = 2.5408872300734704e-05
step = 6, Training Accuracy: 1.0
Training loss = 3.924960891405741e-05
step = 7, Training Accuracy: 1.0
Training loss = 4.5678153013189635e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.3026479209656827e-05
step = 9, Training Accuracy: 1.0
Training loss = 8.39726792643584e-06
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6925
Training loss = 1.2378560301537315e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.5813840727787466e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.994803547859192e-05
step = 13, Training Accuracy: 1.0
Training loss = 7.435523594419161e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6925
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00042506400088313965
step = 0, Training Accuracy: 0.9933333333333333
Validation Accuracy: 0.68125
Training loss = 0.00016294192105609302
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 4.040221373240153e-05
step = 2, Training Accuracy: 1.0
Training loss = 1.6336821718141438e-05
step = 3, Training Accuracy: 1.0
Training loss = 2.9961648906464688e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.0001296968168268601
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67375
Training loss = 3.574437566082148e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.584678888320923e-05
step = 7, Training Accuracy: 1.0
Training loss = 3.0668982205194577e-05
step = 8, Training Accuracy: 1.0
Training loss = 6.233929772861302e-05
step = 9, Training Accuracy: 1.0
Training loss = 9.624037067017828e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 2.5123291610119244e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00013857446610927583
step = 12, Training Accuracy: 1.0
Training loss = 1.0879991784046676e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.0076268253130062e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67625
28 	6     	0.684167	0.00610953	0.67625	0.6925 
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 2.0037293434143067e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 0.00010181675354639689
step = 1, Training Accuracy: 1.0
Training loss = 1.6527084844710772e-05
step = 2, Training Accuracy: 1.0
Training loss = 4.011205504260336e-05
step = 3, Training Accuracy: 1.0
Training loss = 4.005405639569896e-05
step = 4, Training Accuracy: 1.0
Training loss = 7.493230999292185e-06
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 4.190430821230014e-05
step = 6, Training Accuracy: 1.0
Training loss = 9.558567156394322e-05
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 1.7043227950731915e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.771127046396335e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.470167604566086e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.00011020442262330714
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 0.00014939712981383005
step = 12, Training Accuracy: 0.9966666666666667
Training loss = 1.6114388902982075e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.8404610153908532e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.685
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 3.329596588931357e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 1.674027075447763e-05
step = 1, Training Accuracy: 1.0
Training loss = 0.00022579108675320944
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 9.534077544230967e-06
step = 3, Training Accuracy: 1.0
Training loss = 9.87315426270167e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.7840986450513205e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68375
Training loss = 9.6855726345287e-06
step = 6, Training Accuracy: 1.0
Training loss = 0.0008601393053929011
step = 7, Training Accuracy: 0.9966666666666667
Training loss = 3.377002974351247e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.005608089248805e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.885027885592232e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.685
Training loss = 7.040503124396006e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.4899795254071553e-05
step = 12, Training Accuracy: 1.0
Training loss = 8.105876545111338e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.0127731511602179e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0004493160463122573
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67375
Training loss = 1.798665364428113e-05
step = 1, Training Accuracy: 1.0
Training loss = 1.7387933201386356e-05
step = 2, Training Accuracy: 1.0
Training loss = 3.915900985399882e-06
step = 3, Training Accuracy: 1.0
Training loss = 1.4048334625537488e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.1423718594111657e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.0001043897287066405
step = 6, Training Accuracy: 1.0
Training loss = 6.402684996525447e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.3415291905403137e-05
step = 8, Training Accuracy: 1.0
Training loss = 5.4497685696333064e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.6040648420651755e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 1.3693306439866623e-05
step = 11, Training Accuracy: 1.0
Training loss = 4.034520049269001e-05
step = 12, Training Accuracy: 1.0
Training loss = 6.065484558348544e-06
step = 13, Training Accuracy: 1.0
Training loss = 3.998570144176483e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 1.0724845860750066e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 7.200125604867935e-05
step = 1, Training Accuracy: 1.0
Training loss = 6.492329955411453e-05
step = 2, Training Accuracy: 1.0
Training loss = 1.550066802337824e-05
step = 3, Training Accuracy: 1.0
Training loss = 1.745482285817464e-05
step = 4, Training Accuracy: 1.0
Training loss = 7.073413997810955e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 0.0002786661849919862
step = 6, Training Accuracy: 0.9966666666666667
Training loss = 1.0530832732911221e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.3260729115766783e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.1014437079429628e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.2680648166375856e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 6.381803104886785e-06
step = 11, Training Accuracy: 1.0
Training loss = 6.49458004772896e-06
step = 12, Training Accuracy: 1.0
Training loss = 1.1754060784975687e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.0648138025620332e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00034116139014561973
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.685
Training loss = 5.567555626233419e-05
step = 1, Training Accuracy: 1.0
Training loss = 3.708103516449531e-05
step = 2, Training Accuracy: 1.0
Training loss = 3.2237850828096274e-05
step = 3, Training Accuracy: 1.0
Training loss = 1.7030835151672364e-05
step = 4, Training Accuracy: 1.0
Training loss = 7.041810701290767e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 1.7241578962057248e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.7659217119216918e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.0691603422164916e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00030613379339532306
step = 9, Training Accuracy: 0.9966666666666667
Training loss = 7.861217677903672e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 1.111952794114283e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.00020788416266441346
step = 12, Training Accuracy: 0.9966666666666667
Training loss = 9.026055534680685e-06
step = 13, Training Accuracy: 1.0
Training loss = 0.0002849821249643962
step = 14, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 2.1283063591302684e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 4.486814141273499e-05
step = 1, Training Accuracy: 1.0
Training loss = 2.6463327618936697e-05
step = 2, Training Accuracy: 1.0
Training loss = 6.21749802182118e-05
step = 3, Training Accuracy: 1.0
Training loss = 2.1245280901590983e-05
step = 4, Training Accuracy: 1.0
Training loss = 1.279162034431162e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6825
Training loss = 8.914338250178844e-06
step = 6, Training Accuracy: 1.0
Training loss = 3.5708803285767016e-05
step = 7, Training Accuracy: 1.0
Training loss = 4.3515182139041526e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.564486124863227e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.416588652830494e-06
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 3.7954954508071144e-05
step = 11, Training Accuracy: 1.0
Training loss = 0.0003752122322718302
step = 12, Training Accuracy: 0.9966666666666667
Training loss = 3.300185780972242e-05
step = 13, Training Accuracy: 1.0
Training loss = 5.664063840716457e-06
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6725
29 	6     	0.677708	0.00470021	0.67125	0.685  
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 1.8517168039882867e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 6.569698452949524e-06
step = 1, Training Accuracy: 1.0
Training loss = 0.0001624416559934616
step = 2, Training Accuracy: 1.0
Training loss = 4.9905098082187274e-05
step = 3, Training Accuracy: 1.0
Training loss = 2.7491052945454917e-05
step = 4, Training Accuracy: 1.0
Training loss = 5.7046529157863305e-06
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 1.3977794187667314e-05
step = 6, Training Accuracy: 1.0
Training loss = 5.0825029611587524e-05
step = 7, Training Accuracy: 1.0
Training loss = 8.416010277869646e-06
step = 8, Training Accuracy: 1.0
Training loss = 1.2885588742695594e-05
step = 9, Training Accuracy: 1.0
Training loss = 1.0832349459330242e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 4.2938780461554414e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.6573700656105453e-05
step = 12, Training Accuracy: 1.0
Training loss = 2.8372125489113386e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.937036712964376e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67625
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 8.706185544724576e-06
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 3.693513159911769e-05
step = 1, Training Accuracy: 1.0
Training loss = 4.0701180696487425e-05
step = 2, Training Accuracy: 1.0
Training loss = 4.7045018945937044e-05
step = 3, Training Accuracy: 1.0
Training loss = 4.435618718465169e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.0004441506415605545
step = 5, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67625
Training loss = 2.252014974753062e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.713853285968071e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.3884367611420505e-05
step = 8, Training Accuracy: 1.0
Training loss = 5.26637164875865e-05
step = 9, Training Accuracy: 1.0
Training loss = 3.355861486246188e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 1.3161475459734599e-05
step = 11, Training Accuracy: 1.0
Training loss = 1.639069775895526e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.546606341842562e-05
step = 13, Training Accuracy: 1.0
Training loss = 8.324417819191392e-06
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00015918354620225728
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.6775
Training loss = 3.402094046274821e-05
step = 1, Training Accuracy: 1.0
Training loss = 9.59931022953242e-05
step = 2, Training Accuracy: 1.0
Training loss = 2.399298051993052e-05
step = 3, Training Accuracy: 1.0
Training loss = 7.08006260295709e-05
step = 4, Training Accuracy: 1.0
Training loss = 3.4504905343055726e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 3.249012748710811e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.0990007451473504e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.02625658736603e-05
step = 8, Training Accuracy: 1.0
Training loss = 3.0228421092033387e-05
step = 9, Training Accuracy: 1.0
Training loss = 5.207187600414424e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 0.00011137374570049966
step = 11, Training Accuracy: 0.9966666666666667
Training loss = 3.6201228698094684e-05
step = 12, Training Accuracy: 1.0
Training loss = 1.6686957775770375e-05
step = 13, Training Accuracy: 1.0
Training loss = 2.245244468213059e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0003278175907083399
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67
Training loss = 0.00013059604912996292
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 2.2179964532066757e-05
step = 2, Training Accuracy: 1.0
Training loss = 3.0311768253644307e-05
step = 3, Training Accuracy: 1.0
Training loss = 2.676023377716774e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.0001296896239121755
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.66625
Training loss = 5.2997743089993795e-05
step = 6, Training Accuracy: 1.0
Training loss = 7.833470486123891e-05
step = 7, Training Accuracy: 1.0
Training loss = 1.6245742638905843e-05
step = 8, Training Accuracy: 1.0
Training loss = 1.829161411781873e-05
step = 9, Training Accuracy: 1.0
Training loss = 6.375610828399658e-06
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 1.1947014281759038e-05
step = 11, Training Accuracy: 1.0
Training loss = 5.710588544995214e-06
step = 12, Training Accuracy: 1.0
Training loss = 2.446843544021249e-05
step = 13, Training Accuracy: 1.0
Training loss = 3.616519272327423e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.66875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 3.8140656154913204e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.66625
Training loss = 0.0005149375398953756
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.00017601565354198102
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 0.00010344714754258651
step = 3, Training Accuracy: 1.0
Training loss = 9.596861103394379e-06
step = 4, Training Accuracy: 1.0
Training loss = 1.333764856099151e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 2.5006118764091905e-05
step = 6, Training Accuracy: 1.0
Training loss = 2.2884623807234068e-05
step = 7, Training Accuracy: 1.0
Training loss = 3.9443506126796515e-05
step = 8, Training Accuracy: 1.0
Training loss = 0.00011335982630650202
step = 9, Training Accuracy: 1.0
Training loss = 9.316920406263307e-05
step = 10, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67625
Training loss = 7.864617655286566e-06
step = 11, Training Accuracy: 1.0
Training loss = 2.7434445097848463e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.97956785225991e-05
step = 13, Training Accuracy: 1.0
Training loss = 7.953097422917684e-06
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6775
30 	5     	0.6775  	0.00456435	0.66875	0.68375
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0004119111266239391
step = 0, Training Accuracy: 0.9966666666666667
Validation Accuracy: 0.67125
Training loss = 0.0002365334580341975
step = 1, Training Accuracy: 0.9966666666666667
Training loss = 0.00022149381950536433
step = 2, Training Accuracy: 0.9966666666666667
Training loss = 1.5681741933804007e-05
step = 3, Training Accuracy: 1.0
Training loss = 4.11446350820673e-05
step = 4, Training Accuracy: 1.0
Training loss = 0.00011656155188878378
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68
Training loss = 6.084243844573696e-05
step = 6, Training Accuracy: 1.0
Training loss = 0.00010157587200713655
step = 7, Training Accuracy: 1.0
Training loss = 5.723254958866164e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.245072689220251e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.0211678396056717e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67375
Training loss = 0.00012482003619273505
step = 11, Training Accuracy: 1.0
Training loss = 7.224642671644687e-05
step = 12, Training Accuracy: 1.0
Training loss = 3.0509638988102477e-05
step = 13, Training Accuracy: 1.0
Training loss = 6.488286890089512e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68125
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 1.5756181577065337e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6775
Training loss = 1.8425509333610536e-05
step = 1, Training Accuracy: 1.0
Training loss = 8.565261960029601e-06
step = 2, Training Accuracy: 1.0
Training loss = 5.625089009602865e-06
step = 3, Training Accuracy: 1.0
Training loss = 2.3348554968833923e-05
step = 4, Training Accuracy: 1.0
Training loss = 9.092777346571287e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.68125
Training loss = 2.1904218786706528e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.9343453944505504e-05
step = 7, Training Accuracy: 1.0
Training loss = 8.354683717091878e-06
step = 8, Training Accuracy: 1.0
Training loss = 9.074310461680095e-06
step = 9, Training Accuracy: 1.0
Training loss = 1.134792963663737e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 7.672122834871213e-05
step = 11, Training Accuracy: 1.0
Training loss = 2.8565857137436977e-05
step = 12, Training Accuracy: 1.0
Training loss = 5.654965837796529e-06
step = 13, Training Accuracy: 1.0
Training loss = 4.723204522936915e-06
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.68
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 1.2464771668116252e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.67875
Training loss = 7.359957089647651e-05
step = 1, Training Accuracy: 1.0
Training loss = 6.853938102722168e-06
step = 2, Training Accuracy: 1.0
Training loss = 1.036615838529542e-05
step = 3, Training Accuracy: 1.0
Training loss = 7.181581524188611e-06
step = 4, Training Accuracy: 1.0
Training loss = 1.595015327135722e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67
Training loss = 1.1260501213049186e-05
step = 6, Training Accuracy: 1.0
Training loss = 1.6846706469853718e-05
step = 7, Training Accuracy: 1.0
Training loss = 3.942317428785221e-06
step = 8, Training Accuracy: 1.0
Training loss = 1.3344975110764305e-05
step = 9, Training Accuracy: 1.0
Training loss = 3.6302043372415936e-06
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 1.2192850311597188e-05
step = 11, Training Accuracy: 1.0
Training loss = 6.633682387473527e-06
step = 12, Training Accuracy: 1.0
Training loss = 6.630511731297399e-06
step = 13, Training Accuracy: 1.0
Training loss = 6.427052964378769e-06
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.6825
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 3.8906766308173245e-05
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 9.608342428691685e-05
step = 1, Training Accuracy: 1.0
Training loss = 1.126661062395821e-05
step = 2, Training Accuracy: 1.0
Training loss = 2.0844803851408264e-05
step = 3, Training Accuracy: 1.0
Training loss = 1.1244424519342525e-05
step = 4, Training Accuracy: 1.0
Training loss = 2.1209634044983735e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.67625
Training loss = 2.9737237427980288e-05
step = 6, Training Accuracy: 1.0
Training loss = 6.416592339519411e-05
step = 7, Training Accuracy: 1.0
Training loss = 2.630973079552253e-05
step = 8, Training Accuracy: 1.0
Training loss = 2.424077853599253e-05
step = 9, Training Accuracy: 1.0
Training loss = 2.546688774600625e-05
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.675
Training loss = 7.628301779429118e-06
step = 11, Training Accuracy: 1.0
Training loss = 8.315708910231479e-06
step = 12, Training Accuracy: 1.0
Training loss = 1.3507530093193055e-05
step = 13, Training Accuracy: 1.0
Training loss = 1.840252015729978e-05
step = 14, Training Accuracy: 1.0
Validation Accuracy: 0.67875
pipeline:  []
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 8.147905270258585e-06
step = 0, Training Accuracy: 1.0
Validation Accuracy: 0.67125
Training loss = 2.1244370291242376e-05
step = 1, Training Accuracy: 1.0
Training loss = 4.312353829542796e-05
step = 2, Training Accuracy: 1.0
Training loss = 1.237910648342222e-05
step = 3, Training Accuracy: 1.0
Training loss = 6.43177992363538e-06
step = 4, Training Accuracy: 1.0
Training loss = 1.8285475671291352e-05
step = 5, Training Accuracy: 1.0
Validation Accuracy: 0.6725
Training loss = 2.2801020077167777e-05
step = 6, Training Accuracy: 1.0
Training loss = 5.151491224144896e-05
step = 7, Training Accuracy: 1.0
Training loss = 7.2522958119710286e-06
step = 8, Training Accuracy: 1.0
Training loss = 1.725197665412755e-05
step = 9, Training Accuracy: 1.0
Training loss = 9.037935075563534e-06
step = 10, Training Accuracy: 1.0
Validation Accuracy: 0.6775
