parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.03355254505361829
step = 0, Training Accuracy: 0.45321428571428574
Validation Accuracy: 0.5
Training loss = 0.03090250154691083
step = 1, Training Accuracy: 0.48178571428571426
Training loss = 0.030111022836395673
step = 2, Training Accuracy: 0.515
Training loss = 0.02906113062586103
step = 3, Training Accuracy: 0.5523214285714285
Training loss = 0.02752167997615678
step = 4, Training Accuracy: 0.5826785714285714
Training loss = 0.025377477386168072
step = 5, Training Accuracy: 0.6216071428571428
Training loss = 0.024025922470859117
step = 6, Training Accuracy: 0.6482142857142857
Training loss = 0.023713945746421813
step = 7, Training Accuracy: 0.6596428571428572
Training loss = 0.022931492206241404
step = 8, Training Accuracy: 0.6730357142857143
Training loss = 0.022759636268019676
step = 9, Training Accuracy: 0.68125
Validation Accuracy: 0.7375
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.022099764022443975
step = 0, Training Accuracy: 0.6867857142857143
Validation Accuracy: 0.73
Training loss = 0.022449370643922262
step = 1, Training Accuracy: 0.6705357142857142
Training loss = 0.021759100763925485
step = 2, Training Accuracy: 0.6926785714285715
Training loss = 0.022045209242829256
step = 3, Training Accuracy: 0.6798214285714286
Training loss = 0.02123617097735405
step = 4, Training Accuracy: 0.7021428571428572
Training loss = 0.021381058245897294
step = 5, Training Accuracy: 0.70375
Training loss = 0.021258707908647402
step = 6, Training Accuracy: 0.6948214285714286
Training loss = 0.02085441564342805
step = 7, Training Accuracy: 0.7039285714285715
Training loss = 0.02124558498816831
step = 8, Training Accuracy: 0.70125
Training loss = 0.02100869213363954
step = 9, Training Accuracy: 0.6989285714285715
Validation Accuracy: 0.76625
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.020747596291559083
step = 0, Training Accuracy: 0.7098214285714286
Validation Accuracy: 0.74125
Training loss = 0.020641803853213788
step = 1, Training Accuracy: 0.7117857142857142
Training loss = 0.02053065320742982
step = 2, Training Accuracy: 0.7203571428571428
Training loss = 0.02033912838037525
step = 3, Training Accuracy: 0.7085714285714285
Training loss = 0.02003231328512941
step = 4, Training Accuracy: 0.7125
Training loss = 0.01986377272222723
step = 5, Training Accuracy: 0.7132142857142857
Training loss = 0.019948236112083708
step = 6, Training Accuracy: 0.7146428571428571
Training loss = 0.020413285520459925
step = 7, Training Accuracy: 0.71375
Training loss = 0.019896120013935224
step = 8, Training Accuracy: 0.7191071428571428
Training loss = 0.01957380862108299
step = 9, Training Accuracy: 0.7216071428571429
Validation Accuracy: 0.77875
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.01983725701059614
step = 0, Training Accuracy: 0.7180357142857143
Validation Accuracy: 0.77
Training loss = 0.019672188545976365
step = 1, Training Accuracy: 0.7178571428571429
Training loss = 0.019655125715902874
step = 2, Training Accuracy: 0.7198214285714286
Training loss = 0.019859592850719178
step = 3, Training Accuracy: 0.7289285714285715
Training loss = 0.0192662424115198
step = 4, Training Accuracy: 0.7267857142857143
Training loss = 0.01953377377774034
step = 5, Training Accuracy: 0.7216071428571429
Training loss = 0.01958785839378834
step = 6, Training Accuracy: 0.7266071428571429
Training loss = 0.019728002159723215
step = 7, Training Accuracy: 0.7233928571428572
Training loss = 0.01884230471083096
step = 8, Training Accuracy: 0.735
Training loss = 0.018832756355404854
step = 9, Training Accuracy: 0.7319642857142857
Validation Accuracy: 0.7625
gen	nevals	avg    	std      	min   	max    
0  	4     	0.76125	0.0149739	0.7375	0.77875
parameter = [0.49139999999999995, 0.4822000000000001, 0.4465, 0.20230000000000004, 0.19939999999999997, 0.201]
Training loss = 0.019174674366201672
step = 0, Training Accuracy: 0.7292857142857143
Validation Accuracy: 0.76875
Training loss = 0.01925676988703864
step = 1, Training Accuracy: 0.7233928571428572
Training loss = 0.018810742273926734
step = 2, Training Accuracy: 0.7341071428571428
Training loss = 0.019258502157671113
step = 3, Training Accuracy: 0.72625
Training loss = 0.019014625905879906
step = 4, Training Accuracy: 0.7346428571428572
Training loss = 0.018810997466955866
step = 5, Training Accuracy: 0.7405357142857143
Training loss = 0.018693416411323206
step = 6, Training Accuracy: 0.7432142857142857
Training loss = 0.018609307727643423
step = 7, Training Accuracy: 0.7332142857142857
Training loss = 0.018599176635699613
step = 8, Training Accuracy: 0.7360714285714286
Training loss = 0.018679701595434122
step = 9, Training Accuracy: 0.7396428571428572
Validation Accuracy: 0.77625
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.018709545066314084
step = 0, Training Accuracy: 0.7396428571428572
Validation Accuracy: 0.765
Training loss = 0.01823976495968444
step = 1, Training Accuracy: 0.7458928571428571
Training loss = 0.018342527699257646
step = 2, Training Accuracy: 0.7405357142857143
Training loss = 0.018019047656229564
step = 3, Training Accuracy: 0.7460714285714286
Training loss = 0.01807978370626058
step = 4, Training Accuracy: 0.7475
Training loss = 0.018246781857950346
step = 5, Training Accuracy: 0.74125
Training loss = 0.018352030664682387
step = 6, Training Accuracy: 0.7416071428571429
Training loss = 0.018397952121283326
step = 7, Training Accuracy: 0.74125
Training loss = 0.01821906490517514
step = 8, Training Accuracy: 0.745
Training loss = 0.018479797004589012
step = 9, Training Accuracy: 0.7385714285714285
Validation Accuracy: 0.77
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.017876147335129124
step = 0, Training Accuracy: 0.7489285714285714
Validation Accuracy: 0.7675
Training loss = 0.018613836036196776
step = 1, Training Accuracy: 0.7371428571428571
Training loss = 0.018004413385476384
step = 2, Training Accuracy: 0.745
Training loss = 0.018084811940789224
step = 3, Training Accuracy: 0.7507142857142857
Training loss = 0.01808539466666324
step = 4, Training Accuracy: 0.7460714285714286
Training loss = 0.01793506453612021
step = 5, Training Accuracy: 0.7491071428571429
Training loss = 0.01799529380564179
step = 6, Training Accuracy: 0.7419642857142857
Training loss = 0.017955405829208237
step = 7, Training Accuracy: 0.7483928571428572
Training loss = 0.018107984497078827
step = 8, Training Accuracy: 0.7442857142857143
Training loss = 0.017728127323623215
step = 9, Training Accuracy: 0.7476785714285714
Validation Accuracy: 0.78625
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.20100000000000004]
Training loss = 0.018106050193309783
step = 0, Training Accuracy: 0.7496428571428572
Validation Accuracy: 0.78125
Training loss = 0.017463400422462395
step = 1, Training Accuracy: 0.7532142857142857
Training loss = 0.017504807354084082
step = 2, Training Accuracy: 0.7625
Training loss = 0.017629882395267485
step = 3, Training Accuracy: 0.7516071428571428
Training loss = 0.017519435877246515
step = 4, Training Accuracy: 0.75625
Training loss = 0.01744556123656886
step = 5, Training Accuracy: 0.7594642857142857
Training loss = 0.017645639308861323
step = 6, Training Accuracy: 0.7530357142857143
Training loss = 0.017442808268325668
step = 7, Training Accuracy: 0.7507142857142857
Training loss = 0.017491485960781573
step = 8, Training Accuracy: 0.7435714285714285
Training loss = 0.01763853962932314
step = 9, Training Accuracy: 0.7541071428571429
Validation Accuracy: 0.78
parameter = [0.49140000000000006, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.017449844580675875
step = 0, Training Accuracy: 0.7544642857142857
Validation Accuracy: 0.79
Training loss = 0.017400795577892234
step = 1, Training Accuracy: 0.7601785714285715
Training loss = 0.0172547333581107
step = 2, Training Accuracy: 0.7557142857142857
Training loss = 0.017366519910948616
step = 3, Training Accuracy: 0.7501785714285715
Training loss = 0.017652501368096898
step = 4, Training Accuracy: 0.7553571428571428
Training loss = 0.017234662914914746
step = 5, Training Accuracy: 0.7528571428571429
Training loss = 0.01752969793443169
step = 6, Training Accuracy: 0.7539285714285714
Training loss = 0.016970357926828522
step = 7, Training Accuracy: 0.7610714285714286
Training loss = 0.01732902614665883
step = 8, Training Accuracy: 0.7610714285714286
Training loss = 0.01727238314492362
step = 9, Training Accuracy: 0.7532142857142857
Validation Accuracy: 0.79375
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.016630395241081716
step = 0, Training Accuracy: 0.7680357142857143
Validation Accuracy: 0.78125
Training loss = 0.01733596366963216
step = 1, Training Accuracy: 0.7573214285714286
Training loss = 0.017283583506941796
step = 2, Training Accuracy: 0.7598214285714285
Training loss = 0.017213307358324527
step = 3, Training Accuracy: 0.7603571428571428
Training loss = 0.017190891222230026
step = 4, Training Accuracy: 0.7608928571428571
Training loss = 0.01727804252079555
step = 5, Training Accuracy: 0.7496428571428572
Training loss = 0.017405120458986078
step = 6, Training Accuracy: 0.7551785714285715
Training loss = 0.017396364797438894
step = 7, Training Accuracy: 0.7660714285714286
Training loss = 0.01705080290458032
step = 8, Training Accuracy: 0.7621428571428571
Training loss = 0.017021868101188116
step = 9, Training Accuracy: 0.7655357142857143
Validation Accuracy: 0.7875
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.01699227457067796
step = 0, Training Accuracy: 0.7591071428571429
Validation Accuracy: 0.79125
Training loss = 0.017199512661567756
step = 1, Training Accuracy: 0.76
Training loss = 0.017148902857942242
step = 2, Training Accuracy: 0.7576785714285714
Training loss = 0.01703694229147264
step = 3, Training Accuracy: 0.7671428571428571
Training loss = 0.017350623948233466
step = 4, Training Accuracy: 0.7555357142857143
Training loss = 0.016721357836255005
step = 5, Training Accuracy: 0.7673214285714286
Training loss = 0.017321146274251596
step = 6, Training Accuracy: 0.7571428571428571
Training loss = 0.0168778661478843
step = 7, Training Accuracy: 0.7689285714285714
Training loss = 0.0165736951519336
step = 8, Training Accuracy: 0.7728571428571429
Training loss = 0.017232430752898965
step = 9, Training Accuracy: 0.7582142857142857
Validation Accuracy: 0.79875
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.016950856090656347
step = 0, Training Accuracy: 0.7669642857142858
Validation Accuracy: 0.7975
Training loss = 0.017009977458843164
step = 1, Training Accuracy: 0.76375
Training loss = 0.017039422770696026
step = 2, Training Accuracy: 0.7526785714285714
Training loss = 0.017329636524830546
step = 3, Training Accuracy: 0.7546428571428572
Training loss = 0.01724484829498189
step = 4, Training Accuracy: 0.7646428571428572
Training loss = 0.01659960076212883
step = 5, Training Accuracy: 0.7717857142857143
Training loss = 0.016960222343248982
step = 6, Training Accuracy: 0.7623214285714286
Training loss = 0.017042269249047552
step = 7, Training Accuracy: 0.7630357142857143
Training loss = 0.016967570366603988
step = 8, Training Accuracy: 0.7641071428571429
Training loss = 0.016717254727014474
step = 9, Training Accuracy: 0.7623214285714286
Validation Accuracy: 0.7975
1  	8     	0.794687	0.00462458	0.7875	0.79875
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.01709162830774273
step = 0, Training Accuracy: 0.7582142857142857
Validation Accuracy: 0.8025
Training loss = 0.017043766948793615
step = 1, Training Accuracy: 0.7607142857142857
Training loss = 0.01713673939130136
step = 2, Training Accuracy: 0.7571428571428571
Training loss = 0.0167856028303504
step = 3, Training Accuracy: 0.7669642857142858
Training loss = 0.016856698484293053
step = 4, Training Accuracy: 0.7598214285714285
Training loss = 0.01695139331477029
step = 5, Training Accuracy: 0.7571428571428571
Training loss = 0.017033854818769862
step = 6, Training Accuracy: 0.765
Training loss = 0.016460730193981102
step = 7, Training Accuracy: 0.7741071428571429
Training loss = 0.017017566678779465
step = 8, Training Accuracy: 0.7626785714285714
Training loss = 0.0167806495779327
step = 9, Training Accuracy: 0.7676785714285714
Validation Accuracy: 0.79
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.01705060794417347
step = 0, Training Accuracy: 0.7607142857142857
Validation Accuracy: 0.7925
Training loss = 0.016722535666610513
step = 1, Training Accuracy: 0.7651785714285714
Training loss = 0.017007214102361883
step = 2, Training Accuracy: 0.7675
Training loss = 0.016821893086390836
step = 3, Training Accuracy: 0.7648214285714285
Training loss = 0.01675588541265045
step = 4, Training Accuracy: 0.7671428571428571
Training loss = 0.016818629072180815
step = 5, Training Accuracy: 0.7632142857142857
Training loss = 0.017088156464908803
step = 6, Training Accuracy: 0.76125
Training loss = 0.01710681056337697
step = 7, Training Accuracy: 0.7585714285714286
Training loss = 0.016684455733214105
step = 8, Training Accuracy: 0.7685714285714286
Training loss = 0.017161324535097396
step = 9, Training Accuracy: 0.765
Validation Accuracy: 0.795
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.01659678620419332
step = 0, Training Accuracy: 0.7669642857142858
Validation Accuracy: 0.78875
Training loss = 0.017105566348348346
step = 1, Training Accuracy: 0.7582142857142857
Training loss = 0.01688490624406508
step = 2, Training Accuracy: 0.7657142857142857
Training loss = 0.016482123019439833
step = 3, Training Accuracy: 0.7676785714285714
Training loss = 0.016676718810839312
step = 4, Training Accuracy: 0.7714285714285715
Training loss = 0.01666567847664867
step = 5, Training Accuracy: 0.77125
Training loss = 0.01669255796287741
step = 6, Training Accuracy: 0.76125
Training loss = 0.016660625460956778
step = 7, Training Accuracy: 0.7626785714285714
Training loss = 0.016866515784391335
step = 8, Training Accuracy: 0.7653571428571428
Training loss = 0.01682045280667288
step = 9, Training Accuracy: 0.7605357142857143
Validation Accuracy: 0.78375
parameter = [0.49140000000000006, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.017039423968110767
step = 0, Training Accuracy: 0.7626785714285714
Validation Accuracy: 0.7925
Training loss = 0.016391691203628267
step = 1, Training Accuracy: 0.7701785714285714
Training loss = 0.016663727941257613
step = 2, Training Accuracy: 0.7644642857142857
Training loss = 0.016824180632829665
step = 3, Training Accuracy: 0.7673214285714286
Training loss = 0.016730860008725097
step = 4, Training Accuracy: 0.7657142857142857
Training loss = 0.01671969502632107
step = 5, Training Accuracy: 0.7732142857142857
Training loss = 0.016931071685893195
step = 6, Training Accuracy: 0.7639285714285714
Training loss = 0.016637342753154892
step = 7, Training Accuracy: 0.7716071428571428
Training loss = 0.016709432820124284
step = 8, Training Accuracy: 0.7696428571428572
Training loss = 0.016770379820040295
step = 9, Training Accuracy: 0.7666071428571428
Validation Accuracy: 0.7925
parameter = [0.49140000000000006, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.01662856247808252
step = 0, Training Accuracy: 0.7678571428571429
Validation Accuracy: 0.79
Training loss = 0.016609544099441598
step = 1, Training Accuracy: 0.7685714285714286
Training loss = 0.01629149452384029
step = 2, Training Accuracy: 0.7748214285714285
Training loss = 0.016596364879182406
step = 3, Training Accuracy: 0.765
Training loss = 0.016884579030530793
step = 4, Training Accuracy: 0.7707142857142857
Training loss = 0.01678518934441464
step = 5, Training Accuracy: 0.77
Training loss = 0.016482336393424443
step = 6, Training Accuracy: 0.76875
Training loss = 0.016717970541545325
step = 7, Training Accuracy: 0.7730357142857143
Training loss = 0.01682082623243332
step = 8, Training Accuracy: 0.7641071428571429
Training loss = 0.01665974776659693
step = 9, Training Accuracy: 0.7757142857142857
Validation Accuracy: 0.79125
parameter = [0.49140000000000006, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016791318000427314
step = 0, Training Accuracy: 0.7726785714285714
Validation Accuracy: 0.79125
Training loss = 0.016889361427830797
step = 1, Training Accuracy: 0.7621428571428571
Training loss = 0.016512932628393172
step = 2, Training Accuracy: 0.7707142857142857
Training loss = 0.016980316511222296
step = 3, Training Accuracy: 0.76
Training loss = 0.01651610379772527
step = 4, Training Accuracy: 0.77375
Training loss = 0.016556566719497953
step = 5, Training Accuracy: 0.7730357142857143
Training loss = 0.017140534876712733
step = 6, Training Accuracy: 0.7605357142857143
Training loss = 0.01685551596539361
step = 7, Training Accuracy: 0.7628571428571429
Training loss = 0.01676303587321724
step = 8, Training Accuracy: 0.7691071428571429
Training loss = 0.01699929539114237
step = 9, Training Accuracy: 0.7628571428571429
Validation Accuracy: 0.7825
parameter = [0.49140000000000006, 0.4822000000000001, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.016653566589312895
step = 0, Training Accuracy: 0.7691071428571429
Validation Accuracy: 0.79125
Training loss = 0.01658451413469655
step = 1, Training Accuracy: 0.7689285714285714
Training loss = 0.016353686143245016
step = 2, Training Accuracy: 0.7755357142857143
Training loss = 0.01677255457001073
step = 3, Training Accuracy: 0.7680357142857143
Training loss = 0.01705224260155644
step = 4, Training Accuracy: 0.7646428571428572
Training loss = 0.01641308687095131
step = 5, Training Accuracy: 0.7782142857142857
Training loss = 0.016730908011751516
step = 6, Training Accuracy: 0.77
Training loss = 0.016526064489568983
step = 7, Training Accuracy: 0.7644642857142857
Training loss = 0.01686503304434674
step = 8, Training Accuracy: 0.76375
Training loss = 0.01687914882919618
step = 9, Training Accuracy: 0.76625
Validation Accuracy: 0.7975
parameter = [0.49139999999999995, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016450941296560422
step = 0, Training Accuracy: 0.7692857142857142
Validation Accuracy: 0.79125
Training loss = 0.01666594990129982
step = 1, Training Accuracy: 0.7696428571428572
Training loss = 0.01685155511168497
step = 2, Training Accuracy: 0.7733928571428571
Training loss = 0.016595324320452555
step = 3, Training Accuracy: 0.7655357142857143
Training loss = 0.01656634821955647
step = 4, Training Accuracy: 0.7671428571428571
Training loss = 0.016710983935211386
step = 5, Training Accuracy: 0.7764285714285715
Training loss = 0.016930575392075948
step = 6, Training Accuracy: 0.7658928571428572
Training loss = 0.01676810883251684
step = 7, Training Accuracy: 0.7666071428571428
Training loss = 0.016672999449074268
step = 8, Training Accuracy: 0.76875
Training loss = 0.016632781230977604
step = 9, Training Accuracy: 0.76875
Validation Accuracy: 0.79125
2  	8     	0.793438	0.0016238 	0.79125	0.795  
parameter = [0.49139999999999995, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.01631234538874456
step = 0, Training Accuracy: 0.7764285714285715
Validation Accuracy: 0.7925
Training loss = 0.016749852358230524
step = 1, Training Accuracy: 0.7658928571428572
Training loss = 0.016468882044511184
step = 2, Training Accuracy: 0.7716071428571428
Training loss = 0.01651520467762436
step = 3, Training Accuracy: 0.7689285714285714
Training loss = 0.016444722030844006
step = 4, Training Accuracy: 0.7683928571428571
Training loss = 0.016807739926236017
step = 5, Training Accuracy: 0.7666071428571428
Training loss = 0.01681656352643456
step = 6, Training Accuracy: 0.76875
Training loss = 0.01675606684493167
step = 7, Training Accuracy: 0.765
Training loss = 0.01667801252433232
step = 8, Training Accuracy: 0.7658928571428572
Training loss = 0.016496882497199945
step = 9, Training Accuracy: 0.7725
Validation Accuracy: 0.78625
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.016265781532440866
step = 0, Training Accuracy: 0.7726785714285714
Validation Accuracy: 0.79125
Training loss = 0.016593354147459778
step = 1, Training Accuracy: 0.7742857142857142
Training loss = 0.016648331130189556
step = 2, Training Accuracy: 0.7723214285714286
Training loss = 0.01682711236178875
step = 3, Training Accuracy: 0.7648214285714285
Training loss = 0.01664408103163753
step = 4, Training Accuracy: 0.7707142857142857
Training loss = 0.016627205280320984
step = 5, Training Accuracy: 0.7660714285714286
Training loss = 0.016511953297470298
step = 6, Training Accuracy: 0.7669642857142858
Training loss = 0.01671218602252858
step = 7, Training Accuracy: 0.7632142857142857
Training loss = 0.016204369797238282
step = 8, Training Accuracy: 0.7796428571428572
Training loss = 0.017055591903626918
step = 9, Training Accuracy: 0.7673214285714286
Validation Accuracy: 0.79
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016354733854532243
step = 0, Training Accuracy: 0.7783928571428571
Validation Accuracy: 0.7925
Training loss = 0.016736197703118835
step = 1, Training Accuracy: 0.7621428571428571
Training loss = 0.016380000987223215
step = 2, Training Accuracy: 0.7701785714285714
Training loss = 0.016857398743075985
step = 3, Training Accuracy: 0.7617857142857143
Training loss = 0.016635833169732776
step = 4, Training Accuracy: 0.7782142857142857
Training loss = 0.01686514073982835
step = 5, Training Accuracy: 0.7698214285714285
Training loss = 0.016710418963006565
step = 6, Training Accuracy: 0.76625
Training loss = 0.016739647979182856
step = 7, Training Accuracy: 0.7701785714285714
Training loss = 0.0166534354111978
step = 8, Training Accuracy: 0.765
Training loss = 0.016573377661406995
step = 9, Training Accuracy: 0.7689285714285714
Validation Accuracy: 0.79
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016521254011562892
step = 0, Training Accuracy: 0.7746428571428572
Validation Accuracy: 0.78375
Training loss = 0.016665643400379588
step = 1, Training Accuracy: 0.7692857142857142
Training loss = 0.016978435670690878
step = 2, Training Accuracy: 0.7578571428571429
Training loss = 0.01675532016903162
step = 3, Training Accuracy: 0.7725
Training loss = 0.016613866191889558
step = 4, Training Accuracy: 0.77
Training loss = 0.016668333102549827
step = 5, Training Accuracy: 0.7739285714285714
Training loss = 0.016938313485256262
step = 6, Training Accuracy: 0.7676785714285714
Training loss = 0.016661024189421107
step = 7, Training Accuracy: 0.7633928571428571
Training loss = 0.016824603032852922
step = 8, Training Accuracy: 0.7658928571428572
Training loss = 0.01698497062548995
step = 9, Training Accuracy: 0.7655357142857143
Validation Accuracy: 0.78875
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.017128472748611654
step = 0, Training Accuracy: 0.7566071428571428
Validation Accuracy: 0.7875
Training loss = 0.016954971136791366
step = 1, Training Accuracy: 0.7625
Training loss = 0.016336883514055184
step = 2, Training Accuracy: 0.7760714285714285
Training loss = 0.016651414606188023
step = 3, Training Accuracy: 0.7705357142857143
Training loss = 0.016795017479785852
step = 4, Training Accuracy: 0.7641071428571429
Training loss = 0.01674867090369974
step = 5, Training Accuracy: 0.7723214285714286
Training loss = 0.016606502777763776
step = 6, Training Accuracy: 0.7653571428571428
Training loss = 0.01652387836681945
step = 7, Training Accuracy: 0.7726785714285714
Training loss = 0.016748750039509364
step = 8, Training Accuracy: 0.7666071428571428
Training loss = 0.01659096181924854
step = 9, Training Accuracy: 0.7703571428571429
Validation Accuracy: 0.78625
parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016718016676604747
step = 0, Training Accuracy: 0.7639285714285714
Validation Accuracy: 0.7875
Training loss = 0.016537113705916064
step = 1, Training Accuracy: 0.7710714285714285
Training loss = 0.016406350689274925
step = 2, Training Accuracy: 0.7694642857142857
Training loss = 0.016467942020722798
step = 3, Training Accuracy: 0.7703571428571429
Training loss = 0.016439843768520014
step = 4, Training Accuracy: 0.7717857142857143
Training loss = 0.016291820619787487
step = 5, Training Accuracy: 0.7705357142857143
Training loss = 0.016734032426029444
step = 6, Training Accuracy: 0.7660714285714286
Training loss = 0.016738355856920992
step = 7, Training Accuracy: 0.7660714285714286
Training loss = 0.016674489054296696
step = 8, Training Accuracy: 0.7623214285714286
Training loss = 0.016577281898685865
step = 9, Training Accuracy: 0.7691071428571429
Validation Accuracy: 0.7875
parameter = [0.49139999999999995, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.01619873580123697
step = 0, Training Accuracy: 0.7814285714285715
Validation Accuracy: 0.79125
Training loss = 0.016476350096719605
step = 1, Training Accuracy: 0.7742857142857142
Training loss = 0.01649232597489442
step = 2, Training Accuracy: 0.7748214285714285
Training loss = 0.016642533487507275
step = 3, Training Accuracy: 0.7716071428571428
Training loss = 0.017081612588039467
step = 4, Training Accuracy: 0.7628571428571429
Training loss = 0.01691052898232426
step = 5, Training Accuracy: 0.7644642857142857
Training loss = 0.016541691688554627
step = 6, Training Accuracy: 0.7714285714285715
Training loss = 0.01677460397992815
step = 7, Training Accuracy: 0.7628571428571429
Training loss = 0.016398280885602745
step = 8, Training Accuracy: 0.7664285714285715
Training loss = 0.016623996309936048
step = 9, Training Accuracy: 0.7669642857142858
Validation Accuracy: 0.79
parameter = [0.4914, 0.4822, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.016465663316526585
step = 0, Training Accuracy: 0.7689285714285714
Validation Accuracy: 0.795
Training loss = 0.016685850588338717
step = 1, Training Accuracy: 0.7633928571428571
Training loss = 0.01677637462637254
step = 2, Training Accuracy: 0.7651785714285714
Training loss = 0.016754701930497374
step = 3, Training Accuracy: 0.7658928571428572
Training loss = 0.017031957884984357
step = 4, Training Accuracy: 0.7633928571428571
Training loss = 0.016610870345362596
step = 5, Training Accuracy: 0.7773214285714286
Training loss = 0.016697602963873317
step = 6, Training Accuracy: 0.7689285714285714
Training loss = 0.016850779285388334
step = 7, Training Accuracy: 0.7651785714285714
Training loss = 0.01666924283440624
step = 8, Training Accuracy: 0.7648214285714285
Training loss = 0.01640947040170431
step = 9, Training Accuracy: 0.7675
Validation Accuracy: 0.79625
3  	8     	0.791563	0.00270633	0.79   	0.79625
parameter = [0.49139999999999995, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016274693400732107
step = 0, Training Accuracy: 0.77
Validation Accuracy: 0.7875
Training loss = 0.01664108300315482
step = 1, Training Accuracy: 0.7648214285714285
Training loss = 0.016574117650410957
step = 2, Training Accuracy: 0.7685714285714286
Training loss = 0.016796735690108366
step = 3, Training Accuracy: 0.76375
Training loss = 0.01641066742794854
step = 4, Training Accuracy: 0.7725
Training loss = 0.016810956512178694
step = 5, Training Accuracy: 0.76125
Training loss = 0.016627998815051146
step = 6, Training Accuracy: 0.7696428571428572
Training loss = 0.01686527940311602
step = 7, Training Accuracy: 0.7676785714285714
Training loss = 0.016827980476830685
step = 8, Training Accuracy: 0.7605357142857143
Training loss = 0.0165279463997909
step = 9, Training Accuracy: 0.7689285714285714
Validation Accuracy: 0.79125
parameter = [0.49139999999999995, 0.4822, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.0165211466620011
step = 0, Training Accuracy: 0.7725
Validation Accuracy: 0.795
Training loss = 0.016600317108844007
step = 1, Training Accuracy: 0.7616071428571428
Training loss = 0.016878971430872167
step = 2, Training Accuracy: 0.7644642857142857
Training loss = 0.016487531374607768
step = 3, Training Accuracy: 0.7723214285714286
Training loss = 0.01671759730471032
step = 4, Training Accuracy: 0.76625
Training loss = 0.016309975183435847
step = 5, Training Accuracy: 0.7705357142857143
Training loss = 0.016425462660512754
step = 6, Training Accuracy: 0.7714285714285715
Training loss = 0.016453878954052925
step = 7, Training Accuracy: 0.7757142857142857
Training loss = 0.016577089420918907
step = 8, Training Accuracy: 0.7648214285714285
Training loss = 0.016867444262440714
step = 9, Training Accuracy: 0.7619642857142858
Validation Accuracy: 0.78875
parameter = [0.49139999999999995, 0.4822000000000001, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.016957903158451828
step = 0, Training Accuracy: 0.7623214285714286
Validation Accuracy: 0.79125
Training loss = 0.016796497186379773
step = 1, Training Accuracy: 0.7617857142857143
Training loss = 0.0167394785795893
step = 2, Training Accuracy: 0.7683928571428571
Training loss = 0.016687923456941332
step = 3, Training Accuracy: 0.7664285714285715
Training loss = 0.01635146778076887
step = 4, Training Accuracy: 0.7682142857142857
Training loss = 0.016928107552230356
step = 5, Training Accuracy: 0.7603571428571428
Training loss = 0.016655163639890298
step = 6, Training Accuracy: 0.7646428571428572
Training loss = 0.016910873747297696
step = 7, Training Accuracy: 0.7685714285714286
Training loss = 0.016494506698633945
step = 8, Training Accuracy: 0.7692857142857142
Training loss = 0.016847343796065877
step = 9, Training Accuracy: 0.7655357142857143
Validation Accuracy: 0.79375
parameter = [0.4914, 0.4822, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.20099999999999998]
Training loss = 0.016774944423564843
step = 0, Training Accuracy: 0.7675
Validation Accuracy: 0.79375
Training loss = 0.01692350498799767
step = 1, Training Accuracy: 0.7669642857142858
Training loss = 0.016921706646680832
step = 2, Training Accuracy: 0.7644642857142857
Training loss = 0.016630083748272486
step = 3, Training Accuracy: 0.7682142857142857
Training loss = 0.017052649445831777
step = 4, Training Accuracy: 0.7623214285714286
Training loss = 0.016753128532852445
step = 5, Training Accuracy: 0.7623214285714286
Training loss = 0.016554741987160275
step = 6, Training Accuracy: 0.7678571428571429
Training loss = 0.01665546279400587
step = 7, Training Accuracy: 0.7675
Training loss = 0.017082008735409805
step = 8, Training Accuracy: 0.7603571428571428
Training loss = 0.01675158982830388
step = 9, Training Accuracy: 0.7667857142857143
Validation Accuracy: 0.79
parameter = [0.49140000000000006, 0.48219999999999996, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.016540884843894415
step = 0, Training Accuracy: 0.7689285714285714
Validation Accuracy: 0.7975
Training loss = 0.016485104071242467
step = 1, Training Accuracy: 0.7653571428571428
Training loss = 0.01646330771169492
step = 2, Training Accuracy: 0.7755357142857143
Training loss = 0.01682678562722036
step = 3, Training Accuracy: 0.7698214285714285
Training loss = 0.016768496802874972
step = 4, Training Accuracy: 0.7705357142857143
Training loss = 0.016365907133689947
step = 5, Training Accuracy: 0.7655357142857143
Training loss = 0.01660090444875615
step = 6, Training Accuracy: 0.76875
Training loss = 0.016703120283782482
step = 7, Training Accuracy: 0.7655357142857143
Training loss = 0.01687366193426507
step = 8, Training Accuracy: 0.7625
Training loss = 0.016551897105361733
step = 9, Training Accuracy: 0.7701785714285714
Validation Accuracy: 0.79375
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016695729637784616
step = 0, Training Accuracy: 0.76625
Validation Accuracy: 0.79
Training loss = 0.016742397599986622
step = 1, Training Accuracy: 0.76375
Training loss = 0.01686794465673821
step = 2, Training Accuracy: 0.7655357142857143
Training loss = 0.016859555111399718
step = 3, Training Accuracy: 0.7619642857142858
Training loss = 0.01671037365815469
step = 4, Training Accuracy: 0.7694642857142857
Training loss = 0.01639231491301741
step = 5, Training Accuracy: 0.77375
Training loss = 0.016339192640568528
step = 6, Training Accuracy: 0.77
Training loss = 0.0165973162651062
step = 7, Training Accuracy: 0.7680357142857143
Training loss = 0.016802731140383654
step = 8, Training Accuracy: 0.7708928571428572
Training loss = 0.016776164802057403
step = 9, Training Accuracy: 0.7614285714285715
Validation Accuracy: 0.79
4  	6     	0.794063	0.00255792	0.79   	0.79625
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.016767175657940763
step = 0, Training Accuracy: 0.7655357142857143
Validation Accuracy: 0.795
Training loss = 0.016650145913341217
step = 1, Training Accuracy: 0.7717857142857143
Training loss = 0.016626384971397262
step = 2, Training Accuracy: 0.7658928571428572
Training loss = 0.016335122609244926
step = 3, Training Accuracy: 0.7730357142857143
Training loss = 0.016990470620138306
step = 4, Training Accuracy: 0.7598214285714285
Training loss = 0.016498050460858005
step = 5, Training Accuracy: 0.7689285714285714
Training loss = 0.01681898443826607
step = 6, Training Accuracy: 0.7669642857142858
Training loss = 0.016702991082732165
step = 7, Training Accuracy: 0.7696428571428572
Training loss = 0.01653497683150428
step = 8, Training Accuracy: 0.7689285714285714
Training loss = 0.016599990837275983
step = 9, Training Accuracy: 0.7694642857142857
Validation Accuracy: 0.79125
parameter = [0.49139999999999995, 0.4822000000000001, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.016707591739084038
step = 0, Training Accuracy: 0.7630357142857143
Validation Accuracy: 0.79625
Training loss = 0.016919359910701003
step = 1, Training Accuracy: 0.7651785714285714
Training loss = 0.016512301686619008
step = 2, Training Accuracy: 0.7642857142857142
Training loss = 0.016457578601049527
step = 3, Training Accuracy: 0.76375
Training loss = 0.016770311700446267
step = 4, Training Accuracy: 0.7651785714285714
Training loss = 0.016620848604610987
step = 5, Training Accuracy: 0.7646428571428572
Training loss = 0.01647185021213123
step = 6, Training Accuracy: 0.76875
Training loss = 0.016400633318615812
step = 7, Training Accuracy: 0.76625
Training loss = 0.01661469107227666
step = 8, Training Accuracy: 0.7691071428571429
Training loss = 0.016468234501246896
step = 9, Training Accuracy: 0.7676785714285714
Validation Accuracy: 0.79375
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.2023, 0.19939999999999997, 0.201]
Training loss = 0.016371997392603328
step = 0, Training Accuracy: 0.7725
Validation Accuracy: 0.78875
Training loss = 0.01649177568831614
step = 1, Training Accuracy: 0.7717857142857143
Training loss = 0.01631281672843865
step = 2, Training Accuracy: 0.7728571428571429
Training loss = 0.017013601240302836
step = 3, Training Accuracy: 0.7614285714285715
Training loss = 0.016795741974243095
step = 4, Training Accuracy: 0.7685714285714286
Training loss = 0.016463373372597352
step = 5, Training Accuracy: 0.7703571428571429
Training loss = 0.0162299110101802
step = 6, Training Accuracy: 0.7721428571428571
Training loss = 0.016683524048754148
step = 7, Training Accuracy: 0.7685714285714286
Training loss = 0.016702075893325466
step = 8, Training Accuracy: 0.7664285714285715
Training loss = 0.016418880431779793
step = 9, Training Accuracy: 0.7669642857142858
Validation Accuracy: 0.79
parameter = [0.49139999999999995, 0.48219999999999996, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.01693790225578206
step = 0, Training Accuracy: 0.76
Validation Accuracy: 0.7925
Training loss = 0.01651916589587927
step = 1, Training Accuracy: 0.7678571428571429
Training loss = 0.016610119632844415
step = 2, Training Accuracy: 0.7701785714285714
Training loss = 0.017004685141146184
step = 3, Training Accuracy: 0.7616071428571428
Training loss = 0.016503227991717204
step = 4, Training Accuracy: 0.7669642857142858
Training loss = 0.016691032786454472
step = 5, Training Accuracy: 0.76875
Training loss = 0.016538127070026738
step = 6, Training Accuracy: 0.7689285714285714
Training loss = 0.016744470734681403
step = 7, Training Accuracy: 0.7655357142857143
Training loss = 0.01684221691851105
step = 8, Training Accuracy: 0.7583928571428571
Training loss = 0.016563030273786614
step = 9, Training Accuracy: 0.7680357142857143
Validation Accuracy: 0.79375
parameter = [0.4914, 0.4822000000000001, 0.4465, 0.20229999999999998, 0.19939999999999997, 0.201]
Training loss = 0.01685792952243771
step = 0, Training Accuracy: 0.7669642857142858
Validation Accuracy: 0.7925
Training loss = 0.016624431876199587
step = 1, Training Accuracy: 0.7691071428571429
Training loss = 0.016957027576863765
step = 2, Training Accuracy: 0.7591071428571429
Training loss = 0.016778483039566448
step = 3, Training Accuracy: 0.7660714285714286
Training loss = 0.016664659636361257
step = 4, Training Accuracy: 0.7680357142857143
Training loss = 0.016517310568264554
step = 5, Training Accuracy: 0.7721428571428571
