params:  [0.4490142459033698, 0.4959508325786198, 0.01, 0.4467634736309567, 0.6337469050086934, 0.5626590785014266, 0.01, 0.15709974088602646, 0.39239170409407037, 0.7215399739986231, 0.38474381769032445, 0.2986388486168612, 0.2430022246565467, 0.05644340288977179, 0.06180836871206377, 0.356247728646413, 0.5171366678656747, 0.6030854868705384, 0.01, 0.2972251908184385, 0.38447531587510503, 0.29692339990821237, 0.43350288665226033, 0.6092998567487853, 0.7793840357348596, 0.01, 0.7254181054264539, 0.09937902942106919, 0.5926635381367078, 0.99, 0.01, 0.01, 0.06980839302435851, 0.4585207096486446, 0.527639894763541, 0.7569089569224076, 0.1797539875829992, 0.4297589129152458, 0.6737638446522174, 0.7302304187458726, 0.3591576842195144, 0.41276801307578936, 0.3609746921562613, 0.01, 0.5725886814698102, 0.01, 0.01, 0.29798040789437485, 0.1961506638996729, 0.29427419977858216, 0.01, 0.5763088895994126, 0.9396946306764662, 0.26560044318737264, 0.32025846140637715, 0.01, 0.1366851826424452, 0.5332767769129598, 0.15470192677330918, 0.6127094055037016, 0.2840467374815874, 0.4443023070008549]
[0.4490142459033698, 0.4959508325786198, 0.01, 0.4467634736309567, 0.6337469050086934, 0.5626590785014266, 0.01, 0.15709974088602646, 0.39239170409407037, 0.7215399739986231, 0.38474381769032445, 0.2986388486168612, 0.2430022246565467, 0.05644340288977179, 0.06180836871206377, 0.356247728646413, 0.5171366678656747, 0.6030854868705384, 0.01, 0.2972251908184385, 0.38447531587510503, 0.29692339990821237, 0.43350288665226033, 0.6092998567487853, 0.7793840357348596, 0.01, 0.7254181054264539, 0.09937902942106919, 0.5926635381367078, 0.99, 0.01, 0.01, 0.06980839302435851, 0.4585207096486446, 0.527639894763541, 0.7569089569224076, 0.1797539875829992, 0.4297589129152458, 0.6737638446522174, 0.7302304187458726, 0.3591576842195144, 0.41276801307578936, 0.3609746921562613, 0.01, 0.5725886814698102, 0.01, 0.01, 0.29798040789437485, 0.1961506638996729, 0.29427419977858216, 0.01, 0.5763088895994126, 0.9396946306764662, 0.26560044318737264, 0.32025846140637715, 0.01, 0.1366851826424452, 0.5332767769129598, 0.15470192677330918, 0.6127094055037016, 0.2840467374815874, 0.4443023070008549]
Training loss = 0.04265468160311381
step = 0, Training Accuracy: 0.31666666666666665
Validation Accuracy: 0.30375
Training loss = 0.043479044834772745
step = 1, Training Accuracy: 0.41333333333333333
Training loss = 0.04288043260574341
step = 2, Training Accuracy: 0.38333333333333336
Training loss = 0.038863051732381186
step = 3, Training Accuracy: 0.38
Training loss = 0.03701184113820394
step = 4, Training Accuracy: 0.4066666666666667
Training loss = 0.03591239333152771
step = 5, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.4725
Training loss = 0.035378883282343544
step = 6, Training Accuracy: 0.47
Training loss = 0.03443868478139241
step = 7, Training Accuracy: 0.46
Training loss = 0.035706172386805214
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03536111315091451
step = 9, Training Accuracy: 0.4766666666666667
Training loss = 0.03292871554692586
step = 10, Training Accuracy: 0.52
Validation Accuracy: 0.5025
Training loss = 0.032541852990786234
step = 11, Training Accuracy: 0.52
Training loss = 0.03325549383958181
step = 12, Training Accuracy: 0.44666666666666666
Training loss = 0.032194476723670956
step = 13, Training Accuracy: 0.4666666666666667
Training loss = 0.03273639221986135
step = 14, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.51375
params:  [0.01, 0.3823675540603527, 0.01, 0.2888360831193728, 0.99, 0.5015340369927382, 0.26295719332078926, 0.13094433294043134, 0.2071397365037256, 0.3971856450419692, 0.09265015256684767, 0.28494761983353056, 0.4545485903776948, 0.99, 0.27726511721682934, 0.9208382932808297, 0.17766622527014986, 0.01, 0.49204583736523494, 0.21806906298230794, 0.99, 0.44229171056566324, 0.3404642027000837, 0.289586469088427, 0.1493965887141404, 0.433755935263597, 0.99, 0.23730958411291406, 0.02718376356157831, 0.40170135602066953, 0.01, 0.34059349715986675, 0.27912326480441213, 0.1411380127757988, 0.5770910800515927, 0.7068720085712469, 0.22839696352589983, 0.8010598693676072, 0.30849080751429026, 0.30646407361846273, 0.6084186816525242, 0.7114109699397908, 0.48925218826701455, 0.5011391284902336, 0.01, 0.7132374179792338, 0.492780787138118, 0.37696446152690644, 0.5275282329606507, 0.01, 0.13409843364874643, 0.99, 0.9433682134224548, 0.17785226785123912, 0.05745191913204373, 0.09947288692463904, 0.5746206353106222, 0.5986253328979053, 0.3410719388698884, 0.6539802299340068, 0.5523733438495517, 0.07944468116231573]
[0.01, 0.3823675540603527, 0.01, 0.2888360831193728, 0.99, 0.5015340369927382, 0.26295719332078926, 0.13094433294043134, 0.2071397365037256, 0.3971856450419692, 0.09265015256684767, 0.28494761983353056, 0.4545485903776948, 0.99, 0.27726511721682934, 0.9208382932808297, 0.17766622527014986, 0.01, 0.49204583736523494, 0.21806906298230794, 0.99, 0.44229171056566324, 0.3404642027000837, 0.289586469088427, 0.1493965887141404, 0.433755935263597, 0.99, 0.23730958411291406, 0.02718376356157831, 0.40170135602066953, 0.01, 0.34059349715986675, 0.27912326480441213, 0.1411380127757988, 0.5770910800515927, 0.7068720085712469, 0.22839696352589983, 0.8010598693676072, 0.30849080751429026, 0.30646407361846273, 0.6084186816525242, 0.7114109699397908, 0.48925218826701455, 0.5011391284902336, 0.01, 0.7132374179792338, 0.492780787138118, 0.37696446152690644, 0.5275282329606507, 0.01, 0.13409843364874643, 0.99, 0.9433682134224548, 0.17785226785123912, 0.05745191913204373, 0.09947288692463904, 0.5746206353106222, 0.5986253328979053, 0.3410719388698884, 0.6539802299340068, 0.5523733438495517, 0.07944468116231573]
Training loss = 0.03725245396296183
step = 0, Training Accuracy: 0.39
Validation Accuracy: 0.45125
Training loss = 0.03695935606956482
step = 1, Training Accuracy: 0.37666666666666665
Training loss = 0.03525010704994202
step = 2, Training Accuracy: 0.44333333333333336
Training loss = 0.03378014882405599
step = 3, Training Accuracy: 0.47
Training loss = 0.034861107071240745
step = 4, Training Accuracy: 0.45
Training loss = 0.033590893348058065
step = 5, Training Accuracy: 0.48
Validation Accuracy: 0.49875
Training loss = 0.03386450966199239
step = 6, Training Accuracy: 0.5066666666666667
Training loss = 0.03226658523082733
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.03392536362012227
step = 8, Training Accuracy: 0.4766666666666667
Training loss = 0.033758462468783064
step = 9, Training Accuracy: 0.52
Training loss = 0.03383198002974192
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.51375
Training loss = 0.03256670316060384
step = 11, Training Accuracy: 0.5066666666666667
Training loss = 0.033113030195236204
step = 12, Training Accuracy: 0.48
Training loss = 0.03291538635889689
step = 13, Training Accuracy: 0.5366666666666666
Training loss = 0.031717872619628905
step = 14, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.54
params:  [0.47605712814008105, 0.99, 0.34214987627353627, 0.01, 0.99, 0.20759549893180357, 0.5694587144560689, 0.9031342292577769, 0.08712863782782018, 0.7890128387732965, 0.4571676114142828, 0.5799513813316803, 0.9023712281295175, 0.42638356519913884, 0.01, 0.43296116440224475, 0.01, 0.4768694871757687, 0.6023455924449932, 0.2830072397990057, 0.7481549747108072, 0.5039005675633721, 0.6860602231471951, 0.2206029500286132, 0.99, 0.2786092952385928, 0.5610345512569335, 0.01, 0.4447417245729556, 0.2856945745920897, 0.13792174198960439, 0.11967610914830107, 0.045992583526452774, 0.99, 0.03617243579412682, 0.13011068111916843, 0.2798954095262924, 0.3489573037651402, 0.01, 0.5205688924418082, 0.18130888588216854, 0.3920777291905545, 0.22417272972985908, 0.49672635325129355, 0.26502401229912886, 0.370048211804964, 0.7107218318775677, 0.09740737173648012, 0.5682379803812388, 0.5921428262847284, 0.01, 0.99, 0.577964838274527, 0.5678801948665264, 0.01, 0.01, 0.45658246968506927, 0.5890954019699558, 0.575147855103763, 0.6039344628490927, 0.27387915069275315, 0.7142001482276276]
[0.47605712814008105, 0.99, 0.34214987627353627, 0.01, 0.99, 0.20759549893180357, 0.5694587144560689, 0.9031342292577769, 0.08712863782782018, 0.7890128387732965, 0.4571676114142828, 0.5799513813316803, 0.9023712281295175, 0.42638356519913884, 0.01, 0.43296116440224475, 0.01, 0.4768694871757687, 0.6023455924449932, 0.2830072397990057, 0.7481549747108072, 0.5039005675633721, 0.6860602231471951, 0.2206029500286132, 0.99, 0.2786092952385928, 0.5610345512569335, 0.01, 0.4447417245729556, 0.2856945745920897, 0.13792174198960439, 0.11967610914830107, 0.045992583526452774, 0.99, 0.03617243579412682, 0.13011068111916843, 0.2798954095262924, 0.3489573037651402, 0.01, 0.5205688924418082, 0.18130888588216854, 0.3920777291905545, 0.22417272972985908, 0.49672635325129355, 0.26502401229912886, 0.370048211804964, 0.7107218318775677, 0.09740737173648012, 0.5682379803812388, 0.5921428262847284, 0.01, 0.99, 0.577964838274527, 0.5678801948665264, 0.01, 0.01, 0.45658246968506927, 0.5890954019699558, 0.575147855103763, 0.6039344628490927, 0.27387915069275315, 0.7142001482276276]
Training loss = 0.03490029315153758
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.49625
Training loss = 0.03390600522359212
step = 1, Training Accuracy: 0.49
Training loss = 0.034196757276852924
step = 2, Training Accuracy: 0.47
Training loss = 0.0330013112227122
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03410910646120707
step = 4, Training Accuracy: 0.4633333333333333
Training loss = 0.034193453590075175
step = 5, Training Accuracy: 0.45
Validation Accuracy: 0.48625
Training loss = 0.034235655665397643
step = 6, Training Accuracy: 0.43333333333333335
Training loss = 0.034235536257425946
step = 7, Training Accuracy: 0.45
Training loss = 0.03505216340223948
step = 8, Training Accuracy: 0.38666666666666666
Training loss = 0.03480531990528107
step = 9, Training Accuracy: 0.45666666666666667
Training loss = 0.03453862984975179
step = 10, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.515
Training loss = 0.03401530583699544
step = 11, Training Accuracy: 0.49666666666666665
Training loss = 0.03308726926644643
step = 12, Training Accuracy: 0.5066666666666667
Training loss = 0.03336117704709371
step = 13, Training Accuracy: 0.5033333333333333
Training loss = 0.033475206891695655
step = 14, Training Accuracy: 0.51
Validation Accuracy: 0.48625
params:  [0.4419712873720634, 0.354390935651269, 0.2245622418158968, 0.8943975700020526, 0.4398204422224756, 0.7058780571123541, 0.01, 0.4139759958187256, 0.6600185124235431, 0.5192840057286389, 0.01000989995454149, 0.11874222055534286, 0.5372126580137361, 0.280890010484859, 0.21367155197114415, 0.35751640665171314, 0.01, 0.99, 0.6901757066954034, 0.01, 0.5559362944308283, 0.3014640605694836, 0.5057300004388672, 0.0622437784701898, 0.4655790675599303, 0.24240527460322805, 0.99, 0.01, 0.19964962924771548, 0.4289544179779973, 0.01, 0.2776907661479802, 0.1554192266078963, 0.47815132620293815, 0.07929521791281186, 0.01, 0.11604551437989369, 0.7569196382970417, 0.2642281232390612, 0.1262783663864036, 0.5519542777553545, 0.365595213918651, 0.23484276913966012, 0.07786356352969012, 0.5174626155338, 0.12377557731747973, 0.5740028747711516, 0.634902024577137, 0.8249153729525831, 0.5161406156104709, 0.01, 0.7186524880254632, 0.6545105801625979, 0.48746911860699593, 0.45451430589181435, 0.99, 0.4712671532079501, 0.8406696920541796, 0.7862005290479607, 0.6954173753917394, 0.5649375768745925, 0.30400123022788644]
[0.4419712873720634, 0.354390935651269, 0.2245622418158968, 0.8943975700020526, 0.4398204422224756, 0.7058780571123541, 0.01, 0.4139759958187256, 0.6600185124235431, 0.5192840057286389, 0.01000989995454149, 0.11874222055534286, 0.5372126580137361, 0.280890010484859, 0.21367155197114415, 0.35751640665171314, 0.01, 0.99, 0.6901757066954034, 0.01, 0.5559362944308283, 0.3014640605694836, 0.5057300004388672, 0.0622437784701898, 0.4655790675599303, 0.24240527460322805, 0.99, 0.01, 0.19964962924771548, 0.4289544179779973, 0.01, 0.2776907661479802, 0.1554192266078963, 0.47815132620293815, 0.07929521791281186, 0.01, 0.11604551437989369, 0.7569196382970417, 0.2642281232390612, 0.1262783663864036, 0.5519542777553545, 0.365595213918651, 0.23484276913966012, 0.07786356352969012, 0.5174626155338, 0.12377557731747973, 0.5740028747711516, 0.634902024577137, 0.8249153729525831, 0.5161406156104709, 0.01, 0.7186524880254632, 0.6545105801625979, 0.48746911860699593, 0.45451430589181435, 0.99, 0.4712671532079501, 0.8406696920541796, 0.7862005290479607, 0.6954173753917394, 0.5649375768745925, 0.30400123022788644]
Training loss = 0.034478816191355385
step = 0, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.5125
Training loss = 0.03372423390547435
step = 1, Training Accuracy: 0.45
Training loss = 0.03309326430161794
step = 2, Training Accuracy: 0.5
Training loss = 0.0331879719098409
step = 3, Training Accuracy: 0.5233333333333333
Training loss = 0.034296709497769674
step = 4, Training Accuracy: 0.4633333333333333
Training loss = 0.03338208436965942
step = 5, Training Accuracy: 0.46
Validation Accuracy: 0.50375
Training loss = 0.03589409331480662
step = 6, Training Accuracy: 0.44333333333333336
Training loss = 0.03388922989368439
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.0329895156621933
step = 8, Training Accuracy: 0.47333333333333333
Training loss = 0.03322917858759562
step = 9, Training Accuracy: 0.4766666666666667
Training loss = 0.03388320008913676
step = 10, Training Accuracy: 0.45666666666666667
Validation Accuracy: 0.54
Training loss = 0.03341598133246104
step = 11, Training Accuracy: 0.47333333333333333
Training loss = 0.03376106401284536
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03425737539927165
step = 13, Training Accuracy: 0.5133333333333333
Training loss = 0.03487396081288656
step = 14, Training Accuracy: 0.49
Validation Accuracy: 0.56375
params:  [0.8296362720843291, 0.5340552035753744, 0.398639202356314, 0.6758050448436056, 0.6286553503519453, 0.99, 0.01, 0.5100200270448806, 0.5098284952787062, 0.5842975603205098, 0.14652347738715518, 0.2708966582261507, 0.18543305293568346, 0.3231905729167366, 0.30710464578951424, 0.6641292143510114, 0.01, 0.7698799626299753, 0.5921898562629828, 0.44385863565168804, 0.6888886525770836, 0.2513014967233783, 0.08194568794090915, 0.5241880815369785, 0.6831110796300395, 0.08463861271984648, 0.8533800331744529, 0.3832994687365275, 0.12252858334925101, 0.38440592094147197, 0.07094062549700568, 0.01, 0.309717908672041, 0.6214945132882866, 0.01, 0.5753585841164328, 0.8866468591037899, 0.809739578165344, 0.01, 0.35472977814012463, 0.8800733447559868, 0.03769916031436579, 0.6331458284438685, 0.2641362477748328, 0.22192085852657512, 0.44880905984812663, 0.01, 0.1593503742663797, 0.4242295545820519, 0.01, 0.6897233911794906, 0.5709575866118102, 0.3679866539909049, 0.3725555065191607, 0.7323819867198347, 0.01, 0.6489491256464879, 0.5030699183058761, 0.20554740468561472, 0.6386310422789812, 0.7548806291063074, 0.4393422042698318]
[0.8296362720843291, 0.5340552035753744, 0.398639202356314, 0.6758050448436056, 0.6286553503519453, 0.99, 0.01, 0.5100200270448806, 0.5098284952787062, 0.5842975603205098, 0.14652347738715518, 0.2708966582261507, 0.18543305293568346, 0.3231905729167366, 0.30710464578951424, 0.6641292143510114, 0.01, 0.7698799626299753, 0.5921898562629828, 0.44385863565168804, 0.6888886525770836, 0.2513014967233783, 0.08194568794090915, 0.5241880815369785, 0.6831110796300395, 0.08463861271984648, 0.8533800331744529, 0.3832994687365275, 0.12252858334925101, 0.38440592094147197, 0.07094062549700568, 0.01, 0.309717908672041, 0.6214945132882866, 0.01, 0.5753585841164328, 0.8866468591037899, 0.809739578165344, 0.01, 0.35472977814012463, 0.8800733447559868, 0.03769916031436579, 0.6331458284438685, 0.2641362477748328, 0.22192085852657512, 0.44880905984812663, 0.01, 0.1593503742663797, 0.4242295545820519, 0.01, 0.6897233911794906, 0.5709575866118102, 0.3679866539909049, 0.3725555065191607, 0.7323819867198347, 0.01, 0.6489491256464879, 0.5030699183058761, 0.20554740468561472, 0.6386310422789812, 0.7548806291063074, 0.4393422042698318]
Training loss = 0.03559749782085419
step = 0, Training Accuracy: 0.45
Validation Accuracy: 0.53625
Training loss = 0.03559323191642761
step = 1, Training Accuracy: 0.38666666666666666
Training loss = 0.03567441046237946
step = 2, Training Accuracy: 0.4033333333333333
Training loss = 0.03431771377722422
step = 3, Training Accuracy: 0.44666666666666666
Training loss = 0.03523257513840993
step = 4, Training Accuracy: 0.43
Training loss = 0.03501979867617289
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.51625
Training loss = 0.03403080582618714
step = 6, Training Accuracy: 0.43333333333333335
Training loss = 0.03437784135341644
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.03349558313687642
step = 8, Training Accuracy: 0.44
Training loss = 0.035604069232940676
step = 9, Training Accuracy: 0.44333333333333336
Training loss = 0.03526723682880402
step = 10, Training Accuracy: 0.42
Validation Accuracy: 0.52625
Training loss = 0.0341424576441447
step = 11, Training Accuracy: 0.45666666666666667
Training loss = 0.03476220587889353
step = 12, Training Accuracy: 0.44333333333333336
Training loss = 0.03511206050713857
step = 13, Training Accuracy: 0.41333333333333333
Training loss = 0.034406640728314716
step = 14, Training Accuracy: 0.43
Validation Accuracy: 0.52625
params:  [0.2346956390318339, 0.5734899713326168, 0.047917047388661094, 0.058688508314503174, 0.99, 0.06557469755080275, 0.01, 0.3400222891798248, 0.26929918781977913, 0.5932722696794014, 0.7759401984181988, 0.5906312202939391, 0.2853517743443052, 0.49429513762919336, 0.19444605920228303, 0.5073530522776828, 0.11340240832395852, 0.5968155681014269, 0.25183071693430314, 0.3558039542723517, 0.9598216739007732, 0.46737195546294275, 0.37051351662968246, 0.5070431975133337, 0.3796338584342491, 0.15813683545221593, 0.8219595384163567, 0.029302829564649514, 0.06809706484336006, 0.5731061634475737, 0.01, 0.01, 0.37387943628268727, 0.8296330555961571, 0.5809582380297422, 0.5440528908001916, 0.6416436421462988, 0.5063011524898278, 0.4045858913884892, 0.4069199730219632, 0.5972499057465326, 0.21095708368969462, 0.5290987894978154, 0.21029313937710584, 0.25453379502995827, 0.99, 0.16486145221675608, 0.10241008283034703, 0.8474332620500203, 0.43749880818888076, 0.3872359451156465, 0.99, 0.4963259681459256, 0.06415702188758388, 0.3227413674581179, 0.046851486546366505, 0.5925359200253253, 0.4558827855493584, 0.2523508409622466, 0.403584247504102, 0.19924119060865736, 0.649399487373635]
[0.2346956390318339, 0.5734899713326168, 0.047917047388661094, 0.058688508314503174, 0.99, 0.06557469755080275, 0.01, 0.3400222891798248, 0.26929918781977913, 0.5932722696794014, 0.7759401984181988, 0.5906312202939391, 0.2853517743443052, 0.49429513762919336, 0.19444605920228303, 0.5073530522776828, 0.11340240832395852, 0.5968155681014269, 0.25183071693430314, 0.3558039542723517, 0.9598216739007732, 0.46737195546294275, 0.37051351662968246, 0.5070431975133337, 0.3796338584342491, 0.15813683545221593, 0.8219595384163567, 0.029302829564649514, 0.06809706484336006, 0.5731061634475737, 0.01, 0.01, 0.37387943628268727, 0.8296330555961571, 0.5809582380297422, 0.5440528908001916, 0.6416436421462988, 0.5063011524898278, 0.4045858913884892, 0.4069199730219632, 0.5972499057465326, 0.21095708368969462, 0.5290987894978154, 0.21029313937710584, 0.25453379502995827, 0.99, 0.16486145221675608, 0.10241008283034703, 0.8474332620500203, 0.43749880818888076, 0.3872359451156465, 0.99, 0.4963259681459256, 0.06415702188758388, 0.3227413674581179, 0.046851486546366505, 0.5925359200253253, 0.4558827855493584, 0.2523508409622466, 0.403584247504102, 0.19924119060865736, 0.649399487373635]
Training loss = 0.03296088715394338
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.53625
Training loss = 0.032966790596644084
step = 1, Training Accuracy: 0.47
Training loss = 0.034503732721010844
step = 2, Training Accuracy: 0.46
Training loss = 0.03286863247553507
step = 3, Training Accuracy: 0.48
Training loss = 0.03256183664004008
step = 4, Training Accuracy: 0.5166666666666667
Training loss = 0.03285175899664561
step = 5, Training Accuracy: 0.48
Validation Accuracy: 0.5425
Training loss = 0.0337274165948232
step = 6, Training Accuracy: 0.49
Training loss = 0.03278769036134084
step = 7, Training Accuracy: 0.5166666666666667
Training loss = 0.03194688340028127
step = 8, Training Accuracy: 0.51
Training loss = 0.03302109956741333
step = 9, Training Accuracy: 0.48333333333333334
Training loss = 0.03331627229849497
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.555
Training loss = 0.03426479915777842
step = 11, Training Accuracy: 0.43
Training loss = 0.032556968530019124
step = 12, Training Accuracy: 0.5
Training loss = 0.03121878465016683
step = 13, Training Accuracy: 0.49666666666666665
Training loss = 0.03280716399351756
step = 14, Training Accuracy: 0.5
Validation Accuracy: 0.5275
params:  [0.7353430823385125, 0.3649803585562269, 0.38685497970424965, 0.01, 0.957286154493612, 0.5360886895135697, 0.487664983550958, 0.7690400189822225, 0.01, 0.039765748779313326, 0.7166363799028861, 0.4330275369272108, 0.10878737236636724, 0.9653455926567569, 0.553789155219148, 0.4191779496666327, 0.2202555444230327, 0.99, 0.99, 0.12531075545627796, 0.7914712852863066, 0.6936127848755442, 0.6605894672597046, 0.01052296182596868, 0.7058154379995318, 0.40843643696396725, 0.29055997225488395, 0.01, 0.01, 0.5140941781294226, 0.051573109915454954, 0.01, 0.01, 0.787781247825562, 0.9792880705868001, 0.06979573113358514, 0.5116961910162034, 0.5550026017215055, 0.8569408799653018, 0.25751051439345457, 0.2480834473457672, 0.07018220636679337, 0.01, 0.01, 0.27226020153389063, 0.511784802609529, 0.5691934593998145, 0.99, 0.7851271514558151, 0.02692890330127909, 0.01, 0.99, 0.10393003789380734, 0.8827709630896394, 0.6538320362163861, 0.10924730436858857, 0.01, 0.9061617122496238, 0.46563804642421464, 0.8713448935920385, 0.5347023902878576, 0.7152626767387886]
[0.7353430823385125, 0.3649803585562269, 0.38685497970424965, 0.01, 0.957286154493612, 0.5360886895135697, 0.487664983550958, 0.7690400189822225, 0.01, 0.039765748779313326, 0.7166363799028861, 0.4330275369272108, 0.10878737236636724, 0.9653455926567569, 0.553789155219148, 0.4191779496666327, 0.2202555444230327, 0.99, 0.99, 0.12531075545627796, 0.7914712852863066, 0.6936127848755442, 0.6605894672597046, 0.01052296182596868, 0.7058154379995318, 0.40843643696396725, 0.29055997225488395, 0.01, 0.01, 0.5140941781294226, 0.051573109915454954, 0.01, 0.01, 0.787781247825562, 0.9792880705868001, 0.06979573113358514, 0.5116961910162034, 0.5550026017215055, 0.8569408799653018, 0.25751051439345457, 0.2480834473457672, 0.07018220636679337, 0.01, 0.01, 0.27226020153389063, 0.511784802609529, 0.5691934593998145, 0.99, 0.7851271514558151, 0.02692890330127909, 0.01, 0.99, 0.10393003789380734, 0.8827709630896394, 0.6538320362163861, 0.10924730436858857, 0.01, 0.9061617122496238, 0.46563804642421464, 0.8713448935920385, 0.5347023902878576, 0.7152626767387886]
Training loss = 0.0334497861067454
step = 0, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.5575
Training loss = 0.03427125175793966
step = 1, Training Accuracy: 0.44666666666666666
Training loss = 0.03348800420761108
step = 2, Training Accuracy: 0.48
Training loss = 0.033051236669222515
step = 3, Training Accuracy: 0.4766666666666667
Training loss = 0.033646684686342875
step = 4, Training Accuracy: 0.4666666666666667
Training loss = 0.03329858958721161
step = 5, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.5525
Training loss = 0.032392405072848005
step = 6, Training Accuracy: 0.49
Training loss = 0.032325847347577416
step = 7, Training Accuracy: 0.5166666666666667
Training loss = 0.03262731234232585
step = 8, Training Accuracy: 0.48
Training loss = 0.03301835298538208
step = 9, Training Accuracy: 0.5
Training loss = 0.03444965362548828
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.51875
Training loss = 0.03288308342297872
step = 11, Training Accuracy: 0.49
Training loss = 0.03387996812661489
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03135123610496521
step = 13, Training Accuracy: 0.54
Training loss = 0.03337531467278798
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.51375
params:  [0.7507071156288083, 0.6842500100130275, 0.42725231301419153, 0.040849655716841765, 0.827254527806596, 0.4174844908545068, 0.01, 0.10099823689598991, 0.7433956135666907, 0.99, 0.25862252146641984, 0.5063004222500632, 0.42670837969639414, 0.99, 0.16162472255577004, 0.9569372231808971, 0.01, 0.018066103922728283, 0.5610390907601669, 0.01, 0.07332388712069776, 0.306028134727242, 0.01, 0.8061424905217693, 0.7644919270848352, 0.0885172985141057, 0.99, 0.02321049229428549, 0.0416147396015209, 0.4337091201400331, 0.016301585092751057, 0.1141939732202666, 0.040082347602224316, 0.5222284341259326, 0.8219179970047208, 0.01, 0.01, 0.48333569033101437, 0.3152196346817922, 0.49019157557177206, 0.01, 0.22326398814616347, 0.10865914984854402, 0.23264779639504327, 0.6099794738290545, 0.1847027307684601, 0.3125065914656586, 0.14890261009998124, 0.48119627081804844, 0.4865426961503715, 0.01, 0.99, 0.3409227144882678, 0.09547148365463007, 0.26789089201363264, 0.01, 0.13390520839584538, 0.1406366322233455, 0.99, 0.5105790655915186, 0.8358724734303731, 0.6616730131053976]
[0.7507071156288083, 0.6842500100130275, 0.42725231301419153, 0.040849655716841765, 0.827254527806596, 0.4174844908545068, 0.01, 0.10099823689598991, 0.7433956135666907, 0.99, 0.25862252146641984, 0.5063004222500632, 0.42670837969639414, 0.99, 0.16162472255577004, 0.9569372231808971, 0.01, 0.018066103922728283, 0.5610390907601669, 0.01, 0.07332388712069776, 0.306028134727242, 0.01, 0.8061424905217693, 0.7644919270848352, 0.0885172985141057, 0.99, 0.02321049229428549, 0.0416147396015209, 0.4337091201400331, 0.016301585092751057, 0.1141939732202666, 0.040082347602224316, 0.5222284341259326, 0.8219179970047208, 0.01, 0.01, 0.48333569033101437, 0.3152196346817922, 0.49019157557177206, 0.01, 0.22326398814616347, 0.10865914984854402, 0.23264779639504327, 0.6099794738290545, 0.1847027307684601, 0.3125065914656586, 0.14890261009998124, 0.48119627081804844, 0.4865426961503715, 0.01, 0.99, 0.3409227144882678, 0.09547148365463007, 0.26789089201363264, 0.01, 0.13390520839584538, 0.1406366322233455, 0.99, 0.5105790655915186, 0.8358724734303731, 0.6616730131053976]
Training loss = 0.032078817486763
step = 0, Training Accuracy: 0.54
Validation Accuracy: 0.49
Training loss = 0.031152536471684773
step = 1, Training Accuracy: 0.5366666666666666
Training loss = 0.031490304072697956
step = 2, Training Accuracy: 0.53
Training loss = 0.031106495062510172
step = 3, Training Accuracy: 0.6033333333333334
Training loss = 0.030362260540326435
step = 4, Training Accuracy: 0.5666666666666667
Training loss = 0.030176549752553305
step = 5, Training Accuracy: 0.5666666666666667
Validation Accuracy: 0.565
Training loss = 0.031014268000920612
step = 6, Training Accuracy: 0.54
Training loss = 0.029335645437240602
step = 7, Training Accuracy: 0.55
Training loss = 0.0313231219847997
step = 8, Training Accuracy: 0.5466666666666666
Training loss = 0.03167228658994039
step = 9, Training Accuracy: 0.5433333333333333
Training loss = 0.03023049235343933
step = 10, Training Accuracy: 0.56
Validation Accuracy: 0.575
Training loss = 0.029588932196299236
step = 11, Training Accuracy: 0.55
Training loss = 0.029104164441426595
step = 12, Training Accuracy: 0.5833333333333334
Training loss = 0.03066110094388326
step = 13, Training Accuracy: 0.55
Training loss = 0.029021704196929933
step = 14, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.5525
gen	nevals	avg     	std     	min    	max    
0  	8     	0.527969	0.022844	0.48625	0.56375
params:  [0.683294663443506, 0.01, 0.1375568026026615, 0.014388687029098568, 0.7794275953469096, 0.33656172613313695, 0.01, 0.34691842072246154, 0.99, 0.121633258546473, 0.01, 0.3524075000029107, 0.5677364716168297, 0.8455651550134353, 0.06363299222459978, 0.6013136733670859, 0.01, 0.5074685825394131, 0.26688227702401013, 0.01, 0.312005101111239, 0.3659894814741586, 0.16130277737991497, 0.4568235856236562, 0.6686763348759016, 0.14207293840629712, 0.9263074171337833, 0.022111872487937504, 0.2921755637557071, 0.46394911778335113, 0.2306392118894517, 0.334953336887286, 0.23995413010435224, 0.1533725567730148, 0.5269079985202145, 0.071172233601313, 0.06327268982176099, 0.7827139467198256, 0.2919599175985122, 0.21079048006925896, 0.6594932121908053, 0.4421223521469881, 0.05483611692105139, 0.15958787738194627, 0.7531026106270172, 0.30543887567796835, 0.47802364902928696, 0.2890144606252022, 0.6619315554262738, 0.8113044620041026, 0.7205220112923308, 0.6117703713907445, 0.6116127565133506, 0.12421201621206265, 0.07128838995070386, 0.6483584457828032, 0.8554480202278528, 0.8856225462645493, 0.7390816362834922, 0.2105894323676884, 0.6318065586575113, 0.32290928126285195]
[0.683294663443506, 0.01, 0.1375568026026615, 0.014388687029098568, 0.7794275953469096, 0.33656172613313695, 0.01, 0.34691842072246154, 0.99, 0.121633258546473, 0.01, 0.3524075000029107, 0.5677364716168297, 0.8455651550134353, 0.06363299222459978, 0.6013136733670859, 0.01, 0.5074685825394131, 0.26688227702401013, 0.01, 0.312005101111239, 0.3659894814741586, 0.16130277737991497, 0.4568235856236562, 0.6686763348759016, 0.14207293840629712, 0.9263074171337833, 0.022111872487937504, 0.2921755637557071, 0.46394911778335113, 0.2306392118894517, 0.334953336887286, 0.23995413010435224, 0.1533725567730148, 0.5269079985202145, 0.071172233601313, 0.06327268982176099, 0.7827139467198256, 0.2919599175985122, 0.21079048006925896, 0.6594932121908053, 0.4421223521469881, 0.05483611692105139, 0.15958787738194627, 0.7531026106270172, 0.30543887567796835, 0.47802364902928696, 0.2890144606252022, 0.6619315554262738, 0.8113044620041026, 0.7205220112923308, 0.6117703713907445, 0.6116127565133506, 0.12421201621206265, 0.07128838995070386, 0.6483584457828032, 0.8554480202278528, 0.8856225462645493, 0.7390816362834922, 0.2105894323676884, 0.6318065586575113, 0.32290928126285195]
Training loss = 0.03466535707314809
step = 0, Training Accuracy: 0.45666666666666667
Validation Accuracy: 0.53625
Training loss = 0.0340379532178243
step = 1, Training Accuracy: 0.4633333333333333
Training loss = 0.0335784778992335
step = 2, Training Accuracy: 0.45666666666666667
Training loss = 0.03422618985176087
step = 3, Training Accuracy: 0.4533333333333333
Training loss = 0.03296756823857625
step = 4, Training Accuracy: 0.46
Training loss = 0.03387888391812643
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.52
Training loss = 0.03323445419470469
step = 6, Training Accuracy: 0.44333333333333336
Training loss = 0.0324463830391566
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.03264947275320689
step = 8, Training Accuracy: 0.48333333333333334
Training loss = 0.03393260618050893
step = 9, Training Accuracy: 0.51
Training loss = 0.033842494090398155
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.5325
Training loss = 0.03268569310506185
step = 11, Training Accuracy: 0.5066666666666667
Training loss = 0.031452393531799315
step = 12, Training Accuracy: 0.5133333333333333
Training loss = 0.03222710450490316
step = 13, Training Accuracy: 0.5466666666666666
Training loss = 0.032082986831665036
step = 14, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.515
params:  [0.9024908687284244, 0.5773615213624086, 0.5261749164605423, 0.5934889408795813, 0.7338323163782388, 0.8819299232476381, 0.5356599723012755, 0.12838195914989417, 0.8809795379347364, 0.01, 0.2907278727485145, 0.17771643160930356, 0.7877754966177135, 0.9654678014919418, 0.13251418575157764, 0.5439495751122476, 0.01, 0.5510495191357977, 0.5144405714473425, 0.41384622210215044, 0.2971695962524783, 0.10320796735863236, 0.7385100750189149, 0.01, 0.2820849908812538, 0.19828367887583492, 0.99, 0.1494001057409262, 0.21539816208066287, 0.4736475507022462, 0.01, 0.10427908937252618, 0.036373950624061374, 0.41885894267775914, 0.9471115423298659, 0.9619190495741119, 0.15335286078485197, 0.7370076189341801, 0.3910108117669034, 0.15792585575159263, 0.4391474645318081, 0.21833461391238634, 0.11211808282799182, 0.6415601785016704, 0.28492475555768937, 0.057772674320644174, 0.20643658867645764, 0.11909373718993932, 0.99, 0.4458528725761205, 0.01, 0.6077044859619478, 0.6194792770433194, 0.33865025166880774, 0.11630248633416648, 0.7739903177905393, 0.4013405640650201, 0.6656313942958288, 0.99, 0.45975936506022475, 0.9676000795915882, 0.3606503999996769]
[0.9024908687284244, 0.5773615213624086, 0.5261749164605423, 0.5934889408795813, 0.7338323163782388, 0.8819299232476381, 0.5356599723012755, 0.12838195914989417, 0.8809795379347364, 0.01, 0.2907278727485145, 0.17771643160930356, 0.7877754966177135, 0.9654678014919418, 0.13251418575157764, 0.5439495751122476, 0.01, 0.5510495191357977, 0.5144405714473425, 0.41384622210215044, 0.2971695962524783, 0.10320796735863236, 0.7385100750189149, 0.01, 0.2820849908812538, 0.19828367887583492, 0.99, 0.1494001057409262, 0.21539816208066287, 0.4736475507022462, 0.01, 0.10427908937252618, 0.036373950624061374, 0.41885894267775914, 0.9471115423298659, 0.9619190495741119, 0.15335286078485197, 0.7370076189341801, 0.3910108117669034, 0.15792585575159263, 0.4391474645318081, 0.21833461391238634, 0.11211808282799182, 0.6415601785016704, 0.28492475555768937, 0.057772674320644174, 0.20643658867645764, 0.11909373718993932, 0.99, 0.4458528725761205, 0.01, 0.6077044859619478, 0.6194792770433194, 0.33865025166880774, 0.11630248633416648, 0.7739903177905393, 0.4013405640650201, 0.6656313942958288, 0.99, 0.45975936506022475, 0.9676000795915882, 0.3606503999996769]
Training loss = 0.037661737402280175
step = 0, Training Accuracy: 0.43666666666666665
Validation Accuracy: 0.52875
Training loss = 0.03542758345603943
step = 1, Training Accuracy: 0.44333333333333336
Training loss = 0.03486113905906677
step = 2, Training Accuracy: 0.44
Training loss = 0.03334788004557292
step = 3, Training Accuracy: 0.5033333333333333
Training loss = 0.03277208904425303
step = 4, Training Accuracy: 0.4866666666666667
Training loss = 0.03232735415299733
step = 5, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.54375
Training loss = 0.03397071381409963
step = 6, Training Accuracy: 0.46
Training loss = 0.03288212120532989
step = 7, Training Accuracy: 0.49666666666666665
Training loss = 0.033447442452112834
step = 8, Training Accuracy: 0.48333333333333334
Training loss = 0.032843581438064574
step = 9, Training Accuracy: 0.48
Training loss = 0.033316325743993125
step = 10, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.54
Training loss = 0.034030831654866533
step = 11, Training Accuracy: 0.44333333333333336
Training loss = 0.0318543404340744
step = 12, Training Accuracy: 0.49
Training loss = 0.03239920357863108
step = 13, Training Accuracy: 0.48333333333333334
Training loss = 0.03299688518047333
step = 14, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.54875
params:  [0.6080894671489864, 0.010189068349665154, 0.24390320249752334, 0.8314647015772182, 0.31444474583419074, 0.5517501241993823, 0.5901292590810278, 0.1857573176929116, 0.5813204464924464, 0.756901887244257, 0.047002929946582964, 0.06028983159903306, 0.7165802683890593, 0.5627997265808456, 0.5914709550532525, 0.6327979229471364, 0.582760652560978, 0.29159274240874383, 0.7597350171498655, 0.01, 0.5285206499389995, 0.33617116002554037, 0.42637488370449217, 0.3209333893371407, 0.7203883496844526, 0.06557388992992624, 0.99, 0.2626400895417366, 0.01, 0.6573106252398808, 0.050265273906642, 0.3276197490891165, 0.01, 0.15801071073943806, 0.2117952945668562, 0.31629986755097494, 0.14464212393195452, 0.7996913363632323, 0.25075074137216546, 0.01, 0.01, 0.99, 0.01, 0.1108486585889664, 0.28291554994867435, 0.01, 0.5209894247099671, 0.1954986910202437, 0.8150520488888092, 0.01, 0.028506229883996724, 0.7368390096713161, 0.869543623390109, 0.4765011528044236, 0.5668866962200674, 0.7238182977349054, 0.43628749310106435, 0.24697215914220166, 0.99, 0.26926495014516993, 0.99, 0.04564030083590764]
[0.6080894671489864, 0.010189068349665154, 0.24390320249752334, 0.8314647015772182, 0.31444474583419074, 0.5517501241993823, 0.5901292590810278, 0.1857573176929116, 0.5813204464924464, 0.756901887244257, 0.047002929946582964, 0.06028983159903306, 0.7165802683890593, 0.5627997265808456, 0.5914709550532525, 0.6327979229471364, 0.582760652560978, 0.29159274240874383, 0.7597350171498655, 0.01, 0.5285206499389995, 0.33617116002554037, 0.42637488370449217, 0.3209333893371407, 0.7203883496844526, 0.06557388992992624, 0.99, 0.2626400895417366, 0.01, 0.6573106252398808, 0.050265273906642, 0.3276197490891165, 0.01, 0.15801071073943806, 0.2117952945668562, 0.31629986755097494, 0.14464212393195452, 0.7996913363632323, 0.25075074137216546, 0.01, 0.01, 0.99, 0.01, 0.1108486585889664, 0.28291554994867435, 0.01, 0.5209894247099671, 0.1954986910202437, 0.8150520488888092, 0.01, 0.028506229883996724, 0.7368390096713161, 0.869543623390109, 0.4765011528044236, 0.5668866962200674, 0.7238182977349054, 0.43628749310106435, 0.24697215914220166, 0.99, 0.26926495014516993, 0.99, 0.04564030083590764]
Training loss = 0.03375022788842519
step = 0, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.53125
Training loss = 0.03420102337996165
step = 1, Training Accuracy: 0.46
Training loss = 0.03316929340362549
step = 2, Training Accuracy: 0.48
Training loss = 0.034006108244260154
step = 3, Training Accuracy: 0.4766666666666667
Training loss = 0.03476961076259613
step = 4, Training Accuracy: 0.4666666666666667
Training loss = 0.03364685952663422
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.56875
Training loss = 0.0332209450006485
step = 6, Training Accuracy: 0.51
Training loss = 0.032652626236279805
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.03255309800306956
step = 8, Training Accuracy: 0.46
Training loss = 0.032964626351992286
step = 9, Training Accuracy: 0.4766666666666667
Training loss = 0.03312904377778371
step = 10, Training Accuracy: 0.51
Validation Accuracy: 0.56
Training loss = 0.03221161524454753
step = 11, Training Accuracy: 0.5333333333333333
Training loss = 0.03234136939048767
step = 12, Training Accuracy: 0.49
Training loss = 0.032036085724830625
step = 13, Training Accuracy: 0.5133333333333333
Training loss = 0.035260794957478844
step = 14, Training Accuracy: 0.42
Validation Accuracy: 0.54625
params:  [0.36932315298871105, 0.4847330294862861, 0.01, 0.630436804323067, 0.99, 0.99, 0.14909801280264962, 0.18077838599713578, 0.7788102966714828, 0.16822130884956082, 0.01, 0.4374905645444951, 0.11857685006642449, 0.5065111821912739, 0.12930799468546972, 0.4848808822980868, 0.6472251183188082, 0.7966136230939735, 0.99, 0.07524137141071637, 0.17215169092349858, 0.7597805562455322, 0.5970258910279029, 0.23345374076891673, 0.39148314133044737, 0.04562844028923019, 0.99, 0.20377090004730328, 0.01, 0.02004073389406602, 0.4287263093813234, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.9055775924535716, 0.9191212657779259, 0.01, 0.31970374883446784, 0.5399484586039904, 0.031852918792914686, 0.01, 0.6143937143376756, 0.5695435584077371, 0.05081316700550953, 0.23589926528792401, 0.3215960062736549, 0.19388672270973106, 0.01, 0.99, 0.6185963240488352, 0.46721096857771605, 0.45110092539765706, 0.696395588802994, 0.72062892155822, 0.3046732912994427, 0.33542987942091235, 0.9055729252558082, 0.6294343717312149, 0.6514634425439225]
[0.36932315298871105, 0.4847330294862861, 0.01, 0.630436804323067, 0.99, 0.99, 0.14909801280264962, 0.18077838599713578, 0.7788102966714828, 0.16822130884956082, 0.01, 0.4374905645444951, 0.11857685006642449, 0.5065111821912739, 0.12930799468546972, 0.4848808822980868, 0.6472251183188082, 0.7966136230939735, 0.99, 0.07524137141071637, 0.17215169092349858, 0.7597805562455322, 0.5970258910279029, 0.23345374076891673, 0.39148314133044737, 0.04562844028923019, 0.99, 0.20377090004730328, 0.01, 0.02004073389406602, 0.4287263093813234, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.9055775924535716, 0.9191212657779259, 0.01, 0.31970374883446784, 0.5399484586039904, 0.031852918792914686, 0.01, 0.6143937143376756, 0.5695435584077371, 0.05081316700550953, 0.23589926528792401, 0.3215960062736549, 0.19388672270973106, 0.01, 0.99, 0.6185963240488352, 0.46721096857771605, 0.45110092539765706, 0.696395588802994, 0.72062892155822, 0.3046732912994427, 0.33542987942091235, 0.9055729252558082, 0.6294343717312149, 0.6514634425439225]
Training loss = 0.03405345698197683
step = 0, Training Accuracy: 0.45
Validation Accuracy: 0.5525
Training loss = 0.03289316316445669
step = 1, Training Accuracy: 0.4766666666666667
Training loss = 0.033071741064389544
step = 2, Training Accuracy: 0.5133333333333333
Training loss = 0.03430944403012594
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.03440053641796112
step = 4, Training Accuracy: 0.47
Training loss = 0.032450509071350095
step = 5, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.53375
Training loss = 0.03232907513777415
step = 6, Training Accuracy: 0.51
Training loss = 0.033729334672292076
step = 7, Training Accuracy: 0.49
Training loss = 0.03290271083513896
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03263406058152517
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.03277152597904205
step = 10, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.5525
Training loss = 0.0332575394709905
step = 11, Training Accuracy: 0.5
Training loss = 0.032902734676996864
step = 12, Training Accuracy: 0.48333333333333334
Training loss = 0.03291926840941111
step = 13, Training Accuracy: 0.5366666666666666
Training loss = 0.033223684628804526
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.5125
params:  [0.04470950315915645, 0.8322675683242342, 0.39325044034664214, 0.20653386917724736, 0.7381473847218251, 0.7458352921370387, 0.4204801371339332, 0.4873075441238529, 0.7424777151803431, 0.28551358677072664, 0.017347414762207247, 0.01, 0.3393663062125092, 0.5343414205876685, 0.01, 0.46435266683060894, 0.5273887598319682, 0.3973439545019095, 0.5845697812351545, 0.3821595530404202, 0.6549153591271479, 0.01, 0.8005605939480418, 0.28830491134883246, 0.4150669320623167, 0.01, 0.9233360994645827, 0.13923223830317744, 0.01, 0.36650326111674514, 0.5768343689210459, 0.2436697182782635, 0.1313458967522507, 0.7015731487951755, 0.5227370967606121, 0.23331356351378135, 0.16724772626741125, 0.6438782004028355, 0.08058604558991969, 0.6782929767187587, 0.8754971439017734, 0.32939896590107964, 0.5587443754583468, 0.017274342204699283, 0.14101817853771104, 0.01, 0.8384193528847964, 0.30940948973174587, 0.7787949493069665, 0.13839004748348405, 0.026470264910907308, 0.43720717546262594, 0.7212197014214503, 0.20863512223401853, 0.4365921415874705, 0.341818719661271, 0.6140176457119855, 0.49071102313077547, 0.5569704518861587, 0.5344466080638892, 0.01, 0.9103000359022702]
[0.04470950315915645, 0.8322675683242342, 0.39325044034664214, 0.20653386917724736, 0.7381473847218251, 0.7458352921370387, 0.4204801371339332, 0.4873075441238529, 0.7424777151803431, 0.28551358677072664, 0.017347414762207247, 0.01, 0.3393663062125092, 0.5343414205876685, 0.01, 0.46435266683060894, 0.5273887598319682, 0.3973439545019095, 0.5845697812351545, 0.3821595530404202, 0.6549153591271479, 0.01, 0.8005605939480418, 0.28830491134883246, 0.4150669320623167, 0.01, 0.9233360994645827, 0.13923223830317744, 0.01, 0.36650326111674514, 0.5768343689210459, 0.2436697182782635, 0.1313458967522507, 0.7015731487951755, 0.5227370967606121, 0.23331356351378135, 0.16724772626741125, 0.6438782004028355, 0.08058604558991969, 0.6782929767187587, 0.8754971439017734, 0.32939896590107964, 0.5587443754583468, 0.017274342204699283, 0.14101817853771104, 0.01, 0.8384193528847964, 0.30940948973174587, 0.7787949493069665, 0.13839004748348405, 0.026470264910907308, 0.43720717546262594, 0.7212197014214503, 0.20863512223401853, 0.4365921415874705, 0.341818719661271, 0.6140176457119855, 0.49071102313077547, 0.5569704518861587, 0.5344466080638892, 0.01, 0.9103000359022702]
Training loss = 0.03252410670121511
step = 0, Training Accuracy: 0.53
Validation Accuracy: 0.5275
Training loss = 0.03309171438217163
step = 1, Training Accuracy: 0.5233333333333333
Training loss = 0.031537528038024905
step = 2, Training Accuracy: 0.51
Training loss = 0.031475582718849184
step = 3, Training Accuracy: 0.55
Training loss = 0.030459362069765728
step = 4, Training Accuracy: 0.55
Training loss = 0.029943909843762717
step = 5, Training Accuracy: 0.57
Validation Accuracy: 0.57375
Training loss = 0.02920417586962382
step = 6, Training Accuracy: 0.5766666666666667
Training loss = 0.030011640389760334
step = 7, Training Accuracy: 0.58
Training loss = 0.03094983915487925
step = 8, Training Accuracy: 0.5633333333333334
Training loss = 0.02879673957824707
step = 9, Training Accuracy: 0.5866666666666667
Training loss = 0.029470532735188803
step = 10, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.58
Training loss = 0.028279813925425213
step = 11, Training Accuracy: 0.6066666666666667
Training loss = 0.029401511748631794
step = 12, Training Accuracy: 0.5933333333333334
Training loss = 0.029694714546203614
step = 13, Training Accuracy: 0.5833333333333334
Training loss = 0.030175883372624716
step = 14, Training Accuracy: 0.5933333333333334
Validation Accuracy: 0.53625
params:  [0.35821685434951867, 0.5094982285789407, 0.37343916334642335, 0.62887396008589, 0.8108807530963724, 0.99, 0.21176586047524204, 0.01, 0.9436614263374127, 0.15564838729775154, 0.04899832876233688, 0.41593065383339417, 0.3137496803420803, 0.023648819284619038, 0.43400579339543, 0.32107154953641204, 0.01, 0.02881424093635232, 0.7738703533569236, 0.2652189697297806, 0.47141317260058047, 0.30238181930555413, 0.8753810251103583, 0.032725671046240634, 0.5304486263312796, 0.01, 0.9197767419121832, 0.01, 0.5459444220042045, 0.6369748905974262, 0.3184883568482058, 0.26310360127610044, 0.3766687589509121, 0.27169457520766, 0.01, 0.014999388074150743, 0.01, 0.12036245412651181, 0.28414575927052943, 0.33974743840639177, 0.01, 0.372483420963218, 0.6190260622262593, 0.01, 0.09907988064660295, 0.01, 0.38257698240395194, 0.6039626510838418, 0.17777617396721856, 0.01, 0.327824220526483, 0.9318586639492967, 0.31669967573199626, 0.18555209556431201, 0.2185657005743401, 0.38180216080352725, 0.2882519367774068, 0.3577168361879667, 0.99, 0.339365995132756, 0.5122756630750651, 0.5478546763845941]
[0.35821685434951867, 0.5094982285789407, 0.37343916334642335, 0.62887396008589, 0.8108807530963724, 0.99, 0.21176586047524204, 0.01, 0.9436614263374127, 0.15564838729775154, 0.04899832876233688, 0.41593065383339417, 0.3137496803420803, 0.023648819284619038, 0.43400579339543, 0.32107154953641204, 0.01, 0.02881424093635232, 0.7738703533569236, 0.2652189697297806, 0.47141317260058047, 0.30238181930555413, 0.8753810251103583, 0.032725671046240634, 0.5304486263312796, 0.01, 0.9197767419121832, 0.01, 0.5459444220042045, 0.6369748905974262, 0.3184883568482058, 0.26310360127610044, 0.3766687589509121, 0.27169457520766, 0.01, 0.014999388074150743, 0.01, 0.12036245412651181, 0.28414575927052943, 0.33974743840639177, 0.01, 0.372483420963218, 0.6190260622262593, 0.01, 0.09907988064660295, 0.01, 0.38257698240395194, 0.6039626510838418, 0.17777617396721856, 0.01, 0.327824220526483, 0.9318586639492967, 0.31669967573199626, 0.18555209556431201, 0.2185657005743401, 0.38180216080352725, 0.2882519367774068, 0.3577168361879667, 0.99, 0.339365995132756, 0.5122756630750651, 0.5478546763845941]
Training loss = 0.03301904360453288
step = 0, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.58125
Training loss = 0.03076613982518514
step = 1, Training Accuracy: 0.5366666666666666
Training loss = 0.03118209441502889
step = 2, Training Accuracy: 0.5533333333333333
Training loss = 0.02940050502618154
step = 3, Training Accuracy: 0.5733333333333334
Training loss = 0.02908675730228424
step = 4, Training Accuracy: 0.6166666666666667
Training loss = 0.03105880359808604
step = 5, Training Accuracy: 0.5433333333333333
Validation Accuracy: 0.55
Training loss = 0.0283763720591863
step = 6, Training Accuracy: 0.6033333333333334
Training loss = 0.02956155260403951
step = 7, Training Accuracy: 0.57
Training loss = 0.029706815282503764
step = 8, Training Accuracy: 0.57
Training loss = 0.02772995173931122
step = 9, Training Accuracy: 0.6
Training loss = 0.02737948735555013
step = 10, Training Accuracy: 0.62
Validation Accuracy: 0.56625
Training loss = 0.02827811320622762
step = 11, Training Accuracy: 0.63
Training loss = 0.028309635122617086
step = 12, Training Accuracy: 0.55
Training loss = 0.029046088059743246
step = 13, Training Accuracy: 0.5833333333333334
Training loss = 0.02880143404006958
step = 14, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.55625
params:  [0.5664058053813064, 0.48456776263495294, 0.17378147348282658, 0.7572451751354677, 0.38488486688828666, 0.6068569889994105, 0.4930453926100705, 0.38909439631587683, 0.99, 0.7861055482261262, 0.38080504729572257, 0.01, 0.8553204304860245, 0.6506891038994673, 0.5171451433312464, 0.783004830550263, 0.255765971971363, 0.3730910884153861, 0.8506333524855632, 0.08789782931496151, 0.5866758026628526, 0.6788671298234604, 0.01, 0.864529154538668, 0.8278261338647285, 0.023046849820829246, 0.7019726108463655, 0.27329411835045264, 0.01, 0.33634228944492756, 0.01, 0.3973855645878621, 0.10499367704238505, 0.27954974502451013, 0.1450070363729104, 0.01, 0.3133751586950734, 0.99, 0.01, 0.4097700716331101, 0.5918349149010892, 0.8054821049029255, 0.6763547274742339, 0.01, 0.21976351015580892, 0.01, 0.589594155200253, 0.42017499579202905, 0.99, 0.8490051625605204, 0.31495095368628856, 0.27582823121941213, 0.99, 0.42093837497852243, 0.01, 0.7834931747527099, 0.029827498495300864, 0.32341664179034835, 0.5554307765201831, 0.8786522858616896, 0.2820453324173383, 0.35501287471981136]
[0.5664058053813064, 0.48456776263495294, 0.17378147348282658, 0.7572451751354677, 0.38488486688828666, 0.6068569889994105, 0.4930453926100705, 0.38909439631587683, 0.99, 0.7861055482261262, 0.38080504729572257, 0.01, 0.8553204304860245, 0.6506891038994673, 0.5171451433312464, 0.783004830550263, 0.255765971971363, 0.3730910884153861, 0.8506333524855632, 0.08789782931496151, 0.5866758026628526, 0.6788671298234604, 0.01, 0.864529154538668, 0.8278261338647285, 0.023046849820829246, 0.7019726108463655, 0.27329411835045264, 0.01, 0.33634228944492756, 0.01, 0.3973855645878621, 0.10499367704238505, 0.27954974502451013, 0.1450070363729104, 0.01, 0.3133751586950734, 0.99, 0.01, 0.4097700716331101, 0.5918349149010892, 0.8054821049029255, 0.6763547274742339, 0.01, 0.21976351015580892, 0.01, 0.589594155200253, 0.42017499579202905, 0.99, 0.8490051625605204, 0.31495095368628856, 0.27582823121941213, 0.99, 0.42093837497852243, 0.01, 0.7834931747527099, 0.029827498495300864, 0.32341664179034835, 0.5554307765201831, 0.8786522858616896, 0.2820453324173383, 0.35501287471981136]
Training loss = 0.03530782163143158
step = 0, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.5925
Training loss = 0.03367079456647237
step = 1, Training Accuracy: 0.47
Training loss = 0.03320468525091807
step = 2, Training Accuracy: 0.4866666666666667
Training loss = 0.032384479443232216
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03295512557029724
step = 4, Training Accuracy: 0.46
Training loss = 0.03328113516171773
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.545
Training loss = 0.03334308743476868
step = 6, Training Accuracy: 0.47333333333333333
Training loss = 0.03188336710135142
step = 7, Training Accuracy: 0.5166666666666667
Training loss = 0.030931236545244854
step = 8, Training Accuracy: 0.5366666666666666
Training loss = 0.03372862279415131
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.033206888635953266
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.54125
Training loss = 0.03248583654562632
step = 11, Training Accuracy: 0.5033333333333333
Training loss = 0.03232218603293101
step = 12, Training Accuracy: 0.52
Training loss = 0.03265372216701508
step = 13, Training Accuracy: 0.5033333333333333
Training loss = 0.033825661142667135
step = 14, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.57375
params:  [0.01, 0.6200032909698754, 0.6907091203310092, 0.36620165662993753, 0.531733969410506, 0.7388540091200633, 0.14777726202564317, 0.19106364473367982, 0.99, 0.890686406560684, 0.4146394310007418, 0.19738982342005956, 0.1335285998901184, 0.99, 0.01, 0.99, 0.01, 0.7941120101206333, 0.6468093950966969, 0.2688544446636861, 0.99, 0.01, 0.29343638154995205, 0.08002541909576308, 0.3124031059941836, 0.01, 0.7753644513839519, 0.07577800994852127, 0.018825664307183437, 0.04046897282947315, 0.12707862856218005, 0.32952849264116574, 0.13517400546914246, 0.2814508001679933, 0.01, 0.01, 0.01, 0.6897638689759417, 0.5828873661267315, 0.36543227817308843, 0.6235644640740592, 0.706128673089658, 0.2516239224867508, 0.25857825461822526, 0.13279869642764458, 0.3134902855004269, 0.1450822050541532, 0.44303033983517526, 0.669483772822765, 0.44128662306215843, 0.43506247861794534, 0.99, 0.99, 0.3269229684803902, 0.01, 0.31856046129604443, 0.17952914394911573, 0.5138903942707775, 0.99, 0.8195290777125714, 0.5842758326453592, 0.5934091895324902]
[0.01, 0.6200032909698754, 0.6907091203310092, 0.36620165662993753, 0.531733969410506, 0.7388540091200633, 0.14777726202564317, 0.19106364473367982, 0.99, 0.890686406560684, 0.4146394310007418, 0.19738982342005956, 0.1335285998901184, 0.99, 0.01, 0.99, 0.01, 0.7941120101206333, 0.6468093950966969, 0.2688544446636861, 0.99, 0.01, 0.29343638154995205, 0.08002541909576308, 0.3124031059941836, 0.01, 0.7753644513839519, 0.07577800994852127, 0.018825664307183437, 0.04046897282947315, 0.12707862856218005, 0.32952849264116574, 0.13517400546914246, 0.2814508001679933, 0.01, 0.01, 0.01, 0.6897638689759417, 0.5828873661267315, 0.36543227817308843, 0.6235644640740592, 0.706128673089658, 0.2516239224867508, 0.25857825461822526, 0.13279869642764458, 0.3134902855004269, 0.1450822050541532, 0.44303033983517526, 0.669483772822765, 0.44128662306215843, 0.43506247861794534, 0.99, 0.99, 0.3269229684803902, 0.01, 0.31856046129604443, 0.17952914394911573, 0.5138903942707775, 0.99, 0.8195290777125714, 0.5842758326453592, 0.5934091895324902]
Training loss = 0.031346909801165265
step = 0, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.605
Training loss = 0.0322532327969869
step = 1, Training Accuracy: 0.57
Training loss = 0.03040837903817495
step = 2, Training Accuracy: 0.5633333333333334
Training loss = 0.029450513323148093
step = 3, Training Accuracy: 0.6033333333333334
Training loss = 0.03168161292870839
step = 4, Training Accuracy: 0.5466666666666666
Training loss = 0.029116143981615702
step = 5, Training Accuracy: 0.6
Validation Accuracy: 0.59
Training loss = 0.027839380502700805
step = 6, Training Accuracy: 0.6333333333333333
Training loss = 0.029829331239064536
step = 7, Training Accuracy: 0.56
Training loss = 0.02990746815999349
step = 8, Training Accuracy: 0.58
Training loss = 0.028874947627385458
step = 9, Training Accuracy: 0.5833333333333334
Training loss = 0.028273786107699077
step = 10, Training Accuracy: 0.6066666666666667
Validation Accuracy: 0.61625
Training loss = 0.028614630699157716
step = 11, Training Accuracy: 0.5866666666666667
Training loss = 0.02793559928735097
step = 12, Training Accuracy: 0.6166666666666667
Training loss = 0.027874215245246886
step = 13, Training Accuracy: 0.6
Training loss = 0.02716155211130778
step = 14, Training Accuracy: 0.61
Validation Accuracy: 0.60875
1  	8     	0.549687	0.0293467	0.5125 	0.60875
params:  [0.46800659888447577, 0.6092720998042737, 0.5756896451028235, 0.20774896191838743, 0.36324392747218875, 0.7045378620367655, 0.01, 0.35436824114249, 0.99, 0.8168023844785514, 0.17226067769734524, 0.11856560855654685, 0.2419081462647785, 0.99, 0.3929690920621335, 0.99, 0.01, 0.8178788375457337, 0.5098993180455064, 0.4869470973577023, 0.5032080747770761, 0.5605058476701725, 0.16746142631330485, 0.1666816821575408, 0.7848761436827736, 0.04455486744109236, 0.439736252442677, 0.05414724619395203, 0.01, 0.01, 0.01, 0.01, 0.5978503879443109, 0.09547860554996795, 0.01, 0.01, 0.15704169525873315, 0.9213727580734082, 0.06535689045089282, 0.30100419857973615, 0.10307652206233847, 0.808775010131411, 0.6280362981057226, 0.5398689305710349, 0.01, 0.17553625487216964, 0.5729167577308708, 0.5075704405471848, 0.6056906987946679, 0.020825366281450763, 0.7636661878907717, 0.8198972037609464, 0.99, 0.03380309860886194, 0.290208277290237, 0.6856685082959815, 0.3476609255465555, 0.8016990277845852, 0.99, 0.804574227573601, 0.5701926787798715, 0.15019289239712302]
[0.46800659888447577, 0.6092720998042737, 0.5756896451028235, 0.20774896191838743, 0.36324392747218875, 0.7045378620367655, 0.01, 0.35436824114249, 0.99, 0.8168023844785514, 0.17226067769734524, 0.11856560855654685, 0.2419081462647785, 0.99, 0.3929690920621335, 0.99, 0.01, 0.8178788375457337, 0.5098993180455064, 0.4869470973577023, 0.5032080747770761, 0.5605058476701725, 0.16746142631330485, 0.1666816821575408, 0.7848761436827736, 0.04455486744109236, 0.439736252442677, 0.05414724619395203, 0.01, 0.01, 0.01, 0.01, 0.5978503879443109, 0.09547860554996795, 0.01, 0.01, 0.15704169525873315, 0.9213727580734082, 0.06535689045089282, 0.30100419857973615, 0.10307652206233847, 0.808775010131411, 0.6280362981057226, 0.5398689305710349, 0.01, 0.17553625487216964, 0.5729167577308708, 0.5075704405471848, 0.6056906987946679, 0.020825366281450763, 0.7636661878907717, 0.8198972037609464, 0.99, 0.03380309860886194, 0.290208277290237, 0.6856685082959815, 0.3476609255465555, 0.8016990277845852, 0.99, 0.804574227573601, 0.5701926787798715, 0.15019289239712302]
Training loss = 0.035724517504374186
step = 0, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.59625
Training loss = 0.03227368871370951
step = 1, Training Accuracy: 0.49333333333333335
Training loss = 0.03389051636060079
step = 2, Training Accuracy: 0.47
Training loss = 0.03279738545417785
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.03314284503459931
step = 4, Training Accuracy: 0.48
Training loss = 0.033107978900273644
step = 5, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.6075
Training loss = 0.033076553146044414
step = 6, Training Accuracy: 0.5
Training loss = 0.03392759203910828
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.03278432786464691
step = 8, Training Accuracy: 0.49
Training loss = 0.03258472601572673
step = 9, Training Accuracy: 0.49
Training loss = 0.03244623323281606
step = 10, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.57875
Training loss = 0.032570322950681053
step = 11, Training Accuracy: 0.49333333333333335
Training loss = 0.032177568276723224
step = 12, Training Accuracy: 0.5366666666666666
Training loss = 0.03332978308200836
step = 13, Training Accuracy: 0.49666666666666665
Training loss = 0.030739886164665223
step = 14, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.57125
params:  [0.26505201005961115, 0.8411842543842143, 0.3039004930329303, 0.4853805377816248, 0.41216715158189515, 0.5492768662953187, 0.01, 0.10372489861337485, 0.9469668412863367, 0.6070682431989869, 0.01, 0.8388956712097961, 0.01, 0.99, 0.6224216901619053, 0.99, 0.01, 0.29232261522031805, 0.21350269742767713, 0.01, 0.610415394619529, 0.01, 0.5190084231260427, 0.3174747483190922, 0.2673351066773556, 0.09248077775953543, 0.99, 0.01, 0.4984305921522311, 0.01, 0.7550294718344953, 0.3333025987294566, 0.01, 0.09758367411921909, 0.6840204620079567, 0.01, 0.01, 0.9462704669990044, 0.407136522174255, 0.24479937267078664, 0.2762927311409772, 0.6577298328921436, 0.24078664523871532, 0.01, 0.01, 0.20702798296031, 0.21708570715940215, 0.574638226359814, 0.329160142429567, 0.40717207737700434, 0.01, 0.29677509331581603, 0.6163231644644074, 0.3733432225121883, 0.2436836313856994, 0.99, 0.3862714349922639, 0.608829045746451, 0.9330309138629393, 0.9116465377090999, 0.15473385559025826, 0.99]
[0.26505201005961115, 0.8411842543842143, 0.3039004930329303, 0.4853805377816248, 0.41216715158189515, 0.5492768662953187, 0.01, 0.10372489861337485, 0.9469668412863367, 0.6070682431989869, 0.01, 0.8388956712097961, 0.01, 0.99, 0.6224216901619053, 0.99, 0.01, 0.29232261522031805, 0.21350269742767713, 0.01, 0.610415394619529, 0.01, 0.5190084231260427, 0.3174747483190922, 0.2673351066773556, 0.09248077775953543, 0.99, 0.01, 0.4984305921522311, 0.01, 0.7550294718344953, 0.3333025987294566, 0.01, 0.09758367411921909, 0.6840204620079567, 0.01, 0.01, 0.9462704669990044, 0.407136522174255, 0.24479937267078664, 0.2762927311409772, 0.6577298328921436, 0.24078664523871532, 0.01, 0.01, 0.20702798296031, 0.21708570715940215, 0.574638226359814, 0.329160142429567, 0.40717207737700434, 0.01, 0.29677509331581603, 0.6163231644644074, 0.3733432225121883, 0.2436836313856994, 0.99, 0.3862714349922639, 0.608829045746451, 0.9330309138629393, 0.9116465377090999, 0.15473385559025826, 0.99]
Training loss = 0.02946327785650889
step = 0, Training Accuracy: 0.57
Validation Accuracy: 0.56375
Training loss = 0.028047893047332764
step = 1, Training Accuracy: 0.6066666666666667
Training loss = 0.029167464176813762
step = 2, Training Accuracy: 0.5733333333333334
Training loss = 0.028684985836346943
step = 3, Training Accuracy: 0.5966666666666667
Training loss = 0.027392945488293966
step = 4, Training Accuracy: 0.5933333333333334
Training loss = 0.027045041720072428
step = 5, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.60375
Training loss = 0.027492058674494425
step = 6, Training Accuracy: 0.5966666666666667
Training loss = 0.02635186572869619
step = 7, Training Accuracy: 0.6266666666666667
Training loss = 0.02645276625951131
step = 8, Training Accuracy: 0.6466666666666666
Training loss = 0.026694423953692117
step = 9, Training Accuracy: 0.59
Training loss = 0.025894291400909424
step = 10, Training Accuracy: 0.6166666666666667
Validation Accuracy: 0.58875
Training loss = 0.0257586940129598
step = 11, Training Accuracy: 0.63
Training loss = 0.02490236202875773
step = 12, Training Accuracy: 0.61
Training loss = 0.025979246695836386
step = 13, Training Accuracy: 0.6233333333333333
Training loss = 0.026320897936820985
step = 14, Training Accuracy: 0.6333333333333333
Validation Accuracy: 0.595
params:  [0.06973047637395502, 0.8755109596185375, 0.6385128882021196, 0.5566573354366486, 0.24826052012409322, 0.7661432971870824, 0.15684660979259124, 0.5426583110768658, 0.7706513829810157, 0.8295407842494442, 0.6552230558562653, 0.6051511619445571, 0.5840322050461237, 0.99, 0.01, 0.31604757380755355, 0.5725003681362129, 0.5400785733003663, 0.5456270502252023, 0.320522115567291, 0.7711605836571576, 0.31600863378979155, 0.18544739231888754, 0.4045447582610684, 0.2793099211099933, 0.0964705729839043, 0.99, 0.09471119451156956, 0.30208694545470877, 0.1482047967724724, 0.01, 0.4891269100728812, 0.34518467536961445, 0.6200813152731883, 0.5689737616002407, 0.26334831994578434, 0.1498157778491787, 0.2502302016548212, 0.5664888509919273, 0.17813683816794146, 0.6868510919958873, 0.5663461404507464, 0.3448299429836874, 0.1893949215077889, 0.22238917450687995, 0.5082004781130894, 0.05426280518055826, 0.21087074425366403, 0.44268751500281933, 0.6528376212707876, 0.19372061055825068, 0.99, 0.99, 0.5666654888514201, 0.01, 0.29627140663603757, 0.09723003998509078, 0.6324151716396904, 0.8204885521249027, 0.5875802627274404, 0.5651025499598191, 0.4253515362108128]
[0.06973047637395502, 0.8755109596185375, 0.6385128882021196, 0.5566573354366486, 0.24826052012409322, 0.7661432971870824, 0.15684660979259124, 0.5426583110768658, 0.7706513829810157, 0.8295407842494442, 0.6552230558562653, 0.6051511619445571, 0.5840322050461237, 0.99, 0.01, 0.31604757380755355, 0.5725003681362129, 0.5400785733003663, 0.5456270502252023, 0.320522115567291, 0.7711605836571576, 0.31600863378979155, 0.18544739231888754, 0.4045447582610684, 0.2793099211099933, 0.0964705729839043, 0.99, 0.09471119451156956, 0.30208694545470877, 0.1482047967724724, 0.01, 0.4891269100728812, 0.34518467536961445, 0.6200813152731883, 0.5689737616002407, 0.26334831994578434, 0.1498157778491787, 0.2502302016548212, 0.5664888509919273, 0.17813683816794146, 0.6868510919958873, 0.5663461404507464, 0.3448299429836874, 0.1893949215077889, 0.22238917450687995, 0.5082004781130894, 0.05426280518055826, 0.21087074425366403, 0.44268751500281933, 0.6528376212707876, 0.19372061055825068, 0.99, 0.99, 0.5666654888514201, 0.01, 0.29627140663603757, 0.09723003998509078, 0.6324151716396904, 0.8204885521249027, 0.5875802627274404, 0.5651025499598191, 0.4253515362108128]
Training loss = 0.03407237807909647
step = 0, Training Accuracy: 0.55
Validation Accuracy: 0.5975
Training loss = 0.029994571010271708
step = 1, Training Accuracy: 0.56
Training loss = 0.030013617078463235
step = 2, Training Accuracy: 0.5333333333333333
Training loss = 0.027442203958829244
step = 3, Training Accuracy: 0.6466666666666666
Training loss = 0.031453391313552855
step = 4, Training Accuracy: 0.5766666666666667
Training loss = 0.028851988116900127
step = 5, Training Accuracy: 0.59
Validation Accuracy: 0.6
Training loss = 0.027319756348927814
step = 6, Training Accuracy: 0.63
Training loss = 0.026406626502672833
step = 7, Training Accuracy: 0.6266666666666667
Training loss = 0.02751033385594686
step = 8, Training Accuracy: 0.6066666666666667
Training loss = 0.02658387800057729
step = 9, Training Accuracy: 0.6233333333333333
Training loss = 0.028472060362497966
step = 10, Training Accuracy: 0.5666666666666667
Validation Accuracy: 0.59125
Training loss = 0.02789095719655355
step = 11, Training Accuracy: 0.6333333333333333
Training loss = 0.02619771718978882
step = 12, Training Accuracy: 0.6166666666666667
Training loss = 0.025835238695144654
step = 13, Training Accuracy: 0.65
Training loss = 0.02755181352297465
step = 14, Training Accuracy: 0.6366666666666667
Validation Accuracy: 0.6125
params:  [0.27668794169257643, 0.29004170759757925, 0.6160269553107388, 0.6903498010745954, 0.5479702866255599, 0.9079974606629059, 0.3075808774250089, 0.7742714212906101, 0.5223976586969015, 0.627832592236008, 0.5069505537793114, 0.45905064199264434, 0.329691671486596, 0.6652141151696579, 0.29977142283219366, 0.7930083244564055, 0.20769548355622686, 0.8791499737246213, 0.885359318126494, 0.01, 0.8691700691507062, 0.01, 0.2254833626873071, 0.28901072750856494, 0.19728663084120435, 0.01, 0.48993833908134, 0.12164916090388646, 0.01, 0.01, 0.19347145576925628, 0.01, 0.7768659086022105, 0.6724937790975964, 0.4176239680368656, 0.7022337701713448, 0.01, 0.01, 0.5140281179997878, 0.11166660339952666, 0.5401127695157597, 0.8316572924591108, 0.5610272450687057, 0.1608294945906163, 0.01, 0.5990944380115564, 0.7554661424327174, 0.7300222176783961, 0.4994283950954028, 0.7938395822409247, 0.46709846889735007, 0.6608355500498952, 0.8798791690389793, 0.01, 0.01, 0.6283638423401117, 0.033103219348890045, 0.01, 0.99, 0.29819809306873524, 0.6518913665415269, 0.5838922949550566]
[0.27668794169257643, 0.29004170759757925, 0.6160269553107388, 0.6903498010745954, 0.5479702866255599, 0.9079974606629059, 0.3075808774250089, 0.7742714212906101, 0.5223976586969015, 0.627832592236008, 0.5069505537793114, 0.45905064199264434, 0.329691671486596, 0.6652141151696579, 0.29977142283219366, 0.7930083244564055, 0.20769548355622686, 0.8791499737246213, 0.885359318126494, 0.01, 0.8691700691507062, 0.01, 0.2254833626873071, 0.28901072750856494, 0.19728663084120435, 0.01, 0.48993833908134, 0.12164916090388646, 0.01, 0.01, 0.19347145576925628, 0.01, 0.7768659086022105, 0.6724937790975964, 0.4176239680368656, 0.7022337701713448, 0.01, 0.01, 0.5140281179997878, 0.11166660339952666, 0.5401127695157597, 0.8316572924591108, 0.5610272450687057, 0.1608294945906163, 0.01, 0.5990944380115564, 0.7554661424327174, 0.7300222176783961, 0.4994283950954028, 0.7938395822409247, 0.46709846889735007, 0.6608355500498952, 0.8798791690389793, 0.01, 0.01, 0.6283638423401117, 0.033103219348890045, 0.01, 0.99, 0.29819809306873524, 0.6518913665415269, 0.5838922949550566]
Training loss = 0.034696849385897316
step = 0, Training Accuracy: 0.48
Validation Accuracy: 0.5775
Training loss = 0.033075126806894936
step = 1, Training Accuracy: 0.5533333333333333
Training loss = 0.03310040652751923
step = 2, Training Accuracy: 0.4866666666666667
Training loss = 0.031873239676157634
step = 3, Training Accuracy: 0.5166666666666667
Training loss = 0.03178422669569651
step = 4, Training Accuracy: 0.53
Training loss = 0.03367962181568146
step = 5, Training Accuracy: 0.5
Validation Accuracy: 0.6025
Training loss = 0.03076974332332611
step = 6, Training Accuracy: 0.5733333333333334
Training loss = 0.03018018066883087
step = 7, Training Accuracy: 0.57
Training loss = 0.030653257966041566
step = 8, Training Accuracy: 0.57
Training loss = 0.030531949996948242
step = 9, Training Accuracy: 0.5566666666666666
Training loss = 0.03017142395178477
step = 10, Training Accuracy: 0.6166666666666667
Validation Accuracy: 0.60125
Training loss = 0.029304420351982118
step = 11, Training Accuracy: 0.5933333333333334
Training loss = 0.030504740873972574
step = 12, Training Accuracy: 0.55
Training loss = 0.030625458558400473
step = 13, Training Accuracy: 0.5766666666666667
Training loss = 0.02984732488791148
step = 14, Training Accuracy: 0.5866666666666667
Validation Accuracy: 0.6
params:  [0.606330455653232, 0.1837346467949092, 0.469362224132003, 0.7620736105136872, 0.25851266485755964, 0.33884039163629676, 0.01, 0.01, 0.99, 0.7984845148779359, 0.18518464095772993, 0.0792849607585557, 0.41762817613809555, 0.5378428965122815, 0.010715729177674743, 0.99, 0.3729242360527182, 0.18791817954088624, 0.8115497536810681, 0.16392758874863747, 0.99, 0.3786944276506822, 0.5724511020099179, 0.01, 0.01, 0.01, 0.99, 0.43447473316767454, 0.07528478119563539, 0.5661271563284296, 0.3797011764004302, 0.7129718033515413, 0.17379601394341404, 0.01, 0.5050150033120098, 0.01, 0.09236187958798542, 0.8340301853360692, 0.4497568399379104, 0.12177828386872983, 0.4968449880162513, 0.21975856001490407, 0.09926429753877913, 0.06897028243379355, 0.4121260871508977, 0.1673500444159141, 0.5244893110881733, 0.5516607341229346, 0.8241196705020256, 0.8121282725904886, 0.2408091469444226, 0.6459385235799479, 0.6119139975364202, 0.01, 0.01, 0.5959617036968863, 0.01, 0.6120987861922456, 0.99, 0.6415190705980203, 0.49234890491406613, 0.2899709020223653]
[0.606330455653232, 0.1837346467949092, 0.469362224132003, 0.7620736105136872, 0.25851266485755964, 0.33884039163629676, 0.01, 0.01, 0.99, 0.7984845148779359, 0.18518464095772993, 0.0792849607585557, 0.41762817613809555, 0.5378428965122815, 0.010715729177674743, 0.99, 0.3729242360527182, 0.18791817954088624, 0.8115497536810681, 0.16392758874863747, 0.99, 0.3786944276506822, 0.5724511020099179, 0.01, 0.01, 0.01, 0.99, 0.43447473316767454, 0.07528478119563539, 0.5661271563284296, 0.3797011764004302, 0.7129718033515413, 0.17379601394341404, 0.01, 0.5050150033120098, 0.01, 0.09236187958798542, 0.8340301853360692, 0.4497568399379104, 0.12177828386872983, 0.4968449880162513, 0.21975856001490407, 0.09926429753877913, 0.06897028243379355, 0.4121260871508977, 0.1673500444159141, 0.5244893110881733, 0.5516607341229346, 0.8241196705020256, 0.8121282725904886, 0.2408091469444226, 0.6459385235799479, 0.6119139975364202, 0.01, 0.01, 0.5959617036968863, 0.01, 0.6120987861922456, 0.99, 0.6415190705980203, 0.49234890491406613, 0.2899709020223653]
Training loss = 0.032448292175928754
step = 0, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.6025
Training loss = 0.03195480326811473
step = 1, Training Accuracy: 0.52
Training loss = 0.031247295339902243
step = 2, Training Accuracy: 0.54
Training loss = 0.03099258363246918
step = 3, Training Accuracy: 0.5366666666666666
Training loss = 0.03002441187699636
step = 4, Training Accuracy: 0.5366666666666666
Training loss = 0.02920221984386444
step = 5, Training Accuracy: 0.5666666666666667
Validation Accuracy: 0.6075
Training loss = 0.030662975311279296
step = 6, Training Accuracy: 0.5766666666666667
Training loss = 0.02918151338895162
step = 7, Training Accuracy: 0.5833333333333334
Training loss = 0.02941600779692332
step = 8, Training Accuracy: 0.5966666666666667
Training loss = 0.028891244133313496
step = 9, Training Accuracy: 0.5633333333333334
Training loss = 0.03137049456437429
step = 10, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.60625
Training loss = 0.02922395706176758
step = 11, Training Accuracy: 0.55
Training loss = 0.028135144114494325
step = 12, Training Accuracy: 0.6266666666666667
Training loss = 0.030166286627451577
step = 13, Training Accuracy: 0.5733333333333334
Training loss = 0.029071768919626872
step = 14, Training Accuracy: 0.59
Validation Accuracy: 0.61375
params:  [0.03886615453805464, 0.8290267934239848, 0.5216102667042203, 0.603753258989287, 0.4688845821235261, 0.9795862996841718, 0.3333210803291954, 0.39287121565279925, 0.99, 0.99, 0.409304092565911, 0.2136625878352984, 0.18001868589636277, 0.6382877730548313, 0.5582166432649878, 0.7803442514536443, 0.01, 0.5828588262859836, 0.811994297188479, 0.01, 0.8898480421202839, 0.7148414847195497, 0.01, 0.2047145860978793, 0.8023164364259059, 0.01, 0.8716424816953202, 0.01, 0.1498208118851027, 0.22128880556183106, 0.23428463701679778, 0.31384113873548153, 0.41295790625705925, 0.05828224872258131, 0.02902676146304571, 0.33065584707702067, 0.01, 0.7816729247590918, 0.731060595930332, 0.9109678542013449, 0.5351523283143478, 0.6869438869419663, 0.6206423674267748, 0.29695636823808436, 0.01, 0.37267581051237153, 0.32287092359795705, 0.7222149982720634, 0.6110259781161895, 0.6639337922343022, 0.8191688536465036, 0.7288533149083714, 0.99, 0.5492279059600622, 0.39037024401622067, 0.28847312240212175, 0.020926962112947145, 0.7495981233965929, 0.99, 0.99, 0.45638216687005007, 0.6455180629390201]
[0.03886615453805464, 0.8290267934239848, 0.5216102667042203, 0.603753258989287, 0.4688845821235261, 0.9795862996841718, 0.3333210803291954, 0.39287121565279925, 0.99, 0.99, 0.409304092565911, 0.2136625878352984, 0.18001868589636277, 0.6382877730548313, 0.5582166432649878, 0.7803442514536443, 0.01, 0.5828588262859836, 0.811994297188479, 0.01, 0.8898480421202839, 0.7148414847195497, 0.01, 0.2047145860978793, 0.8023164364259059, 0.01, 0.8716424816953202, 0.01, 0.1498208118851027, 0.22128880556183106, 0.23428463701679778, 0.31384113873548153, 0.41295790625705925, 0.05828224872258131, 0.02902676146304571, 0.33065584707702067, 0.01, 0.7816729247590918, 0.731060595930332, 0.9109678542013449, 0.5351523283143478, 0.6869438869419663, 0.6206423674267748, 0.29695636823808436, 0.01, 0.37267581051237153, 0.32287092359795705, 0.7222149982720634, 0.6110259781161895, 0.6639337922343022, 0.8191688536465036, 0.7288533149083714, 0.99, 0.5492279059600622, 0.39037024401622067, 0.28847312240212175, 0.020926962112947145, 0.7495981233965929, 0.99, 0.99, 0.45638216687005007, 0.6455180629390201]
Training loss = 0.03356753726800283
step = 0, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.6125
Training loss = 0.03280294875303904
step = 1, Training Accuracy: 0.5166666666666667
Training loss = 0.03277925372123718
step = 2, Training Accuracy: 0.55
Training loss = 0.0332153175274531
step = 3, Training Accuracy: 0.51
Training loss = 0.0333801652987798
step = 4, Training Accuracy: 0.5233333333333333
Training loss = 0.032286195556322735
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.5925
Training loss = 0.03149084905783335
step = 6, Training Accuracy: 0.52
Training loss = 0.031087389787038167
step = 7, Training Accuracy: 0.51
Training loss = 0.030960482358932496
step = 8, Training Accuracy: 0.5433333333333333
Training loss = 0.03286099672317505
step = 9, Training Accuracy: 0.5333333333333333
Training loss = 0.032114858826001486
step = 10, Training Accuracy: 0.53
Validation Accuracy: 0.59625
Training loss = 0.03286643981933594
step = 11, Training Accuracy: 0.52
Training loss = 0.0320445171991984
step = 12, Training Accuracy: 0.55
Training loss = 0.03089276095231374
step = 13, Training Accuracy: 0.5866666666666667
Training loss = 0.030833456913630167
step = 14, Training Accuracy: 0.5533333333333333
Validation Accuracy: 0.595
params:  [0.4905107523219614, 0.99, 0.8796008890610663, 0.14951395295996445, 0.39724253908319496, 0.8065253430480025, 0.17207343028034255, 0.12698083392902315, 0.9683957436929191, 0.5790578888352912, 0.25988592173046376, 0.028909914424195576, 0.19364115869924184, 0.7072630265672484, 0.01, 0.99, 0.01, 0.291179904406345, 0.8226896997106136, 0.6021750094672869, 0.32105546563766485, 0.10098573536523459, 0.6073766453934593, 0.6269351661368474, 0.6339190827285546, 0.16705660128103242, 0.9127062523787657, 0.05051451251559967, 0.15035088976687508, 0.38125410040042984, 0.415570011130314, 0.01, 0.01, 0.7493588331901779, 0.01, 0.37692994755369663, 0.7290321745945321, 0.8026041390428376, 0.1405009362824599, 0.2256523374902521, 0.5065149168685718, 0.7483517206409462, 0.3160792057797668, 0.33743587846667383, 0.031147437592603272, 0.11546047740081872, 0.04175795189637693, 0.3619896632539274, 0.8956608589631041, 0.343768767829987, 0.3936900001174324, 0.9201597365374554, 0.99, 0.31872441705779636, 0.047505965100674244, 0.6461747732959486, 0.01, 0.4708774496002474, 0.4350023807502134, 0.7747286972826061, 0.052221378831232956, 0.15631266270052052]
[0.4905107523219614, 0.99, 0.8796008890610663, 0.14951395295996445, 0.39724253908319496, 0.8065253430480025, 0.17207343028034255, 0.12698083392902315, 0.9683957436929191, 0.5790578888352912, 0.25988592173046376, 0.028909914424195576, 0.19364115869924184, 0.7072630265672484, 0.01, 0.99, 0.01, 0.291179904406345, 0.8226896997106136, 0.6021750094672869, 0.32105546563766485, 0.10098573536523459, 0.6073766453934593, 0.6269351661368474, 0.6339190827285546, 0.16705660128103242, 0.9127062523787657, 0.05051451251559967, 0.15035088976687508, 0.38125410040042984, 0.415570011130314, 0.01, 0.01, 0.7493588331901779, 0.01, 0.37692994755369663, 0.7290321745945321, 0.8026041390428376, 0.1405009362824599, 0.2256523374902521, 0.5065149168685718, 0.7483517206409462, 0.3160792057797668, 0.33743587846667383, 0.031147437592603272, 0.11546047740081872, 0.04175795189637693, 0.3619896632539274, 0.8956608589631041, 0.343768767829987, 0.3936900001174324, 0.9201597365374554, 0.99, 0.31872441705779636, 0.047505965100674244, 0.6461747732959486, 0.01, 0.4708774496002474, 0.4350023807502134, 0.7747286972826061, 0.052221378831232956, 0.15631266270052052]
Training loss = 0.032133458256721495
step = 0, Training Accuracy: 0.53
Validation Accuracy: 0.6
Training loss = 0.031693651874860125
step = 1, Training Accuracy: 0.5333333333333333
Training loss = 0.030486094951629638
step = 2, Training Accuracy: 0.5433333333333333
Training loss = 0.030939230521519978
step = 3, Training Accuracy: 0.58
Training loss = 0.029680161476135253
step = 4, Training Accuracy: 0.56
Training loss = 0.03153517146905263
step = 5, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.57875
Training loss = 0.029482331474622092
step = 6, Training Accuracy: 0.61
Training loss = 0.031087624033292134
step = 7, Training Accuracy: 0.5533333333333333
Training loss = 0.028738253513971964
step = 8, Training Accuracy: 0.6133333333333333
Training loss = 0.030024396975835164
step = 9, Training Accuracy: 0.57
Training loss = 0.028158337076505027
step = 10, Training Accuracy: 0.62
Validation Accuracy: 0.60375
Training loss = 0.028013733426729838
step = 11, Training Accuracy: 0.6066666666666667
Training loss = 0.027345870931943256
step = 12, Training Accuracy: 0.57
Training loss = 0.029293854037920633
step = 13, Training Accuracy: 0.5833333333333334
Training loss = 0.02903207798798879
step = 14, Training Accuracy: 0.5833333333333334
Validation Accuracy: 0.60875
params:  [0.01, 0.8841156205120084, 0.559689563126724, 0.3529188304065547, 0.48575678418766444, 0.9130392359655581, 0.08653505623098434, 0.2940266506597969, 0.9478287599941067, 0.19112369509756122, 0.5788927935119064, 0.4784681163298692, 0.35936529456004246, 0.4051835780944576, 0.4592295580613671, 0.99, 0.13083400027935588, 0.7360025801141488, 0.9288745232686971, 0.7946905240525857, 0.6548245677896118, 0.4169053779136709, 0.537785007476805, 0.01, 0.5945782381758496, 0.01, 0.99, 0.14142054100574106, 0.03113953809261083, 0.2668747277985205, 0.01, 0.1844538596840196, 0.01, 0.27754271202332237, 0.01, 0.01, 0.01, 0.5142337835966844, 0.3600601462592711, 0.956756937859113, 0.5376566809243492, 0.8506803556503416, 0.01, 0.14794524902165182, 0.10592327864337149, 0.6966957115545319, 0.4874702835962077, 0.32386132125518363, 0.9073792703239107, 0.5591926991425801, 0.8766536457558503, 0.7721657065331412, 0.6011397529855282, 0.6496992660731244, 0.29161681150400465, 0.21607360299065959, 0.24399990996665322, 0.7178262755404925, 0.99, 0.40576639907652795, 0.8476928718490807, 0.3279662724144456]
[0.01, 0.8841156205120084, 0.559689563126724, 0.3529188304065547, 0.48575678418766444, 0.9130392359655581, 0.08653505623098434, 0.2940266506597969, 0.9478287599941067, 0.19112369509756122, 0.5788927935119064, 0.4784681163298692, 0.35936529456004246, 0.4051835780944576, 0.4592295580613671, 0.99, 0.13083400027935588, 0.7360025801141488, 0.9288745232686971, 0.7946905240525857, 0.6548245677896118, 0.4169053779136709, 0.537785007476805, 0.01, 0.5945782381758496, 0.01, 0.99, 0.14142054100574106, 0.03113953809261083, 0.2668747277985205, 0.01, 0.1844538596840196, 0.01, 0.27754271202332237, 0.01, 0.01, 0.01, 0.5142337835966844, 0.3600601462592711, 0.956756937859113, 0.5376566809243492, 0.8506803556503416, 0.01, 0.14794524902165182, 0.10592327864337149, 0.6966957115545319, 0.4874702835962077, 0.32386132125518363, 0.9073792703239107, 0.5591926991425801, 0.8766536457558503, 0.7721657065331412, 0.6011397529855282, 0.6496992660731244, 0.29161681150400465, 0.21607360299065959, 0.24399990996665322, 0.7178262755404925, 0.99, 0.40576639907652795, 0.8476928718490807, 0.3279662724144456]
Training loss = 0.029925642013549806
step = 0, Training Accuracy: 0.5733333333333334
Validation Accuracy: 0.605
Training loss = 0.030326072772343952
step = 1, Training Accuracy: 0.59
Training loss = 0.0310809584458669
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.030957422455151876
step = 3, Training Accuracy: 0.5466666666666666
Training loss = 0.029568792780240376
step = 4, Training Accuracy: 0.5333333333333333
Training loss = 0.03004304627577464
step = 5, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.585
Training loss = 0.029683023492495218
step = 6, Training Accuracy: 0.6033333333333334
Training loss = 0.030895219643910725
step = 7, Training Accuracy: 0.59
Training loss = 0.03069461981455485
step = 8, Training Accuracy: 0.56
Training loss = 0.029418302178382875
step = 9, Training Accuracy: 0.54
Training loss = 0.02930809458096822
step = 10, Training Accuracy: 0.5533333333333333
Validation Accuracy: 0.5775
Training loss = 0.027378674546877542
step = 11, Training Accuracy: 0.6133333333333333
Training loss = 0.030452611843744915
step = 12, Training Accuracy: 0.5433333333333333
Training loss = 0.028601802388827004
step = 13, Training Accuracy: 0.5666666666666667
Training loss = 0.02731013298034668
step = 14, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.58625
2  	8     	0.597813	0.0134593	0.57125	0.61375
params:  [0.26808527661776665, 0.30466869200943314, 0.576019916085225, 0.3866877695974611, 0.3852802563894636, 0.8470162130671912, 0.3701318783415136, 0.15664366214224296, 0.99, 0.804412208184131, 0.2815073031702689, 0.16257047529992932, 0.49347083370174394, 0.8653138494877524, 0.14769662977969564, 0.730793027934738, 0.02572659695787527, 0.16491805592327435, 0.7787048179164541, 0.01190858283465096, 0.8119904312494803, 0.12961564426026742, 0.6511042978796813, 0.03166718865720028, 0.23078473735747457, 0.08308232604235989, 0.706336023073549, 0.13388540321280618, 0.29394266717987727, 0.8977289454226076, 0.01, 0.99, 0.04491548382732172, 0.6963628216702469, 0.9114121481196429, 0.13930169967456874, 0.01, 0.9071815966937606, 0.33065287560489476, 0.09482239358413647, 0.33227717917724686, 0.5300319163740782, 0.01, 0.5239330760939336, 0.1596676453565417, 0.2792223445905383, 0.5348014497000202, 0.01, 0.7169732197905301, 0.9850516494262274, 0.3266877913403379, 0.99, 0.99, 0.18372676658676462, 0.01, 0.8316227275698393, 0.08244244945171685, 0.42529699170782, 0.99, 0.4757130854828592, 0.7378827954609145, 0.20799728245347998]
[0.26808527661776665, 0.30466869200943314, 0.576019916085225, 0.3866877695974611, 0.3852802563894636, 0.8470162130671912, 0.3701318783415136, 0.15664366214224296, 0.99, 0.804412208184131, 0.2815073031702689, 0.16257047529992932, 0.49347083370174394, 0.8653138494877524, 0.14769662977969564, 0.730793027934738, 0.02572659695787527, 0.16491805592327435, 0.7787048179164541, 0.01190858283465096, 0.8119904312494803, 0.12961564426026742, 0.6511042978796813, 0.03166718865720028, 0.23078473735747457, 0.08308232604235989, 0.706336023073549, 0.13388540321280618, 0.29394266717987727, 0.8977289454226076, 0.01, 0.99, 0.04491548382732172, 0.6963628216702469, 0.9114121481196429, 0.13930169967456874, 0.01, 0.9071815966937606, 0.33065287560489476, 0.09482239358413647, 0.33227717917724686, 0.5300319163740782, 0.01, 0.5239330760939336, 0.1596676453565417, 0.2792223445905383, 0.5348014497000202, 0.01, 0.7169732197905301, 0.9850516494262274, 0.3266877913403379, 0.99, 0.99, 0.18372676658676462, 0.01, 0.8316227275698393, 0.08244244945171685, 0.42529699170782, 0.99, 0.4757130854828592, 0.7378827954609145, 0.20799728245347998]
Training loss = 0.031297418475151065
step = 0, Training Accuracy: 0.5666666666666667
Validation Accuracy: 0.59125
Training loss = 0.03081485609213511
step = 1, Training Accuracy: 0.59
Training loss = 0.02898304065068563
step = 2, Training Accuracy: 0.5833333333333334
Training loss = 0.029431840578715007
step = 3, Training Accuracy: 0.6033333333333334
Training loss = 0.029651760856310525
step = 4, Training Accuracy: 0.5533333333333333
