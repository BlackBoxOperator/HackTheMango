pipeline:  [81, 14, 3, 35]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.047500888109207155
step = 0, Training Accuracy: 0.30666666666666664
Validation Accuracy: 0.30375
Training loss = 0.040254666606585186
step = 1, Training Accuracy: 0.4666666666666667
Training loss = 0.036028446555137636
step = 2, Training Accuracy: 0.4766666666666667
Training loss = 0.03289737343788147
step = 3, Training Accuracy: 0.48
Training loss = 0.030625884731610615
step = 4, Training Accuracy: 0.5433333333333333
Training loss = 0.026037755111853283
step = 5, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.53375
Training loss = 0.025178731282552082
step = 6, Training Accuracy: 0.6333333333333333
Training loss = 0.02522833307584127
step = 7, Training Accuracy: 0.63
Training loss = 0.02556097209453583
step = 8, Training Accuracy: 0.66
Training loss = 0.021615101397037505
step = 9, Training Accuracy: 0.71
Training loss = 0.020123924911022186
step = 10, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.5225
Training loss = 0.019402491251627605
step = 11, Training Accuracy: 0.74
Training loss = 0.019150125384330748
step = 12, Training Accuracy: 0.7466666666666667
Training loss = 0.018345264196395875
step = 13, Training Accuracy: 0.7766666666666666
Training loss = 0.018114572763442992
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.52875
pipeline:  [34, 8, 27, 72]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                               'always_apply': False,
                               'color_shift': (0.01, 0.05),
                               'intensity': (0.1, 0.5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04773966868718465
step = 0, Training Accuracy: 0.3933333333333333
Validation Accuracy: 0.3675
Training loss = 0.03665962596734365
step = 1, Training Accuracy: 0.4033333333333333
Training loss = 0.03559493521849314
step = 2, Training Accuracy: 0.4666666666666667
Training loss = 0.033698912461598715
step = 3, Training Accuracy: 0.4766666666666667
Training loss = 0.03214200973510742
step = 4, Training Accuracy: 0.5266666666666666
Training loss = 0.03169798771540324
step = 5, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.53875
Training loss = 0.031977907220522565
step = 6, Training Accuracy: 0.5366666666666666
Training loss = 0.03125026484330495
step = 7, Training Accuracy: 0.5433333333333333
Training loss = 0.029772587418556214
step = 8, Training Accuracy: 0.5633333333333334
Training loss = 0.029046330451965332
step = 9, Training Accuracy: 0.5633333333333334
Training loss = 0.02919492801030477
step = 10, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.585
Training loss = 0.028671087423960368
step = 11, Training Accuracy: 0.6133333333333333
Training loss = 0.02942745268344879
step = 12, Training Accuracy: 0.5766666666666667
Training loss = 0.029004734953244526
step = 13, Training Accuracy: 0.5933333333333334
Training loss = 0.027527966499328614
step = 14, Training Accuracy: 0.61
Validation Accuracy: 0.5675
pipeline:  [68, 16, 91, 84]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                                               'always_apply': False,
                                               'brightness_coeff': 2.5,
                                               'p': 0.5,
                                               'snow_point_lower': 0.1,
                                               'snow_point_upper': 0.3},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                                               'always_apply': False,
                                               'blur_value': 7,
                                               'brightness_coefficient': 0.7,
                                               'drop_color': (200, 200, 200),
                                               'drop_length': 20,
                                               'drop_width': 1,
                                               'p': 0.5,
                                               'rain_type': None,
                                               'slant_lower': -10,
                                               'slant_upper': 10},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                                               'alpha_coef': 0.08,
                                               'always_apply': False,
                                               'fog_coef_lower': 0.3,
                                               'fog_coef_upper': 1,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                                               'always_apply': False,
                                               'angle_lower': 0,
                                               'angle_upper': 1,
                                               'flare_roi': (0, 0, 1, 0.5),
                                               'num_flare_circles_lower': 6,
                                               'num_flare_circles_upper': 10,
                                               'p': 0.5,
                                               'src_color': (255, 255, 255),
                                               'src_radius': 400},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                                               'always_apply': False,
                                               'num_shadows_lower': 1,
                                               'num_shadows_upper': 2,
                                               'p': 0.5,
                                               'shadow_dimension': 5,
                                               'shadow_roi': (0, 0.5, 1, 1)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'threshold': (128, 128)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03510581771532695
step = 0, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.4925
Training loss = 0.035639049609502156
step = 1, Training Accuracy: 0.44666666666666666
Training loss = 0.036813820203145345
step = 2, Training Accuracy: 0.42
Training loss = 0.0336273850997289
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03247549076875051
step = 4, Training Accuracy: 0.5033333333333333
Training loss = 0.03495358089605967
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.53
Training loss = 0.03221595267454783
step = 6, Training Accuracy: 0.5033333333333333
Training loss = 0.031622679432233174
step = 7, Training Accuracy: 0.53
Training loss = 0.031706224083900454
step = 8, Training Accuracy: 0.5333333333333333
Training loss = 0.031443508664766945
step = 9, Training Accuracy: 0.51
Training loss = 0.03198871850967407
step = 10, Training Accuracy: 0.52
Validation Accuracy: 0.49375
Training loss = 0.030898263653119405
step = 11, Training Accuracy: 0.55
Training loss = 0.03365218857924143
step = 12, Training Accuracy: 0.5233333333333333
Training loss = 0.03176132659117381
step = 13, Training Accuracy: 0.5633333333333334
Training loss = 0.0308353853225708
step = 14, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.54
pipeline:  [52, 62, 61, 27]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03235037783781687
step = 0, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.55375
Training loss = 0.03185689806938172
step = 1, Training Accuracy: 0.56
Training loss = 0.030397584239641826
step = 2, Training Accuracy: 0.54
Training loss = 0.028456602096557617
step = 3, Training Accuracy: 0.5833333333333334
Training loss = 0.0293093470732371
step = 4, Training Accuracy: 0.5833333333333334
Training loss = 0.02701254665851593
step = 5, Training Accuracy: 0.6566666666666666
Validation Accuracy: 0.58
Training loss = 0.027053769826889038
step = 6, Training Accuracy: 0.6333333333333333
Training loss = 0.02788029134273529
step = 7, Training Accuracy: 0.6166666666666667
Training loss = 0.028758909106254577
step = 8, Training Accuracy: 0.6133333333333333
Training loss = 0.026823810935020446
step = 9, Training Accuracy: 0.64
Training loss = 0.024649946093559263
step = 10, Training Accuracy: 0.6733333333333333
Validation Accuracy: 0.59375
Training loss = 0.023919922709465028
step = 11, Training Accuracy: 0.68
Training loss = 0.02663477897644043
step = 12, Training Accuracy: 0.6333333333333333
Training loss = 0.029847861925760905
step = 13, Training Accuracy: 0.6233333333333333
Training loss = 0.026510427196820577
step = 14, Training Accuracy: 0.6533333333333333
Validation Accuracy: 0.5975
pipeline:  [17, 33, 14, 13]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.030381940007209778
step = 0, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.59
Training loss = 0.029394304951032003
step = 1, Training Accuracy: 0.64
Training loss = 0.02741175870100657
step = 2, Training Accuracy: 0.6666666666666666
Training loss = 0.024577497045199077
step = 3, Training Accuracy: 0.7066666666666667
Training loss = 0.023553620378176373
step = 4, Training Accuracy: 0.71
Training loss = 0.02208106259504954
step = 5, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.5925
Training loss = 0.02042091151078542
step = 6, Training Accuracy: 0.75
Training loss = 0.019903038839499156
step = 7, Training Accuracy: 0.7366666666666667
Training loss = 0.016654406388600666
step = 8, Training Accuracy: 0.7966666666666666
Training loss = 0.016923268338044483
step = 9, Training Accuracy: 0.81
Training loss = 0.01368977482120196
step = 10, Training Accuracy: 0.85
Validation Accuracy: 0.58
Training loss = 0.014268760532140733
step = 11, Training Accuracy: 0.8166666666666667
Training loss = 0.013723513682683309
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.01385089486837387
step = 13, Training Accuracy: 0.83
Training loss = 0.01522996465365092
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.51375
pipeline:  [44, 82, 65, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.039047653873761495
step = 0, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.5
Training loss = 0.03293550451596578
step = 1, Training Accuracy: 0.54
Training loss = 0.0286773814757665
step = 2, Training Accuracy: 0.6066666666666667
Training loss = 0.02790751854578654
step = 3, Training Accuracy: 0.6
Training loss = 0.027064311106999715
step = 4, Training Accuracy: 0.6266666666666667
Training loss = 0.02745830496152242
step = 5, Training Accuracy: 0.6266666666666667
Validation Accuracy: 0.56625
Training loss = 0.025534717440605162
step = 6, Training Accuracy: 0.6
Training loss = 0.02690921982129415
step = 7, Training Accuracy: 0.6566666666666666
Training loss = 0.02546256105105082
step = 8, Training Accuracy: 0.6566666666666666
Training loss = 0.02653223156929016
step = 9, Training Accuracy: 0.5866666666666667
Training loss = 0.0256166934967041
step = 10, Training Accuracy: 0.64
Validation Accuracy: 0.56625
Training loss = 0.025644686818122864
step = 11, Training Accuracy: 0.6333333333333333
Training loss = 0.023862438003222148
step = 12, Training Accuracy: 0.6666666666666666
Training loss = 0.023775719006856284
step = 13, Training Accuracy: 0.68
Training loss = 0.02331999997297923
step = 14, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.55125
gen	nevals	Avg     	Std      	Min    	Max   
0  	6     	0.549792	0.0271705	0.51375	0.5975
pipeline:  [68, 5, 27, 23]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03125167409578959
step = 0, Training Accuracy: 0.58
Validation Accuracy: 0.585
Training loss = 0.028391645550727845
step = 1, Training Accuracy: 0.5866666666666667
Training loss = 0.02607734938462575
step = 2, Training Accuracy: 0.6433333333333333
Training loss = 0.024035258889198302
step = 3, Training Accuracy: 0.6933333333333334
Training loss = 0.02411536792914073
step = 4, Training Accuracy: 0.68
Training loss = 0.023627012769381204
step = 5, Training Accuracy: 0.66
Validation Accuracy: 0.59
Training loss = 0.02143106798330943
step = 6, Training Accuracy: 0.7066666666666667
Training loss = 0.022963648438453676
step = 7, Training Accuracy: 0.6933333333333334
Training loss = 0.023452564775943756
step = 8, Training Accuracy: 0.7133333333333334
Training loss = 0.0200054806470871
step = 9, Training Accuracy: 0.73
Training loss = 0.02186661273241043
step = 10, Training Accuracy: 0.7233333333333334
Validation Accuracy: 0.6
Training loss = 0.021716844141483307
step = 11, Training Accuracy: 0.7266666666666667
Training loss = 0.02037758747736613
step = 12, Training Accuracy: 0.7666666666666667
Training loss = 0.02062330275774002
step = 13, Training Accuracy: 0.7166666666666667
Training loss = 0.019465041955312092
step = 14, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.5625
pipeline:  [37, 2, 6, 84]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                                               'always_apply': False,
                                               'brightness_coeff': 2.5,
                                               'p': 0.5,
                                               'snow_point_lower': 0.1,
                                               'snow_point_upper': 0.3},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                                               'always_apply': False,
                                               'blur_value': 7,
                                               'brightness_coefficient': 0.7,
                                               'drop_color': (200, 200, 200),
                                               'drop_length': 20,
                                               'drop_width': 1,
                                               'p': 0.5,
                                               'rain_type': None,
                                               'slant_lower': -10,
                                               'slant_upper': 10},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                                               'alpha_coef': 0.08,
                                               'always_apply': False,
                                               'fog_coef_lower': 0.3,
                                               'fog_coef_upper': 1,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                                               'always_apply': False,
                                               'angle_lower': 0,
                                               'angle_upper': 1,
                                               'flare_roi': (0, 0, 1, 0.5),
                                               'num_flare_circles_lower': 6,
                                               'num_flare_circles_upper': 10,
                                               'p': 0.5,
                                               'src_color': (255, 255, 255),
                                               'src_radius': 400},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                                               'always_apply': False,
                                               'num_shadows_lower': 1,
                                               'num_shadows_upper': 2,
                                               'p': 0.5,
                                               'shadow_dimension': 5,
                                               'shadow_roi': (0, 0.5, 1, 1)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.037361599405606585
step = 0, Training Accuracy: 0.5
Validation Accuracy: 0.52625
Training loss = 0.03317423979441325
step = 1, Training Accuracy: 0.5133333333333333
Training loss = 0.031773308316866554
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.03123502274354299
step = 3, Training Accuracy: 0.5033333333333333
Training loss = 0.03081041395664215
step = 4, Training Accuracy: 0.6
Training loss = 0.028609102567036946
step = 5, Training Accuracy: 0.6266666666666667
Validation Accuracy: 0.555
Training loss = 0.029933049281438192
step = 6, Training Accuracy: 0.5566666666666666
Training loss = 0.027876476844151815
step = 7, Training Accuracy: 0.6
Training loss = 0.027924556930859882
step = 8, Training Accuracy: 0.6166666666666667
Training loss = 0.02715847154458364
step = 9, Training Accuracy: 0.6366666666666667
Training loss = 0.027329147458076478
step = 10, Training Accuracy: 0.6233333333333333
Validation Accuracy: 0.5875
Training loss = 0.026461306015650433
step = 11, Training Accuracy: 0.6933333333333334
Training loss = 0.025500348806381225
step = 12, Training Accuracy: 0.6733333333333333
Training loss = 0.024216957092285156
step = 13, Training Accuracy: 0.6733333333333333
Training loss = 0.025180176695187885
step = 14, Training Accuracy: 0.6533333333333333
Validation Accuracy: 0.57375
1  	2     	0.565417	0.0180662	0.54   	0.5975
pipeline:  [52, 62, 61, 27]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03203151941299438
step = 0, Training Accuracy: 0.5533333333333333
Validation Accuracy: 0.59875
Training loss = 0.029349015553792317
step = 1, Training Accuracy: 0.62
Training loss = 0.027634523510932922
step = 2, Training Accuracy: 0.64
Training loss = 0.027181932330131532
step = 3, Training Accuracy: 0.6433333333333333
Training loss = 0.026227084398269655
step = 4, Training Accuracy: 0.61
Training loss = 0.02652518928050995
step = 5, Training Accuracy: 0.69
Validation Accuracy: 0.5775
Training loss = 0.027068556944529216
step = 6, Training Accuracy: 0.6333333333333333
Training loss = 0.024251158436139425
step = 7, Training Accuracy: 0.7066666666666667
Training loss = 0.025899746815363566
step = 8, Training Accuracy: 0.6766666666666666
Training loss = 0.02387151082356771
step = 9, Training Accuracy: 0.6833333333333333
Training loss = 0.02286568284034729
step = 10, Training Accuracy: 0.7
Validation Accuracy: 0.6025
Training loss = 0.023031271696090698
step = 11, Training Accuracy: 0.6666666666666666
Training loss = 0.023675931990146636
step = 12, Training Accuracy: 0.7233333333333334
Training loss = 0.024269304672876992
step = 13, Training Accuracy: 0.6966666666666667
Training loss = 0.022610065539677936
step = 14, Training Accuracy: 0.7066666666666667
Validation Accuracy: 0.58125
pipeline:  [92, 76, 16, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                               'always_apply': False,
                               'p': 0.5,
                               'threshold': (128, 128)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03652224858601888
step = 0, Training Accuracy: 0.52
Validation Accuracy: 0.59625
Training loss = 0.030683571298917134
step = 1, Training Accuracy: 0.5066666666666667
Training loss = 0.02885282019774119
step = 2, Training Accuracy: 0.62
Training loss = 0.02808509866396586
step = 3, Training Accuracy: 0.5866666666666667
Training loss = 0.027400606671969096
step = 4, Training Accuracy: 0.5966666666666667
Training loss = 0.026445330977439882
step = 5, Training Accuracy: 0.62
Validation Accuracy: 0.59125
Training loss = 0.026243378619352976
step = 6, Training Accuracy: 0.63
Training loss = 0.025381928086280824
step = 7, Training Accuracy: 0.6333333333333333
Training loss = 0.025780258476734163
step = 8, Training Accuracy: 0.6433333333333333
Training loss = 0.025526307821273804
step = 9, Training Accuracy: 0.65
Training loss = 0.025353017846743264
step = 10, Training Accuracy: 0.6666666666666666
Validation Accuracy: 0.59625
Training loss = 0.024528992772102357
step = 11, Training Accuracy: 0.6533333333333333
Training loss = 0.024903939763704936
step = 12, Training Accuracy: 0.6433333333333333
Training loss = 0.02326161543528239
step = 13, Training Accuracy: 0.69
Training loss = 0.023436112403869627
step = 14, Training Accuracy: 0.6766666666666666
Validation Accuracy: 0.60375
pipeline:  [65, 33, 87, 15]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03414045989513397
step = 0, Training Accuracy: 0.5466666666666666
Validation Accuracy: 0.38875
Training loss = 0.029511691133181254
step = 1, Training Accuracy: 0.5766666666666667
Training loss = 0.027309807936350506
step = 2, Training Accuracy: 0.64
Training loss = 0.026436680157979328
step = 3, Training Accuracy: 0.6366666666666667
Training loss = 0.025661673347155252
step = 4, Training Accuracy: 0.6566666666666666
Training loss = 0.026444477836290996
step = 5, Training Accuracy: 0.64
Validation Accuracy: 0.36
Training loss = 0.026366389592488607
step = 6, Training Accuracy: 0.63
Training loss = 0.024695943792661032
step = 7, Training Accuracy: 0.65
Training loss = 0.023885870178540547
step = 8, Training Accuracy: 0.65
Training loss = 0.02355745236078898
step = 9, Training Accuracy: 0.6866666666666666
Training loss = 0.02357163727283478
step = 10, Training Accuracy: 0.6633333333333333
Validation Accuracy: 0.36125
Training loss = 0.021413745482762654
step = 11, Training Accuracy: 0.7233333333333334
Training loss = 0.022708280384540556
step = 12, Training Accuracy: 0.7166666666666667
Training loss = 0.020128496984640757
step = 13, Training Accuracy: 0.6933333333333334
Training loss = 0.022432906329631807
step = 14, Training Accuracy: 0.71
Validation Accuracy: 0.3475
pipeline:  [62, 36, 61, 28]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.033876816829045614
step = 0, Training Accuracy: 0.56
Validation Accuracy: 0.59875
Training loss = 0.02827816943327586
step = 1, Training Accuracy: 0.6366666666666667
Training loss = 0.026609416604042053
step = 2, Training Accuracy: 0.6466666666666666
Training loss = 0.02688125828901927
step = 3, Training Accuracy: 0.6633333333333333
Training loss = 0.02512066900730133
step = 4, Training Accuracy: 0.6733333333333333
Training loss = 0.02365129510561625
step = 5, Training Accuracy: 0.6833333333333333
Validation Accuracy: 0.62
Training loss = 0.024185840586821238
step = 6, Training Accuracy: 0.71
Training loss = 0.027752164800961814
step = 7, Training Accuracy: 0.6533333333333333
Training loss = 0.024513514041900636
step = 8, Training Accuracy: 0.64
Training loss = 0.02298670987288157
step = 9, Training Accuracy: 0.6966666666666667
Training loss = 0.02357952614625295
step = 10, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.61125
Training loss = 0.021342240075270334
step = 11, Training Accuracy: 0.7133333333333334
Training loss = 0.02068337102731069
step = 12, Training Accuracy: 0.7166666666666667
Training loss = 0.022629035115242006
step = 13, Training Accuracy: 0.74
Training loss = 0.02372904817263285
step = 14, Training Accuracy: 0.68
Validation Accuracy: 0.59125
2  	4     	0.543333	0.0885316	0.3475 	0.60375
pipeline:  [67, 57, 26, 53]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.033815295298894245
step = 0, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.5575
Training loss = 0.03141307532787323
step = 1, Training Accuracy: 0.55
Training loss = 0.030590124924977622
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.03135220726331075
step = 3, Training Accuracy: 0.5633333333333334
Training loss = 0.030005021293958028
step = 4, Training Accuracy: 0.5633333333333334
Training loss = 0.03070564349492391
step = 5, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.5625
Training loss = 0.029999990463256836
step = 6, Training Accuracy: 0.49333333333333335
Training loss = 0.02914488176504771
step = 7, Training Accuracy: 0.54
Training loss = 0.02882764458656311
step = 8, Training Accuracy: 0.5666666666666667
Training loss = 0.02869745135307312
step = 9, Training Accuracy: 0.56
Training loss = 0.030109325249989827
step = 10, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.58125
Training loss = 0.028864010175069173
step = 11, Training Accuracy: 0.6066666666666667
Training loss = 0.028379661043485004
step = 12, Training Accuracy: 0.57
Training loss = 0.028821776111920674
step = 13, Training Accuracy: 0.54
Training loss = 0.028066574732462567
step = 14, Training Accuracy: 0.5866666666666667
Validation Accuracy: 0.56875
pipeline:  [37, 2, 6, 84]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                                               'always_apply': False,
                                               'brightness_coeff': 2.5,
                                               'p': 0.5,
                                               'snow_point_lower': 0.1,
                                               'snow_point_upper': 0.3},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                                               'always_apply': False,
                                               'blur_value': 7,
                                               'brightness_coefficient': 0.7,
                                               'drop_color': (200, 200, 200),
                                               'drop_length': 20,
                                               'drop_width': 1,
                                               'p': 0.5,
                                               'rain_type': None,
                                               'slant_lower': -10,
                                               'slant_upper': 10},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                                               'alpha_coef': 0.08,
                                               'always_apply': False,
                                               'fog_coef_lower': 0.3,
                                               'fog_coef_upper': 1,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                                               'always_apply': False,
                                               'angle_lower': 0,
                                               'angle_upper': 1,
                                               'flare_roi': (0, 0, 1, 0.5),
                                               'num_flare_circles_lower': 6,
                                               'num_flare_circles_upper': 10,
                                               'p': 0.5,
                                               'src_color': (255, 255, 255),
                                               'src_radius': 400},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                                               'always_apply': False,
                                               'num_shadows_lower': 1,
                                               'num_shadows_upper': 2,
                                               'p': 0.5,
                                               'shadow_dimension': 5,
                                               'shadow_roi': (0, 0.5, 1, 1)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.033040642738342285
step = 0, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.6125
Training loss = 0.030819319486618042
step = 1, Training Accuracy: 0.5333333333333333
Training loss = 0.02961232662200928
step = 2, Training Accuracy: 0.5466666666666666
Training loss = 0.027114816109339395
step = 3, Training Accuracy: 0.6133333333333333
Training loss = 0.02823180298010508
step = 4, Training Accuracy: 0.6166666666666667
Training loss = 0.026874393622080484
step = 5, Training Accuracy: 0.6333333333333333
Validation Accuracy: 0.595
Training loss = 0.026742103099822997
step = 6, Training Accuracy: 0.66
Training loss = 0.027338460485140482
step = 7, Training Accuracy: 0.6133333333333333
Training loss = 0.025275160272916156
step = 8, Training Accuracy: 0.6566666666666666
Training loss = 0.024933844606081643
step = 9, Training Accuracy: 0.6366666666666667
Training loss = 0.021734079122543336
step = 10, Training Accuracy: 0.71
Validation Accuracy: 0.60375
Training loss = 0.02471516211827596
step = 11, Training Accuracy: 0.68
Training loss = 0.023291047910849252
step = 12, Training Accuracy: 0.67
Training loss = 0.024487760265668235
step = 13, Training Accuracy: 0.6766666666666666
Training loss = 0.022980212370554608
step = 14, Training Accuracy: 0.72
Validation Accuracy: 0.5775
pipeline:  [62, 27, 61, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.029081393082936606
step = 0, Training Accuracy: 0.6266666666666667
Validation Accuracy: 0.61375
Training loss = 0.02601876119772593
step = 1, Training Accuracy: 0.6566666666666666
Training loss = 0.02459772566954295
step = 2, Training Accuracy: 0.6233333333333333
Training loss = 0.022882087429364522
step = 3, Training Accuracy: 0.71
Training loss = 0.01973208278417587
step = 4, Training Accuracy: 0.7233333333333334
Training loss = 0.019676414330800373
step = 5, Training Accuracy: 0.74
Validation Accuracy: 0.57875
Training loss = 0.02001325786113739
step = 6, Training Accuracy: 0.73
Training loss = 0.01892724394798279
step = 7, Training Accuracy: 0.76
Training loss = 0.023029472827911377
step = 8, Training Accuracy: 0.7333333333333333
Training loss = 0.01993405322233836
step = 9, Training Accuracy: 0.7266666666666667
Training loss = 0.01941204567750295
step = 10, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.63375
Training loss = 0.018763999342918395
step = 11, Training Accuracy: 0.7666666666666667
Training loss = 0.017855962614218394
step = 12, Training Accuracy: 0.8
Training loss = 0.01875595470269521
step = 13, Training Accuracy: 0.78
Training loss = 0.016953242719173433
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.63125
pipeline:  [37, 56, 12, 86]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.031042803525924683
step = 0, Training Accuracy: 0.62
Validation Accuracy: 0.6475
Training loss = 0.028990925947825114
step = 1, Training Accuracy: 0.63
Training loss = 0.02858441134293874
step = 2, Training Accuracy: 0.63
Training loss = 0.025744911630948386
step = 3, Training Accuracy: 0.6366666666666667
Training loss = 0.022712886929512024
step = 4, Training Accuracy: 0.6633333333333333
Training loss = 0.022089165250460306
step = 5, Training Accuracy: 0.71
Validation Accuracy: 0.65125
Training loss = 0.025014440019925435
step = 6, Training Accuracy: 0.6966666666666667
Training loss = 0.022860227227210997
step = 7, Training Accuracy: 0.6966666666666667
Training loss = 0.02177182932694753
step = 8, Training Accuracy: 0.71
Training loss = 0.020446742077668507
step = 9, Training Accuracy: 0.7466666666666667
Training loss = 0.019734882215658823
step = 10, Training Accuracy: 0.7333333333333333
Validation Accuracy: 0.66625
Training loss = 0.02195240338643392
step = 11, Training Accuracy: 0.7266666666666667
Training loss = 0.021536480486392975
step = 12, Training Accuracy: 0.7333333333333333
Training loss = 0.019419435958067575
step = 13, Training Accuracy: 0.7566666666666667
Training loss = 0.018123433887958527
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.68
3  	4     	0.607083	0.0385659	0.56875	0.68   
pipeline:  [61, 62, 39, 53]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02471954107284546
step = 0, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.6775
Training loss = 0.02403558909893036
step = 1, Training Accuracy: 0.7
Training loss = 0.022246668537457784
step = 2, Training Accuracy: 0.7066666666666667
Training loss = 0.020324083666006725
step = 3, Training Accuracy: 0.73
Training loss = 0.01883749802907308
step = 4, Training Accuracy: 0.77
Training loss = 0.021792616844177246
step = 5, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.6825
Training loss = 0.019658115804195405
step = 6, Training Accuracy: 0.7333333333333333
Training loss = 0.018253482033809026
step = 7, Training Accuracy: 0.7966666666666666
Training loss = 0.01700262427330017
step = 8, Training Accuracy: 0.79
Training loss = 0.016931452850500742
step = 9, Training Accuracy: 0.7866666666666666
Training loss = 0.015634217858314516
step = 10, Training Accuracy: 0.83
Validation Accuracy: 0.65125
Training loss = 0.013865311642487844
step = 11, Training Accuracy: 0.85
Training loss = 0.013598492294549942
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.015573749442895253
step = 13, Training Accuracy: 0.8166666666666667
Training loss = 0.012158508201440175
step = 14, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.63625
pipeline:  [62, 27, 61, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.026275345385074617
step = 0, Training Accuracy: 0.68
Validation Accuracy: 0.53875
Training loss = 0.023344732224941253
step = 1, Training Accuracy: 0.6933333333333334
Training loss = 0.01978567361831665
step = 2, Training Accuracy: 0.7433333333333333
Training loss = 0.01964845061302185
step = 3, Training Accuracy: 0.76
Training loss = 0.0185641144712766
step = 4, Training Accuracy: 0.75
Training loss = 0.01852503369251887
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.68375
Training loss = 0.016253793239593507
step = 6, Training Accuracy: 0.8
Training loss = 0.016271192183097204
step = 7, Training Accuracy: 0.7766666666666666
Training loss = 0.01704126924276352
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.015112411379814148
step = 9, Training Accuracy: 0.81
Training loss = 0.015757245520750682
step = 10, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.6675
Training loss = 0.015350417494773864
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.014824771881103515
step = 12, Training Accuracy: 0.82
Training loss = 0.014153520117203394
step = 13, Training Accuracy: 0.82
Training loss = 0.01468496153752009
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.6725
pipeline:  [20, 72, 87, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04648992677529653
step = 0, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.5625
Training loss = 0.03485238552093506
step = 1, Training Accuracy: 0.5166666666666667
Training loss = 0.031091021696726482
step = 2, Training Accuracy: 0.5533333333333333
Training loss = 0.0302355287472407
step = 3, Training Accuracy: 0.6
Training loss = 0.02956321040789286
step = 4, Training Accuracy: 0.5566666666666666
Training loss = 0.027993828058242798
step = 5, Training Accuracy: 0.5533333333333333
Validation Accuracy: 0.635
Training loss = 0.029173195362091064
step = 6, Training Accuracy: 0.5566666666666666
Training loss = 0.028255291978518168
step = 7, Training Accuracy: 0.5833333333333334
Training loss = 0.02786271631717682
step = 8, Training Accuracy: 0.6033333333333334
Training loss = 0.026717513004938763
step = 9, Training Accuracy: 0.6433333333333333
Training loss = 0.027510684529940287
step = 10, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.67875
Training loss = 0.02484005073706309
step = 11, Training Accuracy: 0.6766666666666666
Training loss = 0.02662692666053772
step = 12, Training Accuracy: 0.6333333333333333
Training loss = 0.02705495556195577
step = 13, Training Accuracy: 0.6366666666666667
Training loss = 0.024770531256993612
step = 14, Training Accuracy: 0.6766666666666666
Validation Accuracy: 0.69625
pipeline:  [4, 76, 60, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                               'always_apply': False,
                               'p': 0.5,
                               'threshold': (128, 128)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.037985693415006
step = 0, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.70375
Training loss = 0.030656033158302308
step = 1, Training Accuracy: 0.5633333333333334
Training loss = 0.029455398917198183
step = 2, Training Accuracy: 0.5966666666666667
Training loss = 0.027058412233988444
step = 3, Training Accuracy: 0.6
Training loss = 0.028957569003105164
step = 4, Training Accuracy: 0.6033333333333334
Training loss = 0.027837399442990622
step = 5, Training Accuracy: 0.6533333333333333
Validation Accuracy: 0.69625
Training loss = 0.024699655771255494
step = 6, Training Accuracy: 0.68
Training loss = 0.02392118434111277
step = 7, Training Accuracy: 0.6633333333333333
Training loss = 0.02649543066819509
step = 8, Training Accuracy: 0.6366666666666667
Training loss = 0.02436248302459717
step = 9, Training Accuracy: 0.6733333333333333
Training loss = 0.025544315179189047
step = 10, Training Accuracy: 0.6666666666666666
Validation Accuracy: 0.71625
Training loss = 0.023603021303812664
step = 11, Training Accuracy: 0.6933333333333334
Training loss = 0.024255711237589517
step = 12, Training Accuracy: 0.71
Training loss = 0.021812131504217784
step = 13, Training Accuracy: 0.7233333333333334
Training loss = 0.021819766958554587
step = 14, Training Accuracy: 0.74
Validation Accuracy: 0.68375
pipeline:  [62, 71, 61, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02890502542257309
step = 0, Training Accuracy: 0.57
Validation Accuracy: 0.695
Training loss = 0.025537609457969665
step = 1, Training Accuracy: 0.6633333333333333
Training loss = 0.02183208833138148
step = 2, Training Accuracy: 0.7133333333333334
Training loss = 0.019613266587257386
step = 3, Training Accuracy: 0.7566666666666667
Training loss = 0.019071364104747773
step = 4, Training Accuracy: 0.75
Training loss = 0.019089104235172273
step = 5, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.72125
Training loss = 0.018817355930805205
step = 6, Training Accuracy: 0.78
Training loss = 0.015575558046499889
step = 7, Training Accuracy: 0.8133333333333334
Training loss = 0.015197103321552276
step = 8, Training Accuracy: 0.8033333333333333
Training loss = 0.01531510978937149
step = 9, Training Accuracy: 0.8133333333333334
Training loss = 0.01564967249830564
step = 10, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.705
Training loss = 0.014986139833927154
step = 11, Training Accuracy: 0.81
Training loss = 0.015942699213822683
step = 12, Training Accuracy: 0.8033333333333333
Training loss = 0.013430152237415314
step = 13, Training Accuracy: 0.83
Training loss = 0.013100552956263225
step = 14, Training Accuracy: 0.83
Validation Accuracy: 0.695
pipeline:  [37, 2, 87, 26]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.039026740789413455
step = 0, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.63625
Training loss = 0.02931042472521464
step = 1, Training Accuracy: 0.5633333333333334
Training loss = 0.027931915720303853
step = 2, Training Accuracy: 0.5833333333333334
Training loss = 0.02843036691347758
step = 3, Training Accuracy: 0.61
Training loss = 0.028928373058636984
step = 4, Training Accuracy: 0.5666666666666667
Training loss = 0.028460521499315897
step = 5, Training Accuracy: 0.5666666666666667
Validation Accuracy: 0.69375
Training loss = 0.026897717316945395
step = 6, Training Accuracy: 0.6633333333333333
Training loss = 0.02556013305981954
step = 7, Training Accuracy: 0.6066666666666667
Training loss = 0.025623257358868917
step = 8, Training Accuracy: 0.5833333333333334
Training loss = 0.027307468454043072
step = 9, Training Accuracy: 0.5766666666666667
Training loss = 0.026183377305666607
step = 10, Training Accuracy: 0.6133333333333333
Validation Accuracy: 0.70375
Training loss = 0.02413693646589915
step = 11, Training Accuracy: 0.6433333333333333
Training loss = 0.026176575819651285
step = 12, Training Accuracy: 0.6
Training loss = 0.02675189177195231
step = 13, Training Accuracy: 0.61
Training loss = 0.024281537532806395
step = 14, Training Accuracy: 0.6133333333333333
Validation Accuracy: 0.70375
4  	6     	0.68125 	0.0224653	0.63625	0.70375
pipeline:  [78, 13, 87, 24]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.Compose',
                               'additional_targets': {},
                               'bbox_params': None,
                               'keypoint_params': None,
                               'p': 1,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                               'always_apply': False,
                                               'height': 128,
                                               'p': 1.0,
                                               'width': 128},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1,
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.031095306873321533
step = 0, Training Accuracy: 0.6
Validation Accuracy: 0.6075
Training loss = 0.026022058924039203
step = 1, Training Accuracy: 0.6533333333333333
Training loss = 0.025152256687482197
step = 2, Training Accuracy: 0.6733333333333333
Training loss = 0.02277042806148529
step = 3, Training Accuracy: 0.72
Training loss = 0.021374355057875317
step = 4, Training Accuracy: 0.7433333333333333
Training loss = 0.021304336587587992
step = 5, Training Accuracy: 0.73
Validation Accuracy: 0.39125
Training loss = 0.01913829356431961
step = 6, Training Accuracy: 0.76
Training loss = 0.020284365713596344
step = 7, Training Accuracy: 0.76
Training loss = 0.0227762038509051
step = 8, Training Accuracy: 0.7333333333333333
Training loss = 0.01802777757247289
step = 9, Training Accuracy: 0.7633333333333333
Training loss = 0.019402146637439728
step = 10, Training Accuracy: 0.77
Validation Accuracy: 0.44875
Training loss = 0.0178493931889534
step = 11, Training Accuracy: 0.79
Training loss = 0.01835750083128611
step = 12, Training Accuracy: 0.77
Training loss = 0.01859226812918981
step = 13, Training Accuracy: 0.7666666666666667
Training loss = 0.01721831500530243
step = 14, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.5025
pipeline:  [92, 85, 87, 4]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.030981959104537965
step = 0, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.62375
Training loss = 0.025431589285532633
step = 1, Training Accuracy: 0.6533333333333333
Training loss = 0.02259285738070806
step = 2, Training Accuracy: 0.6933333333333334
Training loss = 0.021764652729034425
step = 3, Training Accuracy: 0.7133333333333334
Training loss = 0.022269584933916727
step = 4, Training Accuracy: 0.72
Training loss = 0.021028013626734416
step = 5, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.715
Training loss = 0.02250305622816086
step = 6, Training Accuracy: 0.7233333333333334
Training loss = 0.020923568109671276
step = 7, Training Accuracy: 0.7266666666666667
Training loss = 0.021493101219336192
step = 8, Training Accuracy: 0.7333333333333333
Training loss = 0.021142435669898988
step = 9, Training Accuracy: 0.7366666666666667
Training loss = 0.022328994870185852
step = 10, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.705
Training loss = 0.02045305520296097
step = 11, Training Accuracy: 0.7366666666666667
Training loss = 0.019954932928085325
step = 12, Training Accuracy: 0.7233333333333334
Training loss = 0.018851423958937328
step = 13, Training Accuracy: 0.7366666666666667
Training loss = 0.019861610134442646
step = 14, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.70375
pipeline:  [42, 70, 33, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02980356494585673
step = 0, Training Accuracy: 0.6066666666666667
Validation Accuracy: 0.69
Training loss = 0.025715251962343852
step = 1, Training Accuracy: 0.6433333333333333
Training loss = 0.024178741971651714
step = 2, Training Accuracy: 0.6633333333333333
Training loss = 0.024508845607439676
step = 3, Training Accuracy: 0.6633333333333333
Training loss = 0.022747936844825744
step = 4, Training Accuracy: 0.7233333333333334
Training loss = 0.021854993303616843
step = 5, Training Accuracy: 0.7166666666666667
Validation Accuracy: 0.72875
Training loss = 0.023004489640394848
step = 6, Training Accuracy: 0.71
Training loss = 0.021733849346637725
step = 7, Training Accuracy: 0.6966666666666667
Training loss = 0.020777704417705534
step = 8, Training Accuracy: 0.7133333333333334
Training loss = 0.018933144807815553
step = 9, Training Accuracy: 0.7433333333333333
Training loss = 0.01916819890340169
step = 10, Training Accuracy: 0.76
Validation Accuracy: 0.74
Training loss = 0.019581353267033894
step = 11, Training Accuracy: 0.7433333333333333
Training loss = 0.01800115317106247
step = 12, Training Accuracy: 0.7933333333333333
Training loss = 0.01887568324804306
step = 13, Training Accuracy: 0.7566666666666667
Training loss = 0.0220591934521993
step = 14, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.74625
pipeline:  [37, 2, 87, 26]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03153810679912567
step = 0, Training Accuracy: 0.52
Validation Accuracy: 0.69125
Training loss = 0.02890410323937734
step = 1, Training Accuracy: 0.5466666666666666
Training loss = 0.026908163825670878
step = 2, Training Accuracy: 0.56
Training loss = 0.029029454588890075
step = 3, Training Accuracy: 0.6033333333333334
Training loss = 0.028491362134615582
step = 4, Training Accuracy: 0.58
Training loss = 0.02551383008559545
step = 5, Training Accuracy: 0.57
Validation Accuracy: 0.72125
Training loss = 0.025010475715001423
step = 6, Training Accuracy: 0.6166666666666667
Training loss = 0.026299753586451213
step = 7, Training Accuracy: 0.6466666666666666
Training loss = 0.026044882933298746
step = 8, Training Accuracy: 0.62
Training loss = 0.024516438047091166
step = 9, Training Accuracy: 0.63
Training loss = 0.0254074635108312
step = 10, Training Accuracy: 0.6333333333333333
Validation Accuracy: 0.715
Training loss = 0.025970523158709208
step = 11, Training Accuracy: 0.6
Training loss = 0.02345944821834564
step = 12, Training Accuracy: 0.6566666666666666
Training loss = 0.024395739634831746
step = 13, Training Accuracy: 0.64
Training loss = 0.023441211779912312
step = 14, Training Accuracy: 0.66
Validation Accuracy: 0.6925
pipeline:  [92, 72, 87, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04067704101403554
step = 0, Training Accuracy: 0.54
Validation Accuracy: 0.60875
Training loss = 0.029490432341893514
step = 1, Training Accuracy: 0.5466666666666666
Training loss = 0.026694619059562684
step = 2, Training Accuracy: 0.59
Training loss = 0.027563674847284954
step = 3, Training Accuracy: 0.5966666666666667
Training loss = 0.025952837467193603
step = 4, Training Accuracy: 0.6466666666666666
Training loss = 0.02551404317220052
step = 5, Training Accuracy: 0.6666666666666666
Validation Accuracy: 0.7
Training loss = 0.02531011462211609
step = 6, Training Accuracy: 0.62
Training loss = 0.027004631360371907
step = 7, Training Accuracy: 0.66
Training loss = 0.023781929810841877
step = 8, Training Accuracy: 0.6666666666666666
Training loss = 0.023871987263361615
step = 9, Training Accuracy: 0.6633333333333333
Training loss = 0.024520273009936016
step = 10, Training Accuracy: 0.6833333333333333
Validation Accuracy: 0.68
Training loss = 0.022975354393323263
step = 11, Training Accuracy: 0.7
Training loss = 0.02459796627362569
step = 12, Training Accuracy: 0.6866666666666666
Training loss = 0.02469609340031942
step = 13, Training Accuracy: 0.6866666666666666
Training loss = 0.02191074748833974
step = 14, Training Accuracy: 0.7033333333333334
Validation Accuracy: 0.72625
5  	5     	0.679167	0.0809471	0.5025 	0.74625
pipeline:  [92, 85, 6, 4]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.028855449159940084
step = 0, Training Accuracy: 0.6133333333333333
Validation Accuracy: 0.73125
Training loss = 0.027368335127830504
step = 1, Training Accuracy: 0.6333333333333333
Training loss = 0.02431745986143748
step = 2, Training Accuracy: 0.6966666666666667
Training loss = 0.025291565557320914
step = 3, Training Accuracy: 0.6366666666666667
Training loss = 0.02496914545694987
step = 4, Training Accuracy: 0.6566666666666666
Training loss = 0.02555262585481008
step = 5, Training Accuracy: 0.6633333333333333
Validation Accuracy: 0.715
Training loss = 0.02581906855106354
step = 6, Training Accuracy: 0.6466666666666666
Training loss = 0.026112610499064128
step = 7, Training Accuracy: 0.6366666666666667
Training loss = 0.02374765674273173
step = 8, Training Accuracy: 0.6633333333333333
Training loss = 0.022827980717023213
step = 9, Training Accuracy: 0.7133333333333334
Training loss = 0.02312873403231303
step = 10, Training Accuracy: 0.7166666666666667
Validation Accuracy: 0.70125
Training loss = 0.0238588813940684
step = 11, Training Accuracy: 0.69
Training loss = 0.02151795874039332
step = 12, Training Accuracy: 0.71
Training loss = 0.022020114262898762
step = 13, Training Accuracy: 0.7
Training loss = 0.022626577913761138
step = 14, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.7075
pipeline:  [42, 20, 33, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.030167921781539916
step = 0, Training Accuracy: 0.5733333333333334
Validation Accuracy: 0.705
Training loss = 0.02787224014600118
step = 1, Training Accuracy: 0.61
Training loss = 0.028732337156931558
step = 2, Training Accuracy: 0.6033333333333334
Training loss = 0.02727507472038269
step = 3, Training Accuracy: 0.6033333333333334
Training loss = 0.02614544649918874
step = 4, Training Accuracy: 0.6066666666666667
Training loss = 0.02339790980021159
step = 5, Training Accuracy: 0.6733333333333333
Validation Accuracy: 0.72875
Training loss = 0.024361709356307982
step = 6, Training Accuracy: 0.6633333333333333
Training loss = 0.024818862875302633
step = 7, Training Accuracy: 0.6633333333333333
Training loss = 0.022957112987836203
step = 8, Training Accuracy: 0.7033333333333334
Training loss = 0.02403324782848358
step = 9, Training Accuracy: 0.68
Training loss = 0.02395218372344971
step = 10, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.72625
Training loss = 0.02171081999937693
step = 11, Training Accuracy: 0.7333333333333333
Training loss = 0.021765700777371725
step = 12, Training Accuracy: 0.7133333333333334
Training loss = 0.023821934858957925
step = 13, Training Accuracy: 0.69
Training loss = 0.02005677233139674
step = 14, Training Accuracy: 0.74
Validation Accuracy: 0.7275
pipeline:  [5, 57, 3, 9]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020721557835737866
step = 0, Training Accuracy: 0.75
Validation Accuracy: 0.73125
Training loss = 0.018328816095987955
step = 1, Training Accuracy: 0.7566666666666667
Training loss = 0.016598753531773886
step = 2, Training Accuracy: 0.7733333333333333
Training loss = 0.015439114918311438
step = 3, Training Accuracy: 0.8033333333333333
Training loss = 0.014016239643096924
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.013648165166378021
step = 5, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.72
Training loss = 0.013470833897590637
step = 6, Training Accuracy: 0.84
Training loss = 0.011859037776788076
step = 7, Training Accuracy: 0.8533333333333334
Training loss = 0.011878823041915893
step = 8, Training Accuracy: 0.87
Training loss = 0.009301650226116181
step = 9, Training Accuracy: 0.8933333333333333
Training loss = 0.008892965664466223
step = 10, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.7375
Training loss = 0.009810891300439835
step = 11, Training Accuracy: 0.8866666666666667
Training loss = 0.007739155789216359
step = 12, Training Accuracy: 0.9166666666666666
Training loss = 0.006660729572176933
step = 13, Training Accuracy: 0.9333333333333333
Training loss = 0.006663693090279897
step = 14, Training Accuracy: 0.9366666666666666
Validation Accuracy: 0.7075
pipeline:  [42, 70, 36, 5]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.031102784276008606
step = 0, Training Accuracy: 0.6433333333333333
Validation Accuracy: 0.7175
Training loss = 0.026965563495953877
step = 1, Training Accuracy: 0.69
Training loss = 0.022648281455039977
step = 2, Training Accuracy: 0.66
Training loss = 0.022982487082481386
step = 3, Training Accuracy: 0.68
Training loss = 0.021310874422391254
step = 4, Training Accuracy: 0.7266666666666667
Training loss = 0.019846175511678058
step = 5, Training Accuracy: 0.74
Validation Accuracy: 0.70625
Training loss = 0.0175749142964681
step = 6, Training Accuracy: 0.7933333333333333
Training loss = 0.01974338521560033
step = 7, Training Accuracy: 0.72
Training loss = 0.019098719557126363
step = 8, Training Accuracy: 0.7433333333333333
Training loss = 0.02058661123116811
step = 9, Training Accuracy: 0.7166666666666667
Training loss = 0.01842853138844172
step = 10, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.73
Training loss = 0.018588458995024364
step = 11, Training Accuracy: 0.7633333333333333
Training loss = 0.016878337760766346
step = 12, Training Accuracy: 0.7633333333333333
Training loss = 0.01869516054789225
step = 13, Training Accuracy: 0.7833333333333333
Training loss = 0.017523261805375417
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.72375
pipeline:  [92, 85, 87, 54]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'rotate_limit': (-45, 45),
                               'scale_limit': (0.0, 0.0),
                               'shift_limit': (-0.0625, 0.0625),
                               'value': None},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.025012911558151246
step = 0, Training Accuracy: 0.67
Validation Accuracy: 0.70125
Training loss = 0.022645044426123303
step = 1, Training Accuracy: 0.6833333333333333
Training loss = 0.02089156667391459
step = 2, Training Accuracy: 0.7166666666666667
Training loss = 0.023002788424491882
step = 3, Training Accuracy: 0.7
Training loss = 0.021792931059996287
step = 4, Training Accuracy: 0.6833333333333333
Training loss = 0.02011057714621226
step = 5, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.76625
Training loss = 0.01920929104089737
step = 6, Training Accuracy: 0.77
Training loss = 0.019219428300857544
step = 7, Training Accuracy: 0.74
Training loss = 0.019501416285832723
step = 8, Training Accuracy: 0.7566666666666667
Training loss = 0.02039735545714696
step = 9, Training Accuracy: 0.7366666666666667
Training loss = 0.01977180500825246
step = 10, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.71875
Training loss = 0.017766785820325214
step = 11, Training Accuracy: 0.7766666666666666
Training loss = 0.018167766729990643
step = 12, Training Accuracy: 0.7766666666666666
Training loss = 0.018900751868883767
step = 13, Training Accuracy: 0.7566666666666667
Training loss = 0.018345118860403697
step = 14, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.7525
pipeline:  [35, 33, 32, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018601319094498952
step = 0, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.73875
Training loss = 0.01852104236682256
step = 1, Training Accuracy: 0.74
Training loss = 0.017783239285151162
step = 2, Training Accuracy: 0.7666666666666667
Training loss = 0.01613840937614441
step = 3, Training Accuracy: 0.77
Training loss = 0.01531344085931778
step = 4, Training Accuracy: 0.78
Training loss = 0.01647454818089803
step = 5, Training Accuracy: 0.78
Validation Accuracy: 0.75875
Training loss = 0.014578450620174408
step = 6, Training Accuracy: 0.8333333333333334
Training loss = 0.01486224631468455
step = 7, Training Accuracy: 0.8033333333333333
Training loss = 0.014200212061405182
step = 8, Training Accuracy: 0.8233333333333334
Training loss = 0.012890562862157822
step = 9, Training Accuracy: 0.8233333333333334
Training loss = 0.012091504534085591
step = 10, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.755
Training loss = 0.011646478970845541
step = 11, Training Accuracy: 0.8566666666666667
Training loss = 0.011931759317715963
step = 12, Training Accuracy: 0.86
Training loss = 0.012882979412873585
step = 13, Training Accuracy: 0.8366666666666667
Training loss = 0.011133864969015122
step = 14, Training Accuracy: 0.86
Validation Accuracy: 0.7625
6  	6     	0.730208	0.0208968	0.7075 	0.7625 
pipeline:  [68, 48, 57, 50]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.046708121101061505
step = 0, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.6425
Training loss = 0.02847729980945587
step = 1, Training Accuracy: 0.6866666666666666
Training loss = 0.026097639004389446
step = 2, Training Accuracy: 0.6933333333333334
Training loss = 0.024246123631795246
step = 3, Training Accuracy: 0.68
Training loss = 0.02265656550725301
step = 4, Training Accuracy: 0.7366666666666667
Training loss = 0.026073726614316305
step = 5, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.71125
Training loss = 0.022366175452868144
step = 6, Training Accuracy: 0.6766666666666666
Training loss = 0.024916511178016663
step = 7, Training Accuracy: 0.6766666666666666
Training loss = 0.024452035228411356
step = 8, Training Accuracy: 0.6833333333333333
Training loss = 0.02393198768297831
step = 9, Training Accuracy: 0.7033333333333334
Training loss = 0.023857995371023812
step = 10, Training Accuracy: 0.74
Validation Accuracy: 0.72125
Training loss = 0.020391869147618612
step = 11, Training Accuracy: 0.7433333333333333
Training loss = 0.02302746653556824
step = 12, Training Accuracy: 0.7066666666666667
Training loss = 0.022243872582912445
step = 13, Training Accuracy: 0.7466666666666667
Training loss = 0.02001188079516093
step = 14, Training Accuracy: 0.71
Validation Accuracy: 0.71875
pipeline:  [42, 20, 33, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03023388425509135
step = 0, Training Accuracy: 0.61
Validation Accuracy: 0.70625
Training loss = 0.025661014318466187
step = 1, Training Accuracy: 0.6633333333333333
Training loss = 0.025372053782145184
step = 2, Training Accuracy: 0.65
Training loss = 0.02494287590185801
step = 3, Training Accuracy: 0.65
Training loss = 0.021992974678675333
step = 4, Training Accuracy: 0.6933333333333334
Training loss = 0.021755160490671794
step = 5, Training Accuracy: 0.6766666666666666
Validation Accuracy: 0.7225
Training loss = 0.023688356280326842
step = 6, Training Accuracy: 0.68
Training loss = 0.02243314097325007
step = 7, Training Accuracy: 0.7
Training loss = 0.022253252267837524
step = 8, Training Accuracy: 0.66
Training loss = 0.02180919309457143
step = 9, Training Accuracy: 0.6933333333333334
Training loss = 0.022048285007476808
step = 10, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.71
Training loss = 0.021163097023963927
step = 11, Training Accuracy: 0.7166666666666667
Training loss = 0.02094622125228246
step = 12, Training Accuracy: 0.73
Training loss = 0.02384114106496175
step = 13, Training Accuracy: 0.66
Training loss = 0.021584714750448864
step = 14, Training Accuracy: 0.74
Validation Accuracy: 0.7375
pipeline:  [88, 73, 86, 40]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.05, 0.05),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'shift_limit': (-0.05, 0.05),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.3, 0.3),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'num_steps': 5,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                                               'alpha': 1,
                                               'alpha_affine': 50,
                                               'always_apply': False,
                                               'approximate': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'sigma': 50,
                                               'value': None}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020271689097086588
step = 0, Training Accuracy: 0.7433333333333333
Validation Accuracy: 0.755
Training loss = 0.018426216542720794
step = 1, Training Accuracy: 0.7266666666666667
Training loss = 0.019577953815460205
step = 2, Training Accuracy: 0.7533333333333333
Training loss = 0.01774929106235504
step = 3, Training Accuracy: 0.7466666666666667
Training loss = 0.016985572377840676
step = 4, Training Accuracy: 0.7633333333333333
Training loss = 0.01623450736204783
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.75
Training loss = 0.016811396876970926
step = 6, Training Accuracy: 0.7933333333333333
Training loss = 0.014685568114121755
step = 7, Training Accuracy: 0.8366666666666667
Training loss = 0.015880016386508943
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.014675049682458242
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.015367363293965658
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.745
Training loss = 0.015014673868815104
step = 11, Training Accuracy: 0.8066666666666666
Training loss = 0.013390470842520395
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.011952572067578634
step = 13, Training Accuracy: 0.8566666666666667
Training loss = 0.011560955295960108
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.74375
pipeline:  [4, 14, 87, 15]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020252895057201386
step = 0, Training Accuracy: 0.77
Validation Accuracy: 0.4075
Training loss = 0.017961969176928202
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.01731012096007665
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.018557848433653514
step = 3, Training Accuracy: 0.8166666666666667
Training loss = 0.013515842407941818
step = 4, Training Accuracy: 0.82
Training loss = 0.01570494035879771
step = 5, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.41875
Training loss = 0.013938622723023097
step = 6, Training Accuracy: 0.8133333333333334
Training loss = 0.012336184531450271
step = 7, Training Accuracy: 0.8466666666666667
Training loss = 0.013253458638985952
step = 8, Training Accuracy: 0.8133333333333334
Training loss = 0.014536293248335521
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.01466588924328486
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.36625
Training loss = 0.012440273662408192
step = 11, Training Accuracy: 0.8566666666666667
Training loss = 0.011051072974999746
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.012292516976594925
step = 13, Training Accuracy: 0.8433333333333334
Training loss = 0.010969796677430472
step = 14, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.3875
7  	4     	0.678958	0.131112 	0.3875 	0.7625 
pipeline:  [42, 20, 33, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.029406212170918784
step = 0, Training Accuracy: 0.6633333333333333
Validation Accuracy: 0.73375
Training loss = 0.0242451544602712
step = 1, Training Accuracy: 0.67
Training loss = 0.027873610258102418
step = 2, Training Accuracy: 0.6666666666666666
Training loss = 0.025933188597361247
step = 3, Training Accuracy: 0.6666666666666666
Training loss = 0.024962687492370607
step = 4, Training Accuracy: 0.6766666666666666
Training loss = 0.022441060543060304
step = 5, Training Accuracy: 0.6833333333333333
Validation Accuracy: 0.73875
Training loss = 0.022669890920321147
step = 6, Training Accuracy: 0.6933333333333334
Training loss = 0.020313512682914734
step = 7, Training Accuracy: 0.7033333333333334
Training loss = 0.020925246079762778
step = 8, Training Accuracy: 0.69
Training loss = 0.022777904669443766
step = 9, Training Accuracy: 0.69
Training loss = 0.022109735012054443
step = 10, Training Accuracy: 0.6966666666666667
Validation Accuracy: 0.7725
Training loss = 0.019448143045107523
step = 11, Training Accuracy: 0.73
Training loss = 0.01950357625881831
step = 12, Training Accuracy: 0.7166666666666667
Training loss = 0.021134366194407145
step = 13, Training Accuracy: 0.7166666666666667
Training loss = 0.019008865455786388
step = 14, Training Accuracy: 0.73
Validation Accuracy: 0.75125
pipeline:  [34, 33, 32, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021925603648026783
step = 0, Training Accuracy: 0.7233333333333334
Validation Accuracy: 0.7575
Training loss = 0.021610249082247415
step = 1, Training Accuracy: 0.7366666666666667
Training loss = 0.01904095192750295
step = 2, Training Accuracy: 0.72
Training loss = 0.018644391993681588
step = 3, Training Accuracy: 0.74
Training loss = 0.018029624223709108
step = 4, Training Accuracy: 0.7566666666666667
Training loss = 0.017168764770030976
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.75
Training loss = 0.016251302659511566
step = 6, Training Accuracy: 0.77
Training loss = 0.01609272261460622
step = 7, Training Accuracy: 0.79
Training loss = 0.015153131087621053
step = 8, Training Accuracy: 0.7833333333333333
Training loss = 0.013957525491714478
step = 9, Training Accuracy: 0.8366666666666667
Training loss = 0.014913677672545115
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.76875
Training loss = 0.013648040195306143
step = 11, Training Accuracy: 0.81
Training loss = 0.013122750620047252
step = 12, Training Accuracy: 0.8366666666666667
Training loss = 0.014366176029046376
step = 13, Training Accuracy: 0.7933333333333333
Training loss = 0.012875108669201532
step = 14, Training Accuracy: 0.83
Validation Accuracy: 0.7375
pipeline:  [35, 33, 32, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021582732101281484
step = 0, Training Accuracy: 0.7
Validation Accuracy: 0.74625
Training loss = 0.01651247004667918
step = 1, Training Accuracy: 0.7866666666666666
Training loss = 0.015821885665257773
step = 2, Training Accuracy: 0.7966666666666666
Training loss = 0.015478080908457438
step = 3, Training Accuracy: 0.77
Training loss = 0.015266123612721762
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.013100385069847106
step = 5, Training Accuracy: 0.83
Validation Accuracy: 0.76875
Training loss = 0.01418830007314682
step = 6, Training Accuracy: 0.84
Training loss = 0.013337391912937164
step = 7, Training Accuracy: 0.8133333333333334
Training loss = 0.011912296911080679
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.011477002998193105
step = 9, Training Accuracy: 0.87
Training loss = 0.010469059199094773
step = 10, Training Accuracy: 0.9
Validation Accuracy: 0.75625
Training loss = 0.009298154016335805
step = 11, Training Accuracy: 0.89
Training loss = 0.008974427034457525
step = 12, Training Accuracy: 0.8666666666666667
Training loss = 0.009389800628026327
step = 13, Training Accuracy: 0.8766666666666667
Training loss = 0.008275245775779089
step = 14, Training Accuracy: 0.9
Validation Accuracy: 0.7575
pipeline:  [35, 33, 32, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020580989420413972
step = 0, Training Accuracy: 0.76
Validation Accuracy: 0.74875
Training loss = 0.016882405479749042
step = 1, Training Accuracy: 0.7833333333333333
Training loss = 0.015225741664568583
step = 2, Training Accuracy: 0.79
Training loss = 0.013107400933901468
step = 3, Training Accuracy: 0.86
Training loss = 0.011188341875871022
step = 4, Training Accuracy: 0.8666666666666667
Training loss = 0.010419532557328541
step = 5, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.7575
Training loss = 0.010099987983703613
step = 6, Training Accuracy: 0.87
Training loss = 0.010185337165991465
step = 7, Training Accuracy: 0.9033333333333333
Training loss = 0.008018667995929717
step = 8, Training Accuracy: 0.91
Training loss = 0.008258670394619305
step = 9, Training Accuracy: 0.9133333333333333
Training loss = 0.008839274942874908
step = 10, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.72625
Training loss = 0.00866495668888092
step = 11, Training Accuracy: 0.92
Training loss = 0.007541834513346354
step = 12, Training Accuracy: 0.91
Training loss = 0.007343187977870306
step = 13, Training Accuracy: 0.93
Training loss = 0.0073736876497666045
step = 14, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.74125
pipeline:  [10, 33, 28, 47]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02235327531894048
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.7275
Training loss = 0.01714688221613566
step = 1, Training Accuracy: 0.82
Training loss = 0.016881876389185587
step = 2, Training Accuracy: 0.7933333333333333
Training loss = 0.012628363172213237
step = 3, Training Accuracy: 0.8466666666666667
Training loss = 0.012316492100556692
step = 4, Training Accuracy: 0.8633333333333333
Training loss = 0.011382771134376525
step = 5, Training Accuracy: 0.88
Validation Accuracy: 0.7225
Training loss = 0.010101643204689027
step = 6, Training Accuracy: 0.89
Training loss = 0.008096300065517426
step = 7, Training Accuracy: 0.9266666666666666
Training loss = 0.009092401961485546
step = 8, Training Accuracy: 0.9
Training loss = 0.008602759962280592
step = 9, Training Accuracy: 0.91
Training loss = 0.008046879023313523
step = 10, Training Accuracy: 0.91
Validation Accuracy: 0.71625
Training loss = 0.007072795455654462
step = 11, Training Accuracy: 0.94
Training loss = 0.005387619063258171
step = 12, Training Accuracy: 0.9433333333333334
Training loss = 0.006515557815631231
step = 13, Training Accuracy: 0.9333333333333333
Training loss = 0.004599137219289938
step = 14, Training Accuracy: 0.95
Validation Accuracy: 0.71625
8  	5     	0.744375	0.0152539	0.71625	0.7625 
pipeline:  [35, 33, 32, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.024137972791989645
step = 0, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.71875
Training loss = 0.01959173321723938
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.013475213299194972
step = 2, Training Accuracy: 0.8133333333333334
Training loss = 0.014253104130427043
step = 3, Training Accuracy: 0.8433333333333334
Training loss = 0.0106149190167586
step = 4, Training Accuracy: 0.86
Training loss = 0.010820555835962295
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.7375
Training loss = 0.008608658164739609
step = 6, Training Accuracy: 0.8966666666666666
Training loss = 0.008292142550150554
step = 7, Training Accuracy: 0.8933333333333333
Training loss = 0.008429593046506246
step = 8, Training Accuracy: 0.9033333333333333
Training loss = 0.0075289658705393475
step = 9, Training Accuracy: 0.91
Training loss = 0.006053681919972102
step = 10, Training Accuracy: 0.9366666666666666
Validation Accuracy: 0.72
Training loss = 0.005409866025050481
step = 11, Training Accuracy: 0.9433333333333334
Training loss = 0.005684377327561378
step = 12, Training Accuracy: 0.9366666666666666
Training loss = 0.005648613187174002
step = 13, Training Accuracy: 0.9466666666666667
Training loss = 0.0045828836038708685
step = 14, Training Accuracy: 0.9633333333333334
Validation Accuracy: 0.71625
pipeline:  [35, 33, 32, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.023671091000239054
step = 0, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.73875
Training loss = 0.017335194995005927
step = 1, Training Accuracy: 0.79
Training loss = 0.013474194705486298
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.011171463876962662
step = 3, Training Accuracy: 0.86
Training loss = 0.01115503028035164
step = 4, Training Accuracy: 0.8533333333333334
Training loss = 0.010609980175892512
step = 5, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.7325
Training loss = 0.00904480184117953
step = 6, Training Accuracy: 0.8866666666666667
Training loss = 0.007771890908479691
step = 7, Training Accuracy: 0.9133333333333333
Training loss = 0.009169525901476542
step = 8, Training Accuracy: 0.9
Training loss = 0.008079072684049607
step = 9, Training Accuracy: 0.91
Training loss = 0.007529794027407964
step = 10, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.7125
Training loss = 0.006976186583439509
step = 11, Training Accuracy: 0.93
Training loss = 0.005869943747917811
step = 12, Training Accuracy: 0.9433333333333334
Training loss = 0.007614861950278282
step = 13, Training Accuracy: 0.9366666666666666
Training loss = 0.005273821478088697
step = 14, Training Accuracy: 0.96
Validation Accuracy: 0.70625
pipeline:  [25, 33, 4, 65]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02643865704536438
step = 0, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.73875
Training loss = 0.019175857504208884
step = 1, Training Accuracy: 0.7633333333333333
Training loss = 0.01607285072406133
step = 2, Training Accuracy: 0.8033333333333333
Training loss = 0.013436286946137747
step = 3, Training Accuracy: 0.84
Training loss = 0.011881544589996337
step = 4, Training Accuracy: 0.8433333333333334
Training loss = 0.011605178316434225
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.755
Training loss = 0.01049128532409668
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.008512805153926214
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.007972423086563747
step = 8, Training Accuracy: 0.92
Training loss = 0.007413110385338466
step = 9, Training Accuracy: 0.92
Training loss = 0.005339884782830874
step = 10, Training Accuracy: 0.9566666666666667
Validation Accuracy: 0.76
Training loss = 0.00573238713045915
step = 11, Training Accuracy: 0.96
Training loss = 0.0049305576706926025
step = 12, Training Accuracy: 0.9533333333333334
Training loss = 0.004713466813166936
step = 13, Training Accuracy: 0.9466666666666667
Training loss = 0.004221259020268917
step = 14, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.74875
pipeline:  [42, 20, 33, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04035232643286387
step = 0, Training Accuracy: 0.6166666666666667
Validation Accuracy: 0.715
Training loss = 0.029005921681722006
step = 1, Training Accuracy: 0.6433333333333333
Training loss = 0.024608572324117024
step = 2, Training Accuracy: 0.65
Training loss = 0.02482373297214508
step = 3, Training Accuracy: 0.6266666666666667
Training loss = 0.022761903405189514
step = 4, Training Accuracy: 0.66
Training loss = 0.021698986490567524
step = 5, Training Accuracy: 0.69
Validation Accuracy: 0.7425
Training loss = 0.020288932720820108
step = 6, Training Accuracy: 0.7333333333333333
Training loss = 0.02208754708369573
step = 7, Training Accuracy: 0.66
Training loss = 0.01963821768760681
step = 8, Training Accuracy: 0.7366666666666667
Training loss = 0.020512326955795288
step = 9, Training Accuracy: 0.73
Training loss = 0.019913871983687083
step = 10, Training Accuracy: 0.75
Validation Accuracy: 0.73625
Training loss = 0.02134147047996521
step = 11, Training Accuracy: 0.6966666666666667
Training loss = 0.0187985701362292
step = 12, Training Accuracy: 0.74
Training loss = 0.018342214127381642
step = 13, Training Accuracy: 0.72
Training loss = 0.017180893619855246
step = 14, Training Accuracy: 0.7433333333333333
Validation Accuracy: 0.74375
pipeline:  [69, 29, 66, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03574032763640086
step = 0, Training Accuracy: 0.65
Validation Accuracy: 0.5375
Training loss = 0.023842721978823343
step = 1, Training Accuracy: 0.6933333333333334
Training loss = 0.018297825157642365
step = 2, Training Accuracy: 0.7766666666666666
Training loss = 0.016594875355561575
step = 3, Training Accuracy: 0.8166666666666667
Training loss = 0.01484771619240443
step = 4, Training Accuracy: 0.8366666666666667
Training loss = 0.012633534967899323
step = 5, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.71125
Training loss = 0.011716442902882894
step = 6, Training Accuracy: 0.8466666666666667
Training loss = 0.010474714835484823
step = 7, Training Accuracy: 0.8933333333333333
Training loss = 0.009871333142121633
step = 8, Training Accuracy: 0.8766666666666667
Training loss = 0.008892117391029993
step = 9, Training Accuracy: 0.8833333333333333
Training loss = 0.008430906136830648
step = 10, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.70625
Training loss = 0.006514368529121081
step = 11, Training Accuracy: 0.94
Training loss = 0.006555400937795639
step = 12, Training Accuracy: 0.9366666666666666
Training loss = 0.006160532062252363
step = 13, Training Accuracy: 0.9333333333333333
Training loss = 0.007699526051680247
step = 14, Training Accuracy: 0.92
Validation Accuracy: 0.71625
pipeline:  [26, 24, 49, 29]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.04144500037034353
step = 0, Training Accuracy: 0.5433333333333333
Validation Accuracy: 0.6575
Training loss = 0.02703452746073405
step = 1, Training Accuracy: 0.6266666666666667
Training loss = 0.026609243551890056
step = 2, Training Accuracy: 0.6066666666666667
Training loss = 0.025076413154602052
step = 3, Training Accuracy: 0.6666666666666666
Training loss = 0.023354219893614452
step = 4, Training Accuracy: 0.64
Training loss = 0.02250289579232534
step = 5, Training Accuracy: 0.7066666666666667
Validation Accuracy: 0.72125
Training loss = 0.023603336215019227
step = 6, Training Accuracy: 0.6766666666666666
Training loss = 0.023895512620608014
step = 7, Training Accuracy: 0.6666666666666666
Training loss = 0.02326273441314697
step = 8, Training Accuracy: 0.6733333333333333
Training loss = 0.02055853565533956
step = 9, Training Accuracy: 0.6833333333333333
Training loss = 0.02005317171414693
step = 10, Training Accuracy: 0.7
Validation Accuracy: 0.725
Training loss = 0.019774839182694754
step = 11, Training Accuracy: 0.74
Training loss = 0.017435738295316697
step = 12, Training Accuracy: 0.7633333333333333
Training loss = 0.018901966412862143
step = 13, Training Accuracy: 0.7333333333333333
Training loss = 0.01786426196495692
step = 14, Training Accuracy: 0.76
Validation Accuracy: 0.72125
9  	6     	0.725417	0.015456 	0.70625	0.74875
pipeline:  [3, 51, 53, 44]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020222801268100738
step = 0, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.72875
Training loss = 0.02135742465655009
step = 1, Training Accuracy: 0.7133333333333334
Training loss = 0.016299122472604115
step = 2, Training Accuracy: 0.7866666666666666
Training loss = 0.014466304381688435
step = 3, Training Accuracy: 0.82
Training loss = 0.013361341953277588
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.013237156669298807
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.72125
Training loss = 0.012614502410093943
step = 6, Training Accuracy: 0.85
Training loss = 0.012641678154468537
step = 7, Training Accuracy: 0.8533333333333334
Training loss = 0.010987300376097362
step = 8, Training Accuracy: 0.8866666666666667
Training loss = 0.01017657607793808
step = 9, Training Accuracy: 0.89
Training loss = 0.009684366633494696
step = 10, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.72125
Training loss = 0.008581066330273945
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.007931002974510193
step = 12, Training Accuracy: 0.9033333333333333
Training loss = 0.006675139566262563
step = 13, Training Accuracy: 0.9466666666666667
Training loss = 0.0073198641339937845
step = 14, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.7125
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.025985433260599773
step = 0, Training Accuracy: 0.6966666666666667
Validation Accuracy: 0.74875
Training loss = 0.020990070203940073
step = 1, Training Accuracy: 0.7433333333333333
Training loss = 0.019202512403329212
step = 2, Training Accuracy: 0.7333333333333333
Training loss = 0.01761458863814672
step = 3, Training Accuracy: 0.7633333333333333
Training loss = 0.018818299174308776
step = 4, Training Accuracy: 0.7666666666666667
Training loss = 0.015870385269323984
step = 5, Training Accuracy: 0.8
Validation Accuracy: 0.75125
Training loss = 0.01793007691701253
step = 6, Training Accuracy: 0.79
Training loss = 0.016132190426190695
step = 7, Training Accuracy: 0.8
Training loss = 0.0161230860153834
step = 8, Training Accuracy: 0.8033333333333333
Training loss = 0.016497356394926707
step = 9, Training Accuracy: 0.77
Training loss = 0.01535360207160314
step = 10, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.77125
Training loss = 0.014580111801624298
step = 11, Training Accuracy: 0.8233333333333334
Training loss = 0.016912380556265514
step = 12, Training Accuracy: 0.7966666666666666
Training loss = 0.016626021067301433
step = 13, Training Accuracy: 0.81
Training loss = 0.014590382625659306
step = 14, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.76
pipeline:  [73, 8, 33, 1]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                               'always_apply': False,
                               'color_shift': (0.01, 0.05),
                               'intensity': (0.1, 0.5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017628984451293947
step = 0, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.7625
Training loss = 0.016044635872046152
step = 1, Training Accuracy: 0.7866666666666666
Training loss = 0.013245891630649567
step = 2, Training Accuracy: 0.82
Training loss = 0.013260632008314132
step = 3, Training Accuracy: 0.83
Training loss = 0.013339839528004329
step = 4, Training Accuracy: 0.87
Training loss = 0.010773326059182485
step = 5, Training Accuracy: 0.88
Validation Accuracy: 0.765
Training loss = 0.00994547704855601
step = 6, Training Accuracy: 0.8833333333333333
Training loss = 0.010528631458679836
step = 7, Training Accuracy: 0.8966666666666666
Training loss = 0.007838146338860194
step = 8, Training Accuracy: 0.9333333333333333
Training loss = 0.007674546142419179
step = 9, Training Accuracy: 0.9266666666666666
Training loss = 0.006889204432566961
step = 10, Training Accuracy: 0.94
Validation Accuracy: 0.76
Training loss = 0.006669802591204643
step = 11, Training Accuracy: 0.94
Training loss = 0.005477933833996455
step = 12, Training Accuracy: 0.9633333333333334
Training loss = 0.005105145225922266
step = 13, Training Accuracy: 0.93
Training loss = 0.004826053058107694
step = 14, Training Accuracy: 0.9633333333333334
Validation Accuracy: 0.76
pipeline:  [26, 33, 81, 14]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03818294862906138
step = 0, Training Accuracy: 0.64
Validation Accuracy: 0.74875
Training loss = 0.025644381543000538
step = 1, Training Accuracy: 0.6566666666666666
Training loss = 0.02512704928716024
step = 2, Training Accuracy: 0.65
Training loss = 0.024177184800306957
step = 3, Training Accuracy: 0.6766666666666666
Training loss = 0.02313417464494705
step = 4, Training Accuracy: 0.69
Training loss = 0.022029257516066235
step = 5, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.75
Training loss = 0.020157326459884644
step = 6, Training Accuracy: 0.7266666666666667
Training loss = 0.020472856263319652
step = 7, Training Accuracy: 0.7033333333333334
Training loss = 0.019847205181916554
step = 8, Training Accuracy: 0.77
Training loss = 0.019492142498493195
step = 9, Training Accuracy: 0.75
Training loss = 0.020159912904103596
step = 10, Training Accuracy: 0.7266666666666667
Validation Accuracy: 0.7275
Training loss = 0.017685690919558208
step = 11, Training Accuracy: 0.7533333333333333
Training loss = 0.018293361167112988
step = 12, Training Accuracy: 0.7733333333333333
Training loss = 0.0173354775706927
step = 13, Training Accuracy: 0.7533333333333333
Training loss = 0.015896434287230175
step = 14, Training Accuracy: 0.8
Validation Accuracy: 0.7375
10 	4     	0.74375 	0.0161697	0.7125 	0.76   
pipeline:  [65, 4, 33, 48]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.024466195702552797
step = 0, Training Accuracy: 0.7
Validation Accuracy: 0.74
Training loss = 0.02055410196383794
step = 1, Training Accuracy: 0.7166666666666667
Training loss = 0.01689296990633011
step = 2, Training Accuracy: 0.7766666666666666
Training loss = 0.017798955341180166
step = 3, Training Accuracy: 0.74
Training loss = 0.0169659498333931
step = 4, Training Accuracy: 0.7933333333333333
Training loss = 0.015436498721440633
step = 5, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.75625
Training loss = 0.015299186209837596
step = 6, Training Accuracy: 0.7866666666666666
Training loss = 0.01499273935953776
step = 7, Training Accuracy: 0.82
Training loss = 0.013844473958015443
step = 8, Training Accuracy: 0.81
Training loss = 0.013973835706710815
step = 9, Training Accuracy: 0.83
Training loss = 0.012594543000062308
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.765
Training loss = 0.01294662689169248
step = 11, Training Accuracy: 0.83
Training loss = 0.011744692424933116
step = 12, Training Accuracy: 0.86
Training loss = 0.012656199932098388
step = 13, Training Accuracy: 0.8366666666666667
Training loss = 0.012181439101696015
step = 14, Training Accuracy: 0.86
Validation Accuracy: 0.76
pipeline:  [34, 6, 61, 47]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.026921897629896798
step = 0, Training Accuracy: 0.6766666666666666
Validation Accuracy: 0.73125
Training loss = 0.022494840224583944
step = 1, Training Accuracy: 0.7066666666666667
Training loss = 0.018724475502967835
step = 2, Training Accuracy: 0.73
Training loss = 0.017010451952616374
step = 3, Training Accuracy: 0.7566666666666667
Training loss = 0.016799295643965404
step = 4, Training Accuracy: 0.7566666666666667
Training loss = 0.016898081401983896
step = 5, Training Accuracy: 0.79
Validation Accuracy: 0.70375
Training loss = 0.014623721738656363
step = 6, Training Accuracy: 0.8233333333333334
Training loss = 0.015028340021769206
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.014878703355789185
step = 8, Training Accuracy: 0.82
Training loss = 0.016436383028825125
step = 9, Training Accuracy: 0.8066666666666666
Training loss = 0.013041624923547109
step = 10, Training Accuracy: 0.83
Validation Accuracy: 0.71875
Training loss = 0.013466617067654927
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.01275384783744812
step = 12, Training Accuracy: 0.8233333333333334
Training loss = 0.012584909995396932
step = 13, Training Accuracy: 0.8333333333333334
Training loss = 0.011936045388380686
step = 14, Training Accuracy: 0.83
Validation Accuracy: 0.7325
11 	2     	0.753542	0.0102677	0.7325 	0.76   
pipeline:  [52, 11, 62, 70]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.023747167189915975
step = 0, Training Accuracy: 0.6966666666666667
Validation Accuracy: 0.7325
Training loss = 0.02131998856862386
step = 1, Training Accuracy: 0.7333333333333333
Training loss = 0.019292387068271636
step = 2, Training Accuracy: 0.7466666666666667
Training loss = 0.02064949909845988
step = 3, Training Accuracy: 0.7533333333333333
Training loss = 0.017577350835005442
step = 4, Training Accuracy: 0.7766666666666666
Training loss = 0.017620367805163066
step = 5, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.75875
Training loss = 0.016542311807473502
step = 6, Training Accuracy: 0.7866666666666666
Training loss = 0.015498669544855754
step = 7, Training Accuracy: 0.7966666666666666
Training loss = 0.01668883244196574
step = 8, Training Accuracy: 0.7566666666666667
Training loss = 0.016502673625946044
step = 9, Training Accuracy: 0.7966666666666666
Training loss = 0.015478092829386393
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.73375
Training loss = 0.01680878152449926
step = 11, Training Accuracy: 0.7733333333333333
Training loss = 0.017654480536778767
step = 12, Training Accuracy: 0.7866666666666666
Training loss = 0.014255958596865336
step = 13, Training Accuracy: 0.83
Training loss = 0.017670700252056123
step = 14, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.73125
pipeline:  [62, 8, 90, 24]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                               'always_apply': False,
                               'color_shift': (0.01, 0.05),
                               'intensity': (0.1, 0.5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016776572167873382
step = 0, Training Accuracy: 0.79
Validation Accuracy: 0.725
Training loss = 0.01697631468375524
step = 1, Training Accuracy: 0.79
Training loss = 0.018273276885350544
step = 2, Training Accuracy: 0.81
Training loss = 0.015099398295084636
step = 3, Training Accuracy: 0.84
Training loss = 0.01435193101565043
step = 4, Training Accuracy: 0.8466666666666667
Training loss = 0.013916020592053732
step = 5, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.76125
Training loss = 0.01429853101571401
step = 6, Training Accuracy: 0.8266666666666667
Training loss = 0.012547183632850647
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.01316718985637029
step = 8, Training Accuracy: 0.8533333333333334
Training loss = 0.013165501952171326
step = 9, Training Accuracy: 0.85
Training loss = 0.012151592969894409
step = 10, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.76625
Training loss = 0.01293246736129125
step = 11, Training Accuracy: 0.85
Training loss = 0.013689312040805817
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.011774289856354396
step = 13, Training Accuracy: 0.8833333333333333
Training loss = 0.011157504518826803
step = 14, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.74875
pipeline:  [25, 59, 45, 74]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.025714027484258016
step = 0, Training Accuracy: 0.66
Validation Accuracy: 0.76125
Training loss = 0.020317399303118388
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.019526092608769734
step = 2, Training Accuracy: 0.7433333333333333
Training loss = 0.016943914890289305
step = 3, Training Accuracy: 0.77
Training loss = 0.015900123318036398
step = 4, Training Accuracy: 0.8
Training loss = 0.018185529112815856
step = 5, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.765
Training loss = 0.014776978691418965
step = 6, Training Accuracy: 0.8
Training loss = 0.015607044994831086
step = 7, Training Accuracy: 0.81
Training loss = 0.01273340533177058
step = 8, Training Accuracy: 0.8633333333333333
Training loss = 0.011193435440460841
step = 9, Training Accuracy: 0.88
Training loss = 0.012765048096577327
step = 10, Training Accuracy: 0.86
Validation Accuracy: 0.74
Training loss = 0.011830990711847941
step = 11, Training Accuracy: 0.8433333333333334
Training loss = 0.013439003825187684
step = 12, Training Accuracy: 0.8333333333333334
Training loss = 0.010940795789162319
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.010018633902072907
step = 14, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.735
12 	3     	0.749167	0.012069 	0.73125	0.76   
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.025455505152543387
step = 0, Training Accuracy: 0.7
Validation Accuracy: 0.75875
Training loss = 0.02341879467169444
step = 1, Training Accuracy: 0.7166666666666667
Training loss = 0.021289604802926382
step = 2, Training Accuracy: 0.71
Training loss = 0.02145399103562037
step = 3, Training Accuracy: 0.7166666666666667
Training loss = 0.019708476960659027
step = 4, Training Accuracy: 0.76
Training loss = 0.01791453719139099
step = 5, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.76875
Training loss = 0.018640265961488087
step = 6, Training Accuracy: 0.7333333333333333
Training loss = 0.017910854915777843
step = 7, Training Accuracy: 0.7566666666666667
Training loss = 0.019162521958351136
step = 8, Training Accuracy: 0.7466666666666667
Training loss = 0.016348667641480765
step = 9, Training Accuracy: 0.79
Training loss = 0.016194373766581217
step = 10, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.76875
Training loss = 0.01615198016166687
step = 11, Training Accuracy: 0.77
Training loss = 0.016510414878527325
step = 12, Training Accuracy: 0.7633333333333333
Training loss = 0.014789282729228338
step = 13, Training Accuracy: 0.8333333333333334
Training loss = 0.01486845721801122
step = 14, Training Accuracy: 0.84
Validation Accuracy: 0.775
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022052202423413596
step = 0, Training Accuracy: 0.7033333333333334
Validation Accuracy: 0.775
Training loss = 0.022199644446372985
step = 1, Training Accuracy: 0.7066666666666667
Training loss = 0.01933551182349523
step = 2, Training Accuracy: 0.7233333333333334
Training loss = 0.020842440028985342
step = 3, Training Accuracy: 0.75
Training loss = 0.020242480238278706
step = 4, Training Accuracy: 0.6966666666666667
Training loss = 0.019768657286961873
step = 5, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.78
Training loss = 0.019273467560609183
step = 6, Training Accuracy: 0.77
Training loss = 0.01859134743611018
step = 7, Training Accuracy: 0.77
Training loss = 0.018698217769463857
step = 8, Training Accuracy: 0.72
Training loss = 0.019662940601507823
step = 9, Training Accuracy: 0.7633333333333333
Training loss = 0.01834717353185018
step = 10, Training Accuracy: 0.78
Validation Accuracy: 0.77375
Training loss = 0.018884204427401224
step = 11, Training Accuracy: 0.7633333333333333
Training loss = 0.017221085727214813
step = 12, Training Accuracy: 0.81
Training loss = 0.016958581109841664
step = 13, Training Accuracy: 0.79
Training loss = 0.017125082810719807
step = 14, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.765
pipeline:  [46, 11, 3, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02090444227059682
step = 0, Training Accuracy: 0.73
Validation Accuracy: 0.76875
Training loss = 0.019361107051372527
step = 1, Training Accuracy: 0.7366666666666667
Training loss = 0.02041509062051773
step = 2, Training Accuracy: 0.7366666666666667
Training loss = 0.020920876761277518
step = 3, Training Accuracy: 0.7533333333333333
Training loss = 0.019662837783495587
step = 4, Training Accuracy: 0.7533333333333333
Training loss = 0.017704705993334454
step = 5, Training Accuracy: 0.78
Validation Accuracy: 0.75875
Training loss = 0.016736411948998768
step = 6, Training Accuracy: 0.7833333333333333
Training loss = 0.016959384183088937
step = 7, Training Accuracy: 0.8
Training loss = 0.015826089978218078
step = 8, Training Accuracy: 0.7866666666666666
Training loss = 0.016027276615301768
step = 9, Training Accuracy: 0.8066666666666666
Training loss = 0.0156815630197525
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.7775
Training loss = 0.014632366249958674
step = 11, Training Accuracy: 0.8066666666666666
Training loss = 0.01529211734731992
step = 12, Training Accuracy: 0.8033333333333333
Training loss = 0.015131729940573374
step = 13, Training Accuracy: 0.8266666666666667
Training loss = 0.013692434032758077
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.77125
pipeline:  [56, 22, 24, 86]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                               'always_apply': False,
                               'blur_value': 7,
                               'brightness_coefficient': 0.7,
                               'drop_color': (200, 200, 200),
                               'drop_length': 20,
                               'drop_width': 1,
                               'p': 0.5,
                               'rain_type': None,
                               'slant_lower': -10,
                               'slant_upper': 10},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.024943169355392456
step = 0, Training Accuracy: 0.6833333333333333
Validation Accuracy: 0.76
Training loss = 0.021303305625915526
step = 1, Training Accuracy: 0.73
Training loss = 0.020467481315135955
step = 2, Training Accuracy: 0.7233333333333334
Training loss = 0.018207003970940907
step = 3, Training Accuracy: 0.7766666666666666
Training loss = 0.01914214462041855
step = 4, Training Accuracy: 0.7533333333333333
Training loss = 0.01968303680419922
step = 5, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.75625
Training loss = 0.019176078935464223
step = 6, Training Accuracy: 0.75
Training loss = 0.016165609260400136
step = 7, Training Accuracy: 0.82
Training loss = 0.01779899979631106
step = 8, Training Accuracy: 0.78
Training loss = 0.016821115960677466
step = 9, Training Accuracy: 0.7833333333333333
Training loss = 0.01798612336317698
step = 10, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.7775
Training loss = 0.01838388741016388
step = 11, Training Accuracy: 0.8033333333333333
Training loss = 0.01593849539756775
step = 12, Training Accuracy: 0.8133333333333334
Training loss = 0.01705783009529114
step = 13, Training Accuracy: 0.81
Training loss = 0.017943885425726572
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.775
13 	4     	0.767708	0.00639078	0.76   	0.775  
pipeline:  [4, 85, 17, 39]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022785059809684753
step = 0, Training Accuracy: 0.7033333333333334
Validation Accuracy: 0.7625
Training loss = 0.020651016334692636
step = 1, Training Accuracy: 0.72
Training loss = 0.01826636999845505
step = 2, Training Accuracy: 0.7433333333333333
Training loss = 0.017515250742435456
step = 3, Training Accuracy: 0.7733333333333333
Training loss = 0.016438654561837514
step = 4, Training Accuracy: 0.7866666666666666
Training loss = 0.015538177490234374
step = 5, Training Accuracy: 0.8
Validation Accuracy: 0.7575
Training loss = 0.015314587155977884
step = 6, Training Accuracy: 0.7833333333333333
Training loss = 0.01454126273592313
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.015803139507770538
step = 8, Training Accuracy: 0.7833333333333333
Training loss = 0.012368276019891104
step = 9, Training Accuracy: 0.8333333333333334
Training loss = 0.013895615885655086
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.7525
Training loss = 0.014660566647847494
step = 11, Training Accuracy: 0.8166666666666667
Training loss = 0.014211784303188323
step = 12, Training Accuracy: 0.79
Training loss = 0.011813380420207978
step = 13, Training Accuracy: 0.8533333333333334
Training loss = 0.01268744985262553
step = 14, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.7475
pipeline:  [3, 37, 56, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022817648649215698
step = 0, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.76875
Training loss = 0.020648993055025735
step = 1, Training Accuracy: 0.7033333333333334
Training loss = 0.016258581529061
step = 2, Training Accuracy: 0.77
Training loss = 0.01783844659725825
step = 3, Training Accuracy: 0.7633333333333333
Training loss = 0.014516631960868836
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.01507997751235962
step = 5, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.76125
Training loss = 0.012740610738595327
step = 6, Training Accuracy: 0.8366666666666667
Training loss = 0.012665898650884628
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.014342106183369955
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.011783582170804342
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.012888546933730443
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.74875
Training loss = 0.012891010244687398
step = 11, Training Accuracy: 0.8433333333333334
Training loss = 0.012477900733550389
step = 12, Training Accuracy: 0.85
Training loss = 0.010531937082608541
step = 13, Training Accuracy: 0.86
Training loss = 0.009490686953067779
step = 14, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.745
pipeline:  [7, 5, 82, 16]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02081552396217982
step = 0, Training Accuracy: 0.75
Validation Accuracy: 0.74125
Training loss = 0.01799893726905187
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.01677242636680603
step = 2, Training Accuracy: 0.7933333333333333
Training loss = 0.01373740832010905
step = 3, Training Accuracy: 0.8233333333333334
Training loss = 0.014985905090967814
step = 4, Training Accuracy: 0.8133333333333334
Training loss = 0.010810750226179758
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.745
Training loss = 0.01178409218788147
step = 6, Training Accuracy: 0.85
Training loss = 0.012095096657673518
step = 7, Training Accuracy: 0.8633333333333333
Training loss = 0.012676764527956646
step = 8, Training Accuracy: 0.8633333333333333
Training loss = 0.009605370412270229
step = 9, Training Accuracy: 0.89
Training loss = 0.00838574526210626
step = 10, Training Accuracy: 0.9
Validation Accuracy: 0.7425
Training loss = 0.008961061884959539
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.009379720439513524
step = 12, Training Accuracy: 0.9
Training loss = 0.00748475526769956
step = 13, Training Accuracy: 0.9233333333333333
Training loss = 0.007494848916927974
step = 14, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.7375
pipeline:  [46, 11, 3, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021065592964490256
step = 0, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.7425
Training loss = 0.018399407664934794
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.015788896878560384
step = 2, Training Accuracy: 0.82
Training loss = 0.014206779897212982
step = 3, Training Accuracy: 0.83
Training loss = 0.013010961438218753
step = 4, Training Accuracy: 0.8433333333333334
Training loss = 0.011596368898948033
step = 5, Training Accuracy: 0.85
Validation Accuracy: 0.7575
Training loss = 0.013627967635790507
step = 6, Training Accuracy: 0.8433333333333334
Training loss = 0.011227954824765523
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.01046714464823405
step = 8, Training Accuracy: 0.8933333333333333
Training loss = 0.010763418674468995
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.009605131248633067
step = 10, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.7725
Training loss = 0.011780789146820705
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.00875884438554446
step = 12, Training Accuracy: 0.9
Training loss = 0.008326491812864939
step = 13, Training Accuracy: 0.91
Training loss = 0.010341661175092061
step = 14, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.7675
14 	4     	0.757292	0.0144413 	0.7375 	0.775  
pipeline:  [13, 90, 41, 39]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01471354973812898
step = 0, Training Accuracy: 0.82
Validation Accuracy: 0.76
Training loss = 0.010345399528741837
step = 1, Training Accuracy: 0.8733333333333333
Training loss = 0.009820538063844045
step = 2, Training Accuracy: 0.89
Training loss = 0.0077693143983682
step = 3, Training Accuracy: 0.92
Training loss = 0.008675048599640528
step = 4, Training Accuracy: 0.9166666666666666
Training loss = 0.005415401409069697
step = 5, Training Accuracy: 0.96
Validation Accuracy: 0.77125
Training loss = 0.0054093180845181145
step = 6, Training Accuracy: 0.9566666666666667
Training loss = 0.004738171870509783
step = 7, Training Accuracy: 0.95
Training loss = 0.004303486819068591
step = 8, Training Accuracy: 0.9566666666666667
Training loss = 0.003660557319720586
step = 9, Training Accuracy: 0.97
Training loss = 0.0033674285064140956
step = 10, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.75625
Training loss = 0.0033878207579255103
step = 11, Training Accuracy: 0.9833333333333333
Training loss = 0.002447803653776646
step = 12, Training Accuracy: 0.9933333333333333
Training loss = 0.0024732243145505588
step = 13, Training Accuracy: 0.9866666666666667
Training loss = 0.0017420790034035842
step = 14, Training Accuracy: 0.99
Validation Accuracy: 0.745
pipeline:  [37, 81, 25, 4]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01721456309159597
step = 0, Training Accuracy: 0.82
Validation Accuracy: 0.79125
Training loss = 0.013135486468672752
step = 1, Training Accuracy: 0.8466666666666667
Training loss = 0.011486072291930516
step = 2, Training Accuracy: 0.8666666666666667
Training loss = 0.009484407057364782
step = 3, Training Accuracy: 0.89
Training loss = 0.00973475697139899
step = 4, Training Accuracy: 0.8966666666666666
Training loss = 0.007652512739102045
step = 5, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.77375
Training loss = 0.006582344869772593
step = 6, Training Accuracy: 0.9366666666666666
Training loss = 0.005686624646186828
step = 7, Training Accuracy: 0.95
Training loss = 0.007290410126248995
step = 8, Training Accuracy: 0.9333333333333333
Training loss = 0.005283852542440097
step = 9, Training Accuracy: 0.9466666666666667
Training loss = 0.004527879431843757
step = 10, Training Accuracy: 0.96
Validation Accuracy: 0.755
Training loss = 0.004686110988259316
step = 11, Training Accuracy: 0.9566666666666667
Training loss = 0.003533805819849173
step = 12, Training Accuracy: 0.9766666666666667
Training loss = 0.004350705494483312
step = 13, Training Accuracy: 0.9666666666666667
Training loss = 0.004556105919182301
step = 14, Training Accuracy: 0.9666666666666667
Validation Accuracy: 0.76375
pipeline:  [26, 92, 56, 30]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03837724427382151
step = 0, Training Accuracy: 0.6233333333333333
Validation Accuracy: 0.625
Training loss = 0.028950263361136118
step = 1, Training Accuracy: 0.6633333333333333
Training loss = 0.02906787653764089
step = 2, Training Accuracy: 0.6166666666666667
Training loss = 0.026229995687802633
step = 3, Training Accuracy: 0.6366666666666667
Training loss = 0.025981465578079222
step = 4, Training Accuracy: 0.6333333333333333
Training loss = 0.024220514396826428
step = 5, Training Accuracy: 0.7
Validation Accuracy: 0.67625
Training loss = 0.022805803020795188
step = 6, Training Accuracy: 0.66
Training loss = 0.021561418374379474
step = 7, Training Accuracy: 0.6833333333333333
Training loss = 0.020697840352853138
step = 8, Training Accuracy: 0.7066666666666667
Training loss = 0.02262104908625285
step = 9, Training Accuracy: 0.6866666666666666
Training loss = 0.0204416286945343
step = 10, Training Accuracy: 0.7266666666666667
Validation Accuracy: 0.695
Training loss = 0.023723570307095845
step = 11, Training Accuracy: 0.6866666666666666
Training loss = 0.021187678972880045
step = 12, Training Accuracy: 0.7233333333333334
Training loss = 0.02193524827559789
step = 13, Training Accuracy: 0.7133333333333334
Training loss = 0.020076864858468373
step = 14, Training Accuracy: 0.71
Validation Accuracy: 0.68625
15 	3     	0.752708	0.0314528 	0.68625	0.775  
pipeline:  [25, 56, 45, 79]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017870013217131296
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.7425
Training loss = 0.017598276336987812
step = 1, Training Accuracy: 0.7933333333333333
Training loss = 0.01587431440750758
step = 2, Training Accuracy: 0.8266666666666667
Training loss = 0.014511803090572357
step = 3, Training Accuracy: 0.8266666666666667
Training loss = 0.015297359426816304
step = 4, Training Accuracy: 0.8333333333333334
Training loss = 0.013201517562071483
step = 5, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79375
Training loss = 0.013706901868184407
step = 6, Training Accuracy: 0.8366666666666667
Training loss = 0.01273090327779452
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.012419670919577281
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.010645150939623515
step = 9, Training Accuracy: 0.86
Training loss = 0.010039638330539068
step = 10, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.775
Training loss = 0.010461628983418146
step = 11, Training Accuracy: 0.85
Training loss = 0.008849897632996241
step = 12, Training Accuracy: 0.9233333333333333
Training loss = 0.009098045974969864
step = 13, Training Accuracy: 0.8833333333333333
Training loss = 0.009051611423492431
step = 14, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.77625
pipeline:  [70, 25, 11, 41]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016634002725283304
step = 0, Training Accuracy: 0.79
Validation Accuracy: 0.77
Training loss = 0.014554717143376668
step = 1, Training Accuracy: 0.8
Training loss = 0.01121322438120842
step = 2, Training Accuracy: 0.87
Training loss = 0.010698196639617285
step = 3, Training Accuracy: 0.8566666666666667
Training loss = 0.009059796035289764
step = 4, Training Accuracy: 0.9
Training loss = 0.008424924711386363
step = 5, Training Accuracy: 0.89
Validation Accuracy: 0.75625
Training loss = 0.0074609514822562535
step = 6, Training Accuracy: 0.91
Training loss = 0.00688006728887558
step = 7, Training Accuracy: 0.94
Training loss = 0.005430221781134606
step = 8, Training Accuracy: 0.9566666666666667
Training loss = 0.005450103357434273
step = 9, Training Accuracy: 0.9433333333333334
Training loss = 0.004662021746238073
step = 10, Training Accuracy: 0.9566666666666667
Validation Accuracy: 0.76125
Training loss = 0.00391197153677543
step = 11, Training Accuracy: 0.9733333333333334
Training loss = 0.00415040448307991
step = 12, Training Accuracy: 0.97
Training loss = 0.003955351697901885
step = 13, Training Accuracy: 0.9833333333333333
Training loss = 0.0034947185094157856
step = 14, Training Accuracy: 0.9866666666666667
Validation Accuracy: 0.76
pipeline:  [7, 86, 25, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022412033180395762
step = 0, Training Accuracy: 0.75
Validation Accuracy: 0.75625
Training loss = 0.02368446260690689
step = 1, Training Accuracy: 0.7433333333333333
Training loss = 0.021424610118071237
step = 2, Training Accuracy: 0.6966666666666667
Training loss = 0.01840883235136668
step = 3, Training Accuracy: 0.7966666666666666
Training loss = 0.018236497044563295
step = 4, Training Accuracy: 0.7533333333333333
Training loss = 0.017405352691809338
step = 5, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.7525
Training loss = 0.013507196605205536
step = 6, Training Accuracy: 0.84
Training loss = 0.01181687131524086
step = 7, Training Accuracy: 0.8366666666666667
Training loss = 0.013065446217854817
step = 8, Training Accuracy: 0.8333333333333334
Training loss = 0.013993669251600902
step = 9, Training Accuracy: 0.83
Training loss = 0.011462575246890386
step = 10, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.7675
Training loss = 0.011276841064294179
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.013747278153896331
step = 12, Training Accuracy: 0.8133333333333334
Training loss = 0.01215452750523885
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.008532449478904407
step = 14, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.7625
16 	3     	0.77    	0.0064145 	0.76   	0.77625
pipeline:  [12, 56, 42, 79]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02224254886309306
step = 0, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.76375
Training loss = 0.024490000406901042
step = 1, Training Accuracy: 0.6766666666666666
Training loss = 0.02185602307319641
step = 2, Training Accuracy: 0.7033333333333334
Training loss = 0.019012513359387716
step = 3, Training Accuracy: 0.7433333333333333
Training loss = 0.018571538577477138
step = 4, Training Accuracy: 0.7333333333333333
Training loss = 0.020955161650975544
step = 5, Training Accuracy: 0.7
Validation Accuracy: 0.76
Training loss = 0.01818055639664332
step = 6, Training Accuracy: 0.7733333333333333
Training loss = 0.017697537740071614
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.01700705255071322
step = 8, Training Accuracy: 0.7666666666666667
Training loss = 0.017195638616879783
step = 9, Training Accuracy: 0.7733333333333333
Training loss = 0.017536218166351317
step = 10, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.76
Training loss = 0.017039636969566344
step = 11, Training Accuracy: 0.7566666666666667
Training loss = 0.01784201890230179
step = 12, Training Accuracy: 0.7633333333333333
Training loss = 0.018005532920360567
step = 13, Training Accuracy: 0.7866666666666666
Training loss = 0.018222432335217795
step = 14, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.76125
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022305658757686614
step = 0, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.7775
Training loss = 0.01933861235777537
step = 1, Training Accuracy: 0.7466666666666667
Training loss = 0.01878332724173864
step = 2, Training Accuracy: 0.7633333333333333
Training loss = 0.01785276194413503
step = 3, Training Accuracy: 0.77
Training loss = 0.021936838924884797
step = 4, Training Accuracy: 0.7166666666666667
Training loss = 0.01732706626256307
step = 5, Training Accuracy: 0.79
Validation Accuracy: 0.78375
Training loss = 0.017643673916657766
step = 6, Training Accuracy: 0.77
Training loss = 0.017894695699214935
step = 7, Training Accuracy: 0.76
Training loss = 0.016327663163344067
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.016650440593560537
step = 9, Training Accuracy: 0.79
Training loss = 0.015368786454200745
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.7725
Training loss = 0.01595382422208786
step = 11, Training Accuracy: 0.7933333333333333
Training loss = 0.01675369421641032
step = 12, Training Accuracy: 0.7966666666666666
Training loss = 0.01565246909856796
step = 13, Training Accuracy: 0.8266666666666667
Training loss = 0.017574075758457184
step = 14, Training Accuracy: 0.78
Validation Accuracy: 0.785
17 	2     	0.774792	0.00697528	0.76125	0.785  
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02237527330716451
step = 0, Training Accuracy: 0.7066666666666667
Validation Accuracy: 0.78875
Training loss = 0.01991871863603592
step = 1, Training Accuracy: 0.7633333333333333
Training loss = 0.019786937435468038
step = 2, Training Accuracy: 0.7533333333333333
Training loss = 0.01870702435572942
step = 3, Training Accuracy: 0.7533333333333333
Training loss = 0.016835787494977314
step = 4, Training Accuracy: 0.78
Training loss = 0.01685932805140813
step = 5, Training Accuracy: 0.77
Validation Accuracy: 0.7725
Training loss = 0.01832476576169332
step = 6, Training Accuracy: 0.78
Training loss = 0.01807473212480545
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.015583827594916026
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.01446882834037145
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.015872123936812085
step = 10, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.7925
Training loss = 0.016099517643451692
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.012387958765029907
step = 12, Training Accuracy: 0.83
Training loss = 0.01498236745595932
step = 13, Training Accuracy: 0.82
Training loss = 0.01769925743341446
step = 14, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.785
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.019152027865250904
step = 0, Training Accuracy: 0.76
Validation Accuracy: 0.78625
Training loss = 0.018418395419915516
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.01759840726852417
step = 2, Training Accuracy: 0.79
Training loss = 0.016465687652428944
step = 3, Training Accuracy: 0.7733333333333333
Training loss = 0.015519335170586904
step = 4, Training Accuracy: 0.7866666666666666
Training loss = 0.015421870549519857
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.785
Training loss = 0.015077706078688304
step = 6, Training Accuracy: 0.7966666666666666
Training loss = 0.015938551127910615
step = 7, Training Accuracy: 0.79
Training loss = 0.01470755805571874
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.016512700219949085
step = 9, Training Accuracy: 0.7966666666666666
Training loss = 0.013226500848929087
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.77125
Training loss = 0.01592873324950536
step = 11, Training Accuracy: 0.7766666666666666
Training loss = 0.01514729619026184
step = 12, Training Accuracy: 0.81
Training loss = 0.014217879176139831
step = 13, Training Accuracy: 0.8
Training loss = 0.017087001999219257
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.7725
pipeline:  [46, 44, 34, 69]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.019508937895298003
step = 0, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.77375
Training loss = 0.021302670339743295
step = 1, Training Accuracy: 0.7233333333333334
Training loss = 0.01999568889538447
step = 2, Training Accuracy: 0.7366666666666667
Training loss = 0.020103878875573477
step = 3, Training Accuracy: 0.7466666666666667
Training loss = 0.018462583720684052
step = 4, Training Accuracy: 0.75
Training loss = 0.018902082244555155
step = 5, Training Accuracy: 0.7266666666666667
Validation Accuracy: 0.77125
Training loss = 0.01822908232609431
step = 6, Training Accuracy: 0.7466666666666667
Training loss = 0.01670483301083247
step = 7, Training Accuracy: 0.7466666666666667
Training loss = 0.016527929802735646
step = 8, Training Accuracy: 0.7733333333333333
Training loss = 0.01717824712395668
step = 9, Training Accuracy: 0.77
Training loss = 0.01682354946931203
step = 10, Training Accuracy: 0.77
Validation Accuracy: 0.77625
Training loss = 0.016372972925504048
step = 11, Training Accuracy: 0.81
Training loss = 0.01667172501484553
step = 12, Training Accuracy: 0.7766666666666666
Training loss = 0.015562333464622498
step = 13, Training Accuracy: 0.7933333333333333
Training loss = 0.0168683260679245
step = 14, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.76625
pipeline:  [56, 19, 88, 74]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.05, 0.05),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'shift_limit': (-0.05, 0.05),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.3, 0.3),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'num_steps': 5,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                                               'alpha': 1,
                                               'alpha_affine': 50,
                                               'always_apply': False,
                                               'approximate': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'sigma': 50,
                                               'value': None}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02435364782810211
step = 0, Training Accuracy: 0.6633333333333333
Validation Accuracy: 0.75875
Training loss = 0.020429564813772838
step = 1, Training Accuracy: 0.72
Training loss = 0.020181213120619455
step = 2, Training Accuracy: 0.75
Training loss = 0.018297891914844513
step = 3, Training Accuracy: 0.7566666666666667
Training loss = 0.020084794163703918
step = 4, Training Accuracy: 0.7233333333333334
Training loss = 0.017982616623242697
step = 5, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.785
Training loss = 0.017533821165561677
step = 6, Training Accuracy: 0.7833333333333333
Training loss = 0.017197629908720653
step = 7, Training Accuracy: 0.7666666666666667
Training loss = 0.01860240936279297
step = 8, Training Accuracy: 0.7433333333333333
Training loss = 0.017397122085094453
step = 9, Training Accuracy: 0.78
Training loss = 0.016141088207562763
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.78625
Training loss = 0.01641376326481501
step = 11, Training Accuracy: 0.7633333333333333
Training loss = 0.014195849398771922
step = 12, Training Accuracy: 0.8166666666666667
Training loss = 0.017258300284544628
step = 13, Training Accuracy: 0.75
Training loss = 0.01719844510157903
step = 14, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.7825
18 	4     	0.777708	0.00701251	0.76625	0.785  
pipeline:  [85, 46, 86, 31]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022785689036051434
step = 0, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.71375
Training loss = 0.019118003050486245
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.018180546760559083
step = 2, Training Accuracy: 0.7733333333333333
Training loss = 0.01685648222764333
step = 3, Training Accuracy: 0.82
Training loss = 0.016527359386285145
step = 4, Training Accuracy: 0.79
Training loss = 0.016760742366313933
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.7975
Training loss = 0.015396618147691091
step = 6, Training Accuracy: 0.8133333333333334
Training loss = 0.014901206096013387
step = 7, Training Accuracy: 0.8133333333333334
Training loss = 0.013640054911375045
step = 8, Training Accuracy: 0.83
Training loss = 0.016310922702153525
step = 9, Training Accuracy: 0.8133333333333334
Training loss = 0.014270955026149749
step = 10, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.785
Training loss = 0.014347874224185944
step = 11, Training Accuracy: 0.82
Training loss = 0.01618038465579351
step = 12, Training Accuracy: 0.8066666666666666
Training loss = 0.015370873014132182
step = 13, Training Accuracy: 0.81
Training loss = 0.012520762234926224
step = 14, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.78125
pipeline:  [56, 23, 2, 1]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020466456313927968
step = 0, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.79875
Training loss = 0.016193925738334655
step = 1, Training Accuracy: 0.82
Training loss = 0.017790564000606537
step = 2, Training Accuracy: 0.8066666666666666
Training loss = 0.015175573925177255
step = 3, Training Accuracy: 0.83
Training loss = 0.013614473044872283
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.013777023007472355
step = 5, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.79875
Training loss = 0.011680267651875813
step = 6, Training Accuracy: 0.85
Training loss = 0.011853137016296388
step = 7, Training Accuracy: 0.86
Training loss = 0.012314557780822117
step = 8, Training Accuracy: 0.8566666666666667
Training loss = 0.011223123073577881
step = 9, Training Accuracy: 0.8633333333333333
Training loss = 0.011040751735369364
step = 10, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.795
Training loss = 0.01105606387058894
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.009668905089298884
step = 12, Training Accuracy: 0.8866666666666667
Training loss = 0.009919499456882476
step = 13, Training Accuracy: 0.8966666666666666
Training loss = 0.009699084460735322
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.7925
pipeline:  [56, 38, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018920972247918447
step = 0, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.79125
Training loss = 0.019496876299381256
step = 1, Training Accuracy: 0.7533333333333333
Training loss = 0.016683678328990936
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.016150882144769032
step = 3, Training Accuracy: 0.8
Training loss = 0.015158626238505045
step = 4, Training Accuracy: 0.8133333333333334
Training loss = 0.01693774809439977
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.8025
Training loss = 0.01586185961961746
step = 6, Training Accuracy: 0.7966666666666666
Training loss = 0.016663260658582053
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.014226315418879192
step = 8, Training Accuracy: 0.8333333333333334
Training loss = 0.014115848044554392
step = 9, Training Accuracy: 0.8033333333333333
Training loss = 0.012424607773621877
step = 10, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.815
Training loss = 0.015265047053496043
step = 11, Training Accuracy: 0.8466666666666667
Training loss = 0.013451573749383291
step = 12, Training Accuracy: 0.84
Training loss = 0.01593254486719767
step = 13, Training Accuracy: 0.8066666666666666
Training loss = 0.013421797653039297
step = 14, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.805
pipeline:  [34, 32, 46, 74]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02742729385693868
step = 0, Training Accuracy: 0.64
Validation Accuracy: 0.815
Training loss = 0.022873929540316265
step = 1, Training Accuracy: 0.71
Training loss = 0.023219454288482665
step = 2, Training Accuracy: 0.6766666666666666
Training loss = 0.02101912905772527
step = 3, Training Accuracy: 0.7433333333333333
Training loss = 0.02144307533899943
step = 4, Training Accuracy: 0.7233333333333334
Training loss = 0.02211698313554128
step = 5, Training Accuracy: 0.7266666666666667
Validation Accuracy: 0.78875
Training loss = 0.020901567141215008
step = 6, Training Accuracy: 0.72
Training loss = 0.020467147628466287
step = 7, Training Accuracy: 0.7166666666666667
Training loss = 0.01935427337884903
step = 8, Training Accuracy: 0.74
Training loss = 0.020667650202910105
step = 9, Training Accuracy: 0.73
Training loss = 0.018912816842397054
step = 10, Training Accuracy: 0.74
Validation Accuracy: 0.79625
Training loss = 0.01807234843571981
step = 11, Training Accuracy: 0.75
Training loss = 0.019637789328893027
step = 12, Training Accuracy: 0.71
Training loss = 0.01702344020207723
step = 13, Training Accuracy: 0.7666666666666667
Training loss = 0.017457773784796397
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.79
19 	4     	0.789792	0.00771959	0.78125	0.805  
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.019051368137200674
step = 0, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.8075
Training loss = 0.01879872808853785
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.01714545726776123
step = 2, Training Accuracy: 0.7866666666666666
Training loss = 0.016089471280574797
step = 3, Training Accuracy: 0.7566666666666667
Training loss = 0.01632355809211731
step = 4, Training Accuracy: 0.7866666666666666
Training loss = 0.015429893334706624
step = 5, Training Accuracy: 0.81
Validation Accuracy: 0.80875
Training loss = 0.01813240458567937
step = 6, Training Accuracy: 0.76
Training loss = 0.01819504717985789
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.015174422264099121
step = 8, Training Accuracy: 0.8133333333333334
Training loss = 0.01577527085940043
step = 9, Training Accuracy: 0.8
Training loss = 0.012838802337646484
step = 10, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.79375
Training loss = 0.014141689936319988
step = 11, Training Accuracy: 0.8233333333333334
Training loss = 0.014920816322167714
step = 12, Training Accuracy: 0.8133333333333334
Training loss = 0.014088182349999746
step = 13, Training Accuracy: 0.8133333333333334
Training loss = 0.014469159642855327
step = 14, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.78625
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0187648931145668
step = 0, Training Accuracy: 0.78
Validation Accuracy: 0.78875
Training loss = 0.018624673386414846
step = 1, Training Accuracy: 0.7533333333333333
Training loss = 0.020067020058631896
step = 2, Training Accuracy: 0.7566666666666667
Training loss = 0.01718252827723821
step = 3, Training Accuracy: 0.78
Training loss = 0.015332561035950978
step = 4, Training Accuracy: 0.7866666666666666
Training loss = 0.016080855031808217
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.8025
Training loss = 0.01647991081078847
step = 6, Training Accuracy: 0.79
Training loss = 0.017936829129854837
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.017052632570266724
step = 8, Training Accuracy: 0.7966666666666666
Training loss = 0.014228885968526204
step = 9, Training Accuracy: 0.82
Training loss = 0.015940294365088144
step = 10, Training Accuracy: 0.77
Validation Accuracy: 0.80625
Training loss = 0.018207461436589557
step = 11, Training Accuracy: 0.79
Training loss = 0.014676204919815063
step = 12, Training Accuracy: 0.8433333333333334
Training loss = 0.01500429997841517
step = 13, Training Accuracy: 0.7933333333333333
Training loss = 0.014642088214556375
step = 14, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.81
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02118104894955953
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.80375
Training loss = 0.019878152906894684
step = 1, Training Accuracy: 0.76
Training loss = 0.016791335940361023
step = 2, Training Accuracy: 0.78
Training loss = 0.01952187140782674
step = 3, Training Accuracy: 0.7733333333333333
Training loss = 0.01774000068505605
step = 4, Training Accuracy: 0.8133333333333334
Training loss = 0.017441848317782085
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.805
Training loss = 0.016878924171129864
step = 6, Training Accuracy: 0.82
Training loss = 0.016148377358913422
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.01729677011569341
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.018129291931788128
step = 9, Training Accuracy: 0.7766666666666666
Training loss = 0.014567873080571492
step = 10, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.80125
Training loss = 0.01504785418510437
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.01582371910413106
step = 12, Training Accuracy: 0.8
Training loss = 0.01729797840118408
step = 13, Training Accuracy: 0.7766666666666666
Training loss = 0.015107694566249847
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.79625
pipeline:  [56, 38, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018443713386853536
step = 0, Training Accuracy: 0.78
Validation Accuracy: 0.80125
Training loss = 0.018613901237646738
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.01889993021885554
step = 2, Training Accuracy: 0.7866666666666666
Training loss = 0.01690488487482071
step = 3, Training Accuracy: 0.7666666666666667
Training loss = 0.018528018593788147
step = 4, Training Accuracy: 0.7633333333333333
Training loss = 0.015523488769928614
step = 5, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.79375
Training loss = 0.02030645509560903
step = 6, Training Accuracy: 0.7633333333333333
Training loss = 0.01568567901849747
step = 7, Training Accuracy: 0.8
Training loss = 0.015922265748182934
step = 8, Training Accuracy: 0.8033333333333333
Training loss = 0.016096990406513214
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.016765775978565215
step = 10, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.78125
Training loss = 0.01493746687968572
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.015300942460695903
step = 12, Training Accuracy: 0.7966666666666666
Training loss = 0.01634832948446274
step = 13, Training Accuracy: 0.7866666666666666
Training loss = 0.015347910424073538
step = 14, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.78625
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0191359543800354
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.78625
Training loss = 0.018011903663476308
step = 1, Training Accuracy: 0.7433333333333333
Training loss = 0.016703493893146515
step = 2, Training Accuracy: 0.77
Training loss = 0.017522715032100677
step = 3, Training Accuracy: 0.78
Training loss = 0.01697072555621465
step = 4, Training Accuracy: 0.7433333333333333
Training loss = 0.015932100514570873
step = 5, Training Accuracy: 0.79
Validation Accuracy: 0.77125
Training loss = 0.017659006615479787
step = 6, Training Accuracy: 0.7666666666666667
Training loss = 0.01714108347892761
step = 7, Training Accuracy: 0.7833333333333333
Training loss = 0.01556119829416275
step = 8, Training Accuracy: 0.8
Training loss = 0.01696468472480774
step = 9, Training Accuracy: 0.7633333333333333
Training loss = 0.016424584090709685
step = 10, Training Accuracy: 0.79
Validation Accuracy: 0.78125
Training loss = 0.01395892858505249
step = 11, Training Accuracy: 0.8166666666666667
Training loss = 0.0140572190284729
step = 12, Training Accuracy: 0.8233333333333334
Training loss = 0.01600368559360504
step = 13, Training Accuracy: 0.7933333333333333
Training loss = 0.015355148116747538
step = 14, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.7725
pipeline:  [12, 81, 83, 85]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020652870933214825
step = 0, Training Accuracy: 0.75
Validation Accuracy: 0.77625
Training loss = 0.020697012742360434
step = 1, Training Accuracy: 0.7533333333333333
Training loss = 0.01803761104742686
step = 2, Training Accuracy: 0.7533333333333333
Training loss = 0.015539147059122722
step = 3, Training Accuracy: 0.7766666666666666
Training loss = 0.016391463776429496
step = 4, Training Accuracy: 0.8
Training loss = 0.015568872094154357
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.78375
Training loss = 0.016900693376859028
step = 6, Training Accuracy: 0.8066666666666666
Training loss = 0.01510022779305776
step = 7, Training Accuracy: 0.8266666666666667
Training loss = 0.014784345924854279
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.013179026593764622
step = 9, Training Accuracy: 0.8233333333333334
Training loss = 0.01485753466685613
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.78625
Training loss = 0.014173840582370758
step = 11, Training Accuracy: 0.81
Training loss = 0.012529999961455663
step = 12, Training Accuracy: 0.86
Training loss = 0.011544285714626313
step = 13, Training Accuracy: 0.8733333333333333
Training loss = 0.011845211535692214
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.7725
20 	6     	0.787292	0.0131382 	0.7725 	0.81   
pipeline:  [45, 70, 5, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014617907404899598
step = 0, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.7825
Training loss = 0.012527715861797333
step = 1, Training Accuracy: 0.8266666666666667
Training loss = 0.011939312865336737
step = 2, Training Accuracy: 0.8766666666666667
Training loss = 0.00897770345211029
step = 3, Training Accuracy: 0.8866666666666667
Training loss = 0.009807837009429932
step = 4, Training Accuracy: 0.9
Training loss = 0.007734276552995046
step = 5, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.77375
Training loss = 0.008327609499295553
step = 6, Training Accuracy: 0.8866666666666667
Training loss = 0.007375544508298238
step = 7, Training Accuracy: 0.93
Training loss = 0.006611104061206182
step = 8, Training Accuracy: 0.9166666666666666
Training loss = 0.007264454315106074
step = 9, Training Accuracy: 0.9266666666666666
Training loss = 0.006495262682437897
step = 10, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.76375
Training loss = 0.005028897548715274
step = 11, Training Accuracy: 0.9466666666666667
Training loss = 0.006441218579808871
step = 12, Training Accuracy: 0.9366666666666666
Training loss = 0.0053953925396005315
step = 13, Training Accuracy: 0.9433333333333334
Training loss = 0.004625885436932246
step = 14, Training Accuracy: 0.97
Validation Accuracy: 0.76875
pipeline:  [77, 1, 37, 45]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016258997718493144
step = 0, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.77625
Training loss = 0.014205674926439921
step = 1, Training Accuracy: 0.86
Training loss = 0.010145160456498464
step = 2, Training Accuracy: 0.88
Training loss = 0.008473713348309198
step = 3, Training Accuracy: 0.9166666666666666
Training loss = 0.008666678592562675
step = 4, Training Accuracy: 0.9166666666666666
Training loss = 0.00800086868306001
step = 5, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.78
Training loss = 0.007379872798919678
step = 6, Training Accuracy: 0.9133333333333333
Training loss = 0.006236692095796267
step = 7, Training Accuracy: 0.9466666666666667
Training loss = 0.006303396274646123
step = 8, Training Accuracy: 0.9366666666666666
Training loss = 0.005474466507633527
step = 9, Training Accuracy: 0.9466666666666667
Training loss = 0.004702226892113685
step = 10, Training Accuracy: 0.9766666666666667
Validation Accuracy: 0.78125
Training loss = 0.004772375300526619
step = 11, Training Accuracy: 0.9566666666666667
Training loss = 0.0038403482859333355
step = 12, Training Accuracy: 0.97
Training loss = 0.00403971487035354
step = 13, Training Accuracy: 0.96
Training loss = 0.003988326812783877
step = 14, Training Accuracy: 0.9833333333333333
Validation Accuracy: 0.78125
21 	2     	0.791458	0.0131184 	0.76875	0.81   
pipeline:  [63, 16, 53, 72]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.033945151766141254
step = 0, Training Accuracy: 0.69
Validation Accuracy: 0.76875
Training loss = 0.0273945285876592
step = 1, Training Accuracy: 0.69
Training loss = 0.02033318728208542
step = 2, Training Accuracy: 0.7566666666666667
Training loss = 0.023479400873184203
step = 3, Training Accuracy: 0.73
Training loss = 0.022441603938738505
step = 4, Training Accuracy: 0.74
Training loss = 0.022091645201047262
step = 5, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.75875
Training loss = 0.019190290570259096
step = 6, Training Accuracy: 0.76
Training loss = 0.019374805986881256
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.01846406916777293
step = 8, Training Accuracy: 0.7733333333333333
Training loss = 0.016547914743423462
step = 9, Training Accuracy: 0.78
Training loss = 0.01720260535677274
step = 10, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.77375
Training loss = 0.016769672036170958
step = 11, Training Accuracy: 0.79
Training loss = 0.015724680026372274
step = 12, Training Accuracy: 0.8166666666666667
Training loss = 0.013482925444841386
step = 13, Training Accuracy: 0.83
Training loss = 0.016194908420244854
step = 14, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.76625
pipeline:  [82, 16, 31, 81]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01505885029832522
step = 0, Training Accuracy: 0.79
Validation Accuracy: 0.78
Training loss = 0.013737490276495616
step = 1, Training Accuracy: 0.84
Training loss = 0.012443412393331528
step = 2, Training Accuracy: 0.8433333333333334
Training loss = 0.015495990514755248
step = 3, Training Accuracy: 0.8433333333333334
Training loss = 0.010464534014463425
step = 4, Training Accuracy: 0.8766666666666667
Training loss = 0.011237619295716286
step = 5, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.785
Training loss = 0.013694928040107092
step = 6, Training Accuracy: 0.84
Training loss = 0.011331674059232076
step = 7, Training Accuracy: 0.89
Training loss = 0.010726051926612854
step = 8, Training Accuracy: 0.86
Training loss = 0.007248169804612795
step = 9, Training Accuracy: 0.92
Training loss = 0.010511726240317027
step = 10, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.78875
Training loss = 0.009362399900952974
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.008024571736653646
step = 12, Training Accuracy: 0.9133333333333333
Training loss = 0.008412120838960011
step = 13, Training Accuracy: 0.9166666666666666
Training loss = 0.00977119912703832
step = 14, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.77625
pipeline:  [19, 5, 75, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01291586235165596
step = 0, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.785
Training loss = 0.011180727233489354
step = 1, Training Accuracy: 0.8833333333333333
Training loss = 0.011386914849281312
step = 2, Training Accuracy: 0.8933333333333333
Training loss = 0.009919273604949316
step = 3, Training Accuracy: 0.8866666666666667
Training loss = 0.0080478572845459
step = 4, Training Accuracy: 0.9166666666666666
Training loss = 0.007376431922117869
step = 5, Training Accuracy: 0.93
Validation Accuracy: 0.7875
Training loss = 0.0067213191588719684
step = 6, Training Accuracy: 0.9233333333333333
Training loss = 0.0056298311054706575
step = 7, Training Accuracy: 0.94
Training loss = 0.00711901140709718
step = 8, Training Accuracy: 0.9433333333333334
Training loss = 0.005732107162475586
step = 9, Training Accuracy: 0.9466666666666667
Training loss = 0.005670769115289053
step = 10, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.7825
Training loss = 0.005161289026339849
step = 11, Training Accuracy: 0.9666666666666667
Training loss = 0.004351259544491768
step = 12, Training Accuracy: 0.96
Training loss = 0.0036722503478328387
step = 13, Training Accuracy: 0.9833333333333333
Training loss = 0.003711297375460466
step = 14, Training Accuracy: 0.9733333333333334
Validation Accuracy: 0.77125
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02051051249106725
step = 0, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.775
Training loss = 0.01878753423690796
step = 1, Training Accuracy: 0.7633333333333333
Training loss = 0.01940904329220454
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.01745945155620575
step = 3, Training Accuracy: 0.79
Training loss = 0.018691416680812836
step = 4, Training Accuracy: 0.7633333333333333
Training loss = 0.016876336336135864
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.775
Training loss = 0.013079300920168558
step = 6, Training Accuracy: 0.8566666666666667
Training loss = 0.012452518741289775
step = 7, Training Accuracy: 0.8266666666666667
Training loss = 0.012905075897773106
step = 8, Training Accuracy: 0.85
Training loss = 0.013801651298999787
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.01349373256166776
step = 10, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.78
Training loss = 0.013002402782440185
step = 11, Training Accuracy: 0.84
Training loss = 0.012579765369494756
step = 12, Training Accuracy: 0.83
Training loss = 0.012876795530319214
step = 13, Training Accuracy: 0.85
Training loss = 0.013158240964015326
step = 14, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021025265057881673
step = 0, Training Accuracy: 0.75
Validation Accuracy: 0.795
Training loss = 0.021797193586826323
step = 1, Training Accuracy: 0.7466666666666667
Training loss = 0.01643917292356491
step = 2, Training Accuracy: 0.7566666666666667
Training loss = 0.020353320240974426
step = 3, Training Accuracy: 0.7333333333333333
Training loss = 0.01824594775835673
step = 4, Training Accuracy: 0.7466666666666667
Training loss = 0.016422790189584095
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.78375
Training loss = 0.016730878303448358
step = 6, Training Accuracy: 0.8033333333333333
Training loss = 0.01682755728562673
step = 7, Training Accuracy: 0.79
Training loss = 0.015631884833176932
step = 8, Training Accuracy: 0.8033333333333333
Training loss = 0.017490511337916057
step = 9, Training Accuracy: 0.75
Training loss = 0.01626906603574753
step = 10, Training Accuracy: 0.79
Validation Accuracy: 0.77375
Training loss = 0.015511339008808136
step = 11, Training Accuracy: 0.8033333333333333
Training loss = 0.01497258002559344
step = 12, Training Accuracy: 0.7766666666666666
Training loss = 0.01585553338130315
step = 13, Training Accuracy: 0.8033333333333333
Training loss = 0.014467874368031819
step = 14, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.785
pipeline:  [42, 0, 37, 38]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03693264623483022
step = 0, Training Accuracy: 0.5466666666666666
Validation Accuracy: 0.76625
Training loss = 0.03171244164307912
step = 1, Training Accuracy: 0.5733333333333334
Training loss = 0.028002459406852722
step = 2, Training Accuracy: 0.5633333333333334
Training loss = 0.027942004601160687
step = 3, Training Accuracy: 0.5566666666666666
Training loss = 0.02819937765598297
step = 4, Training Accuracy: 0.5566666666666666
Training loss = 0.027714662353197732
step = 5, Training Accuracy: 0.6166666666666667
Validation Accuracy: 0.7375
Training loss = 0.026854533155759176
step = 6, Training Accuracy: 0.58
Training loss = 0.026561270157496136
step = 7, Training Accuracy: 0.63
Training loss = 0.026285360256830852
step = 8, Training Accuracy: 0.6166666666666667
Training loss = 0.02507382333278656
step = 9, Training Accuracy: 0.6233333333333333
Training loss = 0.02513054629166921
step = 10, Training Accuracy: 0.6366666666666667
Validation Accuracy: 0.73875
Training loss = 0.024554217060407002
step = 11, Training Accuracy: 0.67
Training loss = 0.024786750475565594
step = 12, Training Accuracy: 0.63
Training loss = 0.024127056002616883
step = 13, Training Accuracy: 0.6633333333333333
Training loss = 0.025802915692329408
step = 14, Training Accuracy: 0.64
Validation Accuracy: 0.765
22 	6     	0.775625	0.00926322	0.765  	0.79   
pipeline:  [58, 6, 62, 15]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022860768536726635
step = 0, Training Accuracy: 0.6733333333333333
Validation Accuracy: 0.43375
Training loss = 0.02010223428408305
step = 1, Training Accuracy: 0.7433333333333333
Training loss = 0.01892872581879298
step = 2, Training Accuracy: 0.76
Training loss = 0.020029784043629963
step = 3, Training Accuracy: 0.7333333333333333
Training loss = 0.01937020003795624
step = 4, Training Accuracy: 0.7166666666666667
Training loss = 0.0178389510512352
step = 5, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.48125
Training loss = 0.019188545842965445
step = 6, Training Accuracy: 0.75
Training loss = 0.01797941853602727
step = 7, Training Accuracy: 0.7533333333333333
Training loss = 0.01677976538737615
step = 8, Training Accuracy: 0.7866666666666666
Training loss = 0.016550449033578236
step = 9, Training Accuracy: 0.7866666666666666
Training loss = 0.015325692395369211
step = 10, Training Accuracy: 0.78
Validation Accuracy: 0.505
Training loss = 0.016358019510904948
step = 11, Training Accuracy: 0.7733333333333333
Training loss = 0.015634456078211467
step = 12, Training Accuracy: 0.7533333333333333
Training loss = 0.016223592658837636
step = 13, Training Accuracy: 0.77
Training loss = 0.01581688106060028
step = 14, Training Accuracy: 0.81
Validation Accuracy: 0.48625
pipeline:  [19, 5, 75, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012756826281547546
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78375
Training loss = 0.012904595136642456
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.012057341486215591
step = 2, Training Accuracy: 0.8466666666666667
Training loss = 0.010682832250992457
step = 3, Training Accuracy: 0.8566666666666667
Training loss = 0.010629487683375677
step = 4, Training Accuracy: 0.8766666666666667
Training loss = 0.00967137301961581
step = 5, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.7875
Training loss = 0.008893861671288809
step = 6, Training Accuracy: 0.9133333333333333
Training loss = 0.008629847963651021
step = 7, Training Accuracy: 0.9233333333333333
Training loss = 0.008288296014070511
step = 8, Training Accuracy: 0.9066666666666666
Training loss = 0.008106255382299423
step = 9, Training Accuracy: 0.9066666666666666
Training loss = 0.008287022734681765
step = 10, Training Accuracy: 0.93
Validation Accuracy: 0.78625
Training loss = 0.0068715748935937885
step = 11, Training Accuracy: 0.9333333333333333
Training loss = 0.006831614176432291
step = 12, Training Accuracy: 0.9366666666666666
Training loss = 0.006737846235434214
step = 13, Training Accuracy: 0.9366666666666666
Training loss = 0.006237580602367719
step = 14, Training Accuracy: 0.94
Validation Accuracy: 0.78
pipeline:  [30, 17, 44, 57]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016461458603541056
step = 0, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.645
Training loss = 0.015369815429051718
step = 1, Training Accuracy: 0.82
Training loss = 0.015235384305318197
step = 2, Training Accuracy: 0.82
Training loss = 0.013808545470237733
step = 3, Training Accuracy: 0.8266666666666667
Training loss = 0.013436682373285293
step = 4, Training Accuracy: 0.83
Training loss = 0.011610627323389053
step = 5, Training Accuracy: 0.86
Validation Accuracy: 0.59125
Training loss = 0.010553361823161442
step = 6, Training Accuracy: 0.8733333333333333
Training loss = 0.011100040674209595
step = 7, Training Accuracy: 0.87
Training loss = 0.010617441137631734
step = 8, Training Accuracy: 0.8833333333333333
Training loss = 0.010621202190717062
step = 9, Training Accuracy: 0.87
Training loss = 0.00965179075797399
step = 10, Training Accuracy: 0.9
Validation Accuracy: 0.57375
Training loss = 0.009684275388717651
step = 11, Training Accuracy: 0.89
Training loss = 0.010440420955419541
step = 12, Training Accuracy: 0.8933333333333333
Training loss = 0.008398673981428146
step = 13, Training Accuracy: 0.9166666666666666
Training loss = 0.00945528248945872
step = 14, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.565
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016629122396310172
step = 0, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.7075
Training loss = 0.017318609257539114
step = 1, Training Accuracy: 0.7833333333333333
Training loss = 0.016052586833635966
step = 2, Training Accuracy: 0.79
Training loss = 0.015219883422056834
step = 3, Training Accuracy: 0.7933333333333333
Training loss = 0.014835294783115387
step = 4, Training Accuracy: 0.8133333333333334
Training loss = 0.013915573060512543
step = 5, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.7825
Training loss = 0.012703638523817062
step = 6, Training Accuracy: 0.8366666666666667
Training loss = 0.01525288999080658
step = 7, Training Accuracy: 0.83
Training loss = 0.015019671519597372
step = 8, Training Accuracy: 0.8233333333333334
Training loss = 0.014778279562791189
step = 9, Training Accuracy: 0.84
Training loss = 0.013072182138760885
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.78375
Training loss = 0.01241285170118014
step = 11, Training Accuracy: 0.8533333333333334
Training loss = 0.012794717848300934
step = 12, Training Accuracy: 0.8733333333333333
Training loss = 0.013073637187480926
step = 13, Training Accuracy: 0.8533333333333334
Training loss = 0.011417123923699061
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.79125
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02055005411307017
step = 0, Training Accuracy: 0.7333333333333333
Validation Accuracy: 0.7875
Training loss = 0.0183184943596522
step = 1, Training Accuracy: 0.7466666666666667
Training loss = 0.015969082514444986
step = 2, Training Accuracy: 0.8033333333333333
Training loss = 0.01646396259466807
step = 3, Training Accuracy: 0.79
Training loss = 0.013858600556850433
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.016987745364507038
step = 5, Training Accuracy: 0.79
Validation Accuracy: 0.7775
Training loss = 0.014379019737243653
step = 6, Training Accuracy: 0.7933333333333333
Training loss = 0.01671925882498423
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.014936587909857432
step = 8, Training Accuracy: 0.8133333333333334
Training loss = 0.015011848409970602
step = 9, Training Accuracy: 0.8166666666666667
Training loss = 0.014317754159371058
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.7725
Training loss = 0.01581068495909373
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.013574058910210927
step = 12, Training Accuracy: 0.8166666666666667
Training loss = 0.013110604584217072
step = 13, Training Accuracy: 0.8333333333333334
Training loss = 0.013852877120176951
step = 14, Training Accuracy: 0.83
Validation Accuracy: 0.76875
23 	5     	0.696875	0.123429  	0.48625	0.79125
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.019573957125345865
step = 0, Training Accuracy: 0.7333333333333333
Validation Accuracy: 0.76375
Training loss = 0.017413102636734644
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.015857667326927186
step = 2, Training Accuracy: 0.79
Training loss = 0.017677682042121886
step = 3, Training Accuracy: 0.7733333333333333
Training loss = 0.01689885348081589
step = 4, Training Accuracy: 0.7933333333333333
Training loss = 0.01707349787155787
step = 5, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.77875
Training loss = 0.015759119192759196
step = 6, Training Accuracy: 0.77
Training loss = 0.014933288991451264
step = 7, Training Accuracy: 0.81
Training loss = 0.015544207592805226
step = 8, Training Accuracy: 0.7766666666666666
Training loss = 0.0165922279159228
step = 9, Training Accuracy: 0.8066666666666666
Training loss = 0.015162798961003622
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.785
Training loss = 0.014720998108386993
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.014412045280138652
step = 12, Training Accuracy: 0.8133333333333334
Training loss = 0.01341784675916036
step = 13, Training Accuracy: 0.85
Training loss = 0.015156818926334381
step = 14, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.775
pipeline:  [15, 76, 18, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                               'always_apply': False,
                               'eps': 1e-07,
                               'gamma_limit': (80, 120),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                               'always_apply': False,
                               'p': 0.5,
                               'threshold': (128, 128)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.027724864383538564
step = 0, Training Accuracy: 0.6566666666666666
Validation Accuracy: 0.42875
Training loss = 0.02546384076277415
step = 1, Training Accuracy: 0.6866666666666666
Training loss = 0.022845977246761323
step = 2, Training Accuracy: 0.6733333333333333
Training loss = 0.0211424653728803
step = 3, Training Accuracy: 0.7033333333333334
Training loss = 0.023779863119125368
step = 4, Training Accuracy: 0.6866666666666666
Training loss = 0.021455366611480713
step = 5, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.455
Training loss = 0.020314847926298778
step = 6, Training Accuracy: 0.7466666666666667
Training loss = 0.01987879862387975
step = 7, Training Accuracy: 0.7166666666666667
Training loss = 0.019879814783732096
step = 8, Training Accuracy: 0.7133333333333334
Training loss = 0.019148682951927187
step = 9, Training Accuracy: 0.76
Training loss = 0.02032391935586929
step = 10, Training Accuracy: 0.7166666666666667
Validation Accuracy: 0.42875
Training loss = 0.018349254926045735
step = 11, Training Accuracy: 0.7666666666666667
Training loss = 0.018228449622790018
step = 12, Training Accuracy: 0.78
Training loss = 0.018907035291194915
step = 13, Training Accuracy: 0.7433333333333333
Training loss = 0.01679367115100225
step = 14, Training Accuracy: 0.78
Validation Accuracy: 0.43
24 	2     	0.728125	0.133453  	0.43   	0.79125
pipeline:  [10, 45, 70, 3]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01203346461057663
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.77625
Training loss = 0.012045549352963765
step = 1, Training Accuracy: 0.8566666666666667
Training loss = 0.010821234583854675
step = 2, Training Accuracy: 0.8833333333333333
Training loss = 0.009331510613361994
step = 3, Training Accuracy: 0.9133333333333333
Training loss = 0.009019609640041988
step = 4, Training Accuracy: 0.88
Training loss = 0.009257934192816416
step = 5, Training Accuracy: 0.9
Validation Accuracy: 0.77875
Training loss = 0.009877982238928476
step = 6, Training Accuracy: 0.8966666666666666
Training loss = 0.008188290297985077
step = 7, Training Accuracy: 0.9233333333333333
Training loss = 0.0071134114762147265
step = 8, Training Accuracy: 0.9366666666666666
Training loss = 0.007145232011874517
step = 9, Training Accuracy: 0.9266666666666666
Training loss = 0.007047232190767924
step = 10, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.78
Training loss = 0.006371699497103691
step = 11, Training Accuracy: 0.94
Training loss = 0.005496443659067154
step = 12, Training Accuracy: 0.9533333333333334
Training loss = 0.006278160015741984
step = 13, Training Accuracy: 0.9333333333333333
Training loss = 0.006248580639561017
step = 14, Training Accuracy: 0.94
Validation Accuracy: 0.78375
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.019292530318101245
step = 0, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.79875
Training loss = 0.019336996376514436
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.016643238067626954
step = 2, Training Accuracy: 0.7733333333333333
Training loss = 0.017701965173085532
step = 3, Training Accuracy: 0.8
Training loss = 0.014978668292363485
step = 4, Training Accuracy: 0.83
Training loss = 0.014680282672246298
step = 5, Training Accuracy: 0.82
Validation Accuracy: 0.79875
Training loss = 0.014164925813674926
step = 6, Training Accuracy: 0.8366666666666667
Training loss = 0.015459285279115042
step = 7, Training Accuracy: 0.8333333333333334
Training loss = 0.015669429004192353
step = 8, Training Accuracy: 0.84
Training loss = 0.014746186137199403
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.014679053425788879
step = 10, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.8025
Training loss = 0.01439622461795807
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.013487476607163746
step = 12, Training Accuracy: 0.8366666666666667
Training loss = 0.013264135817686717
step = 13, Training Accuracy: 0.87
Training loss = 0.016318320532639822
step = 14, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.7925
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018831089834372202
step = 0, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.79
Training loss = 0.01731349344054858
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.016442029376824697
step = 2, Training Accuracy: 0.8
Training loss = 0.01795978566010793
step = 3, Training Accuracy: 0.7666666666666667
Training loss = 0.014681541025638581
step = 4, Training Accuracy: 0.8033333333333333
Training loss = 0.017267667055130005
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.7775
Training loss = 0.016043821771939595
step = 6, Training Accuracy: 0.8
Training loss = 0.014468724131584168
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.016526846587657927
step = 8, Training Accuracy: 0.81
Training loss = 0.01631599525610606
step = 9, Training Accuracy: 0.8066666666666666
Training loss = 0.015996094793081284
step = 10, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.77875
Training loss = 0.014965368310610454
step = 11, Training Accuracy: 0.82
Training loss = 0.014529330531756084
step = 12, Training Accuracy: 0.8333333333333334
Training loss = 0.014527631103992461
step = 13, Training Accuracy: 0.8166666666666667
Training loss = 0.014440901378790538
step = 14, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.77625
pipeline:  [16, 25, 70, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013157735168933869
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.7825
Training loss = 0.013129342297712962
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.013188348313172659
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.011732033987840017
step = 3, Training Accuracy: 0.8466666666666667
Training loss = 0.012062940746545792
step = 4, Training Accuracy: 0.8433333333333334
Training loss = 0.012441614617904027
step = 5, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.76875
Training loss = 0.011546106934547424
step = 6, Training Accuracy: 0.87
Training loss = 0.011246921320756276
step = 7, Training Accuracy: 0.88
Training loss = 0.011765145858128866
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.011355814536412557
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.010708986222743988
step = 10, Training Accuracy: 0.88
Validation Accuracy: 0.77375
Training loss = 0.009915212988853455
step = 11, Training Accuracy: 0.8833333333333333
Training loss = 0.009781394700209299
step = 12, Training Accuracy: 0.88
Training loss = 0.009160836338996886
step = 13, Training Accuracy: 0.8933333333333333
Training loss = 0.01071772222717603
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.7775
pipeline:  [56, 25, 11, 3]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011971923460563024
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.77
Training loss = 0.011191587547461192
step = 1, Training Accuracy: 0.8733333333333333
Training loss = 0.011193653543790181
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.011258222162723541
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.010497607986132303
step = 4, Training Accuracy: 0.88
Training loss = 0.00920307253797849
step = 5, Training Accuracy: 0.91
Validation Accuracy: 0.77125
Training loss = 0.009765767057736715
step = 6, Training Accuracy: 0.9033333333333333
Training loss = 0.009214438001314799
step = 7, Training Accuracy: 0.89
Training loss = 0.008526745637257895
step = 8, Training Accuracy: 0.9
Training loss = 0.007624755601088206
step = 9, Training Accuracy: 0.93
Training loss = 0.007447396044929822
step = 10, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.775
Training loss = 0.008407053078214327
step = 11, Training Accuracy: 0.9133333333333333
Training loss = 0.0075707277158896125
step = 12, Training Accuracy: 0.9366666666666666
Training loss = 0.0070384618143240615
step = 13, Training Accuracy: 0.93
Training loss = 0.007351757933696111
step = 14, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.76875
25 	5     	0.781667	0.00843686	0.76875	0.7925 
pipeline:  [11, 45, 42, 43]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021976107160250346
step = 0, Training Accuracy: 0.69
Validation Accuracy: 0.785
Training loss = 0.019995315472284954
step = 1, Training Accuracy: 0.75
Training loss = 0.0165573317805926
step = 2, Training Accuracy: 0.7866666666666666
Training loss = 0.016964245239893594
step = 3, Training Accuracy: 0.7533333333333333
Training loss = 0.017424043168624243
step = 4, Training Accuracy: 0.7666666666666667
Training loss = 0.018767114182313284
step = 5, Training Accuracy: 0.73
Validation Accuracy: 0.78
Training loss = 0.01854277640581131
step = 6, Training Accuracy: 0.74
Training loss = 0.014304403762022654
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.017000935177008313
step = 8, Training Accuracy: 0.7733333333333333
Training loss = 0.01651667629679044
step = 9, Training Accuracy: 0.7733333333333333
Training loss = 0.016329809923966727
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.77875
Training loss = 0.015772271951039633
step = 11, Training Accuracy: 0.7866666666666666
Training loss = 0.015430426398913066
step = 12, Training Accuracy: 0.79
Training loss = 0.014364672601222992
step = 13, Training Accuracy: 0.8066666666666666
Training loss = 0.015031911730766297
step = 14, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.7675
pipeline:  [3, 4, 52, 43]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01918765624364217
step = 0, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.77625
Training loss = 0.017097391386826834
step = 1, Training Accuracy: 0.77
Training loss = 0.020125277638435364
step = 2, Training Accuracy: 0.7433333333333333
Training loss = 0.018813421924908955
step = 3, Training Accuracy: 0.7633333333333333
Training loss = 0.01643694132566452
step = 4, Training Accuracy: 0.79
Training loss = 0.01465779259800911
step = 5, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.77
Training loss = 0.015239431063334146
step = 6, Training Accuracy: 0.8233333333333334
Training loss = 0.015163555443286895
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.01677176763614019
step = 8, Training Accuracy: 0.7866666666666666
Training loss = 0.015053776999314625
step = 9, Training Accuracy: 0.7966666666666666
Training loss = 0.015320483942826589
step = 10, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.785
Training loss = 0.01417673001686732
step = 11, Training Accuracy: 0.82
Training loss = 0.01506289392709732
step = 12, Training Accuracy: 0.8066666666666666
Training loss = 0.014618478119373321
step = 13, Training Accuracy: 0.8366666666666667
Training loss = 0.014748262763023377
step = 14, Training Accuracy: 0.81
Validation Accuracy: 0.79
pipeline:  [60, 55, 83, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016763097246487935
step = 0, Training Accuracy: 0.79
Validation Accuracy: 0.7925
Training loss = 0.01809378981590271
step = 1, Training Accuracy: 0.7566666666666667
Training loss = 0.016463756958643595
step = 2, Training Accuracy: 0.82
Training loss = 0.015562364359696707
step = 3, Training Accuracy: 0.8033333333333333
Training loss = 0.013810882568359375
step = 4, Training Accuracy: 0.8366666666666667
Training loss = 0.014524324089288712
step = 5, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.7775
Training loss = 0.01549438049395879
step = 6, Training Accuracy: 0.81
Training loss = 0.014065538644790649
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.015038138727347055
step = 8, Training Accuracy: 0.8266666666666667
Training loss = 0.014447269837061565
step = 9, Training Accuracy: 0.8166666666666667
Training loss = 0.013422158062458039
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78375
Training loss = 0.013178089012702307
step = 11, Training Accuracy: 0.86
Training loss = 0.013041298389434814
step = 12, Training Accuracy: 0.8466666666666667
Training loss = 0.01298044115304947
step = 13, Training Accuracy: 0.8533333333333334
Training loss = 0.01303863267103831
step = 14, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.77625
pipeline:  [44, 77, 17, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015253355403741202
step = 0, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.78
Training loss = 0.01664213389158249
step = 1, Training Accuracy: 0.8033333333333333
Training loss = 0.014011305421590806
step = 2, Training Accuracy: 0.84
Training loss = 0.014207176864147186
step = 3, Training Accuracy: 0.8266666666666667
Training loss = 0.012889656474192938
step = 4, Training Accuracy: 0.83
Training loss = 0.014906327923138936
step = 5, Training Accuracy: 0.82
Validation Accuracy: 0.7925
Training loss = 0.01557425836722056
step = 6, Training Accuracy: 0.81
Training loss = 0.013626454969247182
step = 7, Training Accuracy: 0.8133333333333334
Training loss = 0.01400111402074496
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.012885676970084508
step = 9, Training Accuracy: 0.83
Training loss = 0.012692442288001378
step = 10, Training Accuracy: 0.83
Validation Accuracy: 0.795
Training loss = 0.014290190438429514
step = 11, Training Accuracy: 0.8366666666666667
Training loss = 0.013214842975139618
step = 12, Training Accuracy: 0.8266666666666667
Training loss = 0.01277781198422114
step = 13, Training Accuracy: 0.85
Training loss = 0.010940968344608943
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.79875
pipeline:  [14, 25, 80, 53]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1.0,
                               'ratio': (0.75, 1.3333333333333333),
                               'scale': (0.9, 1.0),
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012408690253893535
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.79875
Training loss = 0.011998927692572275
step = 1, Training Accuracy: 0.86
Training loss = 0.01214406872789065
step = 2, Training Accuracy: 0.8466666666666667
Training loss = 0.011052442491054535
step = 3, Training Accuracy: 0.8733333333333333
Training loss = 0.01100956231355667
step = 4, Training Accuracy: 0.8866666666666667
Training loss = 0.008897240906953811
step = 5, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.77125
Training loss = 0.009133350153764088
step = 6, Training Accuracy: 0.9233333333333333
Training loss = 0.008825990905364355
step = 7, Training Accuracy: 0.91
Training loss = 0.008248285750548045
step = 8, Training Accuracy: 0.91
Training loss = 0.009663867155710855
step = 9, Training Accuracy: 0.8966666666666666
Training loss = 0.007830129116773605
step = 10, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.76625
Training loss = 0.008621852348248164
step = 11, Training Accuracy: 0.91
Training loss = 0.00824937308828036
step = 12, Training Accuracy: 0.92
Training loss = 0.007259277005990346
step = 13, Training Accuracy: 0.9433333333333334
Training loss = 0.006838956897457441
step = 14, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.755
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016885010997454326
step = 0, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.79
Training loss = 0.01876490483681361
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.018709806104501087
step = 2, Training Accuracy: 0.7466666666666667
Training loss = 0.01736385812362035
step = 3, Training Accuracy: 0.7733333333333333
Training loss = 0.014531502425670624
step = 4, Training Accuracy: 0.8033333333333333
Training loss = 0.016287999351819356
step = 5, Training Accuracy: 0.76
Validation Accuracy: 0.785
Training loss = 0.01618426630894343
step = 6, Training Accuracy: 0.7833333333333333
Training loss = 0.014443443020184835
step = 7, Training Accuracy: 0.79
Training loss = 0.016114865243434907
step = 8, Training Accuracy: 0.79
Training loss = 0.013607482463121413
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.015297723015149435
step = 10, Training Accuracy: 0.84
Validation Accuracy: 0.78875
Training loss = 0.01338103860616684
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.013616552948951722
step = 12, Training Accuracy: 0.81
Training loss = 0.014374966422716776
step = 13, Training Accuracy: 0.8266666666666667
Training loss = 0.012972679783900579
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.7975
26 	6     	0.780833	0.0160673 	0.755  	0.79875
pipeline:  [31, 25, 91, 30]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'threshold': (128, 128)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017552354236443836
step = 0, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.62
Training loss = 0.018508014877637226
step = 1, Training Accuracy: 0.7833333333333333
Training loss = 0.01701691875855128
step = 2, Training Accuracy: 0.7566666666666667
Training loss = 0.014023110071818034
step = 3, Training Accuracy: 0.8133333333333334
Training loss = 0.019223619600137076
step = 4, Training Accuracy: 0.7633333333333333
Training loss = 0.013987082242965698
step = 5, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.52875
Training loss = 0.01532889445622762
step = 6, Training Accuracy: 0.8233333333333334
Training loss = 0.014713042875130972
step = 7, Training Accuracy: 0.8333333333333334
Training loss = 0.013417183955510458
step = 8, Training Accuracy: 0.84
Training loss = 0.015075293282667795
step = 9, Training Accuracy: 0.85
Training loss = 0.014116882185141245
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.525
Training loss = 0.013196284373601277
step = 11, Training Accuracy: 0.84
Training loss = 0.0138799849152565
step = 12, Training Accuracy: 0.8333333333333334
Training loss = 0.011881420314311981
step = 13, Training Accuracy: 0.8633333333333333
Training loss = 0.011420928289492925
step = 14, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.5075
pipeline:  [60, 55, 83, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016294307907422385
step = 0, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.65375
Training loss = 0.01693230470021566
step = 1, Training Accuracy: 0.7966666666666666
Training loss = 0.015236506462097168
step = 2, Training Accuracy: 0.7933333333333333
Training loss = 0.016301968495051066
step = 3, Training Accuracy: 0.7766666666666666
Training loss = 0.015806665619214375
step = 4, Training Accuracy: 0.81
Training loss = 0.014160566627979279
step = 5, Training Accuracy: 0.82
Validation Accuracy: 0.785
Training loss = 0.013398668244481087
step = 6, Training Accuracy: 0.8266666666666667
Training loss = 0.014174754420916239
step = 7, Training Accuracy: 0.8233333333333334
Training loss = 0.013919575115044911
step = 8, Training Accuracy: 0.8366666666666667
Training loss = 0.011744633217652638
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.013049418379863103
step = 10, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.7825
Training loss = 0.014730413258075715
step = 11, Training Accuracy: 0.8466666666666667
Training loss = 0.01182022899389267
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.011969944487015407
step = 13, Training Accuracy: 0.86
Training loss = 0.014640550911426544
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.78125
pipeline:  [3, 4, 52, 43]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017891214738289515
step = 0, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.7975
Training loss = 0.020486827890078226
step = 1, Training Accuracy: 0.7333333333333333
Training loss = 0.01702876349290212
step = 2, Training Accuracy: 0.77
Training loss = 0.01775477796792984
step = 3, Training Accuracy: 0.7833333333333333
Training loss = 0.015869989494482675
step = 4, Training Accuracy: 0.7866666666666666
Training loss = 0.01624403675397237
step = 5, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.7925
Training loss = 0.016069528361161548
step = 6, Training Accuracy: 0.7933333333333333
Training loss = 0.015170965244372685
step = 7, Training Accuracy: 0.8033333333333333
Training loss = 0.015408493280410766
step = 8, Training Accuracy: 0.7733333333333333
Training loss = 0.015103143552939097
step = 9, Training Accuracy: 0.79
Training loss = 0.015225050797065098
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.77375
Training loss = 0.015848540663719178
step = 11, Training Accuracy: 0.7866666666666666
Training loss = 0.015123558640480041
step = 12, Training Accuracy: 0.81
Training loss = 0.015508558799823125
step = 13, Training Accuracy: 0.81
Training loss = 0.015749394595623016
step = 14, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.775
pipeline:  [32, 51, 41, 89]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02149606357018153
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.76375
Training loss = 0.021123153368632
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.016692067434390386
step = 2, Training Accuracy: 0.78
Training loss = 0.013392090946435928
step = 3, Training Accuracy: 0.8433333333333334
Training loss = 0.01349747767051061
step = 4, Training Accuracy: 0.84
Training loss = 0.014092749953269958
step = 5, Training Accuracy: 0.84
Validation Accuracy: 0.77375
Training loss = 0.014036321341991424
step = 6, Training Accuracy: 0.8366666666666667
Training loss = 0.013258577585220336
step = 7, Training Accuracy: 0.86
Training loss = 0.012743766208489736
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.01141906703511874
step = 9, Training Accuracy: 0.8633333333333333
Training loss = 0.01242437998453776
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.78625
Training loss = 0.01209118624528249
step = 11, Training Accuracy: 0.88
Training loss = 0.011027673482894898
step = 12, Training Accuracy: 0.87
Training loss = 0.009371825555960337
step = 13, Training Accuracy: 0.8966666666666666
Training loss = 0.00950744758049647
step = 14, Training Accuracy: 0.91
Validation Accuracy: 0.77125
pipeline:  [44, 77, 17, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01853684475024541
step = 0, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.77125
Training loss = 0.017561097939809162
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.01997932900985082
step = 2, Training Accuracy: 0.7633333333333333
Training loss = 0.01761013388633728
step = 3, Training Accuracy: 0.8033333333333333
Training loss = 0.017524820069471994
step = 4, Training Accuracy: 0.7733333333333333
Training loss = 0.017586786647637687
step = 5, Training Accuracy: 0.76
Validation Accuracy: 0.76875
Training loss = 0.016918233533700307
step = 6, Training Accuracy: 0.7966666666666666
Training loss = 0.016317632993062336
step = 7, Training Accuracy: 0.8
Training loss = 0.01421555201212565
step = 8, Training Accuracy: 0.8233333333333334
Training loss = 0.01543862501780192
step = 9, Training Accuracy: 0.8133333333333334
Training loss = 0.015252476334571838
step = 10, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.76625
Training loss = 0.015081789394219716
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.014773893083135287
step = 12, Training Accuracy: 0.81
Training loss = 0.01490636020898819
step = 13, Training Accuracy: 0.8266666666666667
Training loss = 0.013200654784838358
step = 14, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.765
27 	5     	0.732917	0.101316  	0.5075 	0.7975 
pipeline:  [38, 55, 75, 39]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010824902653694153
step = 0, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.7675
Training loss = 0.009705771307150522
step = 1, Training Accuracy: 0.8866666666666667
Training loss = 0.010154245148102443
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.008907390584548314
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.008886961092551549
step = 4, Training Accuracy: 0.9033333333333333
Training loss = 0.008302756051222483
step = 5, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.78125
Training loss = 0.008068831413984298
step = 6, Training Accuracy: 0.91
Training loss = 0.0075140519688526785
step = 7, Training Accuracy: 0.9133333333333333
Training loss = 0.008489665736754736
step = 8, Training Accuracy: 0.92
Training loss = 0.008368715544541676
step = 9, Training Accuracy: 0.9133333333333333
Training loss = 0.008340714971224466
step = 10, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.7825
Training loss = 0.0070890137056509655
step = 11, Training Accuracy: 0.9366666666666666
Training loss = 0.007315715452035268
step = 12, Training Accuracy: 0.9233333333333333
Training loss = 0.0062934064368406935
step = 13, Training Accuracy: 0.9433333333333334
Training loss = 0.007259982277949651
step = 14, Training Accuracy: 0.9366666666666666
Validation Accuracy: 0.7775
pipeline:  [89, 23, 31, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02003706415494283
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.7675
Training loss = 0.01897010028362274
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.01693879907329877
step = 2, Training Accuracy: 0.8166666666666667
Training loss = 0.01672728920976321
step = 3, Training Accuracy: 0.82
Training loss = 0.015556549926598866
step = 4, Training Accuracy: 0.8133333333333334
Training loss = 0.014609442005554835
step = 5, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.74625
Training loss = 0.015692041714986164
step = 6, Training Accuracy: 0.7933333333333333
Training loss = 0.01630231777826945
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.01587768644094467
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.013976796219746271
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.016662705143292746
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.755
Training loss = 0.015472044150034586
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.012455291152000426
step = 12, Training Accuracy: 0.86
Training loss = 0.014594930360714594
step = 13, Training Accuracy: 0.8166666666666667
Training loss = 0.012416470150152842
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.76375
pipeline:  [31, 74, 3, 5]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022929589748382568
step = 0, Training Accuracy: 0.7
Validation Accuracy: 0.75
Training loss = 0.019962155719598133
step = 1, Training Accuracy: 0.74
Training loss = 0.021422253747781117
step = 2, Training Accuracy: 0.7266666666666667
Training loss = 0.01994741121927897
step = 3, Training Accuracy: 0.71
Training loss = 0.017786042392253877
step = 4, Training Accuracy: 0.7633333333333333
Training loss = 0.016721860369046528
step = 5, Training Accuracy: 0.79
Validation Accuracy: 0.75375
Training loss = 0.01752883106470108
step = 6, Training Accuracy: 0.74
Training loss = 0.01663064827521642
step = 7, Training Accuracy: 0.7566666666666667
Training loss = 0.016490767498811086
step = 8, Training Accuracy: 0.78
Training loss = 0.01526308387517929
step = 9, Training Accuracy: 0.8233333333333334
Training loss = 0.0144214395682017
step = 10, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.765
Training loss = 0.01468528171380361
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.015151396592458089
step = 12, Training Accuracy: 0.7933333333333333
Training loss = 0.013555855254332224
step = 13, Training Accuracy: 0.81
Training loss = 0.014666114350159963
step = 14, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.76625
pipeline:  [60, 61, 38, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01576419860124588
step = 0, Training Accuracy: 0.79
Validation Accuracy: 0.78625
Training loss = 0.017526768445968628
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.016185929874579112
step = 2, Training Accuracy: 0.7933333333333333
Training loss = 0.015412287215391795
step = 3, Training Accuracy: 0.7933333333333333
Training loss = 0.016136755396922428
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.015565768778324128
step = 5, Training Accuracy: 0.8
Validation Accuracy: 0.78375
Training loss = 0.01350551555554072
step = 6, Training Accuracy: 0.8266666666666667
Training loss = 0.013416765481233597
step = 7, Training Accuracy: 0.8266666666666667
Training loss = 0.015081530710061391
step = 8, Training Accuracy: 0.7966666666666666
Training loss = 0.013731703559557596
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.0148304416735967
step = 10, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.76875
Training loss = 0.013184620241324108
step = 11, Training Accuracy: 0.8
Training loss = 0.013461953724424044
step = 12, Training Accuracy: 0.8133333333333334
Training loss = 0.013328994164864221
step = 13, Training Accuracy: 0.84
Training loss = 0.013892950564622879
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.775
28 	4     	0.776875	0.0110574 	0.76375	0.7975 
pipeline:  [47, 55, 30, 88]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.05, 0.05),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'shift_limit': (-0.05, 0.05),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.3, 0.3),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'num_steps': 5,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                                               'alpha': 1,
                                               'alpha_affine': 50,
                                               'always_apply': False,
                                               'approximate': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'sigma': 50,
                                               'value': None}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011998425871133804
step = 0, Training Accuracy: 0.84
Validation Accuracy: 0.65125
Training loss = 0.011117650717496872
step = 1, Training Accuracy: 0.8533333333333334
Training loss = 0.010718224744002025
step = 2, Training Accuracy: 0.8833333333333333
Training loss = 0.009423771326740583
step = 3, Training Accuracy: 0.8766666666666667
Training loss = 0.00987223709623019
step = 4, Training Accuracy: 0.8833333333333333
Training loss = 0.010517023156086604
step = 5, Training Accuracy: 0.9
Validation Accuracy: 0.55375
Training loss = 0.009892583092053731
step = 6, Training Accuracy: 0.8933333333333333
Training loss = 0.01069251428047816
step = 7, Training Accuracy: 0.88
Training loss = 0.009517151216665904
step = 8, Training Accuracy: 0.8933333333333333
Training loss = 0.007565116385618845
step = 9, Training Accuracy: 0.9233333333333333
Training loss = 0.010092471142609914
step = 10, Training Accuracy: 0.88
Validation Accuracy: 0.5325
Training loss = 0.009530017822980881
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.009014586359262467
step = 12, Training Accuracy: 0.91
Training loss = 0.00668682503203551
step = 13, Training Accuracy: 0.9366666666666666
Training loss = 0.007735052580634753
step = 14, Training Accuracy: 0.93
Validation Accuracy: 0.5375
pipeline:  [11, 41, 32, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017453026374181113
step = 0, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.6575
Training loss = 0.013090601861476899
step = 1, Training Accuracy: 0.85
Training loss = 0.012737667014201481
step = 2, Training Accuracy: 0.8533333333333334
Training loss = 0.012488087614377339
step = 3, Training Accuracy: 0.85
Training loss = 0.012650318692127864
step = 4, Training Accuracy: 0.84
Training loss = 0.011282769292593002
step = 5, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.7725
Training loss = 0.011895174235105515
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.010550779749949774
step = 7, Training Accuracy: 0.8633333333333333
Training loss = 0.011876701017220815
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.009540294905503592
step = 9, Training Accuracy: 0.8833333333333333
Training loss = 0.010864115804433822
step = 10, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.77375
Training loss = 0.010592277447382609
step = 11, Training Accuracy: 0.8833333333333333
Training loss = 0.011057622730731964
step = 12, Training Accuracy: 0.8966666666666666
Training loss = 0.010712245504061382
step = 13, Training Accuracy: 0.87
Training loss = 0.009094779392083486
step = 14, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.77875
pipeline:  [60, 55, 83, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014546821067730586
step = 0, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.77625
Training loss = 0.0143904776374499
step = 1, Training Accuracy: 0.83
Training loss = 0.014562953213850658
step = 2, Training Accuracy: 0.8166666666666667
Training loss = 0.015923899114131928
step = 3, Training Accuracy: 0.83
Training loss = 0.012685258388519288
step = 4, Training Accuracy: 0.8333333333333334
Training loss = 0.012846867044766744
step = 5, Training Accuracy: 0.83
Validation Accuracy: 0.775
Training loss = 0.014588408768177033
step = 6, Training Accuracy: 0.8166666666666667
Training loss = 0.013117520610491434
step = 7, Training Accuracy: 0.85
Training loss = 0.011922000547250112
step = 8, Training Accuracy: 0.87
Training loss = 0.012851977894703548
step = 9, Training Accuracy: 0.8466666666666667
Training loss = 0.011725010722875595
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78375
Training loss = 0.012458886057138442
step = 11, Training Accuracy: 0.84
Training loss = 0.011501064846913019
step = 12, Training Accuracy: 0.8666666666666667
Training loss = 0.012323634574810664
step = 13, Training Accuracy: 0.8466666666666667
Training loss = 0.010767205009857813
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.78375
pipeline:  [60, 55, 83, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015884388784567514
step = 0, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.79
Training loss = 0.01466029480099678
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.016782495081424712
step = 2, Training Accuracy: 0.81
Training loss = 0.015406666100025177
step = 3, Training Accuracy: 0.8266666666666667
Training loss = 0.013756070832411448
step = 4, Training Accuracy: 0.84
Training loss = 0.013618448475996654
step = 5, Training Accuracy: 0.83
Validation Accuracy: 0.775
Training loss = 0.014601911505063375
step = 6, Training Accuracy: 0.81
Training loss = 0.014684069554011027
step = 7, Training Accuracy: 0.82
Training loss = 0.01423229585091273
step = 8, Training Accuracy: 0.82
Training loss = 0.015082191030184428
step = 9, Training Accuracy: 0.81
Training loss = 0.012732319235801696
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.77125
Training loss = 0.013357496360937754
step = 11, Training Accuracy: 0.84
Training loss = 0.011514041125774383
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.013402532388766607
step = 13, Training Accuracy: 0.8533333333333334
Training loss = 0.012705018768707912
step = 14, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.7775
pipeline:  [83, 76, 33, 18]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                               'always_apply': False,
                               'eps': 1e-07,
                               'gamma_limit': (80, 120),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                               'always_apply': False,
                               'p': 0.5,
                               'threshold': (128, 128)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02183626711368561
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.77375
Training loss = 0.020868284404277803
step = 1, Training Accuracy: 0.71
Training loss = 0.021876243750254314
step = 2, Training Accuracy: 0.7233333333333334
Training loss = 0.02096732348203659
step = 3, Training Accuracy: 0.72
Training loss = 0.018132147590319315
step = 4, Training Accuracy: 0.7566666666666667
Training loss = 0.019023532172044118
step = 5, Training Accuracy: 0.7433333333333333
Validation Accuracy: 0.74625
Training loss = 0.01583950122197469
step = 6, Training Accuracy: 0.7766666666666666
Training loss = 0.015919820467631022
step = 7, Training Accuracy: 0.7933333333333333
Training loss = 0.016529028564691545
step = 8, Training Accuracy: 0.7666666666666667
Training loss = 0.019875807265440623
step = 9, Training Accuracy: 0.7333333333333333
Training loss = 0.017200300594170888
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.755
Training loss = 0.015059772133827209
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.01728677809238434
step = 12, Training Accuracy: 0.78
Training loss = 0.01615162303050359
step = 13, Training Accuracy: 0.81
Training loss = 0.016085773408412933
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.75625
pipeline:  [56, 25, 86, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01944046457608541
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.78625
Training loss = 0.01955965757369995
step = 1, Training Accuracy: 0.73
Training loss = 0.01833165774742762
step = 2, Training Accuracy: 0.7533333333333333
Training loss = 0.017824420829614003
step = 3, Training Accuracy: 0.7233333333333334
Training loss = 0.018119688232739767
step = 4, Training Accuracy: 0.7566666666666667
Training loss = 0.020210561454296113
step = 5, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.7875
Training loss = 0.01640292117993037
step = 6, Training Accuracy: 0.7466666666666667
Training loss = 0.01672147517402967
step = 7, Training Accuracy: 0.7766666666666666
Training loss = 0.0148343193034331
step = 8, Training Accuracy: 0.8233333333333334
Training loss = 0.016648401618003846
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.016305841207504272
step = 10, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.78125
Training loss = 0.016040285130341846
step = 11, Training Accuracy: 0.8066666666666666
Training loss = 0.016073820292949677
step = 12, Training Accuracy: 0.7933333333333333
Training loss = 0.017991912762324015
step = 13, Training Accuracy: 0.7866666666666666
Training loss = 0.015730799039204914
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.78375
29 	6     	0.73625 	0.0893699 	0.5375 	0.78375
pipeline:  [11, 17, 32, 65]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009783240507046381
step = 0, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79
Training loss = 0.010929309328397115
step = 1, Training Accuracy: 0.87
Training loss = 0.010049341022968292
step = 2, Training Accuracy: 0.8833333333333333
Training loss = 0.00989226629336675
step = 3, Training Accuracy: 0.8933333333333333
Training loss = 0.009366711378097534
step = 4, Training Accuracy: 0.89
Training loss = 0.008543056845664978
step = 5, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.79375
Training loss = 0.008159129768610001
step = 6, Training Accuracy: 0.91
Training loss = 0.008892744556069374
step = 7, Training Accuracy: 0.91
Training loss = 0.009308955570062002
step = 8, Training Accuracy: 0.9
Training loss = 0.00869563564658165
step = 9, Training Accuracy: 0.9066666666666666
Training loss = 0.007763789544502894
step = 10, Training Accuracy: 0.93
Validation Accuracy: 0.80125
Training loss = 0.008284803479909897
step = 11, Training Accuracy: 0.8966666666666666
Training loss = 0.007903319224715233
step = 12, Training Accuracy: 0.8933333333333333
Training loss = 0.009386527687311172
step = 13, Training Accuracy: 0.91
Training loss = 0.007391101817289988
step = 14, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.8075
pipeline:  [90, 84, 85, 32]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                                               'always_apply': False,
                                               'brightness_coeff': 2.5,
                                               'p': 0.5,
                                               'snow_point_lower': 0.1,
                                               'snow_point_upper': 0.3},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                                               'always_apply': False,
                                               'blur_value': 7,
                                               'brightness_coefficient': 0.7,
                                               'drop_color': (200, 200, 200),
                                               'drop_length': 20,
                                               'drop_width': 1,
                                               'p': 0.5,
                                               'rain_type': None,
                                               'slant_lower': -10,
                                               'slant_upper': 10},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                                               'alpha_coef': 0.08,
                                               'always_apply': False,
                                               'fog_coef_lower': 0.3,
                                               'fog_coef_upper': 1,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                                               'always_apply': False,
                                               'angle_lower': 0,
                                               'angle_upper': 1,
                                               'flare_roi': (0, 0, 1, 0.5),
                                               'num_flare_circles_lower': 6,
                                               'num_flare_circles_upper': 10,
                                               'p': 0.5,
                                               'src_color': (255, 255, 255),
                                               'src_radius': 400},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                                               'always_apply': False,
                                               'num_shadows_lower': 1,
                                               'num_shadows_upper': 2,
                                               'p': 0.5,
                                               'shadow_dimension': 5,
                                               'shadow_roi': (0, 0.5, 1, 1)}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020735573569933573
step = 0, Training Accuracy: 0.74
Validation Accuracy: 0.78
Training loss = 0.020364976127942403
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.018998156090577444
step = 2, Training Accuracy: 0.7366666666666667
Training loss = 0.015846153944730757
step = 3, Training Accuracy: 0.8033333333333333
Training loss = 0.01688166836897532
step = 4, Training Accuracy: 0.7833333333333333
Training loss = 0.015678967634836834
step = 5, Training Accuracy: 0.82
Validation Accuracy: 0.78
Training loss = 0.017527084052562713
step = 6, Training Accuracy: 0.79
Training loss = 0.019667702118555706
step = 7, Training Accuracy: 0.7633333333333333
Training loss = 0.018245717684427898
step = 8, Training Accuracy: 0.77
Training loss = 0.015119502743085225
step = 9, Training Accuracy: 0.82
Training loss = 0.01560266375541687
step = 10, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.78625
Training loss = 0.015550262729326884
step = 11, Training Accuracy: 0.8166666666666667
Training loss = 0.017095862130324047
step = 12, Training Accuracy: 0.7933333333333333
Training loss = 0.014689884881178538
step = 13, Training Accuracy: 0.8233333333333334
Training loss = 0.015132436503966649
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78
pipeline:  [78, 55, 90, 40]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.Compose',
                               'additional_targets': {},
                               'bbox_params': None,
                               'keypoint_params': None,
                               'p': 1,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                               'always_apply': False,
                                               'height': 128,
                                               'p': 1.0,
                                               'width': 128},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1,
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03623979687690735
step = 0, Training Accuracy: 0.58
Validation Accuracy: 0.72625
Training loss = 0.03244444052378337
step = 1, Training Accuracy: 0.63
Training loss = 0.028220163186391194
step = 2, Training Accuracy: 0.6533333333333333
Training loss = 0.024655916492144266
step = 3, Training Accuracy: 0.6733333333333333
Training loss = 0.023886857628822325
step = 4, Training Accuracy: 0.6833333333333333
Training loss = 0.02202748159567515
step = 5, Training Accuracy: 0.71
Validation Accuracy: 0.5725
Training loss = 0.021948150396347045
step = 6, Training Accuracy: 0.73
Training loss = 0.021522381603717805
step = 7, Training Accuracy: 0.7166666666666667
Training loss = 0.020622861782709757
step = 8, Training Accuracy: 0.7233333333333334
Training loss = 0.019773715734481813
step = 9, Training Accuracy: 0.7633333333333333
Training loss = 0.020671140054861703
step = 10, Training Accuracy: 0.75
Validation Accuracy: 0.59
Training loss = 0.019414790670077006
step = 11, Training Accuracy: 0.75
Training loss = 0.020559660593668618
step = 12, Training Accuracy: 0.7733333333333333
Training loss = 0.019520323872566223
step = 13, Training Accuracy: 0.7466666666666667
Training loss = 0.019566120704015096
step = 14, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.585
30 	3     	0.753958	0.0761078 	0.585  	0.8075 
pipeline:  [11, 17, 32, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.019491041998068493
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.7675
Training loss = 0.017004590829213462
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.016903052826722463
step = 2, Training Accuracy: 0.7733333333333333
Training loss = 0.013468819856643676
step = 3, Training Accuracy: 0.8366666666666667
Training loss = 0.013961910506089529
step = 4, Training Accuracy: 0.8266666666666667
Training loss = 0.012115177909533183
step = 5, Training Accuracy: 0.88
Validation Accuracy: 0.7775
Training loss = 0.012381838262081146
step = 6, Training Accuracy: 0.85
Training loss = 0.01146264210343361
step = 7, Training Accuracy: 0.8566666666666667
Training loss = 0.010213798483212789
step = 8, Training Accuracy: 0.8766666666666667
Training loss = 0.010704971303542456
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.009754147430260976
step = 10, Training Accuracy: 0.89
Validation Accuracy: 0.78875
Training loss = 0.010035839925209681
step = 11, Training Accuracy: 0.88
Training loss = 0.009860910425583522
step = 12, Training Accuracy: 0.88
Training loss = 0.008988288193941117
step = 13, Training Accuracy: 0.9166666666666666
Training loss = 0.009482646683851877
step = 14, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.78875
pipeline:  [76, 33, 58, 41]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                               'always_apply': False,
                               'p': 0.5,
                               'threshold': (128, 128)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.024230790734291078
step = 0, Training Accuracy: 0.7033333333333334
Validation Accuracy: 0.7725
Training loss = 0.020284167726834616
step = 1, Training Accuracy: 0.73
Training loss = 0.01957712382078171
step = 2, Training Accuracy: 0.74
Training loss = 0.019278355042139688
step = 3, Training Accuracy: 0.74
Training loss = 0.018876752654711407
step = 4, Training Accuracy: 0.73
Training loss = 0.016410488386948904
step = 5, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.7675
Training loss = 0.017842619717121123
step = 6, Training Accuracy: 0.7666666666666667
Training loss = 0.017960302432378134
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.016904969414075214
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.017272299726804097
step = 9, Training Accuracy: 0.7866666666666666
Training loss = 0.01578047588467598
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.77125
Training loss = 0.01679409255584081
step = 11, Training Accuracy: 0.7833333333333333
Training loss = 0.015080222884813945
step = 12, Training Accuracy: 0.8
Training loss = 0.014883089462916057
step = 13, Training Accuracy: 0.8166666666666667
Training loss = 0.01525537610054016
step = 14, Training Accuracy: 0.82
Validation Accuracy: 0.77625
pipeline:  [73, 44, 0, 62]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.029087092677752176
step = 0, Training Accuracy: 0.6
Validation Accuracy: 0.7675
Training loss = 0.026263118187586466
step = 1, Training Accuracy: 0.63
Training loss = 0.02459067742029826
step = 2, Training Accuracy: 0.6466666666666666
Training loss = 0.02579356014728546
step = 3, Training Accuracy: 0.63
Training loss = 0.025863382617632547
step = 4, Training Accuracy: 0.63
Training loss = 0.023456083337465922
step = 5, Training Accuracy: 0.66
Validation Accuracy: 0.7675
Training loss = 0.027266008257865907
step = 6, Training Accuracy: 0.62
Training loss = 0.026322694420814516
step = 7, Training Accuracy: 0.65
Training loss = 0.02279431273539861
step = 8, Training Accuracy: 0.7166666666666667
Training loss = 0.023676649729410807
step = 9, Training Accuracy: 0.6933333333333334
Training loss = 0.023891266783078513
step = 10, Training Accuracy: 0.6566666666666666
Validation Accuracy: 0.76375
Training loss = 0.024428243239720662
step = 11, Training Accuracy: 0.6866666666666666
Training loss = 0.025472660064697266
step = 12, Training Accuracy: 0.6566666666666666
Training loss = 0.025479185581207275
step = 13, Training Accuracy: 0.6266666666666667
Training loss = 0.02196287622054418
step = 14, Training Accuracy: 0.6766666666666666
Validation Accuracy: 0.765
pipeline:  [67, 17, 32, 72]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01998471955458323
step = 0, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.77625
Training loss = 0.01980924407641093
step = 1, Training Accuracy: 0.74
Training loss = 0.019140244523684184
step = 2, Training Accuracy: 0.74
Training loss = 0.01758316864569982
step = 3, Training Accuracy: 0.7733333333333333
Training loss = 0.01820549190044403
step = 4, Training Accuracy: 0.7733333333333333
Training loss = 0.020736199617385865
step = 5, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.7825
Training loss = 0.017846575180689495
step = 6, Training Accuracy: 0.7633333333333333
Training loss = 0.02203016330798467
step = 7, Training Accuracy: 0.7166666666666667
Training loss = 0.021957337856292725
step = 8, Training Accuracy: 0.7066666666666667
Training loss = 0.017810535728931428
step = 9, Training Accuracy: 0.7666666666666667
Training loss = 0.018150587181250254
step = 10, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.7775
Training loss = 0.01939789632956187
step = 11, Training Accuracy: 0.7333333333333333
Training loss = 0.017847778797149657
step = 12, Training Accuracy: 0.7866666666666666
Training loss = 0.01796682079633077
step = 13, Training Accuracy: 0.7633333333333333
Training loss = 0.01865231563647588
step = 14, Training Accuracy: 0.7433333333333333
Validation Accuracy: 0.77875
31 	4     	0.779375	0.00756052	0.765  	0.78875
pipeline:  [14, 16, 30, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011615532139937082
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.6025
Training loss = 0.011537900318702062
step = 1, Training Accuracy: 0.8566666666666667
Training loss = 0.011256568084160487
step = 2, Training Accuracy: 0.88
Training loss = 0.012229166726271312
step = 3, Training Accuracy: 0.8433333333333334
Training loss = 0.011259616911411285
step = 4, Training Accuracy: 0.8666666666666667
Training loss = 0.011043607592582702
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.5525
Training loss = 0.01020437573393186
step = 6, Training Accuracy: 0.8833333333333333
Training loss = 0.010484871218601862
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.010943839649359384
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.009997641444206238
step = 9, Training Accuracy: 0.86
Training loss = 0.009679888139168421
step = 10, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.56125
Training loss = 0.01016665980219841
step = 11, Training Accuracy: 0.8733333333333333
Training loss = 0.009267126520474752
step = 12, Training Accuracy: 0.91
Training loss = 0.009793248573939005
step = 13, Training Accuracy: 0.9
Training loss = 0.009440069993336995
step = 14, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.56375
pipeline:  [67, 86, 32, 72]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020893338322639465
step = 0, Training Accuracy: 0.7166666666666667
Validation Accuracy: 0.7
Training loss = 0.022401795188585916
step = 1, Training Accuracy: 0.6833333333333333
Training loss = 0.02291797419389089
step = 2, Training Accuracy: 0.72
Training loss = 0.0218476069966952
step = 3, Training Accuracy: 0.7266666666666667
Training loss = 0.01840098708868027
step = 4, Training Accuracy: 0.75
Training loss = 0.020112541615962983
step = 5, Training Accuracy: 0.73
Validation Accuracy: 0.7775
Training loss = 0.019596665501594543
step = 6, Training Accuracy: 0.7666666666666667
Training loss = 0.019016405244668324
step = 7, Training Accuracy: 0.7433333333333333
Training loss = 0.019118229448795317
step = 8, Training Accuracy: 0.7466666666666667
Training loss = 0.020074614485104877
step = 9, Training Accuracy: 0.7166666666666667
Training loss = 0.017543901205062867
step = 10, Training Accuracy: 0.75
Validation Accuracy: 0.78375
Training loss = 0.018165670931339264
step = 11, Training Accuracy: 0.75
Training loss = 0.017405129969120026
step = 12, Training Accuracy: 0.77
Training loss = 0.017710901399453482
step = 13, Training Accuracy: 0.7533333333333333
Training loss = 0.01944981237252553
step = 14, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.775
pipeline:  [11, 17, 32, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01569731076558431
step = 0, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.79375
Training loss = 0.014720588127772013
step = 1, Training Accuracy: 0.8366666666666667
Training loss = 0.013537556032339733
step = 2, Training Accuracy: 0.85
Training loss = 0.015232556760311126
step = 3, Training Accuracy: 0.8466666666666667
Training loss = 0.013186378479003906
step = 4, Training Accuracy: 0.84
Training loss = 0.012587914367516835
step = 5, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.77625
Training loss = 0.012824884156386057
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.013129780491193135
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.011010033413767814
step = 8, Training Accuracy: 0.8766666666666667
Training loss = 0.011242194523413976
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.01150415614247322
step = 10, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.78
Training loss = 0.010816987852255504
step = 11, Training Accuracy: 0.8833333333333333
Training loss = 0.010453013827403386
step = 12, Training Accuracy: 0.88
Training loss = 0.010176215420166652
step = 13, Training Accuracy: 0.8933333333333333
Training loss = 0.010425625443458557
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.7825
pipeline:  [14, 50, 83, 12]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015267276167869569
step = 0, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.7725
Training loss = 0.015494356006383896
step = 1, Training Accuracy: 0.7966666666666666
Training loss = 0.01755852222442627
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.015601574182510377
step = 3, Training Accuracy: 0.8066666666666666
Training loss = 0.015121957659721375
step = 4, Training Accuracy: 0.81
Training loss = 0.014032606581846872
step = 5, Training Accuracy: 0.81
Validation Accuracy: 0.77
Training loss = 0.013045411308606465
step = 6, Training Accuracy: 0.85
Training loss = 0.01399720182021459
step = 7, Training Accuracy: 0.8233333333333334
Training loss = 0.013846324036518733
step = 8, Training Accuracy: 0.83
Training loss = 0.012862183650334676
step = 9, Training Accuracy: 0.8333333333333334
Training loss = 0.013245562613010407
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.77375
Training loss = 0.01306907703479131
step = 11, Training Accuracy: 0.82
Training loss = 0.014118543813625971
step = 12, Training Accuracy: 0.8433333333333334
Training loss = 0.012526394128799438
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.012923604895671209
step = 14, Training Accuracy: 0.86
Validation Accuracy: 0.77875
pipeline:  [11, 17, 32, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01369610478480657
step = 0, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.78875
Training loss = 0.012834641908605893
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.012078541268905004
step = 2, Training Accuracy: 0.8666666666666667
Training loss = 0.012477850516637166
step = 3, Training Accuracy: 0.85
Training loss = 0.011285058557987213
step = 4, Training Accuracy: 0.8633333333333333
Training loss = 0.011173035105069479
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.79375
Training loss = 0.012109142045180004
step = 6, Training Accuracy: 0.8566666666666667
Training loss = 0.011195846746365229
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.011111200501521428
step = 8, Training Accuracy: 0.8533333333333334
Training loss = 0.01073118691643079
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.010044113000233968
step = 10, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.795
Training loss = 0.011884968678156535
step = 11, Training Accuracy: 0.87
Training loss = 0.010335135807593664
step = 12, Training Accuracy: 0.8833333333333333
Training loss = 0.011435546229283016
step = 13, Training Accuracy: 0.8933333333333333
Training loss = 0.010517419278621674
step = 14, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.795
pipeline:  [53, 73, 50, 26]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.030803547898928325
step = 0, Training Accuracy: 0.61
Validation Accuracy: 0.755
Training loss = 0.02332950790723165
step = 1, Training Accuracy: 0.7
Training loss = 0.02602496147155762
step = 2, Training Accuracy: 0.61
Training loss = 0.02630639572938283
step = 3, Training Accuracy: 0.6366666666666667
Training loss = 0.021961483061313628
step = 4, Training Accuracy: 0.6533333333333333
Training loss = 0.022643123070398966
step = 5, Training Accuracy: 0.6633333333333333
Validation Accuracy: 0.7625
Training loss = 0.022107597390810647
step = 6, Training Accuracy: 0.6966666666666667
Training loss = 0.021842619776725768
step = 7, Training Accuracy: 0.71
Training loss = 0.021259493331114453
step = 8, Training Accuracy: 0.69
Training loss = 0.020920385320981342
step = 9, Training Accuracy: 0.73
Training loss = 0.0232072110970815
step = 10, Training Accuracy: 0.6533333333333333
Validation Accuracy: 0.75625
Training loss = 0.021493802666664123
step = 11, Training Accuracy: 0.69
Training loss = 0.021741215686003366
step = 12, Training Accuracy: 0.6866666666666666
Training loss = 0.02098324954509735
step = 13, Training Accuracy: 0.72
Training loss = 0.020914459228515626
step = 14, Training Accuracy: 0.7233333333333334
Validation Accuracy: 0.76875
32 	6     	0.743958	0.0809881 	0.56375	0.795  
pipeline:  [70, 24, 91, 40]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'threshold': (128, 128)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01746235618988673
step = 0, Training Accuracy: 0.8
Validation Accuracy: 0.77625
Training loss = 0.01777195284763972
step = 1, Training Accuracy: 0.79
Training loss = 0.017593189179897308
step = 2, Training Accuracy: 0.8
Training loss = 0.012342606882254283
step = 3, Training Accuracy: 0.8533333333333334
Training loss = 0.015586986392736434
step = 4, Training Accuracy: 0.8066666666666666
Training loss = 0.014992287456989288
step = 5, Training Accuracy: 0.8
Validation Accuracy: 0.77375
Training loss = 0.014228752752145132
step = 6, Training Accuracy: 0.82
Training loss = 0.014989024897416433
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.016506395836671194
step = 8, Training Accuracy: 0.8133333333333334
Training loss = 0.014265121320883433
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.015600103934605916
step = 10, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.77125
Training loss = 0.015426669816176096
step = 11, Training Accuracy: 0.8033333333333333
Training loss = 0.015073616405328115
step = 12, Training Accuracy: 0.8
Training loss = 0.012946151892344156
step = 13, Training Accuracy: 0.85
Training loss = 0.01498885045448939
step = 14, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.7775
pipeline:  [18, 60, 50, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                               'always_apply': False,
                               'eps': 1e-07,
                               'gamma_limit': (80, 120),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020416773657004037
step = 0, Training Accuracy: 0.76
Validation Accuracy: 0.7875
Training loss = 0.01879198541243871
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.015179983774820964
step = 2, Training Accuracy: 0.8233333333333334
Training loss = 0.014216458201408386
step = 3, Training Accuracy: 0.8133333333333334
Training loss = 0.015919628540674847
step = 4, Training Accuracy: 0.8033333333333333
Training loss = 0.015326557854811351
step = 5, Training Accuracy: 0.82
Validation Accuracy: 0.79625
Training loss = 0.01763107031583786
step = 6, Training Accuracy: 0.7866666666666666
Training loss = 0.01684446503718694
step = 7, Training Accuracy: 0.7966666666666666
Training loss = 0.01697298377752304
step = 8, Training Accuracy: 0.7833333333333333
Training loss = 0.015301702171564102
step = 9, Training Accuracy: 0.82
Training loss = 0.015888659556706746
step = 10, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.79375
Training loss = 0.015020341128110886
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.013936996559302013
step = 12, Training Accuracy: 0.83
Training loss = 0.015336322685082754
step = 13, Training Accuracy: 0.81
Training loss = 0.015492599805196126
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.795
pipeline:  [11, 17, 61, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011270685493946076
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.78875
Training loss = 0.010226552784442901
step = 1, Training Accuracy: 0.8866666666666667
Training loss = 0.010027397821346918
step = 2, Training Accuracy: 0.9
Training loss = 0.009969076067209244
step = 3, Training Accuracy: 0.8866666666666667
Training loss = 0.009928837964932123
step = 4, Training Accuracy: 0.8933333333333333
Training loss = 0.009209589113791784
step = 5, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.7925
Training loss = 0.00889607106645902
step = 6, Training Accuracy: 0.89
Training loss = 0.009047816097736359
step = 7, Training Accuracy: 0.9066666666666666
Training loss = 0.009188758631547292
step = 8, Training Accuracy: 0.9133333333333333
Training loss = 0.008228701278567315
step = 9, Training Accuracy: 0.91
Training loss = 0.008816899061203002
step = 10, Training Accuracy: 0.91
Validation Accuracy: 0.79125
Training loss = 0.008968377063671748
step = 11, Training Accuracy: 0.9033333333333333
Training loss = 0.008115872889757157
step = 12, Training Accuracy: 0.9166666666666666
Training loss = 0.007767254362503687
step = 13, Training Accuracy: 0.92
Training loss = 0.007724383970101675
step = 14, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.785
pipeline:  [14, 71, 83, 68]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020854533910751344
step = 0, Training Accuracy: 0.7266666666666667
Validation Accuracy: 0.7825
Training loss = 0.020504465798536937
step = 1, Training Accuracy: 0.7266666666666667
Training loss = 0.017837950984636943
step = 2, Training Accuracy: 0.7733333333333333
Training loss = 0.019256947040557863
step = 3, Training Accuracy: 0.7566666666666667
Training loss = 0.018973636428515118
step = 4, Training Accuracy: 0.7466666666666667
Training loss = 0.017805793384710947
step = 5, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.78375
Training loss = 0.017768912315368653
step = 6, Training Accuracy: 0.7733333333333333
Training loss = 0.017801842192808788
step = 7, Training Accuracy: 0.7833333333333333
Training loss = 0.01936795115470886
step = 8, Training Accuracy: 0.75
Training loss = 0.019295610884825388
step = 9, Training Accuracy: 0.7566666666666667
Training loss = 0.0177436101436615
step = 10, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.78
Training loss = 0.016762833992640176
step = 11, Training Accuracy: 0.8033333333333333
Training loss = 0.016989026168982187
step = 12, Training Accuracy: 0.7933333333333333
Training loss = 0.016869754294554392
step = 13, Training Accuracy: 0.7866666666666666
Training loss = 0.017109688421090445
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.7825
pipeline:  [60, 17, 83, 12]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012366974676648776
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.76875
Training loss = 0.013527742822964987
step = 1, Training Accuracy: 0.8533333333333334
Training loss = 0.012092321813106537
step = 2, Training Accuracy: 0.87
Training loss = 0.012616310516993206
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.01346140831708908
step = 4, Training Accuracy: 0.8533333333333334
Training loss = 0.013504638175169626
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.7775
Training loss = 0.013208663364251454
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.013005636483430862
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.010879399726788202
step = 8, Training Accuracy: 0.88
Training loss = 0.01245466281970342
step = 9, Training Accuracy: 0.87
Training loss = 0.01257543255885442
step = 10, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.775
Training loss = 0.01150578906138738
step = 11, Training Accuracy: 0.8866666666666667
Training loss = 0.010281736925244332
step = 12, Training Accuracy: 0.8766666666666667
Training loss = 0.009986380835374196
step = 13, Training Accuracy: 0.8833333333333333
Training loss = 0.010436409215132395
step = 14, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.7725
pipeline:  [75, 36, 28, 84]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                                               'always_apply': False,
                                               'brightness_coeff': 2.5,
                                               'p': 0.5,
                                               'snow_point_lower': 0.1,
                                               'snow_point_upper': 0.3},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                                               'always_apply': False,
                                               'blur_value': 7,
                                               'brightness_coefficient': 0.7,
                                               'drop_color': (200, 200, 200),
                                               'drop_length': 20,
                                               'drop_width': 1,
                                               'p': 0.5,
                                               'rain_type': None,
                                               'slant_lower': -10,
                                               'slant_upper': 10},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                                               'alpha_coef': 0.08,
                                               'always_apply': False,
                                               'fog_coef_lower': 0.3,
                                               'fog_coef_upper': 1,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                                               'always_apply': False,
                                               'angle_lower': 0,
                                               'angle_upper': 1,
                                               'flare_roi': (0, 0, 1, 0.5),
                                               'num_flare_circles_lower': 6,
                                               'num_flare_circles_upper': 10,
                                               'p': 0.5,
                                               'src_color': (255, 255, 255),
                                               'src_radius': 400},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                                               'always_apply': False,
                                               'num_shadows_lower': 1,
                                               'num_shadows_upper': 2,
                                               'p': 0.5,
                                               'shadow_dimension': 5,
                                               'shadow_roi': (0, 0.5, 1, 1)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017209330201148988
step = 0, Training Accuracy: 0.79
Validation Accuracy: 0.78
Training loss = 0.01620596577723821
step = 1, Training Accuracy: 0.7933333333333333
Training loss = 0.017312686940034232
step = 2, Training Accuracy: 0.7766666666666666
Training loss = 0.012687300244967142
step = 3, Training Accuracy: 0.8333333333333334
Training loss = 0.01390555277466774
step = 4, Training Accuracy: 0.8266666666666667
Training loss = 0.011960189541180928
step = 5, Training Accuracy: 0.85
Validation Accuracy: 0.78
Training loss = 0.012890292306741078
step = 6, Training Accuracy: 0.84
Training loss = 0.015507869174083073
step = 7, Training Accuracy: 0.8233333333333334
Training loss = 0.012775660355885824
step = 8, Training Accuracy: 0.83
Training loss = 0.014154907564322155
step = 9, Training Accuracy: 0.8333333333333334
Training loss = 0.012219474017620087
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.77875
Training loss = 0.015142902433872223
step = 11, Training Accuracy: 0.7866666666666666
Training loss = 0.012524309754371642
step = 12, Training Accuracy: 0.83
Training loss = 0.015054392317930857
step = 13, Training Accuracy: 0.82
Training loss = 0.013194104731082916
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.78375
33 	6     	0.782708	0.00693784	0.7725 	0.795  
pipeline:  [62, 36, 73, 30]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015298058291276296
step = 0, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.66375
Training loss = 0.013835929334163666
step = 1, Training Accuracy: 0.8033333333333333
Training loss = 0.014808392226696014
step = 2, Training Accuracy: 0.84
Training loss = 0.012793731540441514
step = 3, Training Accuracy: 0.8366666666666667
Training loss = 0.015161282817522685
step = 4, Training Accuracy: 0.81
Training loss = 0.013656580746173859
step = 5, Training Accuracy: 0.83
Validation Accuracy: 0.52875
Training loss = 0.01623001923163732
step = 6, Training Accuracy: 0.81
Training loss = 0.013519518772761027
step = 7, Training Accuracy: 0.8333333333333334
Training loss = 0.014497397343317668
step = 8, Training Accuracy: 0.8266666666666667
Training loss = 0.014524956544240316
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.013375859657923381
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.52875
Training loss = 0.013068167269229889
step = 11, Training Accuracy: 0.8566666666666667
Training loss = 0.01359642336765925
step = 12, Training Accuracy: 0.8366666666666667
Training loss = 0.014193816383679708
step = 13, Training Accuracy: 0.8333333333333334
Training loss = 0.013619284083445867
step = 14, Training Accuracy: 0.83
Validation Accuracy: 0.55
pipeline:  [18, 60, 50, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                               'always_apply': False,
                               'eps': 1e-07,
                               'gamma_limit': (80, 120),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017009692788124083
step = 0, Training Accuracy: 0.78
Validation Accuracy: 0.7175
Training loss = 0.015513788064320883
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.014188036223252614
step = 2, Training Accuracy: 0.8233333333333334
Training loss = 0.015542763074239095
step = 3, Training Accuracy: 0.8033333333333333
Training loss = 0.013807929505904516
step = 4, Training Accuracy: 0.84
Training loss = 0.016305367052555083
step = 5, Training Accuracy: 0.78
Validation Accuracy: 0.785
Training loss = 0.015332682927449545
step = 6, Training Accuracy: 0.8
Training loss = 0.014174262384573618
step = 7, Training Accuracy: 0.8033333333333333
Training loss = 0.016351960996786753
step = 8, Training Accuracy: 0.8033333333333333
Training loss = 0.01426095058520635
step = 9, Training Accuracy: 0.8233333333333334
Training loss = 0.015408341884613036
step = 10, Training Accuracy: 0.83
Validation Accuracy: 0.78875
Training loss = 0.012236048430204392
step = 11, Training Accuracy: 0.8366666666666667
Training loss = 0.01377450446287791
step = 12, Training Accuracy: 0.8333333333333334
Training loss = 0.014317982345819474
step = 13, Training Accuracy: 0.84
Training loss = 0.013353733619054158
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.785
pipeline:  [38, 29, 85, 11]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01621871292591095
step = 0, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.7925
Training loss = 0.01556362509727478
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.01585132579008738
step = 2, Training Accuracy: 0.7933333333333333
Training loss = 0.016416751543680826
step = 3, Training Accuracy: 0.7933333333333333
Training loss = 0.014070968727270762
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.015312712788581848
step = 5, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.78
Training loss = 0.016235706806182863
step = 6, Training Accuracy: 0.8066666666666666
Training loss = 0.014674574335416158
step = 7, Training Accuracy: 0.8133333333333334
Training loss = 0.014392834603786469
step = 8, Training Accuracy: 0.82
Training loss = 0.014323295354843139
step = 9, Training Accuracy: 0.83
Training loss = 0.01337608312567075
step = 10, Training Accuracy: 0.84
Validation Accuracy: 0.78375
Training loss = 0.012058754314978918
step = 11, Training Accuracy: 0.85
Training loss = 0.015837408204873404
step = 12, Training Accuracy: 0.8066666666666666
Training loss = 0.013864224255084991
step = 13, Training Accuracy: 0.8133333333333334
Training loss = 0.012670710384845733
step = 14, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.78625
pipeline:  [58, 43, 50, 13]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013392746696869533
step = 0, Training Accuracy: 0.84
Validation Accuracy: 0.79625
Training loss = 0.012523614714543024
step = 1, Training Accuracy: 0.84
Training loss = 0.012772732079029084
step = 2, Training Accuracy: 0.8266666666666667
Training loss = 0.012374054590861003
step = 3, Training Accuracy: 0.85
Training loss = 0.010682079295317332
step = 4, Training Accuracy: 0.8766666666666667
Training loss = 0.011572337299585343
step = 5, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.78375
Training loss = 0.011376867791016897
step = 6, Training Accuracy: 0.8866666666666667
Training loss = 0.012695812036593755
step = 7, Training Accuracy: 0.8466666666666667
Training loss = 0.012902262558539709
step = 8, Training Accuracy: 0.8333333333333334
Training loss = 0.011184719155232111
step = 9, Training Accuracy: 0.8533333333333334
Training loss = 0.010544069508711496
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78125
Training loss = 0.01116612861553828
step = 11, Training Accuracy: 0.8466666666666667
Training loss = 0.009558034837245941
step = 12, Training Accuracy: 0.89
Training loss = 0.009859684258699417
step = 13, Training Accuracy: 0.88
Training loss = 0.010253542388478915
step = 14, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.78875
34 	4     	0.746042	0.0876945 	0.55   	0.78875
pipeline:  [68, 56, 69, 11]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021297251383463542
step = 0, Training Accuracy: 0.7233333333333334
Validation Accuracy: 0.78875
Training loss = 0.024488208492596943
step = 1, Training Accuracy: 0.7166666666666667
Training loss = 0.0202802441517512
step = 2, Training Accuracy: 0.7466666666666667
Training loss = 0.021984128455320995
step = 3, Training Accuracy: 0.75
Training loss = 0.022036050260066987
step = 4, Training Accuracy: 0.6933333333333334
Training loss = 0.020319811205069226
step = 5, Training Accuracy: 0.7433333333333333
Validation Accuracy: 0.77625
Training loss = 0.021056384940942127
step = 6, Training Accuracy: 0.73
Training loss = 0.023601035674413046
step = 7, Training Accuracy: 0.6966666666666667
Training loss = 0.020590927402178445
step = 8, Training Accuracy: 0.7433333333333333
Training loss = 0.020514656503995258
step = 9, Training Accuracy: 0.77
Training loss = 0.01984283685684204
step = 10, Training Accuracy: 0.73
Validation Accuracy: 0.7725
Training loss = 0.02142271786928177
step = 11, Training Accuracy: 0.7466666666666667
Training loss = 0.01984534561634064
step = 12, Training Accuracy: 0.76
Training loss = 0.02260580728451411
step = 13, Training Accuracy: 0.7133333333333334
Training loss = 0.018708050946394602
step = 14, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.77125
35 	1     	0.78375 	0.00572822	0.77125	0.78875
pipeline:  [78, 83, 74, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.Compose',
                               'additional_targets': {},
                               'bbox_params': None,
                               'keypoint_params': None,
                               'p': 1,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                               'always_apply': False,
                                               'height': 128,
                                               'p': 1.0,
                                               'width': 128},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1,
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0343979533513387
step = 0, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.7075
Training loss = 0.029405898253122967
step = 1, Training Accuracy: 0.5766666666666667
Training loss = 0.030443318287531534
step = 2, Training Accuracy: 0.6166666666666667
Training loss = 0.029221495191256205
step = 3, Training Accuracy: 0.6666666666666666
Training loss = 0.029404918948809308
step = 4, Training Accuracy: 0.6133333333333333
Training loss = 0.02627077360947927
step = 5, Training Accuracy: 0.6666666666666666
Validation Accuracy: 0.62125
Training loss = 0.02814279536406199
step = 6, Training Accuracy: 0.6233333333333333
Training loss = 0.02738903760910034
step = 7, Training Accuracy: 0.6366666666666667
Training loss = 0.02712546130021413
step = 8, Training Accuracy: 0.65
Training loss = 0.02533027946949005
step = 9, Training Accuracy: 0.6533333333333333
Training loss = 0.024911456406116486
step = 10, Training Accuracy: 0.64
Validation Accuracy: 0.63375
Training loss = 0.02568970441818237
step = 11, Training Accuracy: 0.6733333333333333
Training loss = 0.024419673085212708
step = 12, Training Accuracy: 0.65
Training loss = 0.024081098238627117
step = 13, Training Accuracy: 0.7066666666666667
Training loss = 0.02515510320663452
step = 14, Training Accuracy: 0.6666666666666666
Validation Accuracy: 0.63375
pipeline:  [17, 57, 12, 83]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010966805815696716
step = 0, Training Accuracy: 0.86
Validation Accuracy: 0.76
Training loss = 0.010088438714543978
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.010730926940838496
step = 2, Training Accuracy: 0.8866666666666667
Training loss = 0.011382383207480112
step = 3, Training Accuracy: 0.86
Training loss = 0.010661498655875524
step = 4, Training Accuracy: 0.8633333333333333
Training loss = 0.010219013939301172
step = 5, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79625
Training loss = 0.010306871632734934
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.009339573929707209
step = 7, Training Accuracy: 0.8966666666666666
Training loss = 0.009003749191761017
step = 8, Training Accuracy: 0.9
Training loss = 0.008324659218390783
step = 9, Training Accuracy: 0.9233333333333333
Training loss = 0.008118077466885249
step = 10, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.795
Training loss = 0.008747092485427856
step = 11, Training Accuracy: 0.9
Training loss = 0.00863787258664767
step = 12, Training Accuracy: 0.9
Training loss = 0.008122002383073172
step = 13, Training Accuracy: 0.9133333333333333
Training loss = 0.008214237093925476
step = 14, Training Accuracy: 0.9
Validation Accuracy: 0.7975
pipeline:  [58, 43, 50, 13]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013316266338030498
step = 0, Training Accuracy: 0.83
Validation Accuracy: 0.795
Training loss = 0.012592096974452337
step = 1, Training Accuracy: 0.85
Training loss = 0.013284654915332794
step = 2, Training Accuracy: 0.82
Training loss = 0.013184571266174316
step = 3, Training Accuracy: 0.8333333333333334
Training loss = 0.015219805538654327
step = 4, Training Accuracy: 0.8133333333333334
Training loss = 0.012147746781508128
step = 5, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.79625
Training loss = 0.013710010250409445
step = 6, Training Accuracy: 0.8333333333333334
Training loss = 0.0138318233191967
step = 7, Training Accuracy: 0.8466666666666667
Training loss = 0.01232088436683019
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.013239719072977702
step = 9, Training Accuracy: 0.8533333333333334
Training loss = 0.011069480528434117
step = 10, Training Accuracy: 0.85
Validation Accuracy: 0.7875
Training loss = 0.01162802055478096
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.010384739885727565
step = 12, Training Accuracy: 0.8866666666666667
Training loss = 0.013526528577009837
step = 13, Training Accuracy: 0.81
Training loss = 0.011980819801489512
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.79125
pipeline:  [69, 5, 41, 11]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009149980793396632
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.795
Training loss = 0.008048428346713384
step = 1, Training Accuracy: 0.91
Training loss = 0.009530819455782573
step = 2, Training Accuracy: 0.8966666666666666
Training loss = 0.007989363223314285
step = 3, Training Accuracy: 0.9133333333333333
Training loss = 0.008093562920888265
step = 4, Training Accuracy: 0.9333333333333333
Training loss = 0.008327862073977788
step = 5, Training Accuracy: 0.9
Validation Accuracy: 0.77875
Training loss = 0.0075514348844687145
step = 6, Training Accuracy: 0.9233333333333333
Training loss = 0.008081750522057216
step = 7, Training Accuracy: 0.9366666666666666
Training loss = 0.007534622351328532
step = 8, Training Accuracy: 0.9233333333333333
Training loss = 0.006777033309141795
step = 9, Training Accuracy: 0.9333333333333333
Training loss = 0.007161659449338913
step = 10, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.78
Training loss = 0.006688700517018636
step = 11, Training Accuracy: 0.9366666666666666
Training loss = 0.006772958437601726
step = 12, Training Accuracy: 0.93
Training loss = 0.0062918383379777275
step = 13, Training Accuracy: 0.9466666666666667
Training loss = 0.007172739828626315
step = 14, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.7775
36 	4     	0.762083	0.0577065 	0.63375	0.7975 
pipeline:  [20, 29, 28, 16]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020138532718022663
step = 0, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.77625
Training loss = 0.01893238683541616
step = 1, Training Accuracy: 0.78
Training loss = 0.019859929382801057
step = 2, Training Accuracy: 0.74
Training loss = 0.01673531174659729
step = 3, Training Accuracy: 0.7766666666666666
Training loss = 0.018598314225673675
step = 4, Training Accuracy: 0.7633333333333333
Training loss = 0.017842569450537363
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.76
Training loss = 0.015604263643423716
step = 6, Training Accuracy: 0.82
Training loss = 0.019077628453572592
step = 7, Training Accuracy: 0.78
Training loss = 0.0170753941933314
step = 8, Training Accuracy: 0.7866666666666666
Training loss = 0.017337520619233448
step = 9, Training Accuracy: 0.76
Training loss = 0.016865284244219462
step = 10, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.76125
Training loss = 0.018257992664972942
step = 11, Training Accuracy: 0.7566666666666667
Training loss = 0.016462447742621105
step = 12, Training Accuracy: 0.7833333333333333
Training loss = 0.018086564838886262
step = 13, Training Accuracy: 0.7966666666666666
Training loss = 0.01838776489098867
step = 14, Training Accuracy: 0.75
Validation Accuracy: 0.75875
pipeline:  [58, 43, 50, 13]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011844578981399536
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.77125
Training loss = 0.013913253843784333
step = 1, Training Accuracy: 0.8466666666666667
Training loss = 0.01312213251988093
step = 2, Training Accuracy: 0.8333333333333334
Training loss = 0.011995454281568528
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.014346092045307159
step = 4, Training Accuracy: 0.8533333333333334
Training loss = 0.01239938055475553
step = 5, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.78
Training loss = 0.01341295470794042
step = 6, Training Accuracy: 0.8433333333333334
Training loss = 0.012626465260982513
step = 7, Training Accuracy: 0.8566666666666667
Training loss = 0.010597136815388998
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.01087705336511135
step = 9, Training Accuracy: 0.8566666666666667
Training loss = 0.011254337628682455
step = 10, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.77625
Training loss = 0.011218707760175068
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.010738572453459104
step = 12, Training Accuracy: 0.88
Training loss = 0.010882583310206731
step = 13, Training Accuracy: 0.8866666666666667
Training loss = 0.009944010227918625
step = 14, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.78125
pipeline:  [10, 43, 62, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013690761228402456
step = 0, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.78125
Training loss = 0.012757648477951685
step = 1, Training Accuracy: 0.8333333333333334
Training loss = 0.013993015935023626
step = 2, Training Accuracy: 0.8366666666666667
Training loss = 0.012524667382240295
step = 3, Training Accuracy: 0.8433333333333334
Training loss = 0.013158987512191137
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.012338014642397562
step = 5, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.7775
Training loss = 0.015065265546242396
step = 6, Training Accuracy: 0.83
Training loss = 0.01203464095791181
step = 7, Training Accuracy: 0.83
Training loss = 0.014756658673286438
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.012374118864536286
step = 9, Training Accuracy: 0.85
Training loss = 0.012172167003154755
step = 10, Training Accuracy: 0.83
Validation Accuracy: 0.775
Training loss = 0.010996421972910564
step = 11, Training Accuracy: 0.85
Training loss = 0.01133884976307551
step = 12, Training Accuracy: 0.86
Training loss = 0.011766085078318915
step = 13, Training Accuracy: 0.8566666666666667
Training loss = 0.01239468902349472
step = 14, Training Accuracy: 0.88
Validation Accuracy: 0.775
pipeline:  [17, 57, 12, 83]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008803964803616206
step = 0, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.77875
Training loss = 0.009415098826090495
step = 1, Training Accuracy: 0.91
Training loss = 0.008483248700698217
step = 2, Training Accuracy: 0.92
Training loss = 0.00867099513610204
step = 3, Training Accuracy: 0.9
Training loss = 0.008583560585975647
step = 4, Training Accuracy: 0.9
Training loss = 0.008281574696302413
step = 5, Training Accuracy: 0.91
Validation Accuracy: 0.785
Training loss = 0.009324446022510528
step = 6, Training Accuracy: 0.8933333333333333
Training loss = 0.008012761001785596
step = 7, Training Accuracy: 0.9133333333333333
Training loss = 0.007706060111522675
step = 8, Training Accuracy: 0.94
Training loss = 0.00859570195277532
step = 9, Training Accuracy: 0.9166666666666666
Training loss = 0.00943101684252421
step = 10, Training Accuracy: 0.89
Validation Accuracy: 0.78375
Training loss = 0.007588488633433978
step = 11, Training Accuracy: 0.9366666666666666
Training loss = 0.007785337393482526
step = 12, Training Accuracy: 0.93
Training loss = 0.008418831328550975
step = 13, Training Accuracy: 0.9066666666666666
Training loss = 0.007127891232570013
step = 14, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.78125
37 	4     	0.780833	0.012304  	0.75875	0.7975 
pipeline:  [17, 57, 12, 83]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008878384629885355
step = 0, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.7825
Training loss = 0.008661081443230311
step = 1, Training Accuracy: 0.8833333333333333
Training loss = 0.007620030790567398
step = 2, Training Accuracy: 0.91
Training loss = 0.0085166963438193
step = 3, Training Accuracy: 0.8933333333333333
Training loss = 0.008480340912938119
step = 4, Training Accuracy: 0.9033333333333333
Training loss = 0.007543275207281113
step = 5, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.77375
Training loss = 0.007889411946137747
step = 6, Training Accuracy: 0.9033333333333333
Training loss = 0.007760465517640114
step = 7, Training Accuracy: 0.9266666666666666
Training loss = 0.007736414397756259
step = 8, Training Accuracy: 0.9233333333333333
Training loss = 0.007147495895624161
step = 9, Training Accuracy: 0.91
Training loss = 0.007261328250169754
step = 10, Training Accuracy: 0.91
Validation Accuracy: 0.77375
Training loss = 0.008564840704202652
step = 11, Training Accuracy: 0.9066666666666666
Training loss = 0.00858082135518392
step = 12, Training Accuracy: 0.9166666666666666
Training loss = 0.007412853638331095
step = 13, Training Accuracy: 0.93
Training loss = 0.007771983295679092
step = 14, Training Accuracy: 0.91
Validation Accuracy: 0.7775
pipeline:  [10, 43, 62, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012325164675712586
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78
Training loss = 0.01253741761048635
step = 1, Training Accuracy: 0.8333333333333334
Training loss = 0.013678076316912969
step = 2, Training Accuracy: 0.85
Training loss = 0.01226315180460612
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.012183541109164557
step = 4, Training Accuracy: 0.8633333333333333
Training loss = 0.013516944646835328
step = 5, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.7775
Training loss = 0.010846642206112544
step = 6, Training Accuracy: 0.88
Training loss = 0.012505572040875752
step = 7, Training Accuracy: 0.8533333333333334
Training loss = 0.01204317440589269
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.01308565949400266
step = 9, Training Accuracy: 0.82
Training loss = 0.014537481566270192
step = 10, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.7775
Training loss = 0.010117495606342952
step = 11, Training Accuracy: 0.8533333333333334
Training loss = 0.010968382507562636
step = 12, Training Accuracy: 0.8933333333333333
Training loss = 0.011040485203266144
step = 13, Training Accuracy: 0.86
Training loss = 0.011530447502930958
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.78375
pipeline:  [17, 88, 9, 59]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.05, 0.05),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'shift_limit': (-0.05, 0.05),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'distort_limit': (-0.3, 0.3),
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'num_steps': 5,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                                               'alpha': 1,
                                               'alpha_affine': 50,
                                               'always_apply': False,
                                               'approximate': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'sigma': 50,
                                               'value': None}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010481417228778203
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.78125
Training loss = 0.010813564459482828
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.01080376108487447
step = 2, Training Accuracy: 0.8533333333333334
Training loss = 0.00956420789162318
step = 3, Training Accuracy: 0.8866666666666667
Training loss = 0.010105235079924266
step = 4, Training Accuracy: 0.8766666666666667
Training loss = 0.009568789278467497
step = 5, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.77125
Training loss = 0.009397590706745784
step = 6, Training Accuracy: 0.88
Training loss = 0.008242785384257635
step = 7, Training Accuracy: 0.88
Training loss = 0.009944270054499308
step = 8, Training Accuracy: 0.8933333333333333
Training loss = 0.008527791698773702
step = 9, Training Accuracy: 0.9
Training loss = 0.008852083683013916
step = 10, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.7725
Training loss = 0.00803679992755254
step = 11, Training Accuracy: 0.9033333333333333
Training loss = 0.008267005880673726
step = 12, Training Accuracy: 0.9066666666666666
Training loss = 0.007726417233546575
step = 13, Training Accuracy: 0.9066666666666666
Training loss = 0.008043056999643644
step = 14, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.775
pipeline:  [4, 71, 16, 1]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011129693041245142
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.77375
Training loss = 0.010285437603791555
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.012809276233116786
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.010649344523747762
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.010081113676230113
step = 4, Training Accuracy: 0.89
Training loss = 0.009945668180783589
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.78625
Training loss = 0.010393546372652053
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.009492427210013072
step = 7, Training Accuracy: 0.8966666666666666
Training loss = 0.01015146737297376
step = 8, Training Accuracy: 0.8766666666666667
Training loss = 0.00958865354458491
step = 9, Training Accuracy: 0.88
Training loss = 0.00930327499906222
step = 10, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.78625
Training loss = 0.00880669355392456
step = 11, Training Accuracy: 0.8966666666666666
Training loss = 0.008896481196085613
step = 12, Training Accuracy: 0.9066666666666666
Training loss = 0.01026454875866572
step = 13, Training Accuracy: 0.8633333333333333
Training loss = 0.008665567537148793
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79
pipeline:  [58, 77, 42, 68]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02845275362332662
step = 0, Training Accuracy: 0.6333333333333333
Validation Accuracy: 0.7925
Training loss = 0.031338876287142436
step = 1, Training Accuracy: 0.5733333333333334
Training loss = 0.029320490558942158
step = 2, Training Accuracy: 0.5833333333333334
Training loss = 0.029763407905896506
step = 3, Training Accuracy: 0.6066666666666667
Training loss = 0.027025031844774883
step = 4, Training Accuracy: 0.6266666666666667
Training loss = 0.026347612341245014
step = 5, Training Accuracy: 0.6566666666666666
Validation Accuracy: 0.76
Training loss = 0.025332637230555215
step = 6, Training Accuracy: 0.6533333333333333
Training loss = 0.02844213366508484
step = 7, Training Accuracy: 0.65
Training loss = 0.028103178739547728
step = 8, Training Accuracy: 0.58
Training loss = 0.025155832171440125
step = 9, Training Accuracy: 0.66
Training loss = 0.0247662885983785
step = 10, Training Accuracy: 0.68
Validation Accuracy: 0.75125
Training loss = 0.02538685202598572
step = 11, Training Accuracy: 0.67
Training loss = 0.025919919013977052
step = 12, Training Accuracy: 0.6566666666666666
Training loss = 0.02624441921710968
step = 13, Training Accuracy: 0.6433333333333333
Training loss = 0.024854514201482138
step = 14, Training Accuracy: 0.66
Validation Accuracy: 0.76125
38 	5     	0.778125	0.00891949	0.76125	0.79   
pipeline:  [90, 36, 62, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015333640575408935
step = 0, Training Accuracy: 0.81
Validation Accuracy: 0.775
Training loss = 0.014921984722216924
step = 1, Training Accuracy: 0.8033333333333333
Training loss = 0.016641364594300587
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.015130616327126822
step = 3, Training Accuracy: 0.8133333333333334
Training loss = 0.01626747339963913
step = 4, Training Accuracy: 0.8333333333333334
Training loss = 0.015976698299249012
step = 5, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.785
Training loss = 0.014680704971154531
step = 6, Training Accuracy: 0.83
Training loss = 0.01457576076189677
step = 7, Training Accuracy: 0.8233333333333334
Training loss = 0.016103883286317188
step = 8, Training Accuracy: 0.81
Training loss = 0.01813782940308253
step = 9, Training Accuracy: 0.77
Training loss = 0.016864181061585746
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.7825
Training loss = 0.015211697022120158
step = 11, Training Accuracy: 0.7966666666666666
Training loss = 0.015748306413491567
step = 12, Training Accuracy: 0.8066666666666666
Training loss = 0.014377361337343852
step = 13, Training Accuracy: 0.8066666666666666
Training loss = 0.014935990869998932
step = 14, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.785
pipeline:  [74, 72, 21, 60]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.026819159984588625
step = 0, Training Accuracy: 0.6366666666666667
Validation Accuracy: 0.7675
Training loss = 0.024163014690081277
step = 1, Training Accuracy: 0.6533333333333333
Training loss = 0.023940902948379517
step = 2, Training Accuracy: 0.7133333333333334
Training loss = 0.021553640166918436
step = 3, Training Accuracy: 0.7233333333333334
Training loss = 0.025397815306981406
step = 4, Training Accuracy: 0.68
Training loss = 0.020192496379216513
step = 5, Training Accuracy: 0.7233333333333334
Validation Accuracy: 0.7675
Training loss = 0.023110228975613913
step = 6, Training Accuracy: 0.6866666666666666
Training loss = 0.020524162352085113
step = 7, Training Accuracy: 0.7733333333333333
Training loss = 0.020124437113602955
step = 8, Training Accuracy: 0.72
Training loss = 0.020633405447006224
step = 9, Training Accuracy: 0.7266666666666667
Training loss = 0.021670597791671752
step = 10, Training Accuracy: 0.7
Validation Accuracy: 0.76375
Training loss = 0.022547327876091004
step = 11, Training Accuracy: 0.7066666666666667
Training loss = 0.019772308270136516
step = 12, Training Accuracy: 0.7533333333333333
Training loss = 0.020185931225617727
step = 13, Training Accuracy: 0.7466666666666667
Training loss = 0.021306625008583067
step = 14, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.76875
pipeline:  [38, 85, 28, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01760224868853887
step = 0, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.77125
Training loss = 0.018192288776238758
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.016869919300079347
step = 2, Training Accuracy: 0.77
Training loss = 0.018186387717723847
step = 3, Training Accuracy: 0.7633333333333333
Training loss = 0.017082724769910178
step = 4, Training Accuracy: 0.8
Training loss = 0.017353942890961965
step = 5, Training Accuracy: 0.79
Validation Accuracy: 0.7675
Training loss = 0.01779999723037084
step = 6, Training Accuracy: 0.7766666666666666
Training loss = 0.01839801033337911
step = 7, Training Accuracy: 0.7933333333333333
Training loss = 0.016389855047067005
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.017928305367628735
step = 9, Training Accuracy: 0.7866666666666666
Training loss = 0.01553118218978246
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.77375
Training loss = 0.017331004838148752
step = 11, Training Accuracy: 0.81
Training loss = 0.01841572980086009
step = 12, Training Accuracy: 0.7866666666666666
Training loss = 0.01729175627231598
step = 13, Training Accuracy: 0.76
Training loss = 0.017040697435537974
step = 14, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.77
39 	3     	0.778125	0.00664384	0.76875	0.785  
pipeline:  [90, 39, 62, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013073511570692063
step = 0, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.78125
Training loss = 0.01667355716228485
step = 1, Training Accuracy: 0.7833333333333333
Training loss = 0.01497103065252304
step = 2, Training Accuracy: 0.8066666666666666
Training loss = 0.013157492876052857
step = 3, Training Accuracy: 0.8533333333333334
Training loss = 0.015474627514680227
step = 4, Training Accuracy: 0.8033333333333333
Training loss = 0.014329090168078741
step = 5, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.785
Training loss = 0.013579123814900717
step = 6, Training Accuracy: 0.8433333333333334
Training loss = 0.013700574437777202
step = 7, Training Accuracy: 0.8333333333333334
Training loss = 0.014915536145369212
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.017258929560581844
step = 9, Training Accuracy: 0.8366666666666667
Training loss = 0.011847358594338098
step = 10, Training Accuracy: 0.86
Validation Accuracy: 0.79
Training loss = 0.014245050450166066
step = 11, Training Accuracy: 0.8166666666666667
Training loss = 0.013893332680066426
step = 12, Training Accuracy: 0.83
Training loss = 0.015770353575547538
step = 13, Training Accuracy: 0.8
Training loss = 0.01588603417078654
step = 14, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.78375
pipeline:  [17, 57, 14, 83]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010862584461768469
step = 0, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.78375
Training loss = 0.01073550467689832
step = 1, Training Accuracy: 0.88
Training loss = 0.011288643230994542
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.009773609191179276
step = 3, Training Accuracy: 0.89
Training loss = 0.0088050344089667
step = 4, Training Accuracy: 0.92
Training loss = 0.009282487332820893
step = 5, Training Accuracy: 0.9
Validation Accuracy: 0.785
Training loss = 0.009776650369167328
step = 6, Training Accuracy: 0.8866666666666667
Training loss = 0.01017192726333936
step = 7, Training Accuracy: 0.8966666666666666
Training loss = 0.009588214457035065
step = 8, Training Accuracy: 0.89
Training loss = 0.008390755429863929
step = 9, Training Accuracy: 0.8933333333333333
Training loss = 0.009432584345340729
step = 10, Training Accuracy: 0.89
Validation Accuracy: 0.785
Training loss = 0.009550656328598658
step = 11, Training Accuracy: 0.89
Training loss = 0.009217196007569631
step = 12, Training Accuracy: 0.8933333333333333
Training loss = 0.008679574976364771
step = 13, Training Accuracy: 0.9066666666666666
Training loss = 0.009455697188774745
step = 14, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.785
pipeline:  [22, 33, 57, 83]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                               'always_apply': False,
                               'blur_value': 7,
                               'brightness_coefficient': 0.7,
                               'drop_color': (200, 200, 200),
                               'drop_length': 20,
                               'drop_width': 1,
                               'p': 0.5,
                               'rain_type': None,
                               'slant_lower': -10,
                               'slant_upper': 10},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015965296030044554
step = 0, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.78375
Training loss = 0.014427745987971623
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.015304707884788514
step = 2, Training Accuracy: 0.8033333333333333
Training loss = 0.013120847741762797
step = 3, Training Accuracy: 0.8366666666666667
Training loss = 0.012607418050368626
step = 4, Training Accuracy: 0.84
Training loss = 0.013832631210486094
step = 5, Training Accuracy: 0.85
Validation Accuracy: 0.79375
Training loss = 0.013691466351350148
step = 6, Training Accuracy: 0.8266666666666667
Training loss = 0.01315231720606486
step = 7, Training Accuracy: 0.8366666666666667
Training loss = 0.013775962392489115
step = 8, Training Accuracy: 0.8533333333333334
Training loss = 0.012520301540692648
step = 9, Training Accuracy: 0.86
Training loss = 0.012749307602643967
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.7925
Training loss = 0.011842004706462224
step = 11, Training Accuracy: 0.8466666666666667
Training loss = 0.014242442051569621
step = 12, Training Accuracy: 0.83
Training loss = 0.012332367996374766
step = 13, Training Accuracy: 0.8733333333333333
Training loss = 0.012926395038763682
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.795
pipeline:  [90, 86, 62, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018254826068878172
step = 0, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.79375
Training loss = 0.019508871535460156
step = 1, Training Accuracy: 0.7266666666666667
Training loss = 0.01828555126984914
step = 2, Training Accuracy: 0.7533333333333333
Training loss = 0.01606498251358668
step = 3, Training Accuracy: 0.8
Training loss = 0.018520223846038183
step = 4, Training Accuracy: 0.7466666666666667
Training loss = 0.01881357709566752
step = 5, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.79
Training loss = 0.01726777454217275
step = 6, Training Accuracy: 0.7766666666666666
Training loss = 0.018834360837936402
step = 7, Training Accuracy: 0.73
Training loss = 0.01784042050441106
step = 8, Training Accuracy: 0.7833333333333333
Training loss = 0.016443576713403067
step = 9, Training Accuracy: 0.7733333333333333
Training loss = 0.018069602251052856
step = 10, Training Accuracy: 0.77
Validation Accuracy: 0.79125
Training loss = 0.017165420254071553
step = 11, Training Accuracy: 0.7633333333333333
Training loss = 0.018360133568445843
step = 12, Training Accuracy: 0.7466666666666667
Training loss = 0.01774285356203715
step = 13, Training Accuracy: 0.74
Training loss = 0.01732663114865621
step = 14, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.7875
pipeline:  [10, 43, 62, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01390525092681249
step = 0, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.795
Training loss = 0.015132239957650503
step = 1, Training Accuracy: 0.8266666666666667
Training loss = 0.014388401806354523
step = 2, Training Accuracy: 0.8333333333333334
Training loss = 0.013165220419565837
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.01351438343524933
step = 4, Training Accuracy: 0.8433333333333334
Training loss = 0.012407900045315425
step = 5, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.7825
Training loss = 0.01291226327419281
step = 6, Training Accuracy: 0.8333333333333334
Training loss = 0.013599435289700826
step = 7, Training Accuracy: 0.8333333333333334
Training loss = 0.01337376594543457
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.012419057389100393
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.014474714001019795
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.78
Training loss = 0.012622255235910415
step = 11, Training Accuracy: 0.8333333333333334
Training loss = 0.01336262529095014
step = 12, Training Accuracy: 0.82
Training loss = 0.013396315226952235
step = 13, Training Accuracy: 0.82
Training loss = 0.012911905298630396
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78625
40 	5     	0.786875	0.00386962	0.78375	0.795  
pipeline:  [82, 60, 36, 67]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013484020779530207
step = 0, Training Accuracy: 0.83
Validation Accuracy: 0.79375
Training loss = 0.014459204127391179
step = 1, Training Accuracy: 0.8233333333333334
Training loss = 0.01535362958908081
step = 2, Training Accuracy: 0.7966666666666666
Training loss = 0.015784948468208312
step = 3, Training Accuracy: 0.8
Training loss = 0.012954049209753671
step = 4, Training Accuracy: 0.84
Training loss = 0.01453352689743042
step = 5, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.78625
Training loss = 0.01572670469681422
step = 6, Training Accuracy: 0.7966666666666666
Training loss = 0.014538160264492036
step = 7, Training Accuracy: 0.8333333333333334
Training loss = 0.01482230544090271
step = 8, Training Accuracy: 0.79
Training loss = 0.013873595744371414
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.013111210117737452
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.78625
Training loss = 0.01543509155511856
step = 11, Training Accuracy: 0.8166666666666667
Training loss = 0.01548081636428833
step = 12, Training Accuracy: 0.8233333333333334
Training loss = 0.014512140800555547
step = 13, Training Accuracy: 0.8133333333333334
Training loss = 0.012379474937915802
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.78375
pipeline:  [85, 29, 14, 24]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016039887517690657
step = 0, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.79125
Training loss = 0.014067667027314504
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.014839301208655039
step = 2, Training Accuracy: 0.8033333333333333
Training loss = 0.01533335973819097
step = 3, Training Accuracy: 0.83
Training loss = 0.015415602425734202
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.015636689960956573
step = 5, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.775
Training loss = 0.014243713716665904
step = 6, Training Accuracy: 0.82
Training loss = 0.014878920217355093
step = 7, Training Accuracy: 0.82
Training loss = 0.014976621369520823
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.01422855148712794
step = 9, Training Accuracy: 0.86
Training loss = 0.0159397487839063
step = 10, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.775
Training loss = 0.014444813927014669
step = 11, Training Accuracy: 0.81
Training loss = 0.013973580648501713
step = 12, Training Accuracy: 0.81
Training loss = 0.013058616717656454
step = 13, Training Accuracy: 0.8233333333333334
Training loss = 0.012823611944913865
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.77125
pipeline:  [74, 82, 30, 66]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.025149210890134176
step = 0, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.72
Training loss = 0.023633371194203695
step = 1, Training Accuracy: 0.6766666666666666
Training loss = 0.025294701258341473
step = 2, Training Accuracy: 0.68
Training loss = 0.021413437128067016
step = 3, Training Accuracy: 0.7366666666666667
Training loss = 0.022134942909081776
step = 4, Training Accuracy: 0.7033333333333334
Training loss = 0.023109245697657266
step = 5, Training Accuracy: 0.7
Validation Accuracy: 0.61875
Training loss = 0.022120015919208525
step = 6, Training Accuracy: 0.7166666666666667
Training loss = 0.021927633980909984
step = 7, Training Accuracy: 0.7166666666666667
Training loss = 0.02011713316043218
step = 8, Training Accuracy: 0.7166666666666667
Training loss = 0.022596922119458518
step = 9, Training Accuracy: 0.7133333333333334
Training loss = 0.020392727553844452
step = 10, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.62125
Training loss = 0.022460149029890696
step = 11, Training Accuracy: 0.71
Training loss = 0.020395005842049917
step = 12, Training Accuracy: 0.7333333333333333
Training loss = 0.020633777678012846
step = 13, Training Accuracy: 0.6966666666666667
Training loss = 0.01945555865764618
step = 14, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.6175
pipeline:  [25, 36, 45, 61]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011041121780872345
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.725
Training loss = 0.011817424048980077
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.010064567426840464
step = 2, Training Accuracy: 0.89
Training loss = 0.011422529816627502
step = 3, Training Accuracy: 0.8766666666666667
Training loss = 0.009823595186074575
step = 4, Training Accuracy: 0.8866666666666667
Training loss = 0.010088868141174316
step = 5, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.78375
Training loss = 0.010571643114089965
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.010072155098120372
step = 7, Training Accuracy: 0.8833333333333333
Training loss = 0.00922845815618833
step = 8, Training Accuracy: 0.88
Training loss = 0.009484551300605139
step = 9, Training Accuracy: 0.89
Training loss = 0.010673317313194274
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78625
Training loss = 0.009435789237419764
step = 11, Training Accuracy: 0.88
Training loss = 0.01019435167312622
step = 12, Training Accuracy: 0.87
Training loss = 0.008896266669034958
step = 13, Training Accuracy: 0.9033333333333333
Training loss = 0.009260432124137878
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.78875
41 	4     	0.755625	0.0620347 	0.6175 	0.78875
pipeline:  [11, 87, 26, 90]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.026512139836947123
step = 0, Training Accuracy: 0.6233333333333333
Validation Accuracy: 0.76125
Training loss = 0.02272923360268275
step = 1, Training Accuracy: 0.6633333333333333
Training loss = 0.023728379408518473
step = 2, Training Accuracy: 0.6366666666666667
Training loss = 0.02271806706984838
step = 3, Training Accuracy: 0.71
Training loss = 0.02359391490618388
step = 4, Training Accuracy: 0.6466666666666666
Training loss = 0.022855120996634167
step = 5, Training Accuracy: 0.6433333333333333
Validation Accuracy: 0.76125
Training loss = 0.022348684072494508
step = 6, Training Accuracy: 0.67
Training loss = 0.02259533594051997
step = 7, Training Accuracy: 0.6666666666666666
Training loss = 0.020016865928967793
step = 8, Training Accuracy: 0.7
Training loss = 0.021911299924055737
step = 9, Training Accuracy: 0.6566666666666666
Training loss = 0.021261293490727744
step = 10, Training Accuracy: 0.6966666666666667
Validation Accuracy: 0.75875
Training loss = 0.021523147026697796
step = 11, Training Accuracy: 0.6966666666666667
Training loss = 0.02028676708539327
step = 12, Training Accuracy: 0.6933333333333334
Training loss = 0.0205233633518219
step = 13, Training Accuracy: 0.7066666666666667
Training loss = 0.02207822769880295
step = 14, Training Accuracy: 0.71
Validation Accuracy: 0.76125
pipeline:  [17, 85, 82, 46]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                                               'always_apply': False,
                                               'max_pixel_value': 255.0,
                                               'mean': (0.485, 0.456, 0.406),
                                               'p': 1.0,
                                               'std': (0.229, 0.224, 0.225)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020503344436486562
step = 0, Training Accuracy: 0.73
Validation Accuracy: 0.76625
Training loss = 0.018895005981127422
step = 1, Training Accuracy: 0.75
Training loss = 0.02035644143819809
step = 2, Training Accuracy: 0.73
Training loss = 0.016732368171215057
step = 3, Training Accuracy: 0.7766666666666666
Training loss = 0.016402099331219992
step = 4, Training Accuracy: 0.78
Training loss = 0.01762261748313904
step = 5, Training Accuracy: 0.77
Validation Accuracy: 0.77125
Training loss = 0.016148054003715516
step = 6, Training Accuracy: 0.81
Training loss = 0.01836595743894577
step = 7, Training Accuracy: 0.7333333333333333
Training loss = 0.019860957463582355
step = 8, Training Accuracy: 0.7466666666666667
Training loss = 0.019158337314923606
step = 9, Training Accuracy: 0.77
Training loss = 0.016618938247362772
step = 10, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.7825
Training loss = 0.021092281142870584
step = 11, Training Accuracy: 0.76
Training loss = 0.015212103525797526
step = 12, Training Accuracy: 0.7966666666666666
Training loss = 0.01587620665629705
step = 13, Training Accuracy: 0.7766666666666666
Training loss = 0.01705831378698349
step = 14, Training Accuracy: 0.81
Validation Accuracy: 0.7825
pipeline:  [79, 69, 37, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01136677806576093
step = 0, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.785
Training loss = 0.010378702084223429
step = 1, Training Accuracy: 0.87
Training loss = 0.011102254390716553
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.011432453642288844
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.01022362252076467
step = 4, Training Accuracy: 0.89
Training loss = 0.010241522093613942
step = 5, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79875
Training loss = 0.011397437651952108
step = 6, Training Accuracy: 0.87
Training loss = 0.009270442376534144
step = 7, Training Accuracy: 0.8833333333333333
Training loss = 0.009735930884877841
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.0089725761115551
step = 9, Training Accuracy: 0.9066666666666666
Training loss = 0.0115382319688797
step = 10, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.79125
Training loss = 0.009910176793734233
step = 11, Training Accuracy: 0.8866666666666667
Training loss = 0.00954652339220047
step = 12, Training Accuracy: 0.89
Training loss = 0.011177942752838135
step = 13, Training Accuracy: 0.8766666666666667
Training loss = 0.010135699510574341
step = 14, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.79125
pipeline:  [79, 73, 29, 61]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007866507098078727
step = 0, Training Accuracy: 0.91
Validation Accuracy: 0.7925
Training loss = 0.008074887941281
step = 1, Training Accuracy: 0.9133333333333333
Training loss = 0.008170041168729464
step = 2, Training Accuracy: 0.91
Training loss = 0.008618682970603307
step = 3, Training Accuracy: 0.9
Training loss = 0.0074813555429379145
step = 4, Training Accuracy: 0.9233333333333333
Training loss = 0.008141409158706665
step = 5, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.8
Training loss = 0.007888454745213191
step = 6, Training Accuracy: 0.92
Training loss = 0.0074495960772037505
step = 7, Training Accuracy: 0.9333333333333333
Training loss = 0.007208640997608502
step = 8, Training Accuracy: 0.9333333333333333
Training loss = 0.007057913665970167
step = 9, Training Accuracy: 0.9466666666666667
Training loss = 0.006837626447280248
step = 10, Training Accuracy: 0.9433333333333334
Validation Accuracy: 0.80125
Training loss = 0.0068631898115078605
step = 11, Training Accuracy: 0.94
Training loss = 0.007710431317488353
step = 12, Training Accuracy: 0.9433333333333334
Training loss = 0.007951343357563019
step = 13, Training Accuracy: 0.95
Training loss = 0.0070889793336391446
step = 14, Training Accuracy: 0.94
Validation Accuracy: 0.79875
42 	4     	0.784792	0.0116238 	0.76125	0.79875
pipeline:  [79, 69, 37, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011424466172854105
step = 0, Training Accuracy: 0.89
Validation Accuracy: 0.7975
Training loss = 0.01013192966580391
step = 1, Training Accuracy: 0.88
Training loss = 0.010227752973635991
step = 2, Training Accuracy: 0.8933333333333333
Training loss = 0.01128692239522934
step = 3, Training Accuracy: 0.88
Training loss = 0.010876320352156956
step = 4, Training Accuracy: 0.8666666666666667
Training loss = 0.010614724109570185
step = 5, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.7975
Training loss = 0.012053766349951426
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.010067891379197438
step = 7, Training Accuracy: 0.8933333333333333
Training loss = 0.009746430069208145
step = 8, Training Accuracy: 0.8966666666666666
Training loss = 0.010178378770748774
step = 9, Training Accuracy: 0.8833333333333333
Training loss = 0.008499776472647986
step = 10, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.7925
Training loss = 0.009798865765333176
step = 11, Training Accuracy: 0.8733333333333333
Training loss = 0.00900988390048345
step = 12, Training Accuracy: 0.9
Training loss = 0.009188882062832514
step = 13, Training Accuracy: 0.8933333333333333
Training loss = 0.008450618386268616
step = 14, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.79125
pipeline:  [79, 69, 37, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010420561283826828
step = 0, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.795
Training loss = 0.009992647791902225
step = 1, Training Accuracy: 0.86
Training loss = 0.01034522275129954
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.009800681297977766
step = 3, Training Accuracy: 0.86
Training loss = 0.009201254397630691
step = 4, Training Accuracy: 0.8866666666666667
Training loss = 0.01019966408610344
step = 5, Training Accuracy: 0.87
Validation Accuracy: 0.78375
Training loss = 0.009996240387360255
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.00933990719417731
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.010233613848686218
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.010270455131928126
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.009393211404482524
step = 10, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.78375
Training loss = 0.010303962777058284
step = 11, Training Accuracy: 0.8833333333333333
Training loss = 0.010255067820350329
step = 12, Training Accuracy: 0.88
Training loss = 0.009412681708733241
step = 13, Training Accuracy: 0.88
Training loss = 0.010107227911551794
step = 14, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.7825
pipeline:  [79, 69, 37, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009631831347942352
step = 0, Training Accuracy: 0.89
Validation Accuracy: 0.785
Training loss = 0.01057712825636069
step = 1, Training Accuracy: 0.9
Training loss = 0.010443083544572195
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.01104365661740303
step = 3, Training Accuracy: 0.8766666666666667
Training loss = 0.008752698476115862
step = 4, Training Accuracy: 0.8833333333333333
Training loss = 0.008975894550482432
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.79
Training loss = 0.009699198504288992
step = 6, Training Accuracy: 0.8933333333333333
Training loss = 0.00972507859269778
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.008926923225323359
step = 8, Training Accuracy: 0.9033333333333333
Training loss = 0.008283383126060168
step = 9, Training Accuracy: 0.91
Training loss = 0.01006486435731252
step = 10, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.79125
Training loss = 0.01094907840092977
step = 11, Training Accuracy: 0.8833333333333333
Training loss = 0.008715002785126368
step = 12, Training Accuracy: 0.8866666666666667
Training loss = 0.009295346190532048
step = 13, Training Accuracy: 0.88
Training loss = 0.008000981956720353
step = 14, Training Accuracy: 0.9
Validation Accuracy: 0.79375
pipeline:  [78, 16, 62, 29]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.Compose',
                               'additional_targets': {},
                               'bbox_params': None,
                               'keypoint_params': None,
                               'p': 1,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                               'always_apply': False,
                                               'height': 128,
                                               'p': 1.0,
                                               'width': 128},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1,
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02767359256744385
step = 0, Training Accuracy: 0.62
Validation Accuracy: 0.69375
Training loss = 0.027625466982523602
step = 1, Training Accuracy: 0.67
Training loss = 0.029404735565185545
step = 2, Training Accuracy: 0.6533333333333333
Training loss = 0.027530224919319154
step = 3, Training Accuracy: 0.62
Training loss = 0.02978560467561086
step = 4, Training Accuracy: 0.6166666666666667
Training loss = 0.026819434563318888
step = 5, Training Accuracy: 0.6466666666666666
Validation Accuracy: 0.58875
Training loss = 0.027692027489344278
step = 6, Training Accuracy: 0.6633333333333333
Training loss = 0.026983286341031393
step = 7, Training Accuracy: 0.6466666666666666
Training loss = 0.02491173674662908
step = 8, Training Accuracy: 0.6633333333333333
Training loss = 0.026373380223910014
step = 9, Training Accuracy: 0.6666666666666666
Training loss = 0.025358391205469767
step = 10, Training Accuracy: 0.6966666666666667
Validation Accuracy: 0.59875
Training loss = 0.025243373215198518
step = 11, Training Accuracy: 0.66
Training loss = 0.024801044464111327
step = 12, Training Accuracy: 0.6933333333333334
Training loss = 0.02541438053051631
step = 13, Training Accuracy: 0.6633333333333333
Training loss = 0.026771223346392314
step = 14, Training Accuracy: 0.6566666666666666
Validation Accuracy: 0.58875
pipeline:  [79, 69, 37, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010123237868150075
step = 0, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.7675
Training loss = 0.0096915698548158
step = 1, Training Accuracy: 0.8733333333333333
Training loss = 0.009660064627726873
step = 2, Training Accuracy: 0.9
Training loss = 0.01070317362745603
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.009328145782152812
step = 4, Training Accuracy: 0.89
Training loss = 0.0107045416533947
step = 5, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.785
Training loss = 0.008452371607224146
step = 6, Training Accuracy: 0.9133333333333333
Training loss = 0.00912795181075732
step = 7, Training Accuracy: 0.8866666666666667
Training loss = 0.00850680872797966
step = 8, Training Accuracy: 0.91
Training loss = 0.008851253738005957
step = 9, Training Accuracy: 0.9033333333333333
Training loss = 0.008610904489954312
step = 10, Training Accuracy: 0.9
Validation Accuracy: 0.78375
Training loss = 0.009283701380093892
step = 11, Training Accuracy: 0.91
Training loss = 0.008949856907129287
step = 12, Training Accuracy: 0.8966666666666666
Training loss = 0.010375183473030725
step = 13, Training Accuracy: 0.9
Training loss = 0.008435183266798655
step = 14, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.79625
pipeline:  [79, 73, 29, 61]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008462713013092676
step = 0, Training Accuracy: 0.91
Validation Accuracy: 0.78625
Training loss = 0.008512447029352188
step = 1, Training Accuracy: 0.9066666666666666
Training loss = 0.00835475668311119
step = 2, Training Accuracy: 0.9066666666666666
Training loss = 0.008365442256132762
step = 3, Training Accuracy: 0.9166666666666666
Training loss = 0.00852057009935379
step = 4, Training Accuracy: 0.9233333333333333
Training loss = 0.008224144677321117
step = 5, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.7875
Training loss = 0.008011037409305572
step = 6, Training Accuracy: 0.9166666666666666
Training loss = 0.007374401887257894
step = 7, Training Accuracy: 0.9333333333333333
Training loss = 0.008441426257292429
step = 8, Training Accuracy: 0.9033333333333333
Training loss = 0.007294392089049021
step = 9, Training Accuracy: 0.9266666666666666
Training loss = 0.007789319505294164
step = 10, Training Accuracy: 0.91
Validation Accuracy: 0.7825
Training loss = 0.007974460522333781
step = 11, Training Accuracy: 0.92
Training loss = 0.007669309129317602
step = 12, Training Accuracy: 0.9266666666666666
Training loss = 0.006920035729805629
step = 13, Training Accuracy: 0.9333333333333333
Training loss = 0.008191855649153392
step = 14, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.78375
43 	6     	0.756042	0.0749806 	0.58875	0.79625
pipeline:  [79, 69, 37, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009748865962028503
step = 0, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.78625
Training loss = 0.008746565083662668
step = 1, Training Accuracy: 0.9166666666666666
Training loss = 0.008804918626944224
step = 2, Training Accuracy: 0.91
Training loss = 0.009182793994744618
step = 3, Training Accuracy: 0.9
Training loss = 0.008081886420647303
step = 4, Training Accuracy: 0.9066666666666666
Training loss = 0.007539071043332418
step = 5, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.7825
Training loss = 0.008164175351460775
step = 6, Training Accuracy: 0.9166666666666666
Training loss = 0.00813518817226092
step = 7, Training Accuracy: 0.9166666666666666
Training loss = 0.009277985592683157
step = 8, Training Accuracy: 0.8933333333333333
Training loss = 0.007988757714629173
step = 9, Training Accuracy: 0.9266666666666666
Training loss = 0.007853171477715174
step = 10, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.785
Training loss = 0.00803116373717785
step = 11, Training Accuracy: 0.9133333333333333
Training loss = 0.009091992179552715
step = 12, Training Accuracy: 0.9066666666666666
Training loss = 0.008710392465194066
step = 13, Training Accuracy: 0.91
Training loss = 0.00840849036971728
step = 14, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.7875
pipeline:  [23, 69, 49, 37]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007093810836474101
step = 0, Training Accuracy: 0.91
Validation Accuracy: 0.79125
Training loss = 0.007751145859559377
step = 1, Training Accuracy: 0.8933333333333333
Training loss = 0.007173886001110077
step = 2, Training Accuracy: 0.9166666666666666
Training loss = 0.0067847640812397
step = 3, Training Accuracy: 0.9266666666666666
Training loss = 0.006621732165416082
step = 4, Training Accuracy: 0.9266666666666666
Training loss = 0.006671034544706344
step = 5, Training Accuracy: 0.9366666666666666
Validation Accuracy: 0.79125
Training loss = 0.006630378365516662
step = 6, Training Accuracy: 0.9233333333333333
Training loss = 0.006929022967815399
step = 7, Training Accuracy: 0.9233333333333333
Training loss = 0.0065959582726160685
step = 8, Training Accuracy: 0.9233333333333333
Training loss = 0.005995835488041242
step = 9, Training Accuracy: 0.93
Training loss = 0.0058774727086226145
step = 10, Training Accuracy: 0.9366666666666666
Validation Accuracy: 0.78625
Training loss = 0.007235092694560687
step = 11, Training Accuracy: 0.9233333333333333
Training loss = 0.005678970329463482
step = 12, Training Accuracy: 0.9333333333333333
Training loss = 0.006275077164173126
step = 13, Training Accuracy: 0.9333333333333333
Training loss = 0.005774979641040166
step = 14, Training Accuracy: 0.9433333333333334
Validation Accuracy: 0.78
pipeline:  [7, 92, 51, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011886788780490558
step = 0, Training Accuracy: 0.85
Validation Accuracy: 0.78375
Training loss = 0.010846895178159078
step = 1, Training Accuracy: 0.88
Training loss = 0.011494413614273072
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.011808504660924276
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.012316371997197468
step = 4, Training Accuracy: 0.8533333333333334
Training loss = 0.011636773447195688
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.77875
Training loss = 0.011800109048684438
step = 6, Training Accuracy: 0.8566666666666667
Training loss = 0.012505319267511368
step = 7, Training Accuracy: 0.8533333333333334
Training loss = 0.011573014458020529
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.011643841216961543
step = 9, Training Accuracy: 0.88
Training loss = 0.011802127112944922
step = 10, Training Accuracy: 0.84
Validation Accuracy: 0.78125
Training loss = 0.011089623024066289
step = 11, Training Accuracy: 0.89
Training loss = 0.01033530647555987
step = 12, Training Accuracy: 0.89
Training loss = 0.01093296488126119
step = 13, Training Accuracy: 0.8866666666666667
Training loss = 0.009866028527418772
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.78375
44 	3     	0.789167	0.00606676	0.78   	0.79625
pipeline:  [79, 69, 37, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008868249704440435
step = 0, Training Accuracy: 0.89
Validation Accuracy: 0.7875
Training loss = 0.009897191325823467
step = 1, Training Accuracy: 0.9
Training loss = 0.009811800718307496
step = 2, Training Accuracy: 0.9033333333333333
Training loss = 0.008478278815746308
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.008556250060598056
step = 4, Training Accuracy: 0.9033333333333333
Training loss = 0.007846012637019157
step = 5, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.78125
Training loss = 0.007754865437746048
step = 6, Training Accuracy: 0.92
Training loss = 0.008334756394227346
step = 7, Training Accuracy: 0.9
Training loss = 0.008465627233187358
step = 8, Training Accuracy: 0.9133333333333333
Training loss = 0.00851344163219134
step = 9, Training Accuracy: 0.9066666666666666
Training loss = 0.007358162105083466
step = 10, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.7825
Training loss = 0.009182289739449819
step = 11, Training Accuracy: 0.92
Training loss = 0.007561600282788277
step = 12, Training Accuracy: 0.9233333333333333
Training loss = 0.008651736974716186
step = 13, Training Accuracy: 0.9233333333333333
Training loss = 0.007362647851308187
step = 14, Training Accuracy: 0.91
Validation Accuracy: 0.78125
pipeline:  [81, 17, 74, 23]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020752360423405964
step = 0, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.77875
Training loss = 0.018266482253869374
step = 1, Training Accuracy: 0.7566666666666667
Training loss = 0.017865317364533742
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.01578561176856359
step = 3, Training Accuracy: 0.7833333333333333
Training loss = 0.015080849428971609
step = 4, Training Accuracy: 0.7933333333333333
Training loss = 0.01691888431708018
step = 5, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.76875
Training loss = 0.016517222821712495
step = 6, Training Accuracy: 0.7666666666666667
Training loss = 0.015014937619368235
step = 7, Training Accuracy: 0.7833333333333333
Training loss = 0.01720888286828995
step = 8, Training Accuracy: 0.7466666666666667
Training loss = 0.01896679719289144
step = 9, Training Accuracy: 0.7466666666666667
Training loss = 0.01716969609260559
step = 10, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.77125
Training loss = 0.0164596027135849
step = 11, Training Accuracy: 0.7933333333333333
Training loss = 0.015315433740615845
step = 12, Training Accuracy: 0.8066666666666666
Training loss = 0.01614222933848699
step = 13, Training Accuracy: 0.7733333333333333
Training loss = 0.016022778749465942
step = 14, Training Accuracy: 0.78
Validation Accuracy: 0.77375
pipeline:  [64, 69, 48, 53]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016465339561303458
step = 0, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.78875
Training loss = 0.01963191161553065
step = 1, Training Accuracy: 0.7666666666666667
Training loss = 0.016434306800365447
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.015402957399686178
step = 3, Training Accuracy: 0.8133333333333334
Training loss = 0.014995470841725667
step = 4, Training Accuracy: 0.8
Training loss = 0.016292318205038705
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.79625
Training loss = 0.014067852099736532
step = 6, Training Accuracy: 0.8566666666666667
Training loss = 0.015616029699643453
step = 7, Training Accuracy: 0.79
Training loss = 0.014899727801481882
step = 8, Training Accuracy: 0.8133333333333334
Training loss = 0.014938210050264994
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.01653636266787847
step = 10, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.7875
Training loss = 0.016881697475910187
step = 11, Training Accuracy: 0.78
Training loss = 0.014823191116253536
step = 12, Training Accuracy: 0.79
Training loss = 0.014482751538356145
step = 13, Training Accuracy: 0.83
Training loss = 0.01320998638868332
step = 14, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78375
pipeline:  [13, 16, 40, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008592113008101782
step = 0, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.785
Training loss = 0.008574234495560329
step = 1, Training Accuracy: 0.92
Training loss = 0.007589612280329069
step = 2, Training Accuracy: 0.9266666666666666
Training loss = 0.007853839198748271
step = 3, Training Accuracy: 0.89
Training loss = 0.008650132765372595
step = 4, Training Accuracy: 0.91
Training loss = 0.007397602970401446
step = 5, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.7875
Training loss = 0.008431651294231415
step = 6, Training Accuracy: 0.9
Training loss = 0.008534460067749024
step = 7, Training Accuracy: 0.9066666666666666
Training loss = 0.007071650003393491
step = 8, Training Accuracy: 0.94
Training loss = 0.008219355394442877
step = 9, Training Accuracy: 0.9133333333333333
Training loss = 0.008210177173217138
step = 10, Training Accuracy: 0.92
Validation Accuracy: 0.78875
Training loss = 0.0071509925772746405
step = 11, Training Accuracy: 0.9233333333333333
Training loss = 0.008138078078627587
step = 12, Training Accuracy: 0.8966666666666666
Training loss = 0.008233949740727742
step = 13, Training Accuracy: 0.9366666666666666
Training loss = 0.0076377373933792115
step = 14, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.785
pipeline:  [79, 41, 33, 15]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007805266976356506
step = 0, Training Accuracy: 0.9
Validation Accuracy: 0.4075
Training loss = 0.007572287966807683
step = 1, Training Accuracy: 0.9166666666666666
Training loss = 0.00808840329448382
step = 2, Training Accuracy: 0.89
Training loss = 0.007565380334854126
step = 3, Training Accuracy: 0.9033333333333333
Training loss = 0.007166322122017543
step = 4, Training Accuracy: 0.92
Training loss = 0.007613273486495018
step = 5, Training Accuracy: 0.89
Validation Accuracy: 0.4025
Training loss = 0.007352709770202637
step = 6, Training Accuracy: 0.9033333333333333
Training loss = 0.008217693169911703
step = 7, Training Accuracy: 0.9
Training loss = 0.007783827582995097
step = 8, Training Accuracy: 0.9133333333333333
Training loss = 0.007490566919247309
step = 9, Training Accuracy: 0.9233333333333333
Training loss = 0.008334628368417422
step = 10, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.3975
Training loss = 0.007933832903703053
step = 11, Training Accuracy: 0.9033333333333333
Training loss = 0.007303204238414764
step = 12, Training Accuracy: 0.9066666666666666
Training loss = 0.00798245241244634
step = 13, Training Accuracy: 0.8966666666666666
Training loss = 0.007425307780504226
step = 14, Training Accuracy: 0.9
Validation Accuracy: 0.4
45 	5     	0.72    	0.143262  	0.4    	0.79625
pipeline:  [87, 52, 75, 55]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01419618288675944
step = 0, Training Accuracy: 0.83
Validation Accuracy: 0.78
Training loss = 0.011420951187610627
step = 1, Training Accuracy: 0.8533333333333334
Training loss = 0.012059557884931564
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.012980947891871134
step = 3, Training Accuracy: 0.8233333333333334
Training loss = 0.014054635862509409
step = 4, Training Accuracy: 0.85
Training loss = 0.014215091367562611
step = 5, Training Accuracy: 0.82
Validation Accuracy: 0.78875
Training loss = 0.013163620034853617
step = 6, Training Accuracy: 0.8133333333333334
Training loss = 0.01302951067686081
step = 7, Training Accuracy: 0.8466666666666667
Training loss = 0.015132763584454855
step = 8, Training Accuracy: 0.8233333333333334
Training loss = 0.014075262943903604
step = 9, Training Accuracy: 0.8166666666666667
Training loss = 0.012316621392965316
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.785
Training loss = 0.014033443927764892
step = 11, Training Accuracy: 0.84
Training loss = 0.011379116376241049
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.01369309773047765
step = 13, Training Accuracy: 0.82
Training loss = 0.015064059793949126
step = 14, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.78125
pipeline:  [48, 92, 40, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01698244720697403
step = 0, Training Accuracy: 0.8
Validation Accuracy: 0.785
Training loss = 0.017189302742481233
step = 1, Training Accuracy: 0.78
Training loss = 0.018491360942522683
step = 2, Training Accuracy: 0.77
Training loss = 0.01775089353322983
step = 3, Training Accuracy: 0.7933333333333333
Training loss = 0.01812930554151535
step = 4, Training Accuracy: 0.7966666666666666
Training loss = 0.0155936132868131
step = 5, Training Accuracy: 0.78
Validation Accuracy: 0.78375
Training loss = 0.020336356461048127
step = 6, Training Accuracy: 0.76
Training loss = 0.018425160547097523
step = 7, Training Accuracy: 0.75
Training loss = 0.019709191222985586
step = 8, Training Accuracy: 0.7533333333333333
Training loss = 0.016599690864483516
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.01754776358604431
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.78375
Training loss = 0.017871141334374747
step = 11, Training Accuracy: 0.7866666666666666
Training loss = 0.018078988591829936
step = 12, Training Accuracy: 0.7966666666666666
Training loss = 0.017012146562337876
step = 13, Training Accuracy: 0.8033333333333333
Training loss = 0.01855173538128535
step = 14, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.78375
pipeline:  [53, 91, 35, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'threshold': (128, 128)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01831457644701004
step = 0, Training Accuracy: 0.8
Validation Accuracy: 0.785
Training loss = 0.01969165951013565
step = 1, Training Accuracy: 0.7233333333333334
Training loss = 0.017985097765922546
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.01511404663324356
step = 3, Training Accuracy: 0.7966666666666666
Training loss = 0.015448731184005738
step = 4, Training Accuracy: 0.8133333333333334
Training loss = 0.013877260287602743
step = 5, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.7825
Training loss = 0.013578329682350159
step = 6, Training Accuracy: 0.83
Training loss = 0.01617519954840342
step = 7, Training Accuracy: 0.8133333333333334
Training loss = 0.017206951777140298
step = 8, Training Accuracy: 0.7533333333333333
Training loss = 0.014098011255264283
step = 9, Training Accuracy: 0.8333333333333334
Training loss = 0.016780486901601156
step = 10, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.7825
Training loss = 0.014885313014189402
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.016359741588433584
step = 12, Training Accuracy: 0.81
Training loss = 0.014249560435612997
step = 13, Training Accuracy: 0.8133333333333334
Training loss = 0.014682659010092417
step = 14, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78125
pipeline:  [8, 74, 42, 6]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                               'always_apply': False,
                               'color_shift': (0.01, 0.05),
                               'intensity': (0.1, 0.5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                               'always_apply': False,
                               'channel_drop_range': (1, 1),
                               'fill_value': 0,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02894974112510681
step = 0, Training Accuracy: 0.61
Validation Accuracy: 0.76125
Training loss = 0.027727804084618887
step = 1, Training Accuracy: 0.5933333333333334
Training loss = 0.029955607453982035
step = 2, Training Accuracy: 0.6133333333333333
Training loss = 0.029089998404184976
step = 3, Training Accuracy: 0.6066666666666667
Training loss = 0.02910426676273346
step = 4, Training Accuracy: 0.6233333333333333
Training loss = 0.03124681850274404
step = 5, Training Accuracy: 0.6066666666666667
Validation Accuracy: 0.75375
Training loss = 0.028452409307161967
step = 6, Training Accuracy: 0.59
Training loss = 0.02782453954219818
step = 7, Training Accuracy: 0.5866666666666667
Training loss = 0.028048529426256817
step = 8, Training Accuracy: 0.6333333333333333
Training loss = 0.023411023020744322
step = 9, Training Accuracy: 0.6566666666666666
Training loss = 0.02492975930372874
step = 10, Training Accuracy: 0.6333333333333333
Validation Accuracy: 0.74625
Training loss = 0.02684728503227234
step = 11, Training Accuracy: 0.62
Training loss = 0.026231858730316162
step = 12, Training Accuracy: 0.6366666666666667
Training loss = 0.025659606258074442
step = 13, Training Accuracy: 0.6166666666666667
Training loss = 0.026082783142725628
step = 14, Training Accuracy: 0.64
Validation Accuracy: 0.75375
46 	4     	0.777708	0.0108113 	0.75375	0.785  
pipeline:  [68, 25, 43, 56]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022119371394316356
step = 0, Training Accuracy: 0.72
Validation Accuracy: 0.755
Training loss = 0.02095491607983907
step = 1, Training Accuracy: 0.7333333333333333
Training loss = 0.021057853599389394
step = 2, Training Accuracy: 0.7066666666666667
Training loss = 0.023045424818992615
step = 3, Training Accuracy: 0.7
Training loss = 0.019692251483599345
step = 4, Training Accuracy: 0.7533333333333333
Training loss = 0.019916140635808308
step = 5, Training Accuracy: 0.76
Validation Accuracy: 0.7825
Training loss = 0.020316780904928843
step = 6, Training Accuracy: 0.71
Training loss = 0.019860569536685944
step = 7, Training Accuracy: 0.7566666666666667
Training loss = 0.02054646929105123
step = 8, Training Accuracy: 0.75
Training loss = 0.02065348873535792
step = 9, Training Accuracy: 0.7233333333333334
Training loss = 0.02021086007356644
step = 10, Training Accuracy: 0.71
Validation Accuracy: 0.78125
Training loss = 0.019963507056236268
step = 11, Training Accuracy: 0.7133333333333334
Training loss = 0.02101239065329234
step = 12, Training Accuracy: 0.74
Training loss = 0.020110709170500438
step = 13, Training Accuracy: 0.72
Training loss = 0.01915731340646744
step = 14, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.78
pipeline:  [48, 92, 40, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01588813031713168
step = 0, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.7825
Training loss = 0.01746034115552902
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.015941758503516514
step = 2, Training Accuracy: 0.77
Training loss = 0.016940333743890125
step = 3, Training Accuracy: 0.7933333333333333
Training loss = 0.0168818595012029
step = 4, Training Accuracy: 0.7933333333333333
Training loss = 0.015736568520466485
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.77375
Training loss = 0.015896357794602713
step = 6, Training Accuracy: 0.82
Training loss = 0.014772916237513225
step = 7, Training Accuracy: 0.8033333333333333
Training loss = 0.01706861615180969
step = 8, Training Accuracy: 0.7866666666666666
Training loss = 0.016160223384698233
step = 9, Training Accuracy: 0.8066666666666666
Training loss = 0.01660569856564204
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.7775
Training loss = 0.01577764332294464
step = 11, Training Accuracy: 0.79
Training loss = 0.017267913619677226
step = 12, Training Accuracy: 0.7766666666666666
Training loss = 0.014238729576269786
step = 13, Training Accuracy: 0.8
Training loss = 0.015918551286061604
step = 14, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.7875
pipeline:  [48, 92, 40, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01929178218046824
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.7825
Training loss = 0.01686467856168747
step = 1, Training Accuracy: 0.7766666666666666
Training loss = 0.01641636292139689
step = 2, Training Accuracy: 0.78
Training loss = 0.018044479290644327
step = 3, Training Accuracy: 0.75
Training loss = 0.017152199844519298
step = 4, Training Accuracy: 0.78
Training loss = 0.015403020344674587
step = 5, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.78
Training loss = 0.018044450581073762
step = 6, Training Accuracy: 0.77
Training loss = 0.0164481520652771
step = 7, Training Accuracy: 0.7966666666666666
Training loss = 0.01864810804526011
step = 8, Training Accuracy: 0.7533333333333333
Training loss = 0.0179041650891304
step = 9, Training Accuracy: 0.7633333333333333
Training loss = 0.016930852631727854
step = 10, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.78
Training loss = 0.016844338178634642
step = 11, Training Accuracy: 0.7766666666666666
Training loss = 0.017476987640062967
step = 12, Training Accuracy: 0.79
Training loss = 0.016840627988179525
step = 13, Training Accuracy: 0.7533333333333333
Training loss = 0.016060655117034913
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.78875
pipeline:  [79, 69, 37, 92]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011693380624055862
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.785
Training loss = 0.011219359536965689
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.011072995314995449
step = 2, Training Accuracy: 0.86
Training loss = 0.010748971129457156
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.010917326062917709
step = 4, Training Accuracy: 0.8666666666666667
Training loss = 0.012457647025585175
step = 5, Training Accuracy: 0.84
Validation Accuracy: 0.78
Training loss = 0.013024007230997085
step = 6, Training Accuracy: 0.8466666666666667
Training loss = 0.010071749836206435
step = 7, Training Accuracy: 0.8566666666666667
Training loss = 0.010103431046009064
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.011420232554276785
step = 9, Training Accuracy: 0.8866666666666667
Training loss = 0.011041743606328964
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.785
Training loss = 0.010062217364708583
step = 11, Training Accuracy: 0.8733333333333333
Training loss = 0.010703792919715245
step = 12, Training Accuracy: 0.8433333333333334
Training loss = 0.012634300589561463
step = 13, Training Accuracy: 0.8433333333333334
Training loss = 0.010807594805955887
step = 14, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78875
pipeline:  [43, 10, 40, 20]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017960451940695444
step = 0, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.7925
Training loss = 0.016996613442897796
step = 1, Training Accuracy: 0.79
Training loss = 0.017171056965986888
step = 2, Training Accuracy: 0.8166666666666667
Training loss = 0.015055426508188247
step = 3, Training Accuracy: 0.8333333333333334
Training loss = 0.01599790612856547
step = 4, Training Accuracy: 0.8066666666666666
Training loss = 0.018033652206261953
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.78875
Training loss = 0.014889242152372997
step = 6, Training Accuracy: 0.8166666666666667
Training loss = 0.018394618233044942
step = 7, Training Accuracy: 0.7933333333333333
Training loss = 0.01690468966960907
step = 8, Training Accuracy: 0.79
Training loss = 0.017431590954462686
step = 9, Training Accuracy: 0.8233333333333334
Training loss = 0.014641380409399668
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78
Training loss = 0.016773200631141662
step = 11, Training Accuracy: 0.8233333333333334
Training loss = 0.017089141607284544
step = 12, Training Accuracy: 0.7966666666666666
Training loss = 0.017293435434500376
step = 13, Training Accuracy: 0.78
Training loss = 0.01841962645451228
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.78625
47 	5     	0.786042	0.00301184	0.78   	0.78875
pipeline:  [79, 69, 37, 92]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012958726286888123
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.7825
Training loss = 0.011076608151197433
step = 1, Training Accuracy: 0.8866666666666667
Training loss = 0.009448277453581492
step = 2, Training Accuracy: 0.8833333333333333
Training loss = 0.0098503773411115
step = 3, Training Accuracy: 0.89
Training loss = 0.011115444252888362
step = 4, Training Accuracy: 0.88
Training loss = 0.009276928255955379
step = 5, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.79125
Training loss = 0.00942956437667211
step = 6, Training Accuracy: 0.88
Training loss = 0.00994238575299581
step = 7, Training Accuracy: 0.87
Training loss = 0.009675233662128448
step = 8, Training Accuracy: 0.8833333333333333
Training loss = 0.00977994292974472
step = 9, Training Accuracy: 0.8966666666666666
Training loss = 0.00908478153248628
step = 10, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.785
Training loss = 0.009652215590079626
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.010919878333806992
step = 12, Training Accuracy: 0.87
Training loss = 0.00903314858675003
step = 13, Training Accuracy: 0.92
Training loss = 0.010077447493871053
step = 14, Training Accuracy: 0.89
Validation Accuracy: 0.78875
pipeline:  [59, 51, 61, 69]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007777684132258098
step = 0, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.79625
Training loss = 0.008345897247393926
step = 1, Training Accuracy: 0.9233333333333333
Training loss = 0.007786868363618851
step = 2, Training Accuracy: 0.9166666666666666
Training loss = 0.006695221364498139
step = 3, Training Accuracy: 0.9233333333333333
Training loss = 0.00713094765941302
step = 4, Training Accuracy: 0.9233333333333333
Training loss = 0.007480214387178421
step = 5, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.7925
Training loss = 0.007215125262737274
step = 6, Training Accuracy: 0.9333333333333333
Training loss = 0.007125393599271774
step = 7, Training Accuracy: 0.9166666666666666
Training loss = 0.00739370326201121
step = 8, Training Accuracy: 0.92
Training loss = 0.007481738577286403
step = 9, Training Accuracy: 0.9233333333333333
Training loss = 0.007164033154646555
step = 10, Training Accuracy: 0.93
Validation Accuracy: 0.7875
Training loss = 0.007694394911328952
step = 11, Training Accuracy: 0.93
Training loss = 0.007123436729113261
step = 12, Training Accuracy: 0.9266666666666666
Training loss = 0.0067469130953152975
step = 13, Training Accuracy: 0.9466666666666667
Training loss = 0.0065502883493900295
step = 14, Training Accuracy: 0.94
Validation Accuracy: 0.7875
pipeline:  [79, 69, 37, 92]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007295567070444425
step = 0, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.7825
Training loss = 0.008300528824329377
step = 1, Training Accuracy: 0.9233333333333333
Training loss = 0.007771329383055369
step = 2, Training Accuracy: 0.9233333333333333
Training loss = 0.00901708667476972
step = 3, Training Accuracy: 0.9066666666666666
Training loss = 0.008290894255042076
step = 4, Training Accuracy: 0.93
Training loss = 0.008701694359381994
step = 5, Training Accuracy: 0.91
Validation Accuracy: 0.78375
Training loss = 0.006718405062953631
step = 6, Training Accuracy: 0.9433333333333334
Training loss = 0.00804243137439092
step = 7, Training Accuracy: 0.9166666666666666
Training loss = 0.007752278248469035
step = 8, Training Accuracy: 0.92
Training loss = 0.00745751495162646
step = 9, Training Accuracy: 0.92
Training loss = 0.008388537963231404
step = 10, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.78375
Training loss = 0.007427891294161479
step = 11, Training Accuracy: 0.9266666666666666
Training loss = 0.007702915569146474
step = 12, Training Accuracy: 0.93
Training loss = 0.008426986758907636
step = 13, Training Accuracy: 0.9133333333333333
Training loss = 0.007961006462574005
step = 14, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.78
pipeline:  [48, 34, 49, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017001275022824607
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.7925
Training loss = 0.01902069608370463
step = 1, Training Accuracy: 0.7833333333333333
Training loss = 0.019177468965450924
step = 2, Training Accuracy: 0.78
Training loss = 0.02235129177570343
step = 3, Training Accuracy: 0.73
Training loss = 0.01611598233381907
step = 4, Training Accuracy: 0.79
Training loss = 0.019608897467454273
step = 5, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.79
Training loss = 0.020324162046114605
step = 6, Training Accuracy: 0.7366666666666667
Training loss = 0.019212882419427237
step = 7, Training Accuracy: 0.7766666666666666
Training loss = 0.01765546530485153
step = 8, Training Accuracy: 0.77
Training loss = 0.01774027422070503
step = 9, Training Accuracy: 0.76
Training loss = 0.01860803782939911
step = 10, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.7925
Training loss = 0.019022168616453807
step = 11, Training Accuracy: 0.76
Training loss = 0.01898729383945465
step = 12, Training Accuracy: 0.7933333333333333
Training loss = 0.019470154941082
step = 13, Training Accuracy: 0.78
Training loss = 0.016913480162620544
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.7975
pipeline:  [15, 53, 67, 91]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'threshold': (128, 128)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013558818946282069
step = 0, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.41625
Training loss = 0.013717493613560994
step = 1, Training Accuracy: 0.8266666666666667
Training loss = 0.014801721225182215
step = 2, Training Accuracy: 0.79
Training loss = 0.015560520887374878
step = 3, Training Accuracy: 0.8066666666666666
Training loss = 0.014005065262317658
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.012594581842422485
step = 5, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.4275
Training loss = 0.015420803527037303
step = 6, Training Accuracy: 0.8066666666666666
Training loss = 0.012405724575122198
step = 7, Training Accuracy: 0.8433333333333334
Training loss = 0.014609829386075338
step = 8, Training Accuracy: 0.8
Training loss = 0.013675476560990016
step = 9, Training Accuracy: 0.84
Training loss = 0.012839222053686778
step = 10, Training Accuracy: 0.83
Validation Accuracy: 0.43125
Training loss = 0.012802840570608775
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.011492801109949748
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.013258270223935446
step = 13, Training Accuracy: 0.8333333333333334
Training loss = 0.013453947703043619
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.4225
pipeline:  [48, 92, 40, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017954237461090088
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.7825
Training loss = 0.017448187669118244
step = 1, Training Accuracy: 0.76
Training loss = 0.01776563803354899
step = 2, Training Accuracy: 0.7666666666666667
Training loss = 0.01583867718776067
step = 3, Training Accuracy: 0.7666666666666667
Training loss = 0.017697260081768036
step = 4, Training Accuracy: 0.7666666666666667
Training loss = 0.015701918254295986
step = 5, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.785
Training loss = 0.016077364087104796
step = 6, Training Accuracy: 0.8066666666666666
Training loss = 0.015883159240086875
step = 7, Training Accuracy: 0.7766666666666666
Training loss = 0.01577056715885798
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.016136171221733095
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.018382969498634338
step = 10, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.79
Training loss = 0.016702310542265574
step = 11, Training Accuracy: 0.7866666666666666
Training loss = 0.01758485605319341
step = 12, Training Accuracy: 0.77
Training loss = 0.016016112565994264
step = 13, Training Accuracy: 0.8066666666666666
Training loss = 0.017391532957553864
step = 14, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.79625
48 	6     	0.72875 	0.137083  	0.4225 	0.7975 
pipeline:  [22, 44, 80, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                               'always_apply': False,
                               'blur_value': 7,
                               'brightness_coefficient': 0.7,
                               'drop_color': (200, 200, 200),
                               'drop_length': 20,
                               'drop_width': 1,
                               'p': 0.5,
                               'rain_type': None,
                               'slant_lower': -10,
                               'slant_upper': 10},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1.0,
                               'ratio': (0.75, 1.3333333333333333),
                               'scale': (0.9, 1.0),
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018524473110834758
step = 0, Training Accuracy: 0.79
Validation Accuracy: 0.7925
Training loss = 0.020096781253814696
step = 1, Training Accuracy: 0.7433333333333333
Training loss = 0.01838643342256546
step = 2, Training Accuracy: 0.81
Training loss = 0.0183214537302653
step = 3, Training Accuracy: 0.7866666666666666
Training loss = 0.015138920843601227
step = 4, Training Accuracy: 0.7966666666666666
Training loss = 0.01666120857000351
step = 5, Training Accuracy: 0.77
Validation Accuracy: 0.795
Training loss = 0.017413102487723032
step = 6, Training Accuracy: 0.76
Training loss = 0.016727903187274934
step = 7, Training Accuracy: 0.7866666666666666
Training loss = 0.019488251705964407
step = 8, Training Accuracy: 0.7533333333333333
Training loss = 0.01712496817111969
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.0158778648575147
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.79375
Training loss = 0.017564690907796224
step = 11, Training Accuracy: 0.8033333333333333
Training loss = 0.01640042891105016
step = 12, Training Accuracy: 0.7833333333333333
Training loss = 0.01726864109436671
step = 13, Training Accuracy: 0.79
Training loss = 0.019022461473941803
step = 14, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.7875
pipeline:  [69, 28, 9, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011996863931417466
step = 0, Training Accuracy: 0.85
Validation Accuracy: 0.80375
Training loss = 0.013732738097508749
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.013907329936822255
step = 2, Training Accuracy: 0.86
Training loss = 0.011619758469363054
step = 3, Training Accuracy: 0.85
Training loss = 0.011107377111911773
step = 4, Training Accuracy: 0.88
Training loss = 0.012191239545742671
step = 5, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.80875
Training loss = 0.012119796772797902
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.01419733981291453
step = 7, Training Accuracy: 0.81
Training loss = 0.013133708039919536
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.012579677204291026
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.012856578081846237
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.80875
Training loss = 0.013098713457584382
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.011934107293685277
step = 12, Training Accuracy: 0.8566666666666667
Training loss = 0.01240317126115163
step = 13, Training Accuracy: 0.8566666666666667
Training loss = 0.011600338816642762
step = 14, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.80875
pipeline:  [48, 34, 49, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017762827575206756
step = 0, Training Accuracy: 0.78
Validation Accuracy: 0.80125
Training loss = 0.016467188497384388
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.01749276340007782
step = 2, Training Accuracy: 0.79
Training loss = 0.018755768835544587
step = 3, Training Accuracy: 0.76
Training loss = 0.017297714352607726
step = 4, Training Accuracy: 0.7833333333333333
Training loss = 0.017052908440430958
step = 5, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.7875
Training loss = 0.018470889727274578
step = 6, Training Accuracy: 0.8033333333333333
Training loss = 0.018944696287314097
step = 7, Training Accuracy: 0.74
Training loss = 0.01677887201309204
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.0190598330895106
step = 9, Training Accuracy: 0.7533333333333333
Training loss = 0.01789572646220525
step = 10, Training Accuracy: 0.78
Validation Accuracy: 0.7875
Training loss = 0.017697671155134837
step = 11, Training Accuracy: 0.78
Training loss = 0.016094359556833904
step = 12, Training Accuracy: 0.8033333333333333
Training loss = 0.017295930733283362
step = 13, Training Accuracy: 0.7766666666666666
Training loss = 0.017496521174907683
step = 14, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.78625
pipeline:  [37, 24, 8, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                               'always_apply': False,
                               'color_shift': (0.01, 0.05),
                               'intensity': (0.1, 0.5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011178861310084661
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.78125
Training loss = 0.011117238799730937
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.012671666940053304
step = 2, Training Accuracy: 0.8633333333333333
Training loss = 0.012986578245957692
step = 3, Training Accuracy: 0.85
Training loss = 0.013396475513776143
step = 4, Training Accuracy: 0.8633333333333333
Training loss = 0.012032134234905243
step = 5, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.77625
Training loss = 0.01308606227238973
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.012694520850976308
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.011544324358304341
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.011138651768366497
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.010946403394142786
step = 10, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.775
Training loss = 0.01201399510105451
step = 11, Training Accuracy: 0.89
Training loss = 0.010513651371002197
step = 12, Training Accuracy: 0.8833333333333333
Training loss = 0.01104396253824234
step = 13, Training Accuracy: 0.8866666666666667
Training loss = 0.011622256388266881
step = 14, Training Accuracy: 0.88
Validation Accuracy: 0.77375
pipeline:  [48, 34, 21, 32]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01670982281366984
step = 0, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.7875
Training loss = 0.018349732955296835
step = 1, Training Accuracy: 0.79
Training loss = 0.017770915726820626
step = 2, Training Accuracy: 0.75
Training loss = 0.01904049168030421
step = 3, Training Accuracy: 0.7766666666666666
Training loss = 0.01519711156686147
step = 4, Training Accuracy: 0.8
Training loss = 0.018603657285372416
step = 5, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.78875
Training loss = 0.019366088112195333
step = 6, Training Accuracy: 0.7666666666666667
Training loss = 0.016113858123620352
step = 7, Training Accuracy: 0.78
Training loss = 0.018211154242356618
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.0181480007370313
step = 9, Training Accuracy: 0.7633333333333333
Training loss = 0.016285000046094258
step = 10, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.78125
Training loss = 0.016370756427447
step = 11, Training Accuracy: 0.82
Training loss = 0.015436618030071259
step = 12, Training Accuracy: 0.82
Training loss = 0.013776295483112336
step = 13, Training Accuracy: 0.8066666666666666
Training loss = 0.018506942093372346
step = 14, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.785
49 	5     	0.789792	0.010931  	0.77375	0.80875
pipeline:  [45, 18, 80, 92]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                               'always_apply': False,
                               'eps': 1e-07,
                               'gamma_limit': (80, 120),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1.0,
                               'ratio': (0.75, 1.3333333333333333),
                               'scale': (0.9, 1.0),
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01236364131172498
step = 0, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.79
Training loss = 0.012725013693173727
step = 1, Training Accuracy: 0.8466666666666667
Training loss = 0.011359141419331233
step = 2, Training Accuracy: 0.86
Training loss = 0.01283233920733134
step = 3, Training Accuracy: 0.8333333333333334
Training loss = 0.012138065447409948
step = 4, Training Accuracy: 0.84
Training loss = 0.0114693317313989
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.7875
Training loss = 0.012612598091363907
step = 6, Training Accuracy: 0.8466666666666667
Training loss = 0.012425697594881057
step = 7, Training Accuracy: 0.84
Training loss = 0.013523869961500169
step = 8, Training Accuracy: 0.85
Training loss = 0.012118560671806335
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.011005398233731587
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.79375
Training loss = 0.010173179109891255
step = 11, Training Accuracy: 0.9033333333333333
Training loss = 0.012990330259005228
step = 12, Training Accuracy: 0.83
Training loss = 0.011868148346741995
step = 13, Training Accuracy: 0.8733333333333333
Training loss = 0.012640606115261714
step = 14, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79375
pipeline:  [74, 75, 9, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016161706844965616
step = 0, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.7825
Training loss = 0.014701480269432068
step = 1, Training Accuracy: 0.8033333333333333
Training loss = 0.015679925133784613
step = 2, Training Accuracy: 0.7933333333333333
Training loss = 0.015867856442928315
step = 3, Training Accuracy: 0.8133333333333334
Training loss = 0.01572641630967458
step = 4, Training Accuracy: 0.81
Training loss = 0.017065783242384593
step = 5, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.78
Training loss = 0.014696059624354045
step = 6, Training Accuracy: 0.8333333333333334
Training loss = 0.014869844019412994
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.015919059018294015
step = 8, Training Accuracy: 0.7933333333333333
Training loss = 0.015261503805716833
step = 9, Training Accuracy: 0.7933333333333333
Training loss = 0.014996225337187448
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.78125
Training loss = 0.01636515696843465
step = 11, Training Accuracy: 0.8
Training loss = 0.015076044797897339
step = 12, Training Accuracy: 0.81
Training loss = 0.016065945227940876
step = 13, Training Accuracy: 0.79
Training loss = 0.016089791158835094
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.7825
pipeline:  [65, 63, 79, 26]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022300921082496643
step = 0, Training Accuracy: 0.7033333333333334
Validation Accuracy: 0.77
Training loss = 0.02018274575471878
step = 1, Training Accuracy: 0.7033333333333334
Training loss = 0.01915949136018753
step = 2, Training Accuracy: 0.7333333333333333
Training loss = 0.021528170307477314
step = 3, Training Accuracy: 0.71
Training loss = 0.020136352876822153
step = 4, Training Accuracy: 0.7066666666666667
Training loss = 0.021089430451393127
step = 5, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.775
Training loss = 0.018837817907333375
step = 6, Training Accuracy: 0.7266666666666667
Training loss = 0.02016143133242925
step = 7, Training Accuracy: 0.7266666666666667
Training loss = 0.018053909440835316
step = 8, Training Accuracy: 0.7633333333333333
Training loss = 0.021124800046284992
step = 9, Training Accuracy: 0.72
Training loss = 0.017997388343016306
step = 10, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.775
Training loss = 0.01907495448986689
step = 11, Training Accuracy: 0.7166666666666667
Training loss = 0.019453597962856294
step = 12, Training Accuracy: 0.7433333333333333
Training loss = 0.01941310226917267
step = 13, Training Accuracy: 0.73
Training loss = 0.017144077022870383
step = 14, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.7675
pipeline:  [90, 24, 49, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008705771118402482
step = 0, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.79125
Training loss = 0.009045989662408828
step = 1, Training Accuracy: 0.89
Training loss = 0.010964273810386657
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.008633076300223669
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.010536947200695673
step = 4, Training Accuracy: 0.8733333333333333
Training loss = 0.010140282313028971
step = 5, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.7925
Training loss = 0.009542876183986663
step = 6, Training Accuracy: 0.89
Training loss = 0.009075238853693008
step = 7, Training Accuracy: 0.8866666666666667
Training loss = 0.008167834530274073
step = 8, Training Accuracy: 0.9
Training loss = 0.008596372654040655
step = 9, Training Accuracy: 0.9133333333333333
Training loss = 0.00936622346440951
step = 10, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.79
Training loss = 0.009807547529538472
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.008940969208876291
step = 12, Training Accuracy: 0.8866666666666667
Training loss = 0.010534647603829701
step = 13, Training Accuracy: 0.89
Training loss = 0.009409014135599136
step = 14, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.78375
pipeline:  [79, 55, 59, 36]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009754817585150401
step = 0, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79625
Training loss = 0.00974782332777977
step = 1, Training Accuracy: 0.88
Training loss = 0.010562350849310558
step = 2, Training Accuracy: 0.8766666666666667
Training loss = 0.01013047993183136
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.008738737031817436
step = 4, Training Accuracy: 0.8866666666666667
Training loss = 0.01015173946817716
step = 5, Training Accuracy: 0.89
Validation Accuracy: 0.795
Training loss = 0.009330260008573532
step = 6, Training Accuracy: 0.89
Training loss = 0.00855071410536766
step = 7, Training Accuracy: 0.9033333333333333
Training loss = 0.008366218556960424
step = 8, Training Accuracy: 0.9133333333333333
Training loss = 0.009762936184803644
step = 9, Training Accuracy: 0.8866666666666667
Training loss = 0.009975586632887522
step = 10, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.79875
Training loss = 0.008755921473105749
step = 11, Training Accuracy: 0.89
Training loss = 0.009496138840913772
step = 12, Training Accuracy: 0.8966666666666666
Training loss = 0.00853716477751732
step = 13, Training Accuracy: 0.9166666666666666
Training loss = 0.008797521591186524
step = 14, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.8
50 	5     	0.789375	0.0133219 	0.7675 	0.80875
pipeline:  [90, 24, 49, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010641781737407048
step = 0, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79375
Training loss = 0.00957213302453359
step = 1, Training Accuracy: 0.9
Training loss = 0.009909752657016118
step = 2, Training Accuracy: 0.88
Training loss = 0.009438705146312714
step = 3, Training Accuracy: 0.8866666666666667
Training loss = 0.00963284874955813
step = 4, Training Accuracy: 0.8866666666666667
Training loss = 0.009110201050837834
step = 5, Training Accuracy: 0.88
Validation Accuracy: 0.78875
Training loss = 0.009398272881905237
step = 6, Training Accuracy: 0.9
Training loss = 0.009336982369422913
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.009261702050765356
step = 8, Training Accuracy: 0.8966666666666666
Training loss = 0.008345105697711309
step = 9, Training Accuracy: 0.9066666666666666
Training loss = 0.00980873592197895
step = 10, Training Accuracy: 0.89
Validation Accuracy: 0.79125
Training loss = 0.00918626733124256
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.01048847327629725
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.008329467078049978
step = 13, Training Accuracy: 0.9033333333333333
Training loss = 0.00997807855407397
step = 14, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.79375
pipeline:  [79, 55, 61, 70]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007214401960372925
step = 0, Training Accuracy: 0.93
Validation Accuracy: 0.79375
Training loss = 0.007195083449284235
step = 1, Training Accuracy: 0.9433333333333334
Training loss = 0.0075975177933772405
step = 2, Training Accuracy: 0.9133333333333333
Training loss = 0.0071779598792394
step = 3, Training Accuracy: 0.9266666666666666
Training loss = 0.006852402165532112
step = 4, Training Accuracy: 0.9233333333333333
Training loss = 0.007489242355028789
step = 5, Training Accuracy: 0.93
Validation Accuracy: 0.79
Training loss = 0.007699722250302633
step = 6, Training Accuracy: 0.93
Training loss = 0.0072633312890927
step = 7, Training Accuracy: 0.9333333333333333
Training loss = 0.007587398489316305
step = 8, Training Accuracy: 0.9166666666666666
Training loss = 0.0067312435805797575
step = 9, Training Accuracy: 0.94
Training loss = 0.007696337600549062
step = 10, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.7975
Training loss = 0.007053111791610718
step = 11, Training Accuracy: 0.9366666666666666
Training loss = 0.006739234576622645
step = 12, Training Accuracy: 0.95
Training loss = 0.006260795518755913
step = 13, Training Accuracy: 0.9466666666666667
Training loss = 0.007532180547714234
step = 14, Training Accuracy: 0.92
Validation Accuracy: 0.79375
pipeline:  [0, 41, 46, 50]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02634380618731181
step = 0, Training Accuracy: 0.6
Validation Accuracy: 0.78875
Training loss = 0.026372540295124054
step = 1, Training Accuracy: 0.6233333333333333
Training loss = 0.028543792366981506
step = 2, Training Accuracy: 0.61
Training loss = 0.02402168353398641
step = 3, Training Accuracy: 0.6266666666666667
Training loss = 0.025859210093816122
step = 4, Training Accuracy: 0.6233333333333333
Training loss = 0.024584080576896667
step = 5, Training Accuracy: 0.6366666666666667
Validation Accuracy: 0.77375
Training loss = 0.025833478371302288
step = 6, Training Accuracy: 0.6733333333333333
Training loss = 0.02510944942633311
step = 7, Training Accuracy: 0.6533333333333333
Training loss = 0.02476657787958781
step = 8, Training Accuracy: 0.6533333333333333
Training loss = 0.025972172816594443
step = 9, Training Accuracy: 0.5966666666666667
Training loss = 0.027801689803600312
step = 10, Training Accuracy: 0.64
Validation Accuracy: 0.77125
Training loss = 0.02366112411022186
step = 11, Training Accuracy: 0.65
Training loss = 0.027251990636189778
step = 12, Training Accuracy: 0.6266666666666667
Training loss = 0.025884170333544412
step = 13, Training Accuracy: 0.62
Training loss = 0.025237254897753397
step = 14, Training Accuracy: 0.6466666666666666
Validation Accuracy: 0.77625
pipeline:  [76, 41, 56, 86]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                               'always_apply': False,
                               'p': 0.5,
                               'threshold': (128, 128)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02135905881722768
step = 0, Training Accuracy: 0.72
Validation Accuracy: 0.77875
Training loss = 0.022795596520105998
step = 1, Training Accuracy: 0.7066666666666667
Training loss = 0.02041359504063924
step = 2, Training Accuracy: 0.72
Training loss = 0.024485352238019308
step = 3, Training Accuracy: 0.69
Training loss = 0.022821446359157564
step = 4, Training Accuracy: 0.71
Training loss = 0.023951834241549175
step = 5, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.78625
Training loss = 0.022026119430859883
step = 6, Training Accuracy: 0.6866666666666666
Training loss = 0.02314544955889384
step = 7, Training Accuracy: 0.6933333333333334
Training loss = 0.02284452279408773
step = 8, Training Accuracy: 0.6866666666666666
Training loss = 0.02243393619855245
step = 9, Training Accuracy: 0.6866666666666666
Training loss = 0.022647656997044883
step = 10, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.7825
Training loss = 0.02448980450630188
step = 11, Training Accuracy: 0.7
Training loss = 0.020642083287239075
step = 12, Training Accuracy: 0.7633333333333333
Training loss = 0.020825889706611634
step = 13, Training Accuracy: 0.6933333333333334
Training loss = 0.023073028226693472
step = 14, Training Accuracy: 0.68
Validation Accuracy: 0.78125
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013625159561634063
step = 0, Training Accuracy: 0.83
Validation Accuracy: 0.80125
Training loss = 0.013917454332113267
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.01637694115440051
step = 2, Training Accuracy: 0.8066666666666666
Training loss = 0.012235726614793142
step = 3, Training Accuracy: 0.8533333333333334
Training loss = 0.013855706850687663
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.01342152863740921
step = 5, Training Accuracy: 0.85
Validation Accuracy: 0.79
Training loss = 0.013857617129882177
step = 6, Training Accuracy: 0.8166666666666667
Training loss = 0.013623997469743092
step = 7, Training Accuracy: 0.82
Training loss = 0.013171237011750539
step = 8, Training Accuracy: 0.8333333333333334
Training loss = 0.013171397844950358
step = 9, Training Accuracy: 0.8166666666666667
Training loss = 0.012941740850607553
step = 10, Training Accuracy: 0.87
Validation Accuracy: 0.79375
Training loss = 0.011549187153577804
step = 11, Training Accuracy: 0.84
Training loss = 0.012815864284833273
step = 12, Training Accuracy: 0.8433333333333334
Training loss = 0.012657936215400695
step = 13, Training Accuracy: 0.8533333333333334
Training loss = 0.013051070620616277
step = 14, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.7925
51 	5     	0.786875	0.00683702	0.77625	0.79375
pipeline:  [90, 25, 4, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01001254936059316
step = 0, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.7975
Training loss = 0.010268255869547526
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.00998600775996844
step = 2, Training Accuracy: 0.88
Training loss = 0.010644908646742503
step = 3, Training Accuracy: 0.8466666666666667
Training loss = 0.01010034378618002
step = 4, Training Accuracy: 0.8733333333333333
Training loss = 0.01125533898671468
step = 5, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.79375
Training loss = 0.010736614167690277
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.009903372923533122
step = 7, Training Accuracy: 0.8566666666666667
Training loss = 0.010119883269071579
step = 8, Training Accuracy: 0.8766666666666667
Training loss = 0.01134268765648206
step = 9, Training Accuracy: 0.8633333333333333
Training loss = 0.010225829084714253
step = 10, Training Accuracy: 0.88
Validation Accuracy: 0.79375
Training loss = 0.011336678564548492
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.010928312589724858
step = 12, Training Accuracy: 0.8866666666666667
Training loss = 0.011873528410991032
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.010546641647815705
step = 14, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.79375
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012884407887856166
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.79875
Training loss = 0.012598945697148641
step = 1, Training Accuracy: 0.83
Training loss = 0.011374140481154123
step = 2, Training Accuracy: 0.8766666666666667
Training loss = 0.012424696385860443
step = 3, Training Accuracy: 0.87
Training loss = 0.011915585150321324
step = 4, Training Accuracy: 0.86
Training loss = 0.01255398874481519
step = 5, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.80375
Training loss = 0.01167781169215838
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.01223236545920372
step = 7, Training Accuracy: 0.88
Training loss = 0.01195363829533259
step = 8, Training Accuracy: 0.8533333333333334
Training loss = 0.011733499318361283
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.012675715585549672
step = 10, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.79875
Training loss = 0.01136923183997472
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.011990319093068441
step = 12, Training Accuracy: 0.8733333333333333
Training loss = 0.011252774149179459
step = 13, Training Accuracy: 0.8733333333333333
Training loss = 0.011624706635872523
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.79875
52 	2     	0.792917	0.00448764	0.78375	0.79875
pipeline:  [63, 0, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.021402689317862194
step = 0, Training Accuracy: 0.7
Validation Accuracy: 0.78375
Training loss = 0.02559290607770284
step = 1, Training Accuracy: 0.6766666666666666
Training loss = 0.02505282074213028
step = 2, Training Accuracy: 0.65
Training loss = 0.02317897895971934
step = 3, Training Accuracy: 0.6666666666666666
Training loss = 0.02413802226384481
step = 4, Training Accuracy: 0.6766666666666666
Training loss = 0.0229385511080424
step = 5, Training Accuracy: 0.6633333333333333
Validation Accuracy: 0.7725
Training loss = 0.024952282110850016
step = 6, Training Accuracy: 0.6433333333333333
Training loss = 0.023716604709625243
step = 7, Training Accuracy: 0.6766666666666666
Training loss = 0.025043068329493205
step = 8, Training Accuracy: 0.6233333333333333
Training loss = 0.02267428457736969
step = 9, Training Accuracy: 0.67
Training loss = 0.021706537107626597
step = 10, Training Accuracy: 0.71
Validation Accuracy: 0.7775
Training loss = 0.02475581645965576
step = 11, Training Accuracy: 0.6466666666666666
Training loss = 0.022650114695231118
step = 12, Training Accuracy: 0.6833333333333333
Training loss = 0.024590414961179096
step = 13, Training Accuracy: 0.6266666666666667
Training loss = 0.02314543565114339
step = 14, Training Accuracy: 0.67
Validation Accuracy: 0.775
pipeline:  [1, 24, 49, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009133517841498058
step = 0, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.78125
Training loss = 0.010053872416416804
step = 1, Training Accuracy: 0.9066666666666666
Training loss = 0.009767912775278092
step = 2, Training Accuracy: 0.9033333333333333
Training loss = 0.009107161263624828
step = 3, Training Accuracy: 0.9066666666666666
Training loss = 0.008498194217681885
step = 4, Training Accuracy: 0.9133333333333333
Training loss = 0.008370237946510315
step = 5, Training Accuracy: 0.9
Validation Accuracy: 0.78625
Training loss = 0.007628589272499085
step = 6, Training Accuracy: 0.9133333333333333
Training loss = 0.007978404661019643
step = 7, Training Accuracy: 0.93
Training loss = 0.00938818410038948
step = 8, Training Accuracy: 0.8766666666666667
Training loss = 0.009414043923219045
step = 9, Training Accuracy: 0.9066666666666666
Training loss = 0.008219908128182093
step = 10, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.785
Training loss = 0.010459129214286805
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.008811495378613471
step = 12, Training Accuracy: 0.9066666666666666
Training loss = 0.008403734018405279
step = 13, Training Accuracy: 0.9133333333333333
Training loss = 0.008077985097964605
step = 14, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.78625
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011369803647200267
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.79375
Training loss = 0.010826297601064046
step = 1, Training Accuracy: 0.8966666666666666
Training loss = 0.011599644968907039
step = 2, Training Accuracy: 0.86
Training loss = 0.011372785866260528
step = 3, Training Accuracy: 0.8766666666666667
Training loss = 0.011142509331305821
step = 4, Training Accuracy: 0.88
Training loss = 0.012669421037038168
step = 5, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.795
Training loss = 0.009989336679379145
step = 6, Training Accuracy: 0.89
Training loss = 0.010307752390702566
step = 7, Training Accuracy: 0.91
Training loss = 0.010672619591156642
step = 8, Training Accuracy: 0.8633333333333333
Training loss = 0.011324073175589243
step = 9, Training Accuracy: 0.86
Training loss = 0.010854302992423376
step = 10, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.795
Training loss = 0.01325998067855835
step = 11, Training Accuracy: 0.8133333333333334
Training loss = 0.010620299776395161
step = 12, Training Accuracy: 0.88
Training loss = 0.010550699879725773
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.010748818119366964
step = 14, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.79625
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01084469233949979
step = 0, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.79625
Training loss = 0.012637366453806559
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.010869959394137065
step = 2, Training Accuracy: 0.88
Training loss = 0.010258430192867915
step = 3, Training Accuracy: 0.8833333333333333
Training loss = 0.010110532641410827
step = 4, Training Accuracy: 0.8833333333333333
Training loss = 0.010110973119735718
step = 5, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.79375
Training loss = 0.011112709119915963
step = 6, Training Accuracy: 0.89
Training loss = 0.009840542127688727
step = 7, Training Accuracy: 0.87
Training loss = 0.010437890887260437
step = 8, Training Accuracy: 0.89
Training loss = 0.010496945182482401
step = 9, Training Accuracy: 0.8833333333333333
Training loss = 0.009593889564275742
step = 10, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.795
Training loss = 0.009820434202750524
step = 11, Training Accuracy: 0.8866666666666667
Training loss = 0.010802189111709595
step = 12, Training Accuracy: 0.8866666666666667
Training loss = 0.010282417734464009
step = 13, Training Accuracy: 0.9033333333333333
Training loss = 0.010410666018724441
step = 14, Training Accuracy: 0.88
Validation Accuracy: 0.79375
pipeline:  [31, 6, 75, 49]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015081655730803807
step = 0, Training Accuracy: 0.8
Validation Accuracy: 0.7925
Training loss = 0.01780228426059087
step = 1, Training Accuracy: 0.7733333333333333
Training loss = 0.01865577032168706
step = 2, Training Accuracy: 0.77
Training loss = 0.016978274981180826
step = 3, Training Accuracy: 0.79
Training loss = 0.015409365097681682
step = 4, Training Accuracy: 0.8066666666666666
Training loss = 0.01525133748849233
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.7875
Training loss = 0.014910860856374105
step = 6, Training Accuracy: 0.79
Training loss = 0.015744980374972024
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.015455925464630127
step = 8, Training Accuracy: 0.8133333333333334
Training loss = 0.01649415711561839
step = 9, Training Accuracy: 0.7866666666666666
Training loss = 0.01482771118481954
step = 10, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.78625
Training loss = 0.014010952413082122
step = 11, Training Accuracy: 0.82
Training loss = 0.014205588599046071
step = 12, Training Accuracy: 0.8266666666666667
Training loss = 0.01636914918820063
step = 13, Training Accuracy: 0.78
Training loss = 0.015739064713319144
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.78875
pipeline:  [43, 74, 78, 27]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.Compose',
                               'additional_targets': {},
                               'bbox_params': None,
                               'keypoint_params': None,
                               'p': 1,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                               'always_apply': False,
                                               'height': 128,
                                               'p': 1.0,
                                               'width': 128},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1,
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03115999142328898
step = 0, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.745
Training loss = 0.029911322395006816
step = 1, Training Accuracy: 0.6
Training loss = 0.032106060385704044
step = 2, Training Accuracy: 0.5866666666666667
Training loss = 0.029094003240267435
step = 3, Training Accuracy: 0.63
Training loss = 0.03127624968687693
step = 4, Training Accuracy: 0.62
Training loss = 0.02942107617855072
step = 5, Training Accuracy: 0.5766666666666667
Validation Accuracy: 0.67375
Training loss = 0.030595654050509135
step = 6, Training Accuracy: 0.59
Training loss = 0.028852439324061077
step = 7, Training Accuracy: 0.58
Training loss = 0.027583144108454385
step = 8, Training Accuracy: 0.6433333333333333
Training loss = 0.029930632909139
step = 9, Training Accuracy: 0.58
Training loss = 0.02909805635611216
step = 10, Training Accuracy: 0.62
Validation Accuracy: 0.68875
Training loss = 0.02979731281598409
step = 11, Training Accuracy: 0.6
Training loss = 0.027357255617777507
step = 12, Training Accuracy: 0.6433333333333333
Training loss = 0.027265935937563577
step = 13, Training Accuracy: 0.62
Training loss = 0.02739084462324778
step = 14, Training Accuracy: 0.6433333333333333
Validation Accuracy: 0.675
53 	6     	0.769167	0.0426509 	0.675  	0.79625
pipeline:  [76, 45, 59, 12]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Solarize',
                               'always_apply': False,
                               'p': 0.5,
                               'threshold': (128, 128)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017689478993415834
step = 0, Training Accuracy: 0.8
Validation Accuracy: 0.75875
Training loss = 0.016992515822251638
step = 1, Training Accuracy: 0.79
Training loss = 0.019434326489766438
step = 2, Training Accuracy: 0.7566666666666667
Training loss = 0.02004941423734029
step = 3, Training Accuracy: 0.7466666666666667
Training loss = 0.019540352324644725
step = 4, Training Accuracy: 0.7566666666666667
Training loss = 0.017631872693697613
step = 5, Training Accuracy: 0.77
Validation Accuracy: 0.77375
Training loss = 0.01864146739244461
step = 6, Training Accuracy: 0.7633333333333333
Training loss = 0.01948042869567871
step = 7, Training Accuracy: 0.7366666666666667
Training loss = 0.017800744672616324
step = 8, Training Accuracy: 0.7733333333333333
Training loss = 0.016459374229113262
step = 9, Training Accuracy: 0.7866666666666666
Training loss = 0.021332840820153555
step = 10, Training Accuracy: 0.6966666666666667
Validation Accuracy: 0.76625
Training loss = 0.017460941970348358
step = 11, Training Accuracy: 0.7666666666666667
Training loss = 0.02066219965616862
step = 12, Training Accuracy: 0.7733333333333333
Training loss = 0.018381727933883665
step = 13, Training Accuracy: 0.7733333333333333
Training loss = 0.018163672685623168
step = 14, Training Accuracy: 0.7766666666666666
Validation Accuracy: 0.7775
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011600285569826762
step = 0, Training Accuracy: 0.84
Validation Accuracy: 0.7975
Training loss = 0.011724438965320588
step = 1, Training Accuracy: 0.8833333333333333
Training loss = 0.012631910393635431
step = 2, Training Accuracy: 0.8533333333333334
Training loss = 0.01240591049194336
step = 3, Training Accuracy: 0.8566666666666667
Training loss = 0.011916517615318298
step = 4, Training Accuracy: 0.8366666666666667
Training loss = 0.012330279896656672
step = 5, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.8
Training loss = 0.01123000204563141
step = 6, Training Accuracy: 0.86
Training loss = 0.011304017752408982
step = 7, Training Accuracy: 0.8633333333333333
Training loss = 0.011517663697401682
step = 8, Training Accuracy: 0.86
Training loss = 0.011904064565896988
step = 9, Training Accuracy: 0.8566666666666667
Training loss = 0.011338634788990021
step = 10, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.7975
Training loss = 0.010764842977126439
step = 11, Training Accuracy: 0.87
Training loss = 0.01213535969456037
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.010800948391358058
step = 13, Training Accuracy: 0.86
Training loss = 0.011317020257314046
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.79625
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011585021068652472
step = 0, Training Accuracy: 0.85
Validation Accuracy: 0.79625
Training loss = 0.011514991869529088
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.013164803385734558
step = 2, Training Accuracy: 0.8233333333333334
Training loss = 0.010697677185138067
step = 3, Training Accuracy: 0.8533333333333334
Training loss = 0.012234375476837159
step = 4, Training Accuracy: 0.86
Training loss = 0.013255580067634583
step = 5, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.795
Training loss = 0.011803448647260666
step = 6, Training Accuracy: 0.87
Training loss = 0.012080057164033254
step = 7, Training Accuracy: 0.85
Training loss = 0.011269418895244599
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.011896611154079438
step = 9, Training Accuracy: 0.8466666666666667
Training loss = 0.012663604468107223
step = 10, Training Accuracy: 0.83
Validation Accuracy: 0.79625
Training loss = 0.011716535066564877
step = 11, Training Accuracy: 0.8466666666666667
Training loss = 0.009632296015818914
step = 12, Training Accuracy: 0.8766666666666667
Training loss = 0.010898122539122899
step = 13, Training Accuracy: 0.85
Training loss = 0.011235787173112233
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.79625
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011107098410526912
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.79125
Training loss = 0.013136264284451802
step = 1, Training Accuracy: 0.86
Training loss = 0.012883219172557196
step = 2, Training Accuracy: 0.8333333333333334
Training loss = 0.013007638106743494
step = 3, Training Accuracy: 0.84
Training loss = 0.011449509660402934
step = 4, Training Accuracy: 0.86
Training loss = 0.013446901241938274
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.7925
Training loss = 0.012114254832267761
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.011724114616711934
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.013092396954695384
step = 8, Training Accuracy: 0.8266666666666667
Training loss = 0.010962591469287873
step = 9, Training Accuracy: 0.8866666666666667
Training loss = 0.013724291324615478
step = 10, Training Accuracy: 0.84
Validation Accuracy: 0.79
Training loss = 0.013974916289250057
step = 11, Training Accuracy: 0.85
Training loss = 0.012760579784711202
step = 12, Training Accuracy: 0.8433333333333334
Training loss = 0.01179005483786265
step = 13, Training Accuracy: 0.8566666666666667
Training loss = 0.012427710195382436
step = 14, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.785
54 	4     	0.789167	0.00687184	0.7775 	0.79625
pipeline:  [28, 26, 58, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022025117576122286
step = 0, Training Accuracy: 0.7033333333333334
Validation Accuracy: 0.78375
Training loss = 0.022421387831370036
step = 1, Training Accuracy: 0.6966666666666667
Training loss = 0.02186943620443344
step = 2, Training Accuracy: 0.66
Training loss = 0.02372246911128362
step = 3, Training Accuracy: 0.6633333333333333
Training loss = 0.023338861366113028
step = 4, Training Accuracy: 0.7166666666666667
Training loss = 0.020749210019906362
step = 5, Training Accuracy: 0.7266666666666667
Validation Accuracy: 0.7675
Training loss = 0.023154667814572653
step = 6, Training Accuracy: 0.6833333333333333
Training loss = 0.02115580439567566
step = 7, Training Accuracy: 0.7166666666666667
Training loss = 0.02294196198383967
step = 8, Training Accuracy: 0.69
Training loss = 0.021081874668598174
step = 9, Training Accuracy: 0.7266666666666667
Training loss = 0.019856848915417988
step = 10, Training Accuracy: 0.73
Validation Accuracy: 0.7675
Training loss = 0.021741446554660798
step = 11, Training Accuracy: 0.7
Training loss = 0.02152865062157313
step = 12, Training Accuracy: 0.7366666666666667
Training loss = 0.021685561140378316
step = 13, Training Accuracy: 0.6866666666666666
Training loss = 0.021702252129713693
step = 14, Training Accuracy: 0.6933333333333334
Validation Accuracy: 0.7725
pipeline:  [77, 9, 40, 50]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01301588346560796
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.79
Training loss = 0.011607423772414525
step = 1, Training Accuracy: 0.86
Training loss = 0.0120807766666015
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.01486889123916626
step = 3, Training Accuracy: 0.8266666666666667
Training loss = 0.012373927632967631
step = 4, Training Accuracy: 0.8466666666666667
Training loss = 0.013021998256444931
step = 5, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78875
Training loss = 0.012635691513617833
step = 6, Training Accuracy: 0.85
Training loss = 0.01158915862441063
step = 7, Training Accuracy: 0.8266666666666667
Training loss = 0.013817295630772908
step = 8, Training Accuracy: 0.8333333333333334
Training loss = 0.011633061468601227
step = 9, Training Accuracy: 0.8566666666666667
Training loss = 0.011810472011566162
step = 10, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.78875
Training loss = 0.01539593239625295
step = 11, Training Accuracy: 0.83
Training loss = 0.012786882619063059
step = 12, Training Accuracy: 0.8466666666666667
Training loss = 0.012910286237796147
step = 13, Training Accuracy: 0.8566666666666667
Training loss = 0.014313831925392151
step = 14, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.7825
55 	2     	0.787292	0.00827322	0.7725 	0.79625
pipeline:  [66, 33, 5, 69]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008543014526367188
step = 0, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.795
Training loss = 0.009910330424706142
step = 1, Training Accuracy: 0.8833333333333333
Training loss = 0.009579427639643352
step = 2, Training Accuracy: 0.8933333333333333
Training loss = 0.009486464013655981
step = 3, Training Accuracy: 0.8733333333333333
Training loss = 0.00955550601085027
step = 4, Training Accuracy: 0.8833333333333333
Training loss = 0.00942955528696378
step = 5, Training Accuracy: 0.9
Validation Accuracy: 0.79125
Training loss = 0.009994366317987441
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.009478188802798588
step = 7, Training Accuracy: 0.8966666666666666
Training loss = 0.009735796203215918
step = 8, Training Accuracy: 0.9033333333333333
Training loss = 0.008559582183758418
step = 9, Training Accuracy: 0.89
Training loss = 0.00946384236216545
step = 10, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.79375
Training loss = 0.009734383970499038
step = 11, Training Accuracy: 0.8933333333333333
Training loss = 0.009986965134739876
step = 12, Training Accuracy: 0.89
Training loss = 0.009197098910808563
step = 13, Training Accuracy: 0.9166666666666666
Training loss = 0.010199551930030188
step = 14, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.79125
pipeline:  [39, 45, 64, 0]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.018769269287586213
step = 0, Training Accuracy: 0.7466666666666667
Validation Accuracy: 0.77875
Training loss = 0.023224202791849773
step = 1, Training Accuracy: 0.6833333333333333
Training loss = 0.021206251382827758
step = 2, Training Accuracy: 0.72
Training loss = 0.02073454330364863
step = 3, Training Accuracy: 0.67
Training loss = 0.022926569779713947
step = 4, Training Accuracy: 0.67
Training loss = 0.022702702283859254
step = 5, Training Accuracy: 0.68
Validation Accuracy: 0.7725
Training loss = 0.0214251043399175
step = 6, Training Accuracy: 0.73
Training loss = 0.02055445154507955
step = 7, Training Accuracy: 0.7133333333333334
Training loss = 0.019574701090653738
step = 8, Training Accuracy: 0.76
Training loss = 0.02176977217197418
step = 9, Training Accuracy: 0.7066666666666667
Training loss = 0.02114399383465449
step = 10, Training Accuracy: 0.6966666666666667
Validation Accuracy: 0.775
Training loss = 0.020554846326510112
step = 11, Training Accuracy: 0.72
Training loss = 0.019595330158869426
step = 12, Training Accuracy: 0.71
Training loss = 0.021415832340717315
step = 13, Training Accuracy: 0.6966666666666667
Training loss = 0.019842596352100374
step = 14, Training Accuracy: 0.7066666666666667
Validation Accuracy: 0.7725
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010530973846713702
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.79375
Training loss = 0.011151123344898223
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.010472221473852794
step = 2, Training Accuracy: 0.8666666666666667
Training loss = 0.010588689496119817
step = 3, Training Accuracy: 0.87
Training loss = 0.01124762733777364
step = 4, Training Accuracy: 0.87
Training loss = 0.013102568586667378
step = 5, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79375
Training loss = 0.01143743708729744
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.010142424950997035
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.01099766770998637
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.009874113748470942
step = 9, Training Accuracy: 0.86
Training loss = 0.010743169486522675
step = 10, Training Accuracy: 0.87
Validation Accuracy: 0.79375
Training loss = 0.009639557550350826
step = 11, Training Accuracy: 0.8866666666666667
Training loss = 0.010617534120877584
step = 12, Training Accuracy: 0.8666666666666667
Training loss = 0.010135859698057175
step = 13, Training Accuracy: 0.8733333333333333
Training loss = 0.011895211984713872
step = 14, Training Accuracy: 0.88
Validation Accuracy: 0.795
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012213632961114248
step = 0, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79
Training loss = 0.012079321692387263
step = 1, Training Accuracy: 0.86
Training loss = 0.011074487666289011
step = 2, Training Accuracy: 0.8766666666666667
Training loss = 0.012168263693650564
step = 3, Training Accuracy: 0.83
Training loss = 0.012600706964731217
step = 4, Training Accuracy: 0.8566666666666667
Training loss = 0.01261962652206421
step = 5, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.7975
Training loss = 0.012917907734711964
step = 6, Training Accuracy: 0.8366666666666667
Training loss = 0.0132751535375913
step = 7, Training Accuracy: 0.8266666666666667
Training loss = 0.012029952903588614
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.01289932370185852
step = 9, Training Accuracy: 0.85
Training loss = 0.01120910475651423
step = 10, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79625
Training loss = 0.013789358337720235
step = 11, Training Accuracy: 0.8433333333333334
Training loss = 0.012710470308860144
step = 12, Training Accuracy: 0.84
Training loss = 0.01119753286242485
step = 13, Training Accuracy: 0.8566666666666667
Training loss = 0.012645882169405619
step = 14, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.7925
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010781459758679073
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.7925
Training loss = 0.010710226794083913
step = 1, Training Accuracy: 0.8733333333333333
Training loss = 0.010928057630856832
step = 2, Training Accuracy: 0.8633333333333333
Training loss = 0.010932924846808115
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.010703946004311243
step = 4, Training Accuracy: 0.8766666666666667
Training loss = 0.01003750408689181
step = 5, Training Accuracy: 0.88
Validation Accuracy: 0.79
Training loss = 0.011082598567008972
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.01180623471736908
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.010820084263881048
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.011237125645081203
step = 9, Training Accuracy: 0.88
Training loss = 0.010588284581899643
step = 10, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.79
Training loss = 0.011504913121461869
step = 11, Training Accuracy: 0.8766666666666667
Training loss = 0.01024222731590271
step = 12, Training Accuracy: 0.89
Training loss = 0.011627720395723979
step = 13, Training Accuracy: 0.8566666666666667
Training loss = 0.011317515422900519
step = 14, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.78625
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011336912165085474
step = 0, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.78625
Training loss = 0.011275653143723805
step = 1, Training Accuracy: 0.85
Training loss = 0.011156195551156997
step = 2, Training Accuracy: 0.87
Training loss = 0.011736814628044764
step = 3, Training Accuracy: 0.87
Training loss = 0.011324924478928248
step = 4, Training Accuracy: 0.8866666666666667
Training loss = 0.011942076782385508
step = 5, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.7925
Training loss = 0.012722585052251816
step = 6, Training Accuracy: 0.8466666666666667
Training loss = 0.011822915176550547
step = 7, Training Accuracy: 0.8466666666666667
Training loss = 0.011588673492272696
step = 8, Training Accuracy: 0.87
Training loss = 0.012588777442773183
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.011511090944210689
step = 10, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.78875
Training loss = 0.011019722819328307
step = 11, Training Accuracy: 0.8566666666666667
Training loss = 0.01193360929687818
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.011307357102632523
step = 13, Training Accuracy: 0.8766666666666667
Training loss = 0.011851648340622583
step = 14, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.79125
56 	6     	0.788125	0.00745647	0.7725 	0.795  
pipeline:  [21, 12, 70, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01292592113216718
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78125
Training loss = 0.01351405551036199
step = 1, Training Accuracy: 0.82
Training loss = 0.013584497074286142
step = 2, Training Accuracy: 0.84
Training loss = 0.014085613091786702
step = 3, Training Accuracy: 0.82
Training loss = 0.01429715077082316
step = 4, Training Accuracy: 0.8433333333333334
Training loss = 0.013960244407256444
step = 5, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.78
Training loss = 0.013192080954710642
step = 6, Training Accuracy: 0.8433333333333334
Training loss = 0.0149142191807429
step = 7, Training Accuracy: 0.8266666666666667
Training loss = 0.014076376259326935
step = 8, Training Accuracy: 0.8633333333333333
Training loss = 0.012855538576841354
step = 9, Training Accuracy: 0.8566666666666667
Training loss = 0.014650867680708567
step = 10, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78375
Training loss = 0.012669666210810343
step = 11, Training Accuracy: 0.8466666666666667
Training loss = 0.014274736394484839
step = 12, Training Accuracy: 0.8166666666666667
Training loss = 0.013013076732556025
step = 13, Training Accuracy: 0.84
Training loss = 0.015155641933282216
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78375
pipeline:  [37, 70, 9, 34]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012755082696676254
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78875
Training loss = 0.012529237816731134
step = 1, Training Accuracy: 0.8533333333333334
Training loss = 0.014179370601971945
step = 2, Training Accuracy: 0.85
Training loss = 0.012656111270189285
step = 3, Training Accuracy: 0.8566666666666667
Training loss = 0.013230323990186055
step = 4, Training Accuracy: 0.8666666666666667
Training loss = 0.013282775282859802
step = 5, Training Accuracy: 0.85
Validation Accuracy: 0.78625
Training loss = 0.014916608730951944
step = 6, Training Accuracy: 0.8333333333333334
Training loss = 0.012260082413752874
step = 7, Training Accuracy: 0.8433333333333334
Training loss = 0.01161686472594738
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.011955564717451732
step = 9, Training Accuracy: 0.86
Training loss = 0.015384118556976318
step = 10, Training Accuracy: 0.84
Validation Accuracy: 0.7825
Training loss = 0.01297407438357671
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.011607106079657873
step = 12, Training Accuracy: 0.8766666666666667
Training loss = 0.012837943236033121
step = 13, Training Accuracy: 0.8433333333333334
Training loss = 0.012425648023684819
step = 14, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.79
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01084240476290385
step = 0, Training Accuracy: 0.89
Validation Accuracy: 0.79
Training loss = 0.010513905584812164
step = 1, Training Accuracy: 0.9033333333333333
Training loss = 0.010240946064392726
step = 2, Training Accuracy: 0.8933333333333333
Training loss = 0.010040968060493469
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.010076678494612376
step = 4, Training Accuracy: 0.88
Training loss = 0.010742425819238026
step = 5, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.78625
Training loss = 0.008978044788042705
step = 6, Training Accuracy: 0.8933333333333333
Training loss = 0.011452845136324564
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.010069357355435689
step = 8, Training Accuracy: 0.8933333333333333
Training loss = 0.011977917402982713
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.013248758365710576
step = 10, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.78625
Training loss = 0.010497112572193146
step = 11, Training Accuracy: 0.9
Training loss = 0.011973528563976288
step = 12, Training Accuracy: 0.8566666666666667
Training loss = 0.01088235820333163
step = 13, Training Accuracy: 0.87
Training loss = 0.010438703298568726
step = 14, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.785
57 	3     	0.790208	0.00447311	0.78375	0.795  
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010156675775845846
step = 0, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.7825
Training loss = 0.010773351738850275
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.011330920060475667
step = 2, Training Accuracy: 0.87
Training loss = 0.011410849789778391
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.011121001839637757
step = 4, Training Accuracy: 0.8733333333333333
Training loss = 0.009749432230989138
step = 5, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.78625
Training loss = 0.01109410380323728
step = 6, Training Accuracy: 0.87
Training loss = 0.010149580786625544
step = 7, Training Accuracy: 0.89
Training loss = 0.010854758222897847
step = 8, Training Accuracy: 0.88
Training loss = 0.010880913386742274
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.011249944617350896
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.79
Training loss = 0.011353616466124853
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.010536829034487407
step = 12, Training Accuracy: 0.88
Training loss = 0.009240255653858186
step = 13, Training Accuracy: 0.9
Training loss = 0.010982739379008611
step = 14, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.785
pipeline:  [47, 16, 78, 31]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.Compose',
                               'additional_targets': {},
                               'bbox_params': None,
                               'keypoint_params': None,
                               'p': 1,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                               'always_apply': False,
                                               'height': 128,
                                               'p': 1.0,
                                               'width': 128},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1,
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.03208806812763214
step = 0, Training Accuracy: 0.5833333333333334
Validation Accuracy: 0.68875
Training loss = 0.02996586501598358
step = 1, Training Accuracy: 0.5933333333333334
Training loss = 0.031027268767356873
step = 2, Training Accuracy: 0.62
Training loss = 0.03074934780597687
step = 3, Training Accuracy: 0.61
Training loss = 0.029374069968859353
step = 4, Training Accuracy: 0.62
Training loss = 0.030943294167518617
step = 5, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.55125
Training loss = 0.030320805311203004
step = 6, Training Accuracy: 0.59
Training loss = 0.028341953953107197
step = 7, Training Accuracy: 0.6533333333333333
Training loss = 0.029501753846804302
step = 8, Training Accuracy: 0.6066666666666667
Training loss = 0.0301859978834788
step = 9, Training Accuracy: 0.6166666666666667
Training loss = 0.029119534691174825
step = 10, Training Accuracy: 0.61
Validation Accuracy: 0.5475
Training loss = 0.030406840244928995
step = 11, Training Accuracy: 0.5833333333333334
Training loss = 0.02909711758295695
step = 12, Training Accuracy: 0.6266666666666667
Training loss = 0.026898253758748374
step = 13, Training Accuracy: 0.63
Training loss = 0.02803692102432251
step = 14, Training Accuracy: 0.6166666666666667
Validation Accuracy: 0.5525
pipeline:  [62, 26, 89, 39]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02318506975968679
step = 0, Training Accuracy: 0.6866666666666666
Validation Accuracy: 0.755
Training loss = 0.023086215456326803
step = 1, Training Accuracy: 0.6933333333333334
Training loss = 0.02370574692885081
step = 2, Training Accuracy: 0.7066666666666667
Training loss = 0.024036396344502768
step = 3, Training Accuracy: 0.63
Training loss = 0.02314662973086039
step = 4, Training Accuracy: 0.6866666666666666
Training loss = 0.026287314693133036
step = 5, Training Accuracy: 0.6266666666666667
Validation Accuracy: 0.77
Training loss = 0.021917346715927124
step = 6, Training Accuracy: 0.6966666666666667
Training loss = 0.023955419262250265
step = 7, Training Accuracy: 0.66
Training loss = 0.02395445426305135
step = 8, Training Accuracy: 0.6666666666666666
Training loss = 0.02303110619386037
step = 9, Training Accuracy: 0.6866666666666666
Training loss = 0.02190615713596344
step = 10, Training Accuracy: 0.6833333333333333
Validation Accuracy: 0.76375
Training loss = 0.027229280670483906
step = 11, Training Accuracy: 0.62
Training loss = 0.021909066538016
step = 12, Training Accuracy: 0.7166666666666667
Training loss = 0.02290002167224884
step = 13, Training Accuracy: 0.6633333333333333
Training loss = 0.02374060869216919
step = 14, Training Accuracy: 0.6566666666666666
Validation Accuracy: 0.7675
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012780978083610535
step = 0, Training Accuracy: 0.83
Validation Accuracy: 0.78375
Training loss = 0.012605722149213155
step = 1, Training Accuracy: 0.8366666666666667
Training loss = 0.010414875596761703
step = 2, Training Accuracy: 0.8633333333333333
Training loss = 0.011407759785652161
step = 3, Training Accuracy: 0.8833333333333333
Training loss = 0.012915129860242208
step = 4, Training Accuracy: 0.84
Training loss = 0.011662568698326747
step = 5, Training Accuracy: 0.88
Validation Accuracy: 0.77875
Training loss = 0.01185660794377327
step = 6, Training Accuracy: 0.8733333333333333
Training loss = 0.01020532580713431
step = 7, Training Accuracy: 0.88
Training loss = 0.010487831979990005
step = 8, Training Accuracy: 0.87
Training loss = 0.012543338437875112
step = 9, Training Accuracy: 0.8533333333333334
Training loss = 0.01100241407752037
step = 10, Training Accuracy: 0.87
Validation Accuracy: 0.78
Training loss = 0.01125287706653277
step = 11, Training Accuracy: 0.87
Training loss = 0.011708532571792602
step = 12, Training Accuracy: 0.8366666666666667
Training loss = 0.011655151049296061
step = 13, Training Accuracy: 0.8633333333333333
Training loss = 0.011492569347222646
step = 14, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.785
pipeline:  [81, 83, 40, 2]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00939022183418274
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.785
Training loss = 0.008997720877329508
step = 1, Training Accuracy: 0.88
Training loss = 0.009398933351039886
step = 2, Training Accuracy: 0.9033333333333333
Training loss = 0.008156282864511012
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.008923218647638956
step = 4, Training Accuracy: 0.8933333333333333
Training loss = 0.009365348269542058
step = 5, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.785
Training loss = 0.00859470084309578
step = 6, Training Accuracy: 0.91
Training loss = 0.008258840441703797
step = 7, Training Accuracy: 0.91
Training loss = 0.009442752202351887
step = 8, Training Accuracy: 0.8833333333333333
Training loss = 0.009380123366912206
step = 9, Training Accuracy: 0.87
Training loss = 0.008296133801341057
step = 10, Training Accuracy: 0.91
Validation Accuracy: 0.78
Training loss = 0.008092573334773381
step = 11, Training Accuracy: 0.9033333333333333
Training loss = 0.008694211319088936
step = 12, Training Accuracy: 0.9
Training loss = 0.00866876780986786
step = 13, Training Accuracy: 0.8933333333333333
Training loss = 0.00876146748661995
step = 14, Training Accuracy: 0.9
Validation Accuracy: 0.7825
58 	5     	0.744583	0.0862822 	0.5525 	0.795  
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010063261687755586
step = 0, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.78
Training loss = 0.013817747036616007
step = 1, Training Accuracy: 0.85
Training loss = 0.011619464159011841
step = 2, Training Accuracy: 0.86
Training loss = 0.01216533159216245
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.010622833967208862
step = 4, Training Accuracy: 0.88
Training loss = 0.011767707963784535
step = 5, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.785
Training loss = 0.012785216569900512
step = 6, Training Accuracy: 0.8566666666666667
Training loss = 0.011396547108888625
step = 7, Training Accuracy: 0.8533333333333334
Training loss = 0.011532342831293741
step = 8, Training Accuracy: 0.85
Training loss = 0.011259652574857075
step = 9, Training Accuracy: 0.87
Training loss = 0.010741627017656963
step = 10, Training Accuracy: 0.88
Validation Accuracy: 0.7875
Training loss = 0.011424308717250824
step = 11, Training Accuracy: 0.87
Training loss = 0.011593479663133621
step = 12, Training Accuracy: 0.8733333333333333
Training loss = 0.011901420454184214
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.01230761930346489
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78875
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013659020165602366
step = 0, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78625
Training loss = 0.012226182868083317
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.0122674094637235
step = 2, Training Accuracy: 0.8433333333333334
Training loss = 0.010686744650204976
step = 3, Training Accuracy: 0.8533333333333334
Training loss = 0.011598702371120453
step = 4, Training Accuracy: 0.8533333333333334
Training loss = 0.012060813009738922
step = 5, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.7825
Training loss = 0.012657613555590311
step = 6, Training Accuracy: 0.8533333333333334
Training loss = 0.011273201604684193
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.011800038963556289
step = 8, Training Accuracy: 0.8866666666666667
Training loss = 0.012748500208059947
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.012692475120226542
step = 10, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.7875
Training loss = 0.014194410691658655
step = 11, Training Accuracy: 0.8433333333333334
Training loss = 0.01351910337805748
step = 12, Training Accuracy: 0.8333333333333334
Training loss = 0.011763051251570384
step = 13, Training Accuracy: 0.8433333333333334
Training loss = 0.011631504992643992
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.78125
pipeline:  [60, 71, 10, 65]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009960550914208095
step = 0, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.785
Training loss = 0.011595692882935205
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.01293009916941325
step = 2, Training Accuracy: 0.8466666666666667
Training loss = 0.010718183865149816
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.01168565571308136
step = 4, Training Accuracy: 0.86
Training loss = 0.01173589716355006
step = 5, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78
Training loss = 0.01053043375412623
step = 6, Training Accuracy: 0.9
Training loss = 0.010909070074558259
step = 7, Training Accuracy: 0.8566666666666667
Training loss = 0.011808312088251114
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.010845089008410773
step = 9, Training Accuracy: 0.89
Training loss = 0.011925879716873169
step = 10, Training Accuracy: 0.86
Validation Accuracy: 0.78125
Training loss = 0.011138658573230108
step = 11, Training Accuracy: 0.87
Training loss = 0.01308174138267835
step = 12, Training Accuracy: 0.8666666666666667
Training loss = 0.010067473699649176
step = 13, Training Accuracy: 0.8866666666666667
Training loss = 0.010951651185750961
step = 14, Training Accuracy: 0.88
Validation Accuracy: 0.78
pipeline:  [81, 43, 7, 33]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007956747114658356
step = 0, Training Accuracy: 0.92
Validation Accuracy: 0.7825
Training loss = 0.008263337761163711
step = 1, Training Accuracy: 0.9033333333333333
Training loss = 0.007703886230786642
step = 2, Training Accuracy: 0.9133333333333333
Training loss = 0.007873087922732036
step = 3, Training Accuracy: 0.9166666666666666
Training loss = 0.007356298392017682
step = 4, Training Accuracy: 0.9266666666666666
Training loss = 0.007566317170858383
step = 5, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.7825
Training loss = 0.007282417515913645
step = 6, Training Accuracy: 0.9166666666666666
Training loss = 0.008733721971511841
step = 7, Training Accuracy: 0.9133333333333333
Training loss = 0.007582905019323031
step = 8, Training Accuracy: 0.9266666666666666
Training loss = 0.008308334797620774
step = 9, Training Accuracy: 0.92
Training loss = 0.007699920882781347
step = 10, Training Accuracy: 0.93
Validation Accuracy: 0.78375
Training loss = 0.007992872695128123
step = 11, Training Accuracy: 0.8966666666666666
Training loss = 0.00749971089263757
step = 12, Training Accuracy: 0.9133333333333333
Training loss = 0.00764350729684035
step = 13, Training Accuracy: 0.9166666666666666
Training loss = 0.006905560692151387
step = 14, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.78125
59 	4     	0.785208	0.00527458	0.78   	0.795  
pipeline:  [32, 16, 36, 58]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                               'always_apply': False,
                               'b_shift_limit': (-20, 20),
                               'g_shift_limit': (-20, 20),
                               'p': 0.5,
                               'r_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.OpticalDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.05, 0.05),
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'shift_limit': (-0.05, 0.05),
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01061463495095571
step = 0, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.77375
Training loss = 0.011634709189335506
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.011110557814439138
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.011619984259208044
step = 3, Training Accuracy: 0.8533333333333334
Training loss = 0.01233740563193957
step = 4, Training Accuracy: 0.86
Training loss = 0.011316776871681214
step = 5, Training Accuracy: 0.86
Validation Accuracy: 0.78
Training loss = 0.012178854097922643
step = 6, Training Accuracy: 0.8533333333333334
Training loss = 0.010725285932421684
step = 7, Training Accuracy: 0.87
Training loss = 0.010779811069369316
step = 8, Training Accuracy: 0.86
Training loss = 0.011323265234629313
step = 9, Training Accuracy: 0.8833333333333333
Training loss = 0.010330198307832082
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78125
Training loss = 0.011400715361038843
step = 11, Training Accuracy: 0.86
Training loss = 0.010632424354553223
step = 12, Training Accuracy: 0.8833333333333333
Training loss = 0.011281939645608266
step = 13, Training Accuracy: 0.8833333333333333
Training loss = 0.010448111146688461
step = 14, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.77625
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010419017548362414
step = 0, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.78125
Training loss = 0.011536918034156164
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.01157613197962443
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.009844735910495122
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.010999301274617512
step = 4, Training Accuracy: 0.85
Training loss = 0.011766194105148316
step = 5, Training Accuracy: 0.87
Validation Accuracy: 0.7825
Training loss = 0.01270781526962916
step = 6, Training Accuracy: 0.85
Training loss = 0.009529728045066198
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.010836938122908275
step = 8, Training Accuracy: 0.8766666666666667
Training loss = 0.011547002693017323
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.011630233128865559
step = 10, Training Accuracy: 0.88
Validation Accuracy: 0.77875
Training loss = 0.01081234152118365
step = 11, Training Accuracy: 0.8566666666666667
Training loss = 0.010760505398114522
step = 12, Training Accuracy: 0.8666666666666667
Training loss = 0.01160816306869189
step = 13, Training Accuracy: 0.85
Training loss = 0.01034463365872701
step = 14, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.78375
60 	2     	0.786667	0.00694722	0.77625	0.795  
pipeline:  [66, 77, 31, 12]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00975470374027888
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.785
Training loss = 0.010893717557191849
step = 1, Training Accuracy: 0.86
Training loss = 0.00950346514582634
step = 2, Training Accuracy: 0.88
Training loss = 0.011634246408939362
step = 3, Training Accuracy: 0.86
Training loss = 0.00989266554514567
step = 4, Training Accuracy: 0.9
Training loss = 0.009698731750249863
step = 5, Training Accuracy: 0.8866666666666667
Validation Accuracy: 0.78875
Training loss = 0.009308655261993409
step = 6, Training Accuracy: 0.8966666666666666
Training loss = 0.010424028635025024
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.009940902441740037
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.009378662258386612
step = 9, Training Accuracy: 0.89
Training loss = 0.009698575834433237
step = 10, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.785
Training loss = 0.00944573163986206
step = 11, Training Accuracy: 0.8833333333333333
Training loss = 0.009526497473319372
step = 12, Training Accuracy: 0.8933333333333333
Training loss = 0.0099344868461291
step = 13, Training Accuracy: 0.89
Training loss = 0.009715381612380346
step = 14, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.78875
pipeline:  [77, 28, 89, 71]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011388756483793259
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.79375
Training loss = 0.013006262878576914
step = 1, Training Accuracy: 0.85
Training loss = 0.012171811908483505
step = 2, Training Accuracy: 0.8333333333333334
Training loss = 0.01308037261168162
step = 3, Training Accuracy: 0.8433333333333334
Training loss = 0.012531713744004568
step = 4, Training Accuracy: 0.8466666666666667
Training loss = 0.011048522889614104
step = 5, Training Accuracy: 0.87
Validation Accuracy: 0.7975
Training loss = 0.01173551102479299
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.012253379225730896
step = 7, Training Accuracy: 0.85
Training loss = 0.011043083220720291
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.011424008111159007
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.011110866963863373
step = 10, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.79375
Training loss = 0.012447905639807383
step = 11, Training Accuracy: 0.86
Training loss = 0.010488393356402715
step = 12, Training Accuracy: 0.8766666666666667
Training loss = 0.012618991136550904
step = 13, Training Accuracy: 0.8466666666666667
Training loss = 0.011345295210679372
step = 14, Training Accuracy: 0.85
Validation Accuracy: 0.79375
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010709451586008072
step = 0, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.7875
Training loss = 0.012550579657157262
step = 1, Training Accuracy: 0.85
Training loss = 0.011054461499055227
step = 2, Training Accuracy: 0.8633333333333333
Training loss = 0.012796528140703837
step = 3, Training Accuracy: 0.85
Training loss = 0.01237515226006508
step = 4, Training Accuracy: 0.8466666666666667
Training loss = 0.013123046060403189
step = 5, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79
Training loss = 0.01006904199719429
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.011679134865601858
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.012715904414653778
step = 8, Training Accuracy: 0.85
Training loss = 0.011640308698018392
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.011132327914237976
step = 10, Training Accuracy: 0.86
Validation Accuracy: 0.79125
Training loss = 0.011012359162171682
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.01214232991139094
step = 12, Training Accuracy: 0.8466666666666667
Training loss = 0.011083112359046935
step = 13, Training Accuracy: 0.86
Training loss = 0.011469034999608994
step = 14, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.79
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012688986162344615
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.78375
Training loss = 0.010968194256226221
step = 1, Training Accuracy: 0.87
Training loss = 0.009209280212720236
step = 2, Training Accuracy: 0.92
Training loss = 0.01203192541996638
step = 3, Training Accuracy: 0.85
Training loss = 0.01207371840874354
step = 4, Training Accuracy: 0.8466666666666667
Training loss = 0.012084571818510692
step = 5, Training Accuracy: 0.85
Validation Accuracy: 0.78625
Training loss = 0.01111522614955902
step = 6, Training Accuracy: 0.85
Training loss = 0.01193570946653684
step = 7, Training Accuracy: 0.87
Training loss = 0.012241399685541788
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.011719773014386495
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.0115157117942969
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.7875
Training loss = 0.010511231670777003
step = 11, Training Accuracy: 0.8733333333333333
Training loss = 0.011574540187915166
step = 12, Training Accuracy: 0.8666666666666667
Training loss = 0.011250080068906149
step = 13, Training Accuracy: 0.8533333333333334
Training loss = 0.0103933518131574
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.78125
pipeline:  [22, 77, 75, 14]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                               'always_apply': False,
                               'blur_value': 7,
                               'brightness_coefficient': 0.7,
                               'drop_color': (200, 200, 200),
                               'drop_length': 20,
                               'drop_width': 1,
                               'p': 0.5,
                               'rain_type': None,
                               'slant_lower': -10,
                               'slant_upper': 10},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012563555339972178
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78375
Training loss = 0.012749333381652832
step = 1, Training Accuracy: 0.8333333333333334
Training loss = 0.01154636561870575
step = 2, Training Accuracy: 0.8533333333333334
Training loss = 0.013138492107391358
step = 3, Training Accuracy: 0.8366666666666667
Training loss = 0.011409029116233189
step = 4, Training Accuracy: 0.85
Training loss = 0.011541622479756673
step = 5, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.7725
Training loss = 0.012223233183224996
step = 6, Training Accuracy: 0.86
Training loss = 0.011754362483819326
step = 7, Training Accuracy: 0.8533333333333334
Training loss = 0.014056123693784077
step = 8, Training Accuracy: 0.8266666666666667
Training loss = 0.011912138760089874
step = 9, Training Accuracy: 0.8566666666666667
Training loss = 0.012493153313795725
step = 10, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.77875
Training loss = 0.011142507965366045
step = 11, Training Accuracy: 0.8433333333333334
Training loss = 0.011932093997796376
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.011202387511730194
step = 13, Training Accuracy: 0.87
Training loss = 0.011738284975290298
step = 14, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.78125
61 	5     	0.788333	0.00543267	0.78125	0.795  
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010218201627333959
step = 0, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.79
Training loss = 0.010702731360991796
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.011361088007688522
step = 2, Training Accuracy: 0.8666666666666667
Training loss = 0.009962663402160008
step = 3, Training Accuracy: 0.89
Training loss = 0.010047603746255239
step = 4, Training Accuracy: 0.89
Training loss = 0.00968298946817716
step = 5, Training Accuracy: 0.91
Validation Accuracy: 0.79625
Training loss = 0.010200545738140741
step = 6, Training Accuracy: 0.8733333333333333
Training loss = 0.010244926263888676
step = 7, Training Accuracy: 0.8833333333333333
Training loss = 0.009506593098243078
step = 8, Training Accuracy: 0.9033333333333333
Training loss = 0.011373337904612223
step = 9, Training Accuracy: 0.89
Training loss = 0.011038870910803477
step = 10, Training Accuracy: 0.86
Validation Accuracy: 0.79125
Training loss = 0.009918186217546462
step = 11, Training Accuracy: 0.8866666666666667
Training loss = 0.01152180830637614
step = 12, Training Accuracy: 0.9
Training loss = 0.009950054834286372
step = 13, Training Accuracy: 0.88
Training loss = 0.00978194976846377
step = 14, Training Accuracy: 0.88
Validation Accuracy: 0.79375
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011238493323326111
step = 0, Training Accuracy: 0.86
Validation Accuracy: 0.78625
Training loss = 0.012362096856037775
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.010872860501209895
step = 2, Training Accuracy: 0.85
Training loss = 0.010810114940007528
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.012716928174098334
step = 4, Training Accuracy: 0.8533333333333334
Training loss = 0.010032377491394679
step = 5, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.785
Training loss = 0.01157847950855891
step = 6, Training Accuracy: 0.8733333333333333
Training loss = 0.010532178729772568
step = 7, Training Accuracy: 0.88
Training loss = 0.011093368331591288
step = 8, Training Accuracy: 0.8566666666666667
Training loss = 0.011427484154701233
step = 9, Training Accuracy: 0.85
Training loss = 0.011298913061618805
step = 10, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.78875
Training loss = 0.011316851725180944
step = 11, Training Accuracy: 0.87
Training loss = 0.010640109380086263
step = 12, Training Accuracy: 0.88
Training loss = 0.012171681274970373
step = 13, Training Accuracy: 0.89
Training loss = 0.011392572820186615
step = 14, Training Accuracy: 0.86
Validation Accuracy: 0.7875
pipeline:  [10, 44, 92, 50]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016248454451560975
step = 0, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.78
Training loss = 0.017687076131502787
step = 1, Training Accuracy: 0.7833333333333333
Training loss = 0.01648998151222865
step = 2, Training Accuracy: 0.7766666666666666
Training loss = 0.01962331175804138
step = 3, Training Accuracy: 0.7766666666666666
Training loss = 0.01580621153116226
step = 4, Training Accuracy: 0.7933333333333333
Training loss = 0.018452953497568765
step = 5, Training Accuracy: 0.78
Validation Accuracy: 0.77
Training loss = 0.016592367788155874
step = 6, Training Accuracy: 0.7833333333333333
Training loss = 0.015434905886650085
step = 7, Training Accuracy: 0.8033333333333333
Training loss = 0.01525337999065717
step = 8, Training Accuracy: 0.81
Training loss = 0.016553523341814678
step = 9, Training Accuracy: 0.8033333333333333
Training loss = 0.01546770840883255
step = 10, Training Accuracy: 0.81
Validation Accuracy: 0.775
Training loss = 0.014621496101220448
step = 11, Training Accuracy: 0.8
Training loss = 0.016970257262388867
step = 12, Training Accuracy: 0.7666666666666667
Training loss = 0.01609205961227417
step = 13, Training Accuracy: 0.81
Training loss = 0.015609214107195537
step = 14, Training Accuracy: 0.8
Validation Accuracy: 0.77875
pipeline:  [8, 18, 6, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                               'always_apply': False,
                               'eps': 1e-07,
                               'gamma_limit': (80, 120),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                               'always_apply': False,
                               'color_shift': (0.01, 0.05),
                               'intensity': (0.1, 0.5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015775715410709382
step = 0, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.8
Training loss = 0.014486823081970215
step = 1, Training Accuracy: 0.82
Training loss = 0.016028695901234943
step = 2, Training Accuracy: 0.8166666666666667
Training loss = 0.015460148950417836
step = 3, Training Accuracy: 0.8133333333333334
Training loss = 0.01750736951828003
step = 4, Training Accuracy: 0.7966666666666666
Training loss = 0.01628341575463613
step = 5, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.7925
Training loss = 0.015078450938065847
step = 6, Training Accuracy: 0.8333333333333334
Training loss = 0.017794103423754374
step = 7, Training Accuracy: 0.8033333333333333
Training loss = 0.014724096258481343
step = 8, Training Accuracy: 0.8233333333333334
Training loss = 0.017501540382703146
step = 9, Training Accuracy: 0.8033333333333333
Training loss = 0.017087435374657314
step = 10, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.78625
Training loss = 0.016272690991560618
step = 11, Training Accuracy: 0.8
Training loss = 0.018087091743946074
step = 12, Training Accuracy: 0.7866666666666666
Training loss = 0.01693297525246938
step = 13, Training Accuracy: 0.7766666666666666
Training loss = 0.016400065322717032
step = 14, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.79125
pipeline:  [43, 67, 75, 26]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0200003049770991
step = 0, Training Accuracy: 0.7533333333333333
Validation Accuracy: 0.76875
Training loss = 0.02067793995141983
step = 1, Training Accuracy: 0.7333333333333333
Training loss = 0.020008725623289744
step = 2, Training Accuracy: 0.71
Training loss = 0.02081524024407069
step = 3, Training Accuracy: 0.74
Training loss = 0.01894639740387599
step = 4, Training Accuracy: 0.7466666666666667
Training loss = 0.02038565089305242
step = 5, Training Accuracy: 0.73
Validation Accuracy: 0.76375
Training loss = 0.020195764005184174
step = 6, Training Accuracy: 0.7166666666666667
Training loss = 0.022669005393981933
step = 7, Training Accuracy: 0.69
Training loss = 0.02088609536488851
step = 8, Training Accuracy: 0.71
Training loss = 0.020232700606187183
step = 9, Training Accuracy: 0.7333333333333333
Training loss = 0.02102045476436615
step = 10, Training Accuracy: 0.7166666666666667
Validation Accuracy: 0.7575
Training loss = 0.021674012541770937
step = 11, Training Accuracy: 0.72
Training loss = 0.01710931460062663
step = 12, Training Accuracy: 0.7533333333333333
Training loss = 0.019040649036566416
step = 13, Training Accuracy: 0.7666666666666667
Training loss = 0.020438048541545868
step = 14, Training Accuracy: 0.7366666666666667
Validation Accuracy: 0.76125
62 	5     	0.784583	0.0117186 	0.76125	0.795  
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011185289720694224
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.7875
Training loss = 0.01125234251221021
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.011044224053621291
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.00973480835556984
step = 3, Training Accuracy: 0.88
Training loss = 0.010436337540547054
step = 4, Training Accuracy: 0.8966666666666666
Training loss = 0.01047118753194809
step = 5, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.7925
Training loss = 0.010361340045928955
step = 6, Training Accuracy: 0.8566666666666667
Training loss = 0.010558666537205379
step = 7, Training Accuracy: 0.8533333333333334
Training loss = 0.010339886993169784
step = 8, Training Accuracy: 0.8633333333333333
Training loss = 0.010006299714247385
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.011991830269495646
step = 10, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.7925
Training loss = 0.009968468348185221
step = 11, Training Accuracy: 0.8866666666666667
Training loss = 0.010323226352532704
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.010288196404774984
step = 13, Training Accuracy: 0.88
Training loss = 0.011117538710435231
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.79625
pipeline:  [66, 83, 19, 28]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00966241697470347
step = 0, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.795
Training loss = 0.010617954954504967
step = 1, Training Accuracy: 0.8733333333333333
Training loss = 0.009996320605278015
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.011390276203552882
step = 3, Training Accuracy: 0.86
Training loss = 0.010553007523218791
step = 4, Training Accuracy: 0.87
Training loss = 0.010911097079515457
step = 5, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79125
Training loss = 0.01126442124446233
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.009680549378196398
step = 7, Training Accuracy: 0.9033333333333333
Training loss = 0.010858541876077652
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.00946656455596288
step = 9, Training Accuracy: 0.9033333333333333
Training loss = 0.010947326024373372
step = 10, Training Accuracy: 0.89
Validation Accuracy: 0.7925
Training loss = 0.011615406771500905
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.009762391795714696
step = 12, Training Accuracy: 0.88
Training loss = 0.010614299575487773
step = 13, Training Accuracy: 0.8733333333333333
Training loss = 0.011041062921285628
step = 14, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.795
pipeline:  [66, 89, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.010317640403906505
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.79125
Training loss = 0.009517211616039276
step = 1, Training Accuracy: 0.89
Training loss = 0.01077237476905187
step = 2, Training Accuracy: 0.8766666666666667
Training loss = 0.01014892006913821
step = 3, Training Accuracy: 0.8833333333333333
Training loss = 0.009750889490048091
step = 4, Training Accuracy: 0.8833333333333333
Training loss = 0.009143105496962865
step = 5, Training Accuracy: 0.9
Validation Accuracy: 0.79
Training loss = 0.008888346503178279
step = 6, Training Accuracy: 0.8866666666666667
Training loss = 0.009490208923816681
step = 7, Training Accuracy: 0.91
Training loss = 0.010534428904453913
step = 8, Training Accuracy: 0.8733333333333333
Training loss = 0.011201766679684321
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.01089350958665212
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.79125
Training loss = 0.011981410384178161
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.009587589154640834
step = 12, Training Accuracy: 0.8966666666666666
Training loss = 0.01037651186188062
step = 13, Training Accuracy: 0.8933333333333333
Training loss = 0.01117054616411527
step = 14, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.79625
pipeline:  [80, 90, 69, 82]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                                               'always_apply': False,
                                               'num_bits': (4, 4),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                                               'always_apply': False,
                                               'clip_limit': (1, 4.0),
                                               'p': 0.5,
                                               'tile_grid_size': (8, 8)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                                               'always_apply': False,
                                               'by_channels': True,
                                               'mode': 'cv',
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                                               'always_apply': False,
                                               'color_shift': (0.01, 0.05),
                                               'intensity': (0.1, 0.5),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1.0,
                               'ratio': (0.75, 1.3333333333333333),
                               'scale': (0.9, 1.0),
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014409884512424469
step = 0, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.79
Training loss = 0.0134047665198644
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.013778855949640274
step = 2, Training Accuracy: 0.8333333333333334
Training loss = 0.014106002350648244
step = 3, Training Accuracy: 0.8233333333333334
Training loss = 0.016393596827983855
step = 4, Training Accuracy: 0.8266666666666667
Training loss = 0.01439449300368627
step = 5, Training Accuracy: 0.81
Validation Accuracy: 0.7925
Training loss = 0.016335844248533248
step = 6, Training Accuracy: 0.7966666666666666
Training loss = 0.013964195251464844
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.015273097554842631
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.013877125531435013
step = 9, Training Accuracy: 0.8466666666666667
Training loss = 0.015975919514894486
step = 10, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.785
Training loss = 0.014395131468772889
step = 11, Training Accuracy: 0.82
Training loss = 0.014636157403389612
step = 12, Training Accuracy: 0.8
Training loss = 0.015133155584335327
step = 13, Training Accuracy: 0.8233333333333334
Training loss = 0.015562899485230446
step = 14, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.785
pipeline:  [6, 0, 20, 3]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSnow',
                               'always_apply': False,
                               'brightness_coeff': 2.5,
                               'p': 0.5,
                               'snow_point_lower': 0.1,
                               'snow_point_upper': 0.3},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Equalize',
                               'always_apply': False,
                               'by_channels': True,
                               'mode': 'cv',
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.031547995011011756
step = 0, Training Accuracy: 0.5933333333333334
Validation Accuracy: 0.77875
Training loss = 0.031530664761861164
step = 1, Training Accuracy: 0.57
Training loss = 0.03186322510242462
step = 2, Training Accuracy: 0.5433333333333333
Training loss = 0.031352456212043765
step = 3, Training Accuracy: 0.5533333333333333
Training loss = 0.031256447037061055
step = 4, Training Accuracy: 0.6066666666666667
Training loss = 0.03131098926067352
step = 5, Training Accuracy: 0.5866666666666667
Validation Accuracy: 0.76125
Training loss = 0.03379618585109711
step = 6, Training Accuracy: 0.5633333333333334
Training loss = 0.032778158982594806
step = 7, Training Accuracy: 0.5733333333333334
Training loss = 0.030578503211339314
step = 8, Training Accuracy: 0.57
Training loss = 0.0333401624361674
step = 9, Training Accuracy: 0.5433333333333333
Training loss = 0.03139355440934499
step = 10, Training Accuracy: 0.5866666666666667
Validation Accuracy: 0.7575
Training loss = 0.0325156040986379
step = 11, Training Accuracy: 0.56
Training loss = 0.03071944753328959
step = 12, Training Accuracy: 0.57
Training loss = 0.03265227496623993
step = 13, Training Accuracy: 0.5833333333333334
Training loss = 0.03512519935766856
step = 14, Training Accuracy: 0.53
Validation Accuracy: 0.7575
63 	5     	0.787292	0.013871  	0.7575 	0.79625
pipeline:  [39, 67, 13, 87]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01235319346189499
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.79
Training loss = 0.010800879647334416
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.01194026251633962
step = 2, Training Accuracy: 0.8533333333333334
Training loss = 0.010907031248013179
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.01154580146074295
step = 4, Training Accuracy: 0.87
Training loss = 0.01051295613249143
step = 5, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.78125
Training loss = 0.01058800866206487
step = 6, Training Accuracy: 0.87
Training loss = 0.010804407546917598
step = 7, Training Accuracy: 0.87
Training loss = 0.010163329392671585
step = 8, Training Accuracy: 0.8566666666666667
Training loss = 0.012998323738574982
step = 9, Training Accuracy: 0.8466666666666667
Training loss = 0.012629583378632863
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78875
Training loss = 0.0103524582584699
step = 11, Training Accuracy: 0.8733333333333333
Training loss = 0.010484924912452698
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.01374028280377388
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.010157211472590764
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.785
pipeline:  [26, 41, 46, 72]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomSunFlare',
                               'always_apply': False,
                               'angle_lower': 0,
                               'angle_upper': 1,
                               'flare_roi': (0, 0, 1, 0.5),
                               'num_flare_circles_lower': 6,
                               'num_flare_circles_upper': 10,
                               'p': 0.5,
                               'src_color': (255, 255, 255),
                               'src_radius': 400},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.027863180339336394
step = 0, Training Accuracy: 0.6066666666666667
Validation Accuracy: 0.7725
Training loss = 0.03009964187939962
step = 1, Training Accuracy: 0.5966666666666667
Training loss = 0.031204400062561036
step = 2, Training Accuracy: 0.55
Training loss = 0.03060631553332011
step = 3, Training Accuracy: 0.56
Training loss = 0.02871203124523163
step = 4, Training Accuracy: 0.61
Training loss = 0.03191568911075592
step = 5, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.7575
Training loss = 0.029831048250198364
step = 6, Training Accuracy: 0.6033333333333334
Training loss = 0.029344022870063782
step = 7, Training Accuracy: 0.57
Training loss = 0.03286308904488881
step = 8, Training Accuracy: 0.5766666666666667
Training loss = 0.030136427283287047
step = 9, Training Accuracy: 0.5733333333333334
Training loss = 0.030669941504796346
step = 10, Training Accuracy: 0.5766666666666667
Validation Accuracy: 0.75875
Training loss = 0.027290129860242207
step = 11, Training Accuracy: 0.59
Training loss = 0.029005327224731446
step = 12, Training Accuracy: 0.5866666666666667
Training loss = 0.033765015006065366
step = 13, Training Accuracy: 0.5566666666666666
Training loss = 0.032831941246986386
step = 14, Training Accuracy: 0.5533333333333333
Validation Accuracy: 0.75875
pipeline:  [13, 50, 1, 48]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013340571522712707
step = 0, Training Accuracy: 0.8233333333333334
Validation Accuracy: 0.78625
Training loss = 0.013927267889181773
step = 1, Training Accuracy: 0.8366666666666667
Training loss = 0.013516712685426075
step = 2, Training Accuracy: 0.81
Training loss = 0.01351131538550059
step = 3, Training Accuracy: 0.83
Training loss = 0.013387552201747895
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.012318912545839946
step = 5, Training Accuracy: 0.86
Validation Accuracy: 0.79
Training loss = 0.013889494687318801
step = 6, Training Accuracy: 0.83
Training loss = 0.014249078234036764
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.012177411615848541
step = 8, Training Accuracy: 0.8266666666666667
Training loss = 0.015516118158896764
step = 9, Training Accuracy: 0.8333333333333334
Training loss = 0.013605835537115732
step = 10, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.78875
Training loss = 0.01374620129664739
step = 11, Training Accuracy: 0.8233333333333334
Training loss = 0.01412701020638148
step = 12, Training Accuracy: 0.8233333333333334
Training loss = 0.013801124195257823
step = 13, Training Accuracy: 0.8266666666666667
Training loss = 0.015449240207672119
step = 14, Training Accuracy: 0.81
Validation Accuracy: 0.78875
pipeline:  [24, 43, 62, 64]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomFog',
                               'alpha_coef': 0.08,
                               'always_apply': False,
                               'fog_coef_lower': 0.3,
                               'fog_coef_upper': 1,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015622045695781708
step = 0, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.7825
Training loss = 0.01531869575381279
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.013914919942617416
step = 2, Training Accuracy: 0.82
Training loss = 0.01325615073243777
step = 3, Training Accuracy: 0.8333333333333334
Training loss = 0.014582319557666779
step = 4, Training Accuracy: 0.8466666666666667
Training loss = 0.015648158093293507
step = 5, Training Accuracy: 0.81
Validation Accuracy: 0.785
Training loss = 0.014302671353022257
step = 6, Training Accuracy: 0.8533333333333334
Training loss = 0.01476970613002777
step = 7, Training Accuracy: 0.8133333333333334
Training loss = 0.014678745667139689
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.015316092173258463
step = 9, Training Accuracy: 0.8066666666666666
Training loss = 0.013246992925802866
step = 10, Training Accuracy: 0.85
Validation Accuracy: 0.78375
Training loss = 0.015321419437726339
step = 11, Training Accuracy: 0.8
Training loss = 0.012253203888734182
step = 12, Training Accuracy: 0.84
Training loss = 0.015621608545382817
step = 13, Training Accuracy: 0.8433333333333334
Training loss = 0.013752147257328033
step = 14, Training Accuracy: 0.82
Validation Accuracy: 0.7825
pipeline:  [66, 83, 40, 75]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009913097669680914
step = 0, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.78625
Training loss = 0.009651237378517787
step = 1, Training Accuracy: 0.8866666666666667
Training loss = 0.008915775815645854
step = 2, Training Accuracy: 0.89
Training loss = 0.010020727415879567
step = 3, Training Accuracy: 0.8766666666666667
Training loss = 0.009564219415187836
step = 4, Training Accuracy: 0.8933333333333333
Training loss = 0.010813828309377034
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.78
Training loss = 0.010046901255846024
step = 6, Training Accuracy: 0.8833333333333333
Training loss = 0.008522902627786001
step = 7, Training Accuracy: 0.9033333333333333
Training loss = 0.008772877951463063
step = 8, Training Accuracy: 0.8866666666666667
Training loss = 0.009286137868960698
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.00895415445168813
step = 10, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.785
Training loss = 0.009362195382515589
step = 11, Training Accuracy: 0.8966666666666666
Training loss = 0.008722671990593274
step = 12, Training Accuracy: 0.87
Training loss = 0.009308359374602636
step = 13, Training Accuracy: 0.8733333333333333
Training loss = 0.009529578387737275
step = 14, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.77875
64 	5     	0.781458	0.0113518 	0.75875	0.795  
pipeline:  [66, 83, 19, 28]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011342345426479975
step = 0, Training Accuracy: 0.88
Validation Accuracy: 0.78375
Training loss = 0.010594482670227686
step = 1, Training Accuracy: 0.8833333333333333
Training loss = 0.00967105468114217
step = 2, Training Accuracy: 0.9033333333333333
Training loss = 0.01130738506714503
step = 3, Training Accuracy: 0.8566666666666667
Training loss = 0.010660764674345652
step = 4, Training Accuracy: 0.8933333333333333
Training loss = 0.01086417332291603
step = 5, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78375
Training loss = 0.012980348070462545
step = 6, Training Accuracy: 0.86
Training loss = 0.010309085349241893
step = 7, Training Accuracy: 0.87
Training loss = 0.0117074782649676
step = 8, Training Accuracy: 0.87
Training loss = 0.012418015996615092
step = 9, Training Accuracy: 0.85
Training loss = 0.011308452238639195
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.7825
Training loss = 0.010576365093390147
step = 11, Training Accuracy: 0.8966666666666666
Training loss = 0.011604701280593871
step = 12, Training Accuracy: 0.8633333333333333
Training loss = 0.010890695254007975
step = 13, Training Accuracy: 0.87
Training loss = 0.010824984262386957
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.7825
pipeline:  [47, 39, 92, 22]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                               'always_apply': False,
                               'blur_value': 7,
                               'brightness_coefficient': 0.7,
                               'drop_color': (200, 200, 200),
                               'drop_length': 20,
                               'drop_width': 1,
                               'p': 0.5,
                               'rain_type': None,
                               'slant_lower': -10,
                               'slant_upper': 10},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013338278879721959
step = 0, Training Accuracy: 0.83
Validation Accuracy: 0.77375
Training loss = 0.015529853105545045
step = 1, Training Accuracy: 0.8033333333333333
Training loss = 0.018627226054668426
step = 2, Training Accuracy: 0.7666666666666667
Training loss = 0.014596000015735626
step = 3, Training Accuracy: 0.8033333333333333
Training loss = 0.015660564204057058
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.015050616363684337
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.765
Training loss = 0.015304590761661529
step = 6, Training Accuracy: 0.8133333333333334
Training loss = 0.016624571283658345
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.01715559959411621
step = 8, Training Accuracy: 0.7833333333333333
Training loss = 0.014911166032155355
step = 9, Training Accuracy: 0.82
Training loss = 0.015537737210591634
step = 10, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.76125
Training loss = 0.015488145152727763
step = 11, Training Accuracy: 0.7933333333333333
Training loss = 0.016598784923553468
step = 12, Training Accuracy: 0.8
Training loss = 0.016971430281798046
step = 13, Training Accuracy: 0.8066666666666666
Training loss = 0.016385388473669688
step = 14, Training Accuracy: 0.79
Validation Accuracy: 0.76
pipeline:  [64, 67, 19, 47]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009490044166644415
step = 0, Training Accuracy: 0.91
Validation Accuracy: 0.7875
Training loss = 0.009057655334472656
step = 1, Training Accuracy: 0.9066666666666666
Training loss = 0.008930441985527674
step = 2, Training Accuracy: 0.91
Training loss = 0.009433137116332849
step = 3, Training Accuracy: 0.9
Training loss = 0.009416109323501587
step = 4, Training Accuracy: 0.91
Training loss = 0.008685105542341868
step = 5, Training Accuracy: 0.9266666666666666
Validation Accuracy: 0.79625
Training loss = 0.009256130854288737
step = 6, Training Accuracy: 0.9166666666666666
Training loss = 0.009710156420866648
step = 7, Training Accuracy: 0.9033333333333333
Training loss = 0.00933172141512235
step = 8, Training Accuracy: 0.9133333333333333
Training loss = 0.008890428642431895
step = 9, Training Accuracy: 0.92
Training loss = 0.009350476662317912
step = 10, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.79
Training loss = 0.00902070626616478
step = 11, Training Accuracy: 0.9166666666666666
Training loss = 0.009090692003568013
step = 12, Training Accuracy: 0.9133333333333333
Training loss = 0.009261250446240108
step = 13, Training Accuracy: 0.8933333333333333
Training loss = 0.009692672242720923
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.79375
pipeline:  [47, 59, 79, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00882654016216596
step = 0, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.785
Training loss = 0.009774225056171417
step = 1, Training Accuracy: 0.87
Training loss = 0.010005713601907095
step = 2, Training Accuracy: 0.9066666666666666
Training loss = 0.009658223539590836
step = 3, Training Accuracy: 0.91
Training loss = 0.008937685439984003
step = 4, Training Accuracy: 0.9033333333333333
Training loss = 0.008384115447600683
step = 5, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.77875
Training loss = 0.009495590031147003
step = 6, Training Accuracy: 0.8933333333333333
Training loss = 0.009198909029364585
step = 7, Training Accuracy: 0.9033333333333333
Training loss = 0.010113246937592824
step = 8, Training Accuracy: 0.8933333333333333
Training loss = 0.009246601263682047
step = 9, Training Accuracy: 0.9066666666666666
Training loss = 0.009905154407024384
step = 10, Training Accuracy: 0.89
Validation Accuracy: 0.78
Training loss = 0.009599030961592992
step = 11, Training Accuracy: 0.8966666666666666
Training loss = 0.009191775719324748
step = 12, Training Accuracy: 0.9066666666666666
Training loss = 0.01000159353017807
step = 13, Training Accuracy: 0.8833333333333333
Training loss = 0.00884834090868632
step = 14, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.78
pipeline:  [60, 90, 69, 66]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011710971693197887
step = 0, Training Accuracy: 0.85
Validation Accuracy: 0.78875
Training loss = 0.011248014022906622
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.010808347711960474
step = 2, Training Accuracy: 0.88
Training loss = 0.011813700397809346
step = 3, Training Accuracy: 0.88
Training loss = 0.010838770866394043
step = 4, Training Accuracy: 0.8533333333333334
Training loss = 0.011611777494351069
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.78875
Training loss = 0.010037527730067572
step = 6, Training Accuracy: 0.87
Training loss = 0.011932085851828257
step = 7, Training Accuracy: 0.8433333333333334
Training loss = 0.011493997474511464
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.011476221630970637
step = 9, Training Accuracy: 0.8766666666666667
Training loss = 0.010449801782766978
step = 10, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.78875
Training loss = 0.012932685365279516
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.010369449406862258
step = 12, Training Accuracy: 0.8933333333333333
Training loss = 0.01271852175394694
step = 13, Training Accuracy: 0.8366666666666667
Training loss = 0.01098982070883115
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.7875
pipeline:  [41, 34, 13, 9]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013161398420731227
step = 0, Training Accuracy: 0.8333333333333334
Validation Accuracy: 0.79
Training loss = 0.01228258823355039
step = 1, Training Accuracy: 0.8666666666666667
Training loss = 0.013440669576327006
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.010936914732058843
step = 3, Training Accuracy: 0.8566666666666667
Training loss = 0.014248703022797902
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.015140516658624013
step = 5, Training Accuracy: 0.83
Validation Accuracy: 0.79125
Training loss = 0.012648646235466004
step = 6, Training Accuracy: 0.84
Training loss = 0.014205739100774129
step = 7, Training Accuracy: 0.83
Training loss = 0.014775211215019226
step = 8, Training Accuracy: 0.8133333333333334
Training loss = 0.012207243790229161
step = 9, Training Accuracy: 0.8466666666666667
Training loss = 0.012495278219381968
step = 10, Training Accuracy: 0.86
Validation Accuracy: 0.78375
Training loss = 0.014390470335880916
step = 11, Training Accuracy: 0.8366666666666667
Training loss = 0.013930427730083466
step = 12, Training Accuracy: 0.8366666666666667
Training loss = 0.016205448508262634
step = 13, Training Accuracy: 0.8166666666666667
Training loss = 0.012577826380729676
step = 14, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.79
65 	6     	0.782292	0.0109548 	0.76   	0.79375
pipeline:  [60, 90, 7, 83]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011287386367718378
step = 0, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.78875
Training loss = 0.010728473663330079
step = 1, Training Accuracy: 0.8933333333333333
Training loss = 0.010420585026343663
step = 2, Training Accuracy: 0.88
Training loss = 0.010395997042457262
step = 3, Training Accuracy: 0.8733333333333333
Training loss = 0.01183033714691798
step = 4, Training Accuracy: 0.8566666666666667
Training loss = 0.009819997524221738
step = 5, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.78625
Training loss = 0.011576007008552552
step = 6, Training Accuracy: 0.8533333333333334
Training loss = 0.010547401557366054
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.0128237218161424
step = 8, Training Accuracy: 0.8366666666666667
Training loss = 0.011491416941086451
step = 9, Training Accuracy: 0.8733333333333333
Training loss = 0.010920212070147196
step = 10, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.785
Training loss = 0.010619137783845265
step = 11, Training Accuracy: 0.88
Training loss = 0.011269199252128602
step = 12, Training Accuracy: 0.85
Training loss = 0.010409044524033864
step = 13, Training Accuracy: 0.87
Training loss = 0.010308512399593989
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.7825
pipeline:  [41, 34, 13, 1]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.014501121640205384
step = 0, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78625
Training loss = 0.014406736642122268
step = 1, Training Accuracy: 0.8133333333333334
Training loss = 0.014080231885115306
step = 2, Training Accuracy: 0.83
Training loss = 0.015011503398418426
step = 3, Training Accuracy: 0.8233333333333334
Training loss = 0.014294763704140982
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.014224814673264821
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.7825
Training loss = 0.012467626258730888
step = 6, Training Accuracy: 0.8466666666666667
Training loss = 0.013584610223770142
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.016104134172201155
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.015504182974497478
step = 9, Training Accuracy: 0.81
Training loss = 0.014879962255557377
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.79
Training loss = 0.013133109360933305
step = 11, Training Accuracy: 0.8433333333333334
Training loss = 0.014322429100672404
step = 12, Training Accuracy: 0.8166666666666667
Training loss = 0.01290292114019394
step = 13, Training Accuracy: 0.86
Training loss = 0.015523164669672648
step = 14, Training Accuracy: 0.7933333333333333
Validation Accuracy: 0.78625
pipeline:  [41, 34, 13, 1]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011165994753440222
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.7875
Training loss = 0.010887332856655121
step = 1, Training Accuracy: 0.8866666666666667
Training loss = 0.011023536870876947
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.011202266116937002
step = 3, Training Accuracy: 0.8866666666666667
Training loss = 0.011771626720825832
step = 4, Training Accuracy: 0.85
Training loss = 0.009666552543640137
step = 5, Training Accuracy: 0.89
Validation Accuracy: 0.78875
Training loss = 0.01052504745622476
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.009432200839122136
step = 7, Training Accuracy: 0.8933333333333333
Training loss = 0.012660890420277914
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.011173520237207413
step = 9, Training Accuracy: 0.9
Training loss = 0.01133910745382309
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.79125
Training loss = 0.011235117763280868
step = 11, Training Accuracy: 0.8666666666666667
Training loss = 0.013076893587907156
step = 12, Training Accuracy: 0.85
Training loss = 0.011697170386711756
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.010116704603036245
step = 14, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.78875
pipeline:  [60, 90, 7, 66]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011806535969177882
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.785
Training loss = 0.010244698723157248
step = 1, Training Accuracy: 0.8833333333333333
Training loss = 0.01208057443300883
step = 2, Training Accuracy: 0.87
Training loss = 0.010331416428089142
step = 3, Training Accuracy: 0.8733333333333333
Training loss = 0.010760940536856651
step = 4, Training Accuracy: 0.8766666666666667
Training loss = 0.011626238177220027
step = 5, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.785
Training loss = 0.010348006238540014
step = 6, Training Accuracy: 0.8566666666666667
Training loss = 0.011583972424268722
step = 7, Training Accuracy: 0.8466666666666667
Training loss = 0.010411901275316875
step = 8, Training Accuracy: 0.85
Training loss = 0.011606417347987492
step = 9, Training Accuracy: 0.85
Training loss = 0.011783689657847086
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78375
Training loss = 0.011827654987573624
step = 11, Training Accuracy: 0.86
Training loss = 0.009657611747582754
step = 12, Training Accuracy: 0.8833333333333333
Training loss = 0.011197389662265777
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.010071233262618383
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78375
66 	4     	0.787083	0.00365624	0.7825 	0.79375
pipeline:  [60, 90, 69, 66]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.009334480067094168
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.78
Training loss = 0.010964653094609578
step = 1, Training Accuracy: 0.8633333333333333
Training loss = 0.010018293013175328
step = 2, Training Accuracy: 0.8833333333333333
Training loss = 0.011038902997970581
step = 3, Training Accuracy: 0.8833333333333333
Training loss = 0.010535178532203038
step = 4, Training Accuracy: 0.8766666666666667
Training loss = 0.010184628814458847
step = 5, Training Accuracy: 0.88
Validation Accuracy: 0.78625
Training loss = 0.013146093239386876
step = 6, Training Accuracy: 0.84
Training loss = 0.011391060252984364
step = 7, Training Accuracy: 0.8666666666666667
Training loss = 0.012401935259501139
step = 8, Training Accuracy: 0.8666666666666667
Training loss = 0.011415674686431884
step = 9, Training Accuracy: 0.87
Training loss = 0.012123680313428243
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78375
Training loss = 0.010439585149288177
step = 11, Training Accuracy: 0.8766666666666667
Training loss = 0.010202194154262543
step = 12, Training Accuracy: 0.88
Training loss = 0.010570365389188131
step = 13, Training Accuracy: 0.87
Training loss = 0.00999285822113355
step = 14, Training Accuracy: 0.89
Validation Accuracy: 0.78625
pipeline:  [64, 67, 19, 47]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008225146234035492
step = 0, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.785
Training loss = 0.008899340480566025
step = 1, Training Accuracy: 0.9
Training loss = 0.008773522476355235
step = 2, Training Accuracy: 0.9133333333333333
Training loss = 0.0074703498681386316
step = 3, Training Accuracy: 0.92
Training loss = 0.009639106939236324
step = 4, Training Accuracy: 0.8833333333333333
Training loss = 0.008332241227229436
step = 5, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.7825
Training loss = 0.008478283733129501
step = 6, Training Accuracy: 0.91
Training loss = 0.009058538128932318
step = 7, Training Accuracy: 0.91
Training loss = 0.00855205237865448
step = 8, Training Accuracy: 0.9
Training loss = 0.008756462385257084
step = 9, Training Accuracy: 0.8933333333333333
Training loss = 0.008413866410652797
step = 10, Training Accuracy: 0.91
Validation Accuracy: 0.78375
Training loss = 0.009334816684325536
step = 11, Training Accuracy: 0.9033333333333333
Training loss = 0.007863404899835587
step = 12, Training Accuracy: 0.92
Training loss = 0.009284937431414923
step = 13, Training Accuracy: 0.89
Training loss = 0.008797160486380259
step = 14, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.785
pipeline:  [64, 34, 5, 10]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.013550173292557399
step = 0, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78625
Training loss = 0.01478201856215795
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.013460618009169896
step = 2, Training Accuracy: 0.8433333333333334
Training loss = 0.015564847787221272
step = 3, Training Accuracy: 0.8066666666666666
Training loss = 0.013746988226970036
step = 4, Training Accuracy: 0.8266666666666667
Training loss = 0.01562295804421107
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.78625
Training loss = 0.015232029358545939
step = 6, Training Accuracy: 0.83
Training loss = 0.012606627643108367
step = 7, Training Accuracy: 0.8266666666666667
Training loss = 0.012919728755950927
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.01248902420202891
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.015540550251801809
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.78375
Training loss = 0.014741651614507039
step = 11, Training Accuracy: 0.8166666666666667
Training loss = 0.014928056250015894
step = 12, Training Accuracy: 0.8366666666666667
Training loss = 0.01418971727291743
step = 13, Training Accuracy: 0.8366666666666667
Training loss = 0.013190810928742091
step = 14, Training Accuracy: 0.85
Validation Accuracy: 0.78625
pipeline:  [74, 89, 28, 1]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ToGray',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.020024532477060954
step = 0, Training Accuracy: 0.7566666666666667
Validation Accuracy: 0.785
Training loss = 0.020339743097623188
step = 1, Training Accuracy: 0.7366666666666667
Training loss = 0.018395344018936156
step = 2, Training Accuracy: 0.7366666666666667
Training loss = 0.020842555463314056
step = 3, Training Accuracy: 0.7266666666666667
Training loss = 0.018745531737804414
step = 4, Training Accuracy: 0.76
Training loss = 0.017324551343917846
step = 5, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.77625
Training loss = 0.019181088705857594
step = 6, Training Accuracy: 0.7533333333333333
Training loss = 0.019144045809904735
step = 7, Training Accuracy: 0.7533333333333333
Training loss = 0.0205967648824056
step = 8, Training Accuracy: 0.74
Training loss = 0.01720523198445638
step = 9, Training Accuracy: 0.78
Training loss = 0.017737169464429218
step = 10, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.7775
Training loss = 0.016358098983764648
step = 11, Training Accuracy: 0.78
Training loss = 0.01692649185657501
step = 12, Training Accuracy: 0.79
Training loss = 0.01787841667731603
step = 13, Training Accuracy: 0.7833333333333333
Training loss = 0.0177949117620786
step = 14, Training Accuracy: 0.7966666666666666
Validation Accuracy: 0.77625
pipeline:  [50, 27, 3, 65]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011179863115151723
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.785
Training loss = 0.011943817933400472
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.010952479292949041
step = 2, Training Accuracy: 0.8733333333333333
Training loss = 0.012609227299690247
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.012094218730926514
step = 4, Training Accuracy: 0.8566666666666667
Training loss = 0.012328677227099736
step = 5, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.7875
Training loss = 0.012301121652126313
step = 6, Training Accuracy: 0.85
Training loss = 0.010612502992153168
step = 7, Training Accuracy: 0.8633333333333333
Training loss = 0.009921596944332122
step = 8, Training Accuracy: 0.8833333333333333
Training loss = 0.01250775416692098
step = 9, Training Accuracy: 0.8666666666666667
Training loss = 0.012415918012460073
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.7875
Training loss = 0.012758891185124716
step = 11, Training Accuracy: 0.84
Training loss = 0.012565040638049444
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.011322479148705801
step = 13, Training Accuracy: 0.85
Training loss = 0.011959697306156158
step = 14, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78375
67 	5     	0.785208	0.00512432	0.77625	0.79375
pipeline:  [70, 72, 68, 21]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                               'always_apply': False,
                               'p': 0.5,
                               'var_limit': (10.0, 50.0)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                               'always_apply': False,
                               'grid': (3, 3),
                               'p': 1.0},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02876634180545807
step = 0, Training Accuracy: 0.62
Validation Accuracy: 0.7925
Training loss = 0.03257723967234294
step = 1, Training Accuracy: 0.5833333333333334
Training loss = 0.031045108834902444
step = 2, Training Accuracy: 0.6066666666666667
Training loss = 0.026117722789446515
step = 3, Training Accuracy: 0.6733333333333333
Training loss = 0.02759938359260559
step = 4, Training Accuracy: 0.6433333333333333
Training loss = 0.028636506001154582
step = 5, Training Accuracy: 0.59
Validation Accuracy: 0.7875
Training loss = 0.03069926957289378
step = 6, Training Accuracy: 0.6066666666666667
Training loss = 0.028549436330795288
step = 7, Training Accuracy: 0.56
Training loss = 0.03044553836186727
step = 8, Training Accuracy: 0.6166666666666667
Training loss = 0.03118351221084595
step = 9, Training Accuracy: 0.62
Training loss = 0.03185204823811849
step = 10, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.78375
Training loss = 0.03159014145533244
step = 11, Training Accuracy: 0.5766666666666667
Training loss = 0.032810517350832624
step = 12, Training Accuracy: 0.57
Training loss = 0.029040577212969463
step = 13, Training Accuracy: 0.6333333333333333
Training loss = 0.03007022758324941
step = 14, Training Accuracy: 0.5933333333333334
Validation Accuracy: 0.79
pipeline:  [92, 37, 89, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                                               'always_apply': False,
                                               'max_height': 8,
                                               'max_holes': 8,
                                               'max_width': 8,
                                               'min_height': 8,
                                               'min_holes': 8,
                                               'min_width': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                                               'always_apply': False,
                                               'max_h_size': 8,
                                               'max_w_size': 8,
                                               'num_holes': 8,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGridShuffle',
                                               'always_apply': False,
                                               'grid': (3, 3),
                                               'p': 1.0}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012599272827307384
step = 0, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.79375
Training loss = 0.011511014054218928
step = 1, Training Accuracy: 0.8766666666666667
Training loss = 0.012266600728034973
step = 2, Training Accuracy: 0.86
Training loss = 0.011639672617117564
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.01139306902885437
step = 4, Training Accuracy: 0.8866666666666667
Training loss = 0.011490940923492114
step = 5, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.78375
Training loss = 0.012085962096850077
step = 6, Training Accuracy: 0.8433333333333334
Training loss = 0.012013401438792547
step = 7, Training Accuracy: 0.8733333333333333
Training loss = 0.011722341626882554
step = 8, Training Accuracy: 0.87
Training loss = 0.012478728195031484
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.012942203481992086
step = 10, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.785
Training loss = 0.01193093905846278
step = 11, Training Accuracy: 0.8633333333333333
Training loss = 0.012421017289161682
step = 12, Training Accuracy: 0.86
Training loss = 0.011920870741208395
step = 13, Training Accuracy: 0.84
Training loss = 0.010942625726262728
step = 14, Training Accuracy: 0.86
Validation Accuracy: 0.7875
pipeline:  [64, 67, 19, 47]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008935110469659169
step = 0, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.7825
Training loss = 0.009445158590873082
step = 1, Training Accuracy: 0.9033333333333333
Training loss = 0.008677108486493428
step = 2, Training Accuracy: 0.9033333333333333
Training loss = 0.008939476609230041
step = 3, Training Accuracy: 0.8966666666666666
Training loss = 0.00879735047618548
step = 4, Training Accuracy: 0.8933333333333333
Training loss = 0.00905648539463679
step = 5, Training Accuracy: 0.8966666666666666
Validation Accuracy: 0.78625
Training loss = 0.009173279305299124
step = 6, Training Accuracy: 0.8866666666666667
Training loss = 0.009036142379045486
step = 7, Training Accuracy: 0.8966666666666666
Training loss = 0.008790160417556763
step = 8, Training Accuracy: 0.9
Training loss = 0.00943195124467214
step = 9, Training Accuracy: 0.9133333333333333
Training loss = 0.00918600286046664
step = 10, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.78625
Training loss = 0.008751657158136368
step = 11, Training Accuracy: 0.9166666666666666
Training loss = 0.00948951984445254
step = 12, Training Accuracy: 0.8833333333333333
Training loss = 0.00861537476380666
step = 13, Training Accuracy: 0.91
Training loss = 0.008560876349608103
step = 14, Training Accuracy: 0.9233333333333333
Validation Accuracy: 0.7875
pipeline:  [60, 0, 69, 66]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.InvertImg',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GridDistortion',
                               'always_apply': False,
                               'border_mode': 4,
                               'distort_limit': (-0.3, 0.3),
                               'interpolation': 1,
                               'mask_value': None,
                               'num_steps': 5,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Cutout',
                               'always_apply': False,
                               'max_h_size': 8,
                               'max_w_size': 8,
                               'num_holes': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.02482427517573039
step = 0, Training Accuracy: 0.67
Validation Accuracy: 0.78
Training loss = 0.024042690893014272
step = 1, Training Accuracy: 0.6333333333333333
Training loss = 0.02492800196011861
step = 2, Training Accuracy: 0.6366666666666667
Training loss = 0.02525907536347707
step = 3, Training Accuracy: 0.6733333333333333
Training loss = 0.02597224275271098
step = 4, Training Accuracy: 0.6466666666666666
Training loss = 0.02469530443350474
step = 5, Training Accuracy: 0.6533333333333333
Validation Accuracy: 0.76625
Training loss = 0.025734655261039734
step = 6, Training Accuracy: 0.6266666666666667
Training loss = 0.024844462871551513
step = 7, Training Accuracy: 0.6633333333333333
Training loss = 0.02523346205552419
step = 8, Training Accuracy: 0.6766666666666666
Training loss = 0.02184589872757594
step = 9, Training Accuracy: 0.7033333333333334
Training loss = 0.026323213974634805
step = 10, Training Accuracy: 0.6133333333333333
Validation Accuracy: 0.7725
Training loss = 0.02528683046499888
step = 11, Training Accuracy: 0.6233333333333333
Training loss = 0.025647764007250468
step = 12, Training Accuracy: 0.6433333333333333
Training loss = 0.02531427065531413
step = 13, Training Accuracy: 0.65
Training loss = 0.024457638959089915
step = 14, Training Accuracy: 0.6566666666666666
Validation Accuracy: 0.76875
68 	4     	0.785625	0.00793036	0.76875	0.79375
pipeline:  [64, 30, 2, 38]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CoarseDropout',
                               'always_apply': False,
                               'max_height': 8,
                               'max_holes': 8,
                               'max_width': 8,
                               'min_height': 8,
                               'min_holes': 8,
                               'min_width': 8,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Normalize',
                               'always_apply': False,
                               'max_pixel_value': 255.0,
                               'mean': (0.485, 0.456, 0.406),
                               'p': 1.0,
                               'std': (0.229, 0.224, 0.225)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.0108312592903773
step = 0, Training Accuracy: 0.86
Validation Accuracy: 0.705
Training loss = 0.012658713757991791
step = 1, Training Accuracy: 0.8333333333333334
Training loss = 0.011517278452714285
step = 2, Training Accuracy: 0.8566666666666667
Training loss = 0.009548105299472809
step = 3, Training Accuracy: 0.88
Training loss = 0.010985716084639231
step = 4, Training Accuracy: 0.8633333333333333
Training loss = 0.010975344081719716
step = 5, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.67375
Training loss = 0.011197760303815207
step = 6, Training Accuracy: 0.8666666666666667
Training loss = 0.011298404236634573
step = 7, Training Accuracy: 0.8433333333333334
Training loss = 0.010526986221472422
step = 8, Training Accuracy: 0.86
Training loss = 0.011534851044416428
step = 9, Training Accuracy: 0.8366666666666667
Training loss = 0.011703948279221853
step = 10, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.6725
Training loss = 0.010613686889410019
step = 11, Training Accuracy: 0.8766666666666667
Training loss = 0.012764492680629095
step = 12, Training Accuracy: 0.8466666666666667
Training loss = 0.011416838467121125
step = 13, Training Accuracy: 0.8633333333333333
Training loss = 0.011276210943857829
step = 14, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.6725
pipeline:  [2, 7, 51, 31]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.007297358512878418
step = 0, Training Accuracy: 0.92
Validation Accuracy: 0.74625
Training loss = 0.008165236413478851
step = 1, Training Accuracy: 0.9233333333333333
Training loss = 0.00737673078974088
step = 2, Training Accuracy: 0.9266666666666666
Training loss = 0.00770212230583032
step = 3, Training Accuracy: 0.9266666666666666
Training loss = 0.007168805922071139
step = 4, Training Accuracy: 0.9433333333333334
Training loss = 0.007652183299263318
step = 5, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.78125
Training loss = 0.007499967763821284
step = 6, Training Accuracy: 0.9166666666666666
Training loss = 0.007148318613568942
step = 7, Training Accuracy: 0.9166666666666666
Training loss = 0.006729427327712377
step = 8, Training Accuracy: 0.9266666666666666
Training loss = 0.007417077571153641
step = 9, Training Accuracy: 0.93
Training loss = 0.007182971561948458
step = 10, Training Accuracy: 0.93
Validation Accuracy: 0.7825
Training loss = 0.007356035659710566
step = 11, Training Accuracy: 0.9233333333333333
Training loss = 0.0076586624483267465
step = 12, Training Accuracy: 0.9266666666666666
Training loss = 0.007158271347482999
step = 13, Training Accuracy: 0.9233333333333333
Training loss = 0.007609166031082471
step = 14, Training Accuracy: 0.9333333333333333
Validation Accuracy: 0.78125
pipeline:  [16, 4, 62, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012852956453959147
step = 0, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.7775
Training loss = 0.013465333779652913
step = 1, Training Accuracy: 0.8233333333333334
Training loss = 0.01516707291205724
step = 2, Training Accuracy: 0.8133333333333334
Training loss = 0.013329865336418152
step = 3, Training Accuracy: 0.8333333333333334
Training loss = 0.015341862738132477
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.01396980494260788
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.79
Training loss = 0.01455017348130544
step = 6, Training Accuracy: 0.8233333333333334
Training loss = 0.015305696527163187
step = 7, Training Accuracy: 0.8233333333333334
Training loss = 0.013492753009001414
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.013970520099004109
step = 9, Training Accuracy: 0.8233333333333334
Training loss = 0.013080369134744009
step = 10, Training Accuracy: 0.8366666666666667
Validation Accuracy: 0.78875
Training loss = 0.013001826802889506
step = 11, Training Accuracy: 0.8533333333333334
Training loss = 0.015937062601248424
step = 12, Training Accuracy: 0.78
Training loss = 0.012941221296787262
step = 13, Training Accuracy: 0.8433333333333334
Training loss = 0.01287646715839704
step = 14, Training Accuracy: 0.84
Validation Accuracy: 0.7875
pipeline:  [48, 80, 4, 87]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1.0,
                               'ratio': (0.75, 1.3333333333333333),
                               'scale': (0.9, 1.0),
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.VerticalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HorizontalFlip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRotate90',
                                               'always_apply': False,
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'limit': (-180, 180),
                                               'mask_value': None,
                                               'p': 0.5,
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ShiftScaleRotate',
                                               'always_apply': False,
                                               'border_mode': 4,
                                               'interpolation': 1,
                                               'mask_value': None,
                                               'p': 0.5,
                                               'rotate_limit': (-45, 45),
                                               'scale_limit': (0.0, 0.0),
                                               'shift_limit': (-0.0625, 0.0625),
                                               'value': None},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                                               'always_apply': False,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016313911974430086
step = 0, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.78375
Training loss = 0.017059492468833922
step = 1, Training Accuracy: 0.7933333333333333
Training loss = 0.016563978592554728
step = 2, Training Accuracy: 0.77
Training loss = 0.01623063733180364
step = 3, Training Accuracy: 0.79
Training loss = 0.015407914022604625
step = 4, Training Accuracy: 0.8066666666666666
Training loss = 0.016585303544998167
step = 5, Training Accuracy: 0.81
Validation Accuracy: 0.7875
Training loss = 0.01609032243490219
step = 6, Training Accuracy: 0.8
Training loss = 0.014405892193317414
step = 7, Training Accuracy: 0.8066666666666666
Training loss = 0.015983998775482178
step = 8, Training Accuracy: 0.7966666666666666
Training loss = 0.01611768881479899
step = 9, Training Accuracy: 0.79
Training loss = 0.01741083731253942
step = 10, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.78875
Training loss = 0.01637115071217219
step = 11, Training Accuracy: 0.7833333333333333
Training loss = 0.01830307920773824
step = 12, Training Accuracy: 0.78
Training loss = 0.016339277029037477
step = 13, Training Accuracy: 0.7866666666666666
Training loss = 0.01602308561404546
step = 14, Training Accuracy: 0.7866666666666666
Validation Accuracy: 0.78625
69 	4     	0.7675  	0.0425673 	0.6725 	0.79   
pipeline:  [77, 92, 11, 32]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                               'always_apply': False,
                               'brightness_by_max': True,
                               'brightness_limit': (-0.2, 0.2),
                               'contrast_limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.00969607561826706
step = 0, Training Accuracy: 0.8933333333333333
Validation Accuracy: 0.7875
Training loss = 0.01180673415462176
step = 1, Training Accuracy: 0.86
Training loss = 0.011206282079219818
step = 2, Training Accuracy: 0.8533333333333334
Training loss = 0.011587345699469249
step = 3, Training Accuracy: 0.85
Training loss = 0.01123618647456169
step = 4, Training Accuracy: 0.8666666666666667
Training loss = 0.01081978311141332
step = 5, Training Accuracy: 0.8466666666666667
Validation Accuracy: 0.78
Training loss = 0.011815860172112783
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.013810288856426874
step = 7, Training Accuracy: 0.8566666666666667
Training loss = 0.011235423286755879
step = 8, Training Accuracy: 0.88
Training loss = 0.009873275359471639
step = 9, Training Accuracy: 0.89
Training loss = 0.012116378049055736
step = 10, Training Accuracy: 0.8733333333333333
Validation Accuracy: 0.7825
Training loss = 0.010331326325734457
step = 11, Training Accuracy: 0.87
Training loss = 0.010478224555651347
step = 12, Training Accuracy: 0.8833333333333333
Training loss = 0.011190078059832255
step = 13, Training Accuracy: 0.85
Training loss = 0.010311084787050883
step = 14, Training Accuracy: 0.8833333333333333
Validation Accuracy: 0.77875
pipeline:  [16, 4, 62, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012028380384047827
step = 0, Training Accuracy: 0.86
Validation Accuracy: 0.7875
Training loss = 0.014529081384340921
step = 1, Training Accuracy: 0.82
Training loss = 0.014326892991860707
step = 2, Training Accuracy: 0.8166666666666667
Training loss = 0.014795198142528533
step = 3, Training Accuracy: 0.8233333333333334
Training loss = 0.01410097599029541
step = 4, Training Accuracy: 0.84
Training loss = 0.014719467560450237
step = 5, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.78625
Training loss = 0.013129062354564666
step = 6, Training Accuracy: 0.8466666666666667
Training loss = 0.014083588322003682
step = 7, Training Accuracy: 0.8166666666666667
Training loss = 0.013753754397233328
step = 8, Training Accuracy: 0.8166666666666667
Training loss = 0.016662324368953704
step = 9, Training Accuracy: 0.8233333333333334
Training loss = 0.0127264936765035
step = 10, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.78625
Training loss = 0.013594247500101726
step = 11, Training Accuracy: 0.83
Training loss = 0.014163680672645569
step = 12, Training Accuracy: 0.8366666666666667
Training loss = 0.01291890839735667
step = 13, Training Accuracy: 0.8533333333333334
Training loss = 0.01627636214097341
step = 14, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.7875
pipeline:  [16, 4, 62, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01478129078944524
step = 0, Training Accuracy: 0.8166666666666667
Validation Accuracy: 0.78375
Training loss = 0.013712058365345002
step = 1, Training Accuracy: 0.8033333333333333
Training loss = 0.015849983394145964
step = 2, Training Accuracy: 0.76
Training loss = 0.012762498160203297
step = 3, Training Accuracy: 0.8466666666666667
Training loss = 0.014033254633347193
step = 4, Training Accuracy: 0.81
Training loss = 0.014809093077977498
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.78625
Training loss = 0.01471020003159841
step = 6, Training Accuracy: 0.82
Training loss = 0.011983008682727813
step = 7, Training Accuracy: 0.85
Training loss = 0.0150590251882871
step = 8, Training Accuracy: 0.8066666666666666
Training loss = 0.012972047825654347
step = 9, Training Accuracy: 0.8266666666666667
Training loss = 0.014637793004512787
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.7875
Training loss = 0.011820741643508275
step = 11, Training Accuracy: 0.8766666666666667
Training loss = 0.014059328933556875
step = 12, Training Accuracy: 0.81
Training loss = 0.0130269426604112
step = 13, Training Accuracy: 0.8333333333333334
Training loss = 0.012805396219094595
step = 14, Training Accuracy: 0.83
Validation Accuracy: 0.78875
pipeline:  [2, 33, 8, 52]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ISONoise',
                               'always_apply': False,
                               'color_shift': (0.01, 0.05),
                               'intensity': (0.1, 0.5),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Posterize',
                               'always_apply': False,
                               'num_bits': (4, 4),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Rotate',
                               'always_apply': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'limit': (-180, 180),
                               'mask_value': None,
                               'p': 0.5,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011836083134015402
step = 0, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.78375
Training loss = 0.011682361265023549
step = 1, Training Accuracy: 0.8733333333333333
Training loss = 0.011235436350107193
step = 2, Training Accuracy: 0.86
Training loss = 0.01161321073770523
step = 3, Training Accuracy: 0.8633333333333333
Training loss = 0.013636234203974406
step = 4, Training Accuracy: 0.81
Training loss = 0.012068170607089996
step = 5, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.79125
Training loss = 0.01291443591316541
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.012492628892262776
step = 7, Training Accuracy: 0.8433333333333334
Training loss = 0.012919358511765799
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.012974266062180202
step = 9, Training Accuracy: 0.87
Training loss = 0.014580376893281937
step = 10, Training Accuracy: 0.8533333333333334
Validation Accuracy: 0.785
Training loss = 0.01236489454905192
step = 11, Training Accuracy: 0.8466666666666667
Training loss = 0.01018654003739357
step = 12, Training Accuracy: 0.89
Training loss = 0.012170621752738952
step = 13, Training Accuracy: 0.86
Training loss = 0.01216818963487943
step = 14, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78625
pipeline:  [53, 22, 25, 17]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomRain',
                               'always_apply': False,
                               'blur_value': 7,
                               'brightness_coefficient': 0.7,
                               'drop_color': (200, 200, 200),
                               'drop_length': 20,
                               'drop_width': 1,
                               'p': 0.5,
                               'rain_type': None,
                               'slant_lower': -10,
                               'slant_upper': 10},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.012687854518493016
step = 0, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.78375
Training loss = 0.01252532569070657
step = 1, Training Accuracy: 0.8433333333333334
Training loss = 0.012766070316235225
step = 2, Training Accuracy: 0.84
Training loss = 0.012525027344624202
step = 3, Training Accuracy: 0.8766666666666667
Training loss = 0.011869413008292517
step = 4, Training Accuracy: 0.8466666666666667
Training loss = 0.011878423442443211
step = 5, Training Accuracy: 0.8566666666666667
Validation Accuracy: 0.78875
Training loss = 0.01240159835666418
step = 6, Training Accuracy: 0.8266666666666667
Training loss = 0.01315649171670278
step = 7, Training Accuracy: 0.8633333333333333
Training loss = 0.01355643148223559
step = 8, Training Accuracy: 0.86
Training loss = 0.012942096094290416
step = 9, Training Accuracy: 0.8433333333333334
Training loss = 0.013790903190771739
step = 10, Training Accuracy: 0.8433333333333334
Validation Accuracy: 0.78625
Training loss = 0.014925406475861868
step = 11, Training Accuracy: 0.81
Training loss = 0.011365460654099782
step = 12, Training Accuracy: 0.87
Training loss = 0.014220252533753712
step = 13, Training Accuracy: 0.81
Training loss = 0.010920440902312596
step = 14, Training Accuracy: 0.87
Validation Accuracy: 0.78625
70 	5     	0.785833	0.00328084	0.77875	0.78875
pipeline:  [4, 86, 9, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01309224138657252
step = 0, Training Accuracy: 0.8266666666666667
Validation Accuracy: 0.78875
Training loss = 0.012611009726921717
step = 1, Training Accuracy: 0.8466666666666667
Training loss = 0.011772742494940758
step = 2, Training Accuracy: 0.85
Training loss = 0.01455682228008906
step = 3, Training Accuracy: 0.8233333333333334
Training loss = 0.01307214930653572
step = 4, Training Accuracy: 0.8366666666666667
Training loss = 0.012705373615026473
step = 5, Training Accuracy: 0.83
Validation Accuracy: 0.7875
Training loss = 0.01332078476746877
step = 6, Training Accuracy: 0.8233333333333334
Training loss = 0.013055020173390707
step = 7, Training Accuracy: 0.8366666666666667
Training loss = 0.012575578838586808
step = 8, Training Accuracy: 0.8566666666666667
Training loss = 0.013909571717182795
step = 9, Training Accuracy: 0.8066666666666666
Training loss = 0.012346884210904439
step = 10, Training Accuracy: 0.82
Validation Accuracy: 0.7925
Training loss = 0.012822360197703043
step = 11, Training Accuracy: 0.83
Training loss = 0.014877876987059911
step = 12, Training Accuracy: 0.83
Training loss = 0.014330025414625804
step = 13, Training Accuracy: 0.84
Training loss = 0.013866402804851533
step = 14, Training Accuracy: 0.83
Validation Accuracy: 0.795
pipeline:  [47, 4, 86, 12]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01516979346672694
step = 0, Training Accuracy: 0.84
Validation Accuracy: 0.7925
Training loss = 0.015687892337640126
step = 1, Training Accuracy: 0.7966666666666666
Training loss = 0.01282180999716123
step = 2, Training Accuracy: 0.84
Training loss = 0.014898531089226405
step = 3, Training Accuracy: 0.8333333333333334
Training loss = 0.013527419865131379
step = 4, Training Accuracy: 0.8166666666666667
Training loss = 0.013432099421819051
step = 5, Training Accuracy: 0.8033333333333333
Validation Accuracy: 0.79125
Training loss = 0.013526036242643992
step = 6, Training Accuracy: 0.8266666666666667
Training loss = 0.015738577445348102
step = 7, Training Accuracy: 0.7866666666666666
Training loss = 0.013797339896361033
step = 8, Training Accuracy: 0.7966666666666666
Training loss = 0.014813234110673269
step = 9, Training Accuracy: 0.81
Training loss = 0.012607724368572236
step = 10, Training Accuracy: 0.82
Validation Accuracy: 0.795
Training loss = 0.015202737053235372
step = 11, Training Accuracy: 0.7933333333333333
Training loss = 0.01438404013713201
step = 12, Training Accuracy: 0.81
Training loss = 0.015521624982357025
step = 13, Training Accuracy: 0.7966666666666666
Training loss = 0.014134953518708547
step = 14, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.79125
pipeline:  [16, 72, 62, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelShuffle',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.022665804823239644
step = 0, Training Accuracy: 0.7133333333333334
Validation Accuracy: 0.7775
Training loss = 0.021584098289410273
step = 1, Training Accuracy: 0.71
Training loss = 0.022772954901059468
step = 2, Training Accuracy: 0.7
Training loss = 0.02231782188018163
step = 3, Training Accuracy: 0.6966666666666667
Training loss = 0.024069568514823912
step = 4, Training Accuracy: 0.6666666666666666
Training loss = 0.02145704319079717
step = 5, Training Accuracy: 0.7333333333333333
Validation Accuracy: 0.77125
Training loss = 0.0212205171585083
step = 6, Training Accuracy: 0.74
Training loss = 0.023613099058469138
step = 7, Training Accuracy: 0.7066666666666667
Training loss = 0.023188258210817974
step = 8, Training Accuracy: 0.6933333333333334
Training loss = 0.02581587036450704
step = 9, Training Accuracy: 0.68
Training loss = 0.023177355329195657
step = 10, Training Accuracy: 0.7066666666666667
Validation Accuracy: 0.77125
Training loss = 0.020452584673961004
step = 11, Training Accuracy: 0.7066666666666667
Training loss = 0.026308361291885376
step = 12, Training Accuracy: 0.65
Training loss = 0.025011493563652037
step = 13, Training Accuracy: 0.69
Training loss = 0.020111276507377623
step = 14, Training Accuracy: 0.74
Validation Accuracy: 0.775
pipeline:  [16, 4, 62, 51]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.ElasticTransform',
                               'alpha': 1,
                               'alpha_affine': 50,
                               'always_apply': False,
                               'approximate': False,
                               'border_mode': 4,
                               'interpolation': 1,
                               'mask_value': None,
                               'p': 0.5,
                               'sigma': 50,
                               'value': None},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.016486374189456303
step = 0, Training Accuracy: 0.7633333333333333
Validation Accuracy: 0.79125
Training loss = 0.014695394982894261
step = 1, Training Accuracy: 0.8166666666666667
Training loss = 0.014859046240647635
step = 2, Training Accuracy: 0.83
Training loss = 0.013677079131205876
step = 3, Training Accuracy: 0.8233333333333334
Training loss = 0.014602772891521454
step = 4, Training Accuracy: 0.8233333333333334
Training loss = 0.01635161111752192
step = 5, Training Accuracy: 0.78
Validation Accuracy: 0.79375
Training loss = 0.01482004274924596
step = 6, Training Accuracy: 0.78
Training loss = 0.014780149857203165
step = 7, Training Accuracy: 0.8366666666666667
Training loss = 0.01394637073079745
step = 8, Training Accuracy: 0.82
Training loss = 0.014658962984879812
step = 9, Training Accuracy: 0.8133333333333334
Training loss = 0.017233317991097768
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.79875
Training loss = 0.014660581698020298
step = 11, Training Accuracy: 0.81
Training loss = 0.015105725725491842
step = 12, Training Accuracy: 0.81
Training loss = 0.014768348534901938
step = 13, Training Accuracy: 0.8033333333333333
Training loss = 0.015279618153969447
step = 14, Training Accuracy: 0.8
Validation Accuracy: 0.79375
71 	4     	0.788125	0.00664384	0.775  	0.795  
pipeline:  [29, 79, 65, 41]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.008474392096201579
step = 0, Training Accuracy: 0.9133333333333333
Validation Accuracy: 0.78875
Training loss = 0.008989994625250498
step = 1, Training Accuracy: 0.8866666666666667
Training loss = 0.008472211956977845
step = 2, Training Accuracy: 0.9066666666666666
Training loss = 0.008145506133635839
step = 3, Training Accuracy: 0.91
Training loss = 0.008788269261519115
step = 4, Training Accuracy: 0.9066666666666666
Training loss = 0.008588549296061197
step = 5, Training Accuracy: 0.9033333333333333
Validation Accuracy: 0.78875
Training loss = 0.00800609345237414
step = 6, Training Accuracy: 0.9166666666666666
Training loss = 0.00839721123377482
step = 7, Training Accuracy: 0.91
Training loss = 0.007699849953254064
step = 8, Training Accuracy: 0.9233333333333333
Training loss = 0.00801548530658086
step = 9, Training Accuracy: 0.93
Training loss = 0.009372230917215348
step = 10, Training Accuracy: 0.9066666666666666
Validation Accuracy: 0.79
Training loss = 0.008348748534917832
step = 11, Training Accuracy: 0.8966666666666666
Training loss = 0.009015985826651255
step = 12, Training Accuracy: 0.9
Training loss = 0.009013651013374329
step = 13, Training Accuracy: 0.9066666666666666
Training loss = 0.008076436122258505
step = 14, Training Accuracy: 0.9166666666666666
Validation Accuracy: 0.78875
pipeline:  [48, 90, 9, 92]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Flip',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.GaussNoise',
                                               'always_apply': False,
                                               'p': 0.5,
                                               'var_limit': (10.0, 50.0)}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.017315237919489544
step = 0, Training Accuracy: 0.7666666666666667
Validation Accuracy: 0.7825
Training loss = 0.014558302064736683
step = 1, Training Accuracy: 0.82
Training loss = 0.01586122304201126
step = 2, Training Accuracy: 0.7833333333333333
Training loss = 0.015804798106352488
step = 3, Training Accuracy: 0.79
Training loss = 0.015799136857191722
step = 4, Training Accuracy: 0.8333333333333334
Training loss = 0.01479033132394155
step = 5, Training Accuracy: 0.8133333333333334
Validation Accuracy: 0.7825
Training loss = 0.015217150251070658
step = 6, Training Accuracy: 0.8
Training loss = 0.016066177785396575
step = 7, Training Accuracy: 0.8
Training loss = 0.01619769404331843
step = 8, Training Accuracy: 0.8066666666666666
Training loss = 0.013737059781948726
step = 9, Training Accuracy: 0.83
Training loss = 0.01729149729013443
step = 10, Training Accuracy: 0.8066666666666666
Validation Accuracy: 0.7775
Training loss = 0.01415433277686437
step = 11, Training Accuracy: 0.82
Training loss = 0.015186758836110432
step = 12, Training Accuracy: 0.8266666666666667
Training loss = 0.015790235797564188
step = 13, Training Accuracy: 0.7966666666666666
Training loss = 0.015988944272200267
step = 14, Training Accuracy: 0.7833333333333333
Validation Accuracy: 0.78375
pipeline:  [47, 4, 86, 12]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                               'always_apply': False,
                               'blur_limit': (3, 7),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.011901390999555587
step = 0, Training Accuracy: 0.87
Validation Accuracy: 0.78875
Training loss = 0.011773426632086435
step = 1, Training Accuracy: 0.85
Training loss = 0.01100256621837616
step = 2, Training Accuracy: 0.8866666666666667
Training loss = 0.012754234770933787
step = 3, Training Accuracy: 0.8666666666666667
Training loss = 0.01029864673813184
step = 4, Training Accuracy: 0.89
Training loss = 0.013604180018107096
step = 5, Training Accuracy: 0.84
Validation Accuracy: 0.79125
Training loss = 0.011918962299823761
step = 6, Training Accuracy: 0.8766666666666667
Training loss = 0.012144132157166799
step = 7, Training Accuracy: 0.8766666666666667
Training loss = 0.012354023605585098
step = 8, Training Accuracy: 0.8466666666666667
Training loss = 0.012523834804693858
step = 9, Training Accuracy: 0.84
Training loss = 0.012640798936287561
step = 10, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.79125
Training loss = 0.011572689414024354
step = 11, Training Accuracy: 0.87
Training loss = 0.012026909738779068
step = 12, Training Accuracy: 0.8733333333333333
Training loss = 0.010479554235935211
step = 13, Training Accuracy: 0.89
Training loss = 0.0107574233909448
step = 14, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.79375
pipeline:  [34, 28, 31, 56]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomShadow',
                               'always_apply': False,
                               'num_shadows_lower': 1,
                               'num_shadows_upper': 2,
                               'p': 0.5,
                               'shadow_dimension': 5,
                               'shadow_roi': (0, 0.5, 1, 1)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                               'always_apply': False,
                               'hue_shift_limit': (-20, 20),
                               'p': 0.5,
                               'sat_shift_limit': (-30, 30),
                               'val_shift_limit': (-20, 20)},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Transpose',
                               'always_apply': False,
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.015917064249515535
step = 0, Training Accuracy: 0.78
Validation Accuracy: 0.7925
Training loss = 0.018408428132534026
step = 1, Training Accuracy: 0.81
Training loss = 0.015261688927809398
step = 2, Training Accuracy: 0.8233333333333334
Training loss = 0.014596833089987438
step = 3, Training Accuracy: 0.8133333333333334
Training loss = 0.013712484687566757
step = 4, Training Accuracy: 0.8333333333333334
Training loss = 0.016289187173048655
step = 5, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.785
Training loss = 0.017404048244158428
step = 6, Training Accuracy: 0.7866666666666666
Training loss = 0.016010445257027942
step = 7, Training Accuracy: 0.7866666666666666
Training loss = 0.01481349378824234
step = 8, Training Accuracy: 0.81
Training loss = 0.017119907041390738
step = 9, Training Accuracy: 0.7866666666666666
Training loss = 0.016007027526696523
step = 10, Training Accuracy: 0.8
Validation Accuracy: 0.78375
Training loss = 0.015231062273184458
step = 11, Training Accuracy: 0.8266666666666667
Training loss = 0.016449097047249474
step = 12, Training Accuracy: 0.7833333333333333
Training loss = 0.01514631986618042
step = 13, Training Accuracy: 0.8
Training loss = 0.020029483338197072
step = 14, Training Accuracy: 0.7733333333333333
Validation Accuracy: 0.785
pipeline:  [47, 4, 86, 45]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.CLAHE',
                               'always_apply': False,
                               'clip_limit': (1, 4.0),
                               'p': 0.5,
                               'tile_grid_size': (8, 8)},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightnessContrast',
                                               'always_apply': False,
                                               'brightness_by_max': True,
                                               'brightness_limit': (-0.2, 0.2),
                                               'contrast_limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.HueSaturationValue',
                                               'always_apply': False,
                                               'hue_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'sat_shift_limit': (-30, 30),
                                               'val_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RGBShift',
                                               'always_apply': False,
                                               'b_shift_limit': (-20, 20),
                                               'g_shift_limit': (-20, 20),
                                               'p': 0.5,
                                               'r_shift_limit': (-20, 20)},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomContrast',
                                               'always_apply': False,
                                               'limit': (-0.2, 0.2),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.ChannelDropout',
                                               'always_apply': False,
                                               'channel_drop_range': (1, 1),
                                               'fill_value': 0,
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
Training loss = 0.01105922465523084
step = 0, Training Accuracy: 0.8633333333333333
Validation Accuracy: 0.79625
Training loss = 0.011531203885873158
step = 1, Training Accuracy: 0.8533333333333334
Training loss = 0.013566009898980458
step = 2, Training Accuracy: 0.8466666666666667
Training loss = 0.010214026470979055
step = 3, Training Accuracy: 0.88
Training loss = 0.01103687882423401
step = 4, Training Accuracy: 0.86
Training loss = 0.009689616610606511
step = 5, Training Accuracy: 0.8766666666666667
Validation Accuracy: 0.78625
Training loss = 0.011392800609270731
step = 6, Training Accuracy: 0.8633333333333333
Training loss = 0.014166744351387024
step = 7, Training Accuracy: 0.83
Training loss = 0.012232719262440999
step = 8, Training Accuracy: 0.8433333333333334
Training loss = 0.01130891834696134
step = 9, Training Accuracy: 0.8833333333333333
Training loss = 0.013151046534379323
step = 10, Training Accuracy: 0.82
Validation Accuracy: 0.79
Training loss = 0.011706971377134324
step = 11, Training Accuracy: 0.8533333333333334
Training loss = 0.011208877861499787
step = 12, Training Accuracy: 0.8533333333333334
Training loss = 0.01179064303636551
step = 13, Training Accuracy: 0.8666666666666667
Training loss = 0.010473099450270335
step = 14, Training Accuracy: 0.8666666666666667
Validation Accuracy: 0.79
72 	5     	0.789167	0.00386401	0.78375	0.79375
pipeline:  [92, 38, 83, 31]
{'__version__': '0.4.5',
 'transform': {'__class_fullname__': 'albumentations.core.composition.Compose',
               'additional_targets': {},
               'bbox_params': None,
               'keypoint_params': None,
               'p': 1,
               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 256,
                               'interpolation': 1,
                               'p': 1,
                               'width': 256},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.Blur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MotionBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.MedianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 5),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.GaussianBlur',
                                               'always_apply': False,
                                               'blur_limit': (3, 7),
                                               'p': 0.5},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomGamma',
                                               'always_apply': False,
                                               'eps': 1e-07,
                                               'gamma_limit': (80, 120),
                                               'p': 0.5}]},
                              {'__class_fullname__': 'albumentations.core.composition.OneOf',
                               'p': 0.3,
                               'transforms': [{'__class_fullname__': 'albumentations.core.composition.Compose',
                                               'additional_targets': {},
                                               'bbox_params': None,
                                               'keypoint_params': None,
                                               'p': 1,
                                               'transforms': [{'__class_fullname__': 'albumentations.augmentations.transforms.CenterCrop',
                                                               'always_apply': False,
                                                               'height': 128,
                                                               'p': 1.0,
                                                               'width': 128},
                                                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                                                               'always_apply': False,
                                                               'height': 256,
                                                               'interpolation': 1,
                                                               'p': 1,
                                                               'width': 256}]},
                                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomResizedCrop',
                                               'always_apply': False,
                                               'height': 256,
                                               'interpolation': 1,
                                               'p': 1.0,
                                               'ratio': (0.75,
                                                         1.3333333333333333),
                                               'scale': (0.9, 1.0),
                                               'width': 256}]},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.RandomBrightness',
                               'always_apply': False,
                               'limit': (-0.2, 0.2),
                               'p': 0.5},
                              {'__class_fullname__': 'albumentations.augmentations.transforms.Resize',
                               'always_apply': False,
                               'height': 128,
                               'interpolation': 1,
                               'p': 1,
                               'width': 128},
                              {'__class_fullname__': 'albumentations.pytorch.transforms.ToTensor',
                               'always_apply': True,
                               'normalize': None,
                               'num_classes': 1,
                               'p': 1.0,
                               'sigmoid': True}]}}
