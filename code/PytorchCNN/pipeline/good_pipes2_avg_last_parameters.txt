params:  [0.4490142459033698, 0.906872008571247, 0.7437577467182594, 0.1411380127757988, 0.16809950779819155, 0.44398961156620825, 0.08352045591914029, 0.7926635381367078, 0.5993790294210692, 0.01, 0.01, 0.37938403573485957, 0.8092998567487852, 0.4835028866522604, 0.29692339990821237, 0.38447531587510503, 0.5972251908184385, 0.01, 0.6030854868705384, 0.8171366678656746, 0.47839696352589983, 0.6343932027009406, 0.44182414084762356, 0.13979740695179604, 0.6539802299340068, 0.01, 0.5986253328979053, 0.306366667056654, 0.34947288692463907, 0.25745191913204374, 0.6522112422102135, 0.99, 0.6071337714535239, 0.22912326480441214, 0.13409843364874643, 0.99, 0.41029779486023976, 0.99, 0.99, 0.01, 0.9693930967442018, 0.03925218826701454, 0.5114109699397907, 0.35841868165252416, 0.3618083687120638, 0.11738007081492072, 0.01, 0.18226710985403932, 0.07630888959941257, 0.01, 0.5942741997785822, 0.1961506638996729, 0.08131374122770821, 0.01, 0.01, 0.2998614087425375, 0.16028107392892293, 0.3609746921562613, 0.36276801307578943, 0.059157684219514395, 0.99, 0.9737638446522174, 0.2630922462485792, 0.4853095431385548, 0.7902422902557409, 0.6943065614302077, 0.2918540429819779, 0.7730279640097995, 0.3535917947397105, 0.4096688913232134, 0.01, 0.4653055152835278, 0.25141048435699115, 0.7215399739986231, 0.5590583707607371, 0.06821085199713756, 0.01, 0.5293257451680933, 0.01, 0.7467634736309567, 0.18268672131322988, 0.4959508325786198, 0.99, 0.31948801633118096, 0.41249187506201695, 0.06980839302435851, 0.6127094055037016, 0.01, 0.13327677691295983, 0.08668518264244521, 0.01, 0.7905934971598667]
[0.4490142459033698, 0.906872008571247, 0.7437577467182594, 0.1411380127757988, 0.16809950779819155, 0.44398961156620825, 0.08352045591914029, 0.7926635381367078, 0.5993790294210692, 0.01, 0.01, 0.37938403573485957, 0.8092998567487852, 0.4835028866522604, 0.29692339990821237, 0.38447531587510503, 0.5972251908184385, 0.01, 0.6030854868705384, 0.8171366678656746, 0.47839696352589983, 0.6343932027009406, 0.44182414084762356, 0.13979740695179604, 0.6539802299340068, 0.01, 0.5986253328979053, 0.306366667056654, 0.34947288692463907, 0.25745191913204374, 0.6522112422102135, 0.99, 0.6071337714535239, 0.22912326480441214, 0.13409843364874643, 0.99, 0.41029779486023976, 0.99, 0.99, 0.01, 0.9693930967442018, 0.03925218826701454, 0.5114109699397907, 0.35841868165252416, 0.3618083687120638, 0.11738007081492072, 0.01, 0.18226710985403932, 0.07630888959941257, 0.01, 0.5942741997785822, 0.1961506638996729, 0.08131374122770821, 0.01, 0.01, 0.2998614087425375, 0.16028107392892293, 0.3609746921562613, 0.36276801307578943, 0.059157684219514395, 0.99, 0.9737638446522174, 0.2630922462485792, 0.4853095431385548, 0.7902422902557409, 0.6943065614302077, 0.2918540429819779, 0.7730279640097995, 0.3535917947397105, 0.4096688913232134, 0.01, 0.4653055152835278, 0.25141048435699115, 0.7215399739986231, 0.5590583707607371, 0.06821085199713756, 0.01, 0.5293257451680933, 0.01, 0.7467634736309567, 0.18268672131322988, 0.4959508325786198, 0.99, 0.31948801633118096, 0.41249187506201695, 0.06980839302435851, 0.6127094055037016, 0.01, 0.13327677691295983, 0.08668518264244521, 0.01, 0.7905934971598667]
Training loss = 0.04677741289138794
step = 0, Training Accuracy: 0.32
Validation Accuracy: 0.33
Training loss = 0.044268818696339925
step = 1, Training Accuracy: 0.3566666666666667
Training loss = 0.046137465238571165
step = 2, Training Accuracy: 0.31333333333333335
Training loss = 0.04245965639750163
step = 3, Training Accuracy: 0.3566666666666667
Training loss = 0.04359933972358704
step = 4, Training Accuracy: 0.3566666666666667
Training loss = 0.039510916471481326
step = 5, Training Accuracy: 0.38333333333333336
Validation Accuracy: 0.43875
Training loss = 0.038402790228525795
step = 6, Training Accuracy: 0.3466666666666667
Training loss = 0.037714494864145916
step = 7, Training Accuracy: 0.38666666666666666
Training loss = 0.03881119867165883
step = 8, Training Accuracy: 0.37666666666666665
Training loss = 0.03665667394797007
step = 9, Training Accuracy: 0.4
Training loss = 0.0369822092851003
step = 10, Training Accuracy: 0.38666666666666666
Validation Accuracy: 0.45625
Training loss = 0.0357349960009257
step = 11, Training Accuracy: 0.42
Training loss = 0.03734394292036692
step = 12, Training Accuracy: 0.37666666666666665
Training loss = 0.036284645001093546
step = 13, Training Accuracy: 0.41
Training loss = 0.0358935151497523
step = 14, Training Accuracy: 0.42333333333333334
Validation Accuracy: 0.4325
params:  [0.08938407183679428, 0.6421498762735363, 0.99, 0.2856945745920897, 0.5879217419896043, 0.5693634137136544, 0.02326531079918004, 0.6039344628490927, 0.575147855103763, 0.09909540196995581, 0.20658246968506927, 0.01, 0.12891478673657542, 0.5345468615331931, 0.577964838274527, 0.5553901575596912, 0.01775502963163178, 0.8921428262847284, 0.5682379803812388, 0.13074070506981345, 0.14260895083920544, 0.5302994159234822, 0.04092883226513688, 0.5694587144560689, 0.24285273307511523, 0.2289373177315637, 0.99, 0.01, 0.9360602231471951, 0.5039005675633721, 0.99, 0.99, 0.6023455924449932, 0.01, 0.17686948717576875, 0.733145671112343, 0.27387915069275315, 0.9263835651991389, 0.99, 0.546618047998347, 0.6238342780809495, 0.3390128387732965, 0.01, 0.5975786737022213, 0.7440551652109009, 0.23671487847163064, 0.06502401229912888, 0.9889726337455859, 0.49204583736523494, 0.01, 0.47766622527014985, 0.5772651172168293, 0.30237334384955167, 0.99, 0.6209025616097149, 0.17888701377292454, 0.05931681923351434, 0.3971856450419692, 0.0738064031703923, 0.01, 0.9296238599874559, 0.5015340369927382, 0.4116499149873001, 0.6443916386749284, 0.01, 0.3823675540603527, 0.23503468935400285, 0.35140239631564124, 0.27562504389899656, 0.9649803215052618, 0.2904642027000838, 0.22417272972985908, 0.34207772919055446, 0.18130888588216854, 0.5205688924418082, 0.01, 0.3156239704318069, 0.49656207619295906, 0.13011068111916843, 0.2028391024607935, 0.99, 0.6760571281400811, 0.07944468116231573, 0.9208382932808297, 0.22718376356157832, 0.48730958411291403, 0.7255799098060323, 0.40534684435450613, 0.01, 0.239586469088427, 0.01, 0.6447417245729556]
[0.08938407183679428, 0.6421498762735363, 0.99, 0.2856945745920897, 0.5879217419896043, 0.5693634137136544, 0.02326531079918004, 0.6039344628490927, 0.575147855103763, 0.09909540196995581, 0.20658246968506927, 0.01, 0.12891478673657542, 0.5345468615331931, 0.577964838274527, 0.5553901575596912, 0.01775502963163178, 0.8921428262847284, 0.5682379803812388, 0.13074070506981345, 0.14260895083920544, 0.5302994159234822, 0.04092883226513688, 0.5694587144560689, 0.24285273307511523, 0.2289373177315637, 0.99, 0.01, 0.9360602231471951, 0.5039005675633721, 0.99, 0.99, 0.6023455924449932, 0.01, 0.17686948717576875, 0.733145671112343, 0.27387915069275315, 0.9263835651991389, 0.99, 0.546618047998347, 0.6238342780809495, 0.3390128387732965, 0.01, 0.5975786737022213, 0.7440551652109009, 0.23671487847163064, 0.06502401229912888, 0.9889726337455859, 0.49204583736523494, 0.01, 0.47766622527014985, 0.5772651172168293, 0.30237334384955167, 0.99, 0.6209025616097149, 0.17888701377292454, 0.05931681923351434, 0.3971856450419692, 0.0738064031703923, 0.01, 0.9296238599874559, 0.5015340369927382, 0.4116499149873001, 0.6443916386749284, 0.01, 0.3823675540603527, 0.23503468935400285, 0.35140239631564124, 0.27562504389899656, 0.9649803215052618, 0.2904642027000838, 0.22417272972985908, 0.34207772919055446, 0.18130888588216854, 0.5205688924418082, 0.01, 0.3156239704318069, 0.49656207619295906, 0.13011068111916843, 0.2028391024607935, 0.99, 0.6760571281400811, 0.07944468116231573, 0.9208382932808297, 0.22718376356157832, 0.48730958411291403, 0.7255799098060323, 0.40534684435450613, 0.01, 0.239586469088427, 0.01, 0.6447417245729556]
Training loss = 0.03609413584073384
step = 0, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.445
Training loss = 0.03498804728190104
step = 1, Training Accuracy: 0.4266666666666667
Training loss = 0.03604004283746084
step = 2, Training Accuracy: 0.43
Training loss = 0.0344263615210851
step = 3, Training Accuracy: 0.45
Training loss = 0.035183647076288856
step = 4, Training Accuracy: 0.46
Training loss = 0.03527188301086426
step = 5, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.4525
Training loss = 0.03462645709514618
step = 6, Training Accuracy: 0.43666666666666665
Training loss = 0.03548800031344096
step = 7, Training Accuracy: 0.43
Training loss = 0.03442611674467722
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03329609791437785
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.034329182902971905
step = 10, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.48125
Training loss = 0.0354242604970932
step = 11, Training Accuracy: 0.43333333333333335
Training loss = 0.03333176016807556
step = 12, Training Accuracy: 0.5
Training loss = 0.03327489058176676
step = 13, Training Accuracy: 0.5
Training loss = 0.03401241262753805
step = 14, Training Accuracy: 0.48
Validation Accuracy: 0.47875
params:  [0.23296116440224474, 0.6214945132882866, 0.99, 0.30400123022788644, 0.35751640665171314, 0.3993369338130689, 0.01, 0.7597265582510364, 0.6514961836941371, 0.01, 0.01, 0.35573000043886716, 0.3014640605694836, 0.3559362944308283, 0.01, 0.6901757066954034, 0.99, 0.3045198957182549, 0.5136715519711441, 0.5649375768745925, 0.12173481369948647, 0.6086919174497661, 0.9699801924371232, 0.6430729114986773, 0.5030699183058761, 0.39018623904854977, 0.06924135464616821, 0.4641280184658664, 0.5392221731858274, 0.3679866539909049, 0.37864989430411794, 0.99, 0.12566504541054518, 0.01, 0.12422955458205193, 0.02761979797927827, 0.48214239318145996, 0.7219208585265751, 0.99, 0.4331458284438685, 0.2876991603143658, 0.4300733447559868, 0.01, 0.01, 0.280890010484859, 0.5372126580137361, 0.08540888722200954, 0.01, 0.8161406156104709, 0.5249153729525831, 0.6682353579104703, 0.607336208104485, 0.01, 0.5174626155338, 0.5458048363490118, 0.01, 0.415595213918651, 0.5519542777553545, 0.01, 0.2642281232390612, 0.99, 0.3660455143798937, 0.01, 0.3015174401350341, 0.31148465953627147, 0.6419712873720634, 0.5475334815609609, 0.01, 0.48784391349593126, 0.17667656662120818, 0.35413578527366263, 0.5192840057286389, 0.5266851790902098, 0.35842044026317, 0.016185238643104505, 0.6725447237790207, 0.01, 0.99, 0.32456224181589677, 0.354390935651269, 0.4289544179779973, 0.2681524356387285, 0.7276907661479802, 0.4054192266078963, 0.6954173753917394, 0.5362005290479607, 0.8406696920541796, 0.23376715320795008, 0.99, 0.40451430589181436, 0.01, 0.6386310422789812]
[0.23296116440224474, 0.6214945132882866, 0.99, 0.30400123022788644, 0.35751640665171314, 0.3993369338130689, 0.01, 0.7597265582510364, 0.6514961836941371, 0.01, 0.01, 0.35573000043886716, 0.3014640605694836, 0.3559362944308283, 0.01, 0.6901757066954034, 0.99, 0.3045198957182549, 0.5136715519711441, 0.5649375768745925, 0.12173481369948647, 0.6086919174497661, 0.9699801924371232, 0.6430729114986773, 0.5030699183058761, 0.39018623904854977, 0.06924135464616821, 0.4641280184658664, 0.5392221731858274, 0.3679866539909049, 0.37864989430411794, 0.99, 0.12566504541054518, 0.01, 0.12422955458205193, 0.02761979797927827, 0.48214239318145996, 0.7219208585265751, 0.99, 0.4331458284438685, 0.2876991603143658, 0.4300733447559868, 0.01, 0.01, 0.280890010484859, 0.5372126580137361, 0.08540888722200954, 0.01, 0.8161406156104709, 0.5249153729525831, 0.6682353579104703, 0.607336208104485, 0.01, 0.5174626155338, 0.5458048363490118, 0.01, 0.415595213918651, 0.5519542777553545, 0.01, 0.2642281232390612, 0.99, 0.3660455143798937, 0.01, 0.3015174401350341, 0.31148465953627147, 0.6419712873720634, 0.5475334815609609, 0.01, 0.48784391349593126, 0.17667656662120818, 0.35413578527366263, 0.5192840057286389, 0.5266851790902098, 0.35842044026317, 0.016185238643104505, 0.6725447237790207, 0.01, 0.99, 0.32456224181589677, 0.354390935651269, 0.4289544179779973, 0.2681524356387285, 0.7276907661479802, 0.4054192266078963, 0.6954173753917394, 0.5362005290479607, 0.8406696920541796, 0.23376715320795008, 0.99, 0.40451430589181436, 0.01, 0.6386310422789812]
Training loss = 0.03594443082809448
step = 0, Training Accuracy: 0.4
Validation Accuracy: 0.4825
Training loss = 0.03362308402856191
step = 1, Training Accuracy: 0.4633333333333333
Training loss = 0.03319169680277507
step = 2, Training Accuracy: 0.4666666666666667
Training loss = 0.03484349469343821
step = 3, Training Accuracy: 0.4533333333333333
Training loss = 0.03437337855497996
step = 4, Training Accuracy: 0.46
Training loss = 0.0338020529349645
step = 5, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.4725
Training loss = 0.03484352231025696
step = 6, Training Accuracy: 0.43333333333333335
Training loss = 0.03489833732446035
step = 7, Training Accuracy: 0.42
Training loss = 0.034409713149070736
step = 8, Training Accuracy: 0.4266666666666667
Training loss = 0.03363101303577423
step = 9, Training Accuracy: 0.44
Training loss = 0.03484352707862854
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.45625
Training loss = 0.03569281776746114
step = 11, Training Accuracy: 0.43333333333333335
Training loss = 0.033848660190900166
step = 12, Training Accuracy: 0.47
Training loss = 0.03384850601355235
step = 13, Training Accuracy: 0.45666666666666667
Training loss = 0.03522569795449575
step = 14, Training Accuracy: 0.4166666666666667
Validation Accuracy: 0.46375
params:  [0.359717908672041, 0.5731061634475737, 0.25333388133007056, 0.3308826341588076, 0.6238794362826873, 0.40327155206945536, 0.01, 0.4558827855493584, 0.7925359200253254, 0.01, 0.0727413674581179, 0.01, 0.4963259681459256, 0.488503652779284, 0.6872359451156466, 0.7374988081888807, 0.8474332620500203, 0.13574341616368035, 0.1981947855500894, 0.99, 0.5734899713326168, 0.1812503807219944, 0.19202184164783648, 0.4029483145406242, 0.3796338584342491, 0.2482803109153956, 0.6205135166296825, 0.01, 0.9598216739007732, 0.6558039542723517, 0.5595230246266109, 0.99, 0.4134024083239585, 0.26722774454312503, 0.19444605920228303, 0.99, 0.4520184410109719, 0.99, 0.99, 0.3932722696794014, 0.4359658544864458, 0.01, 0.01, 0.01, 0.25453379502995827, 0.5118804409644074, 0.32909878949781546, 0.3421898562629828, 0.29212712142180375, 0.30710464578951424, 0.7548806291063074, 0.3231905729167366, 0.10209971960235015, 0.43756332489281746, 0.3128774486191752, 0.31157028759323707, 0.47649516194537295, 0.454464471489325, 0.01, 0.8399100123968799, 0.6286553503519453, 0.9758050448436055, 0.5319725356896473, 0.58961075913093, 0.21773925427480526, 0.5209406254970057, 0.15326827018569492, 0.6032132959633085, 0.5771919689850213, 0.4609570836896946, 0.3888886525770837, 0.5972499057465326, 0.1069199730219632, 0.7045858913884891, 0.5063011524898278, 0.8583103088129653, 0.7107195574668582, 0.7142915713630756, 0.629633055596157, 0.43469563903183395, 0.4393422042698318, 0.6641292143510114, 0.32252858334925105, 0.8832994687365274, 0.5351982149926346, 0.24372952181075555, 0.6831110796300395, 0.28668808153697856, 0.01, 0.01, 0.01, 0.5037777202345385]
[0.359717908672041, 0.5731061634475737, 0.25333388133007056, 0.3308826341588076, 0.6238794362826873, 0.40327155206945536, 0.01, 0.4558827855493584, 0.7925359200253254, 0.01, 0.0727413674581179, 0.01, 0.4963259681459256, 0.488503652779284, 0.6872359451156466, 0.7374988081888807, 0.8474332620500203, 0.13574341616368035, 0.1981947855500894, 0.99, 0.5734899713326168, 0.1812503807219944, 0.19202184164783648, 0.4029483145406242, 0.3796338584342491, 0.2482803109153956, 0.6205135166296825, 0.01, 0.9598216739007732, 0.6558039542723517, 0.5595230246266109, 0.99, 0.4134024083239585, 0.26722774454312503, 0.19444605920228303, 0.99, 0.4520184410109719, 0.99, 0.99, 0.3932722696794014, 0.4359658544864458, 0.01, 0.01, 0.01, 0.25453379502995827, 0.5118804409644074, 0.32909878949781546, 0.3421898562629828, 0.29212712142180375, 0.30710464578951424, 0.7548806291063074, 0.3231905729167366, 0.10209971960235015, 0.43756332489281746, 0.3128774486191752, 0.31157028759323707, 0.47649516194537295, 0.454464471489325, 0.01, 0.8399100123968799, 0.6286553503519453, 0.9758050448436055, 0.5319725356896473, 0.58961075913093, 0.21773925427480526, 0.5209406254970057, 0.15326827018569492, 0.6032132959633085, 0.5771919689850213, 0.4609570836896946, 0.3888886525770837, 0.5972499057465326, 0.1069199730219632, 0.7045858913884891, 0.5063011524898278, 0.8583103088129653, 0.7107195574668582, 0.7142915713630756, 0.629633055596157, 0.43469563903183395, 0.4393422042698318, 0.6641292143510114, 0.32252858334925105, 0.8832994687365274, 0.5351982149926346, 0.24372952181075555, 0.6831110796300395, 0.28668808153697856, 0.01, 0.01, 0.01, 0.5037777202345385]
Training loss = 0.037058434089024865
step = 0, Training Accuracy: 0.41
Validation Accuracy: 0.45625
Training loss = 0.03535310725371043
step = 1, Training Accuracy: 0.44666666666666666
Training loss = 0.03508509119351705
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.034474584062894185
step = 3, Training Accuracy: 0.4666666666666667
Training loss = 0.03528554876645406
step = 4, Training Accuracy: 0.4066666666666667
Training loss = 0.03524754027525584
step = 5, Training Accuracy: 0.41333333333333333
Validation Accuracy: 0.48375
Training loss = 0.03453007141749064
step = 6, Training Accuracy: 0.44333333333333336
Training loss = 0.03368801355361938
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.034577141205469765
step = 8, Training Accuracy: 0.45
Training loss = 0.034515066146850584
step = 9, Training Accuracy: 0.43
Training loss = 0.03477983971436818
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.4525
Training loss = 0.03436664541562398
step = 11, Training Accuracy: 0.4266666666666667
Training loss = 0.03542907694975535
step = 12, Training Accuracy: 0.4266666666666667
Training loss = 0.03456898232301076
step = 13, Training Accuracy: 0.44
Training loss = 0.03412686824798584
step = 14, Training Accuracy: 0.44
Validation Accuracy: 0.47375
params:  [0.3293028295646495, 0.7152626767387886, 0.4191779496666327, 0.01, 0.1450224462002675, 0.01, 0.5448000733276036, 0.7058154379995318, 0.2105229618259687, 0.4205894672597046, 0.24361278487554427, 0.3914712852863066, 0.42531075545627794, 0.8266022527329613, 0.99, 0.5202555444230327, 0.8537891552191479, 0.5347023902878576, 0.9653455926567569, 0.2754540390330339, 0.9507071156288084, 0.3555617674592659, 0.8219179970047208, 0.01, 0.18942730327418777, 0.01, 0.2621381503212967, 0.01, 0.6512139546553533, 0.2042821860993369, 0.99, 0.94273473235651, 0.18223594343331456, 0.033905208395845404, 0.04583992479899196, 0.99, 0.7009017646490115, 0.6086591498485441, 0.9732639881461634, 0.01, 0.49019157557177206, 0.16521963468179218, 0.03333569033101437, 0.01, 0.5996942035938775, 0.7166363799028861, 0.01, 0.07692890330127908, 0.99, 0.30252679273314786, 0.5451181359428623, 0.27226020153389063, 0.09227349349577169, 0.01, 0.31986951093214677, 0.01, 0.05751051439345456, 0.99, 0.2550026017215055, 0.46169619101620346, 0.7697957311335851, 0.99, 0.6211145811588954, 0.99, 0.4827328207069682, 0.5073530522776828, 0.10143039817669339, 0.6184604847891484, 0.06380893192882592, 0.16260737244863926, 0.34757575145195174, 0.7134844634266669, 0.3543316502176247, 0.5360886895135697, 0.45728615449361193, 0.14638053785188837, 0.6535216463709163, 0.3316470252228936, 0.3140941781294226, 0.5015731099154549, 0.3201874931138682, 0.021671702361689915, 0.8713448935920385, 0.46563804642421464, 0.9061617122496238, 0.01, 0.35924730436858854, 0.4163320362163861, 0.649437629756306, 0.01, 0.01, 0.1406366322233455]
[0.3293028295646495, 0.7152626767387886, 0.4191779496666327, 0.01, 0.1450224462002675, 0.01, 0.5448000733276036, 0.7058154379995318, 0.2105229618259687, 0.4205894672597046, 0.24361278487554427, 0.3914712852863066, 0.42531075545627794, 0.8266022527329613, 0.99, 0.5202555444230327, 0.8537891552191479, 0.5347023902878576, 0.9653455926567569, 0.2754540390330339, 0.9507071156288084, 0.3555617674592659, 0.8219179970047208, 0.01, 0.18942730327418777, 0.01, 0.2621381503212967, 0.01, 0.6512139546553533, 0.2042821860993369, 0.99, 0.94273473235651, 0.18223594343331456, 0.033905208395845404, 0.04583992479899196, 0.99, 0.7009017646490115, 0.6086591498485441, 0.9732639881461634, 0.01, 0.49019157557177206, 0.16521963468179218, 0.03333569033101437, 0.01, 0.5996942035938775, 0.7166363799028861, 0.01, 0.07692890330127908, 0.99, 0.30252679273314786, 0.5451181359428623, 0.27226020153389063, 0.09227349349577169, 0.01, 0.31986951093214677, 0.01, 0.05751051439345456, 0.99, 0.2550026017215055, 0.46169619101620346, 0.7697957311335851, 0.99, 0.6211145811588954, 0.99, 0.4827328207069682, 0.5073530522776828, 0.10143039817669339, 0.6184604847891484, 0.06380893192882592, 0.16260737244863926, 0.34757575145195174, 0.7134844634266669, 0.3543316502176247, 0.5360886895135697, 0.45728615449361193, 0.14638053785188837, 0.6535216463709163, 0.3316470252228936, 0.3140941781294226, 0.5015731099154549, 0.3201874931138682, 0.021671702361689915, 0.8713448935920385, 0.46563804642421464, 0.9061617122496238, 0.01, 0.35924730436858854, 0.4163320362163861, 0.649437629756306, 0.01, 0.01, 0.1406366322233455]
Training loss = 0.036025912563006086
step = 0, Training Accuracy: 0.41333333333333333
Validation Accuracy: 0.48375
Training loss = 0.03732482075691223
step = 1, Training Accuracy: 0.38666666666666666
Training loss = 0.03577908198038737
step = 2, Training Accuracy: 0.4166666666666667
Training loss = 0.03569706161816915
step = 3, Training Accuracy: 0.42
Training loss = 0.03484764039516449
step = 4, Training Accuracy: 0.44
Training loss = 0.03575106660525004
step = 5, Training Accuracy: 0.43666666666666665
Validation Accuracy: 0.4525
Training loss = 0.03605608900388082
step = 6, Training Accuracy: 0.4033333333333333
Training loss = 0.036932043234507245
step = 7, Training Accuracy: 0.3233333333333333
Training loss = 0.03574024895826976
step = 8, Training Accuracy: 0.38666666666666666
Training loss = 0.03612418373425801
step = 9, Training Accuracy: 0.37333333333333335
Training loss = 0.035707080364227296
step = 10, Training Accuracy: 0.42
Validation Accuracy: 0.47625
Training loss = 0.0359811004002889
step = 11, Training Accuracy: 0.39666666666666667
Training loss = 0.036140782833099364
step = 12, Training Accuracy: 0.41333333333333333
Training loss = 0.03688106973965963
step = 13, Training Accuracy: 0.38333333333333336
Training loss = 0.03536288380622864
step = 14, Training Accuracy: 0.43
Validation Accuracy: 0.46875
params:  [0.8894175398749167, 0.01, 0.2710222530372449, 0.6711796005779478, 0.301212872316246, 0.6626953622793339, 0.01, 0.7254161370115367, 0.5297996916287677, 0.01, 0.20027515628731424, 0.32661736774772676, 0.3269686008295002, 0.027730901387520657, 0.42831558594007707, 0.4849285671652589, 0.5811370477339517, 0.25071496507668867, 0.5145564883834481, 0.2408027690960552, 0.011737268635051201, 0.3477588173317479, 0.4112500838497779, 0.06203834580201073, 0.31880444398525387, 0.1525808754134545, 0.4390863841871022, 0.20486766990019376, 0.260931423358857, 0.01, 0.99, 0.99, 0.16108794360271456, 0.22597693624186999, 0.4507076336195425, 0.99, 0.3846333367310524, 0.7418759904148142, 0.99, 0.10444916765935225, 0.136695140071263, 0.030176060405805033, 0.01, 0.4415777376332122, 0.3222818227283393, 0.1871957182039245, 0.1048072292634519, 0.01, 0.8358724734303731, 0.99, 0.5933750463630608, 0.67296708891673, 0.17528918813308653, 0.99, 0.9097495847987107, 0.01, 0.01, 0.4174844908545068, 0.027254527806596013, 0.040849655716841765, 0.99, 0.6842500100130275, 0.2670424534733664, 0.5218571406483067, 0.3975273065535999, 0.2900823476022243, 0.3439123989248519, 0.29495805588910334, 0.01, 0.6688907710071712, 0.26103909076016696, 0.08042972785425767, 0.7728249921410391, 0.7778532642594924, 0.08516008071069919, 0.20398119065123954, 0.4095650632415842, 0.15549282036872974, 0.46167301310539754, 0.9569372231808971, 0.2416147396015209, 0.5232104922942855, 0.9439832416670078, 0.4976082076050148, 0.7644919270848352, 0.7561424905217694, 0.17553559891568155, 0.01, 0.01, 0.023094776414709, 0.07693243914305539, 0.45329682938237614]
[0.8894175398749167, 0.01, 0.2710222530372449, 0.6711796005779478, 0.301212872316246, 0.6626953622793339, 0.01, 0.7254161370115367, 0.5297996916287677, 0.01, 0.20027515628731424, 0.32661736774772676, 0.3269686008295002, 0.027730901387520657, 0.42831558594007707, 0.4849285671652589, 0.5811370477339517, 0.25071496507668867, 0.5145564883834481, 0.2408027690960552, 0.011737268635051201, 0.3477588173317479, 0.4112500838497779, 0.06203834580201073, 0.31880444398525387, 0.1525808754134545, 0.4390863841871022, 0.20486766990019376, 0.260931423358857, 0.01, 0.99, 0.99, 0.16108794360271456, 0.22597693624186999, 0.4507076336195425, 0.99, 0.3846333367310524, 0.7418759904148142, 0.99, 0.10444916765935225, 0.136695140071263, 0.030176060405805033, 0.01, 0.4415777376332122, 0.3222818227283393, 0.1871957182039245, 0.1048072292634519, 0.01, 0.8358724734303731, 0.99, 0.5933750463630608, 0.67296708891673, 0.17528918813308653, 0.99, 0.9097495847987107, 0.01, 0.01, 0.4174844908545068, 0.027254527806596013, 0.040849655716841765, 0.99, 0.6842500100130275, 0.2670424534733664, 0.5218571406483067, 0.3975273065535999, 0.2900823476022243, 0.3439123989248519, 0.29495805588910334, 0.01, 0.6688907710071712, 0.26103909076016696, 0.08042972785425767, 0.7728249921410391, 0.7778532642594924, 0.08516008071069919, 0.20398119065123954, 0.4095650632415842, 0.15549282036872974, 0.46167301310539754, 0.9569372231808971, 0.2416147396015209, 0.5232104922942855, 0.9439832416670078, 0.4976082076050148, 0.7644919270848352, 0.7561424905217694, 0.17553559891568155, 0.01, 0.01, 0.023094776414709, 0.07693243914305539, 0.45329682938237614]
Training loss = 0.03519440988699595
step = 0, Training Accuracy: 0.4033333333333333
Validation Accuracy: 0.46375
Training loss = 0.03451027194658915
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.033790915211041765
step = 2, Training Accuracy: 0.4766666666666667
Training loss = 0.033695936997731525
step = 3, Training Accuracy: 0.4666666666666667
Training loss = 0.03238042712211609
step = 4, Training Accuracy: 0.5066666666666667
Training loss = 0.032668544848759966
step = 5, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.4825
Training loss = 0.032336033781369525
step = 6, Training Accuracy: 0.49
Training loss = 0.031999480724334714
step = 7, Training Accuracy: 0.5333333333333333
Training loss = 0.03326677123705546
step = 8, Training Accuracy: 0.4766666666666667
Training loss = 0.03358383039633433
step = 9, Training Accuracy: 0.48
Training loss = 0.03244847635428111
step = 10, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.4575
Training loss = 0.03161924640337626
step = 11, Training Accuracy: 0.4866666666666667
Training loss = 0.03284140865008036
step = 12, Training Accuracy: 0.5066666666666667
Training loss = 0.03222225526968638
step = 13, Training Accuracy: 0.5133333333333333
Training loss = 0.032005110383033754
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.4775
params:  [0.6503346184979422, 0.7177299871696076, 0.5328184383814678, 0.5387663545925683, 0.99, 0.16204059037584045, 0.31126331516867334, 0.4833245987268635, 0.6963096969062174, 0.4588132934467549, 0.01, 0.01, 0.2678632402689281, 0.8630387437674198, 0.6240304709671103, 0.9066913576414852, 0.760881776031698, 0.22335040274671236, 0.7270965849936055, 0.6131901479134556, 0.644302769521014, 0.40049854061707274, 0.09619099669973974, 0.474773840474132, 0.99, 0.01, 0.11147636838091518, 0.01, 0.5219953901565212, 0.7469511751885743, 0.31123530613257694, 0.6579071489604114, 0.37193567901577396, 0.12212259459091858, 0.1525976304263032, 0.4922606110855542, 0.8282574555412845, 0.99, 0.9622639239701055, 0.01, 0.34663529707064444, 0.5279559879918191, 0.45362601384649326, 0.8146073489425101, 0.36671202197716657, 0.039704218598641094, 0.21903751941198862, 0.18426984135734073, 0.99, 0.2055255137568655, 0.3945459547876074, 0.01, 0.01, 0.01, 0.37726469265888796, 0.5876369039219107, 0.20219294034964763, 0.7613374110295077, 0.8226202395936317, 0.2869324570689239, 0.8737046557539211, 0.6183356427134891, 0.20356587698744705, 0.4092736883338075, 0.20977024349659312, 0.6012807986225607, 0.40965958632369726, 0.4314115454625821, 0.58215500768838, 0.3469950803435759, 0.01, 0.8112619832773698, 0.3000986315860845, 0.6436939477239175, 0.356702765970465, 0.4881365378324844, 0.20984151889400654, 0.7157674116299404, 0.04504668916056248, 0.36219173013792677, 0.5744661758901008, 0.5545598765175486, 0.99, 0.6898345598318855, 0.3754136258297596, 0.35154892224832424, 0.8431262129620787, 0.01, 0.33125955816609004, 0.3206843674325698, 0.7088650958381841, 0.04905711406456814]
[0.6503346184979422, 0.7177299871696076, 0.5328184383814678, 0.5387663545925683, 0.99, 0.16204059037584045, 0.31126331516867334, 0.4833245987268635, 0.6963096969062174, 0.4588132934467549, 0.01, 0.01, 0.2678632402689281, 0.8630387437674198, 0.6240304709671103, 0.9066913576414852, 0.760881776031698, 0.22335040274671236, 0.7270965849936055, 0.6131901479134556, 0.644302769521014, 0.40049854061707274, 0.09619099669973974, 0.474773840474132, 0.99, 0.01, 0.11147636838091518, 0.01, 0.5219953901565212, 0.7469511751885743, 0.31123530613257694, 0.6579071489604114, 0.37193567901577396, 0.12212259459091858, 0.1525976304263032, 0.4922606110855542, 0.8282574555412845, 0.99, 0.9622639239701055, 0.01, 0.34663529707064444, 0.5279559879918191, 0.45362601384649326, 0.8146073489425101, 0.36671202197716657, 0.039704218598641094, 0.21903751941198862, 0.18426984135734073, 0.99, 0.2055255137568655, 0.3945459547876074, 0.01, 0.01, 0.01, 0.37726469265888796, 0.5876369039219107, 0.20219294034964763, 0.7613374110295077, 0.8226202395936317, 0.2869324570689239, 0.8737046557539211, 0.6183356427134891, 0.20356587698744705, 0.4092736883338075, 0.20977024349659312, 0.6012807986225607, 0.40965958632369726, 0.4314115454625821, 0.58215500768838, 0.3469950803435759, 0.01, 0.8112619832773698, 0.3000986315860845, 0.6436939477239175, 0.356702765970465, 0.4881365378324844, 0.20984151889400654, 0.7157674116299404, 0.04504668916056248, 0.36219173013792677, 0.5744661758901008, 0.5545598765175486, 0.99, 0.6898345598318855, 0.3754136258297596, 0.35154892224832424, 0.8431262129620787, 0.01, 0.33125955816609004, 0.3206843674325698, 0.7088650958381841, 0.04905711406456814]
Training loss = 0.03643866837024689
step = 0, Training Accuracy: 0.43
Validation Accuracy: 0.42875
Training loss = 0.036309380729993186
step = 1, Training Accuracy: 0.4266666666666667
Training loss = 0.03573003053665161
step = 2, Training Accuracy: 0.4033333333333333
Training loss = 0.035807132720947266
step = 3, Training Accuracy: 0.43333333333333335
Training loss = 0.03609148343404134
step = 4, Training Accuracy: 0.39666666666666667
Training loss = 0.03504356662432353
step = 5, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.46125
Training loss = 0.03624767104784648
step = 6, Training Accuracy: 0.4
Training loss = 0.03541192332903544
step = 7, Training Accuracy: 0.41
Training loss = 0.03583000540733337
step = 8, Training Accuracy: 0.3933333333333333
Training loss = 0.0354390009244283
step = 9, Training Accuracy: 0.44666666666666666
Training loss = 0.035534241994222004
step = 10, Training Accuracy: 0.37666666666666665
Validation Accuracy: 0.39375
Training loss = 0.03636770009994507
step = 11, Training Accuracy: 0.39666666666666667
Training loss = 0.03554902235666911
step = 12, Training Accuracy: 0.42
Training loss = 0.03548843046029409
step = 13, Training Accuracy: 0.4166666666666667
Training loss = 0.03473100701967875
step = 14, Training Accuracy: 0.46
Validation Accuracy: 0.44875
params:  [0.2262770807742167, 0.99, 0.01, 0.99, 0.11587119425111508, 0.6814902899690453, 0.01, 0.07746161109093214, 0.28869689283717226, 0.32470276775106677, 0.01, 0.0445293590671033, 0.7772081057620703, 0.01, 0.5978399066726354, 0.40713606820580295, 0.6779303773905151, 0.6847806820832791, 0.17568100172003082, 0.8477989410092743, 0.5633052401607855, 0.3043193997722156, 0.1698576072906484, 0.4530741676389546, 0.01, 0.1637129401164034, 0.20648816671549042, 0.09049960827533621, 0.2665085823793062, 0.33807209590719156, 0.911966819300809, 0.9670686414580795, 0.44480499909419624, 0.5087466911976931, 0.2512596314383826, 0.5955443733682861, 0.01, 0.99, 0.9829163128836798, 0.19091633633584323, 0.5450905284385633, 0.0842682945986119, 0.3809905646049564, 0.23870958927254549, 0.391710150254276, 0.4666123267791452, 0.5132879904610474, 0.28192906830756903, 0.3369725686598705, 0.1901740189352005, 0.3359423176278824, 0.3279013979359291, 0.20669187642281725, 0.5594254282303565, 0.4924497784323524, 0.23145151484661114, 0.31776553020434645, 0.99, 0.01, 0.11933339283355085, 0.99, 0.99, 0.5421952427773589, 0.4862751964929522, 0.31704487337798964, 0.01, 0.2515162624090322, 0.119479598530184, 0.2568401681070767, 0.38755375773512074, 0.6511978965748066, 0.42790238055255947, 0.41389952905171645, 0.1333616573324164, 0.6468123683683754, 0.3093105867827346, 0.12795113530149793, 0.6831682858796372, 0.6814665284982476, 0.7807035179442383, 0.99, 0.16682724636025137, 0.26665499372273743, 0.07774649158465363, 0.38856774020126256, 0.14719372177589538, 0.01, 0.4363255577492887, 0.4274520555767385, 0.01, 0.4729792282068145, 0.6417792447239129]
[0.2262770807742167, 0.99, 0.01, 0.99, 0.11587119425111508, 0.6814902899690453, 0.01, 0.07746161109093214, 0.28869689283717226, 0.32470276775106677, 0.01, 0.0445293590671033, 0.7772081057620703, 0.01, 0.5978399066726354, 0.40713606820580295, 0.6779303773905151, 0.6847806820832791, 0.17568100172003082, 0.8477989410092743, 0.5633052401607855, 0.3043193997722156, 0.1698576072906484, 0.4530741676389546, 0.01, 0.1637129401164034, 0.20648816671549042, 0.09049960827533621, 0.2665085823793062, 0.33807209590719156, 0.911966819300809, 0.9670686414580795, 0.44480499909419624, 0.5087466911976931, 0.2512596314383826, 0.5955443733682861, 0.01, 0.99, 0.9829163128836798, 0.19091633633584323, 0.5450905284385633, 0.0842682945986119, 0.3809905646049564, 0.23870958927254549, 0.391710150254276, 0.4666123267791452, 0.5132879904610474, 0.28192906830756903, 0.3369725686598705, 0.1901740189352005, 0.3359423176278824, 0.3279013979359291, 0.20669187642281725, 0.5594254282303565, 0.4924497784323524, 0.23145151484661114, 0.31776553020434645, 0.99, 0.01, 0.11933339283355085, 0.99, 0.99, 0.5421952427773589, 0.4862751964929522, 0.31704487337798964, 0.01, 0.2515162624090322, 0.119479598530184, 0.2568401681070767, 0.38755375773512074, 0.6511978965748066, 0.42790238055255947, 0.41389952905171645, 0.1333616573324164, 0.6468123683683754, 0.3093105867827346, 0.12795113530149793, 0.6831682858796372, 0.6814665284982476, 0.7807035179442383, 0.99, 0.16682724636025137, 0.26665499372273743, 0.07774649158465363, 0.38856774020126256, 0.14719372177589538, 0.01, 0.4363255577492887, 0.4274520555767385, 0.01, 0.4729792282068145, 0.6417792447239129]
Training loss = 0.03466393808523814
step = 0, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.465
Training loss = 0.03375571747620901
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.03455646475156148
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.03576305389404297
step = 3, Training Accuracy: 0.41333333333333333
Training loss = 0.03456564207871755
step = 4, Training Accuracy: 0.42333333333333334
Training loss = 0.03504861156145732
step = 5, Training Accuracy: 0.44
Validation Accuracy: 0.4675
Training loss = 0.03575987458229065
step = 6, Training Accuracy: 0.42
Training loss = 0.03550403495629628
step = 7, Training Accuracy: 0.41333333333333333
Training loss = 0.03426499048868815
step = 8, Training Accuracy: 0.4533333333333333
Training loss = 0.03512860278288523
step = 9, Training Accuracy: 0.47
Training loss = 0.03381325562795003
step = 10, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.48
Training loss = 0.03372003495693207
step = 11, Training Accuracy: 0.47
Training loss = 0.033570395509401954
step = 12, Training Accuracy: 0.44666666666666666
Training loss = 0.0344231116771698
step = 13, Training Accuracy: 0.44
Training loss = 0.034160899917284646
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.46125
gen	nevals	avg     	std      	min   	max    
0  	8     	0.463125	0.0147638	0.4325	0.47875
params:  [0.753282132604329, 0.2508425322315887, 0.99, 0.01, 0.99, 0.5101075280232104, 0.01, 0.2678521255346239, 0.43137078248821936, 0.34309399400259233, 0.01, 0.01, 0.4430856566615763, 0.6026825888242103, 0.7234516606638877, 0.4422326069029142, 0.8710154425517519, 0.879283758576612, 0.3588328285849082, 0.01, 0.7570211500746117, 0.708036326398004, 0.2355244964797145, 0.5021276907011714, 0.8927690924227484, 0.020266926201224222, 0.8036910538449223, 0.31480155435962554, 0.8221675018221124, 0.4332640767210355, 0.99, 0.9360082241633849, 0.99, 0.01, 0.13398676973078283, 0.99, 0.4007883158760288, 0.9279510383514492, 0.5909684853444201, 0.632119847566428, 0.99, 0.9035913107185238, 0.3930293675408269, 0.25854422565792395, 0.3044967486104293, 0.3112977821882325, 0.27742789488584346, 0.08729279877594193, 0.1598639418756415, 0.8285779677678636, 0.6721116808285215, 0.3112102671867811, 0.24578476296853793, 0.7398314906773552, 0.713489182751764, 0.1840866580212445, 0.25254509247040496, 0.6593940532930004, 0.32418880650184057, 0.19966730862755067, 0.8431490802477793, 0.543438839094133, 0.17691021011213698, 0.99, 0.139962069468996, 0.5212757343067008, 0.16933261543788897, 0.01, 0.01, 0.99, 0.11990877730504687, 0.2660772377976403, 0.7350553188941948, 0.8970804795307412, 0.01, 0.16545156444538162, 0.3110074471385553, 0.42483397461071226, 0.5733975341499189, 0.6866860721922445, 0.99, 0.4265405716229497, 0.3367913488806118, 0.7875601539616751, 0.6056517032713167, 0.5333535886627286, 0.01, 0.2727037590606255, 0.3327635198029077, 0.01, 0.01, 0.5846660476167928]
[0.753282132604329, 0.2508425322315887, 0.99, 0.01, 0.99, 0.5101075280232104, 0.01, 0.2678521255346239, 0.43137078248821936, 0.34309399400259233, 0.01, 0.01, 0.4430856566615763, 0.6026825888242103, 0.7234516606638877, 0.4422326069029142, 0.8710154425517519, 0.879283758576612, 0.3588328285849082, 0.01, 0.7570211500746117, 0.708036326398004, 0.2355244964797145, 0.5021276907011714, 0.8927690924227484, 0.020266926201224222, 0.8036910538449223, 0.31480155435962554, 0.8221675018221124, 0.4332640767210355, 0.99, 0.9360082241633849, 0.99, 0.01, 0.13398676973078283, 0.99, 0.4007883158760288, 0.9279510383514492, 0.5909684853444201, 0.632119847566428, 0.99, 0.9035913107185238, 0.3930293675408269, 0.25854422565792395, 0.3044967486104293, 0.3112977821882325, 0.27742789488584346, 0.08729279877594193, 0.1598639418756415, 0.8285779677678636, 0.6721116808285215, 0.3112102671867811, 0.24578476296853793, 0.7398314906773552, 0.713489182751764, 0.1840866580212445, 0.25254509247040496, 0.6593940532930004, 0.32418880650184057, 0.19966730862755067, 0.8431490802477793, 0.543438839094133, 0.17691021011213698, 0.99, 0.139962069468996, 0.5212757343067008, 0.16933261543788897, 0.01, 0.01, 0.99, 0.11990877730504687, 0.2660772377976403, 0.7350553188941948, 0.8970804795307412, 0.01, 0.16545156444538162, 0.3110074471385553, 0.42483397461071226, 0.5733975341499189, 0.6866860721922445, 0.99, 0.4265405716229497, 0.3367913488806118, 0.7875601539616751, 0.6056517032713167, 0.5333535886627286, 0.01, 0.2727037590606255, 0.3327635198029077, 0.01, 0.01, 0.5846660476167928]
Training loss = 0.03578625798225403
step = 0, Training Accuracy: 0.4066666666666667
Validation Accuracy: 0.4125
Training loss = 0.036286880572636925
step = 1, Training Accuracy: 0.41333333333333333
Training loss = 0.036487944920857746
step = 2, Training Accuracy: 0.33
Training loss = 0.036231601238250734
step = 3, Training Accuracy: 0.39
Training loss = 0.03678087155024211
step = 4, Training Accuracy: 0.3333333333333333
Training loss = 0.03599223852157593
step = 5, Training Accuracy: 0.38666666666666666
Validation Accuracy: 0.4175
Training loss = 0.03633856654167175
step = 6, Training Accuracy: 0.36
Training loss = 0.035737757881482445
step = 7, Training Accuracy: 0.3566666666666667
Training loss = 0.03606017927328745
step = 8, Training Accuracy: 0.4
Training loss = 0.03593657652537028
step = 9, Training Accuracy: 0.3933333333333333
Training loss = 0.03528632005055746
step = 10, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.45375
Training loss = 0.03673378745714823
step = 11, Training Accuracy: 0.37666666666666665
Training loss = 0.03629995544751485
step = 12, Training Accuracy: 0.3466666666666667
Training loss = 0.036032085021336875
step = 13, Training Accuracy: 0.4033333333333333
Training loss = 0.036063595215479534
step = 14, Training Accuracy: 0.38333333333333336
Validation Accuracy: 0.46625
params:  [0.08420452196479011, 0.5332050218836656, 0.32041176733625387, 0.2420684179781231, 0.36319127328595197, 0.51929826146397, 0.01, 0.37483511104958855, 0.20106544434204066, 0.5598815000211441, 0.35963882702334704, 0.01, 0.5317784127851768, 0.99, 0.7954934794414151, 0.446912965244855, 0.5991509071016211, 0.6447111348099088, 0.20753723441258615, 0.18927359296682228, 0.0959702319707876, 0.99, 0.01, 0.20073028816241795, 0.02680476894202871, 0.05585872448269258, 0.9344554985023632, 0.1616569508882173, 0.8833002349413692, 0.27207433102143386, 0.99, 0.8797339191493554, 0.9507435592180995, 0.2965736060716797, 0.05157346434473262, 0.99, 0.17736468434347913, 0.6916646209667022, 0.99, 0.445238289929619, 0.7395958369683504, 0.22120628531285771, 0.01, 0.44622369621117935, 0.5542872474699033, 0.04815112190096879, 0.5908999709231874, 0.666075700525633, 0.13197247848691812, 0.8249152791089838, 0.99, 0.590337523740869, 0.2885607851257178, 0.99, 0.5648083098436573, 0.4981729772452068, 0.01, 0.3612568740887389, 0.01, 0.313318094647944, 0.99, 0.9474404572456561, 0.23482620391104134, 0.7812418622894011, 0.5721429062697062, 0.14155191546005663, 0.7074542767597665, 0.23478898820698435, 0.38681757090641994, 0.6312977085585438, 0.3745857137936156, 0.01, 0.14503154303608107, 0.44800106845027243, 0.204325550032319, 0.01, 0.1217095377619073, 0.40149752028842683, 0.6867432719462234, 0.7556167291906005, 0.4024804952585186, 0.44228728063923817, 0.4807810934889064, 0.99, 0.18888123573227145, 0.7683156768585847, 0.0745543256854263, 0.11231428101818752, 0.0586515947431939, 0.43837520589027285, 0.01, 0.3110138876378336]
[0.08420452196479011, 0.5332050218836656, 0.32041176733625387, 0.2420684179781231, 0.36319127328595197, 0.51929826146397, 0.01, 0.37483511104958855, 0.20106544434204066, 0.5598815000211441, 0.35963882702334704, 0.01, 0.5317784127851768, 0.99, 0.7954934794414151, 0.446912965244855, 0.5991509071016211, 0.6447111348099088, 0.20753723441258615, 0.18927359296682228, 0.0959702319707876, 0.99, 0.01, 0.20073028816241795, 0.02680476894202871, 0.05585872448269258, 0.9344554985023632, 0.1616569508882173, 0.8833002349413692, 0.27207433102143386, 0.99, 0.8797339191493554, 0.9507435592180995, 0.2965736060716797, 0.05157346434473262, 0.99, 0.17736468434347913, 0.6916646209667022, 0.99, 0.445238289929619, 0.7395958369683504, 0.22120628531285771, 0.01, 0.44622369621117935, 0.5542872474699033, 0.04815112190096879, 0.5908999709231874, 0.666075700525633, 0.13197247848691812, 0.8249152791089838, 0.99, 0.590337523740869, 0.2885607851257178, 0.99, 0.5648083098436573, 0.4981729772452068, 0.01, 0.3612568740887389, 0.01, 0.313318094647944, 0.99, 0.9474404572456561, 0.23482620391104134, 0.7812418622894011, 0.5721429062697062, 0.14155191546005663, 0.7074542767597665, 0.23478898820698435, 0.38681757090641994, 0.6312977085585438, 0.3745857137936156, 0.01, 0.14503154303608107, 0.44800106845027243, 0.204325550032319, 0.01, 0.1217095377619073, 0.40149752028842683, 0.6867432719462234, 0.7556167291906005, 0.4024804952585186, 0.44228728063923817, 0.4807810934889064, 0.99, 0.18888123573227145, 0.7683156768585847, 0.0745543256854263, 0.11231428101818752, 0.0586515947431939, 0.43837520589027285, 0.01, 0.3110138876378336]
Training loss = 0.0354972231388092
step = 0, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.4625
Training loss = 0.03442390620708466
step = 1, Training Accuracy: 0.42333333333333334
Training loss = 0.03453519682089488
step = 2, Training Accuracy: 0.43333333333333335
Training loss = 0.034533025423685706
step = 3, Training Accuracy: 0.44
Training loss = 0.03388257483641306
step = 4, Training Accuracy: 0.4866666666666667
Training loss = 0.03419701635837555
step = 5, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.45875
Training loss = 0.033569195071856184
step = 6, Training Accuracy: 0.43
Training loss = 0.03312251667181651
step = 7, Training Accuracy: 0.4866666666666667
Training loss = 0.03303655425707499
step = 8, Training Accuracy: 0.4766666666666667
Training loss = 0.032642496824264525
step = 9, Training Accuracy: 0.53
Training loss = 0.03202912410100301
step = 10, Training Accuracy: 0.53
Validation Accuracy: 0.4775
Training loss = 0.0328789093097051
step = 11, Training Accuracy: 0.51
Training loss = 0.03485105911890666
step = 12, Training Accuracy: 0.43666666666666665
Training loss = 0.03348839779694875
step = 13, Training Accuracy: 0.5
Training loss = 0.03308432022730509
step = 14, Training Accuracy: 0.5
Validation Accuracy: 0.46125
params:  [0.4801252612623017, 0.38905523536660525, 0.29366167551074845, 0.053668565372950394, 0.7747921162103117, 0.7064074961037178, 0.01, 0.818788958584737, 0.99, 0.4244559800775718, 0.4444913460073906, 0.4167799356747843, 0.5174398138225567, 0.6996672390273031, 0.3592949394994802, 0.6741219624925071, 0.396485213858801, 0.182187909433714, 0.29986651481470084, 0.46940563561738524, 0.01, 0.0948019786305429, 0.01, 0.01, 0.04513571694493615, 0.5900087726791645, 0.8566987795729557, 0.01, 0.8541132343866061, 0.3410203865562675, 0.99, 0.99, 0.7400830662465979, 0.24657840301074613, 0.05027522209115837, 0.99, 0.9361189448355962, 0.9604968571080976, 0.9372127786651702, 0.4870584596770392, 0.6192496371253104, 0.45534328281707565, 0.01, 0.8405005045593414, 0.32369118457231016, 0.07517885623817078, 0.4931433003976608, 0.39768637907613147, 0.3275570286951993, 0.01, 0.6503092491718799, 0.5906517699757218, 0.9745268713531082, 0.7494235452356814, 0.7525891542501677, 0.30823841894569226, 0.01, 0.6457012702071748, 0.01, 0.24998971050758195, 0.99, 0.1596598877939056, 0.07740387442543134, 0.48587099730626593, 0.26267481265823445, 0.27690539729825475, 0.10549984634585266, 0.954074352802313, 0.01, 0.882394313689042, 0.1599337864990259, 0.7359090743875009, 0.01, 0.605899517550267, 0.5513588091117997, 0.47590516884098166, 0.3274710672304434, 0.25094554270749897, 0.01, 0.8071341542485133, 0.3995308559564022, 0.7560901741216699, 0.47046953729066143, 0.5548453991496581, 0.29292161456555676, 0.962865863880852, 0.6376295059893242, 0.287621352205497, 0.20377374193220354, 0.6417568042422628, 0.01, 0.37082858771982397]
[0.4801252612623017, 0.38905523536660525, 0.29366167551074845, 0.053668565372950394, 0.7747921162103117, 0.7064074961037178, 0.01, 0.818788958584737, 0.99, 0.4244559800775718, 0.4444913460073906, 0.4167799356747843, 0.5174398138225567, 0.6996672390273031, 0.3592949394994802, 0.6741219624925071, 0.396485213858801, 0.182187909433714, 0.29986651481470084, 0.46940563561738524, 0.01, 0.0948019786305429, 0.01, 0.01, 0.04513571694493615, 0.5900087726791645, 0.8566987795729557, 0.01, 0.8541132343866061, 0.3410203865562675, 0.99, 0.99, 0.7400830662465979, 0.24657840301074613, 0.05027522209115837, 0.99, 0.9361189448355962, 0.9604968571080976, 0.9372127786651702, 0.4870584596770392, 0.6192496371253104, 0.45534328281707565, 0.01, 0.8405005045593414, 0.32369118457231016, 0.07517885623817078, 0.4931433003976608, 0.39768637907613147, 0.3275570286951993, 0.01, 0.6503092491718799, 0.5906517699757218, 0.9745268713531082, 0.7494235452356814, 0.7525891542501677, 0.30823841894569226, 0.01, 0.6457012702071748, 0.01, 0.24998971050758195, 0.99, 0.1596598877939056, 0.07740387442543134, 0.48587099730626593, 0.26267481265823445, 0.27690539729825475, 0.10549984634585266, 0.954074352802313, 0.01, 0.882394313689042, 0.1599337864990259, 0.7359090743875009, 0.01, 0.605899517550267, 0.5513588091117997, 0.47590516884098166, 0.3274710672304434, 0.25094554270749897, 0.01, 0.8071341542485133, 0.3995308559564022, 0.7560901741216699, 0.47046953729066143, 0.5548453991496581, 0.29292161456555676, 0.962865863880852, 0.6376295059893242, 0.287621352205497, 0.20377374193220354, 0.6417568042422628, 0.01, 0.37082858771982397]
Training loss = 0.033322814702987674
step = 0, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.47125
Training loss = 0.034550329645474755
step = 1, Training Accuracy: 0.44333333333333336
Training loss = 0.03477287471294403
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.03402541021505991
step = 3, Training Accuracy: 0.46
Training loss = 0.03466829121112824
step = 4, Training Accuracy: 0.44333333333333336
Training loss = 0.03474724193414052
step = 5, Training Accuracy: 0.42
Validation Accuracy: 0.50375
Training loss = 0.034121031761169436
step = 6, Training Accuracy: 0.48333333333333334
Training loss = 0.03414345681667328
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.03500215927759806
step = 8, Training Accuracy: 0.43666666666666665
Training loss = 0.03387231747309367
step = 9, Training Accuracy: 0.43666666666666665
Training loss = 0.0342790945370992
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.49
Training loss = 0.034116012454032896
step = 11, Training Accuracy: 0.45666666666666667
Training loss = 0.034774205684661864
step = 12, Training Accuracy: 0.4633333333333333
Training loss = 0.03394971311092377
step = 13, Training Accuracy: 0.52
Training loss = 0.033740005294481915
step = 14, Training Accuracy: 0.49
Validation Accuracy: 0.47125
params:  [0.08460558922991307, 0.1186383356072947, 0.898226060506633, 0.16205558452344102, 0.6796781683776347, 0.6085386797530551, 0.01, 0.9726040114151334, 0.43271850455662997, 0.0573155419738981, 0.26125024382156675, 0.040922861901262333, 0.14244319306900322, 0.15482921710021086, 0.6771212647615603, 0.3144722733783258, 0.31623868357917806, 0.99, 0.35569525772190613, 0.99, 0.21774770819967393, 0.12398222127029873, 0.6735723071125286, 0.01, 0.42847934247073816, 0.5499931743720872, 0.543975173258262, 0.01, 0.99, 0.5306963339516179, 0.99, 0.99, 0.4925063735277757, 0.2695998588311474, 0.06825332528645647, 0.5927420257688261, 0.01, 0.5117592077062447, 0.8179738860134709, 0.7809012851793358, 0.6345422065694684, 0.01, 0.22804035884993945, 0.24979934583891467, 0.7080198956538485, 0.27267662987357905, 0.01, 0.31905591689557267, 0.9083083326983283, 0.6340495940305544, 0.3834389736108761, 0.4835357447912227, 0.4188700393659902, 0.36266764610202273, 0.7694244759263755, 0.2160108802520851, 0.01, 0.38952207768811736, 0.01, 0.05114898915279355, 0.48104688002115525, 0.4996732600337279, 0.01, 0.952001110939249, 0.741152353386257, 0.5359449113601595, 0.2452381833027673, 0.205505805734748, 0.5722151272998183, 0.679712205665504, 0.5707249729212426, 0.01, 0.3301358140391541, 0.48450856974506784, 0.5070684357860056, 0.01, 0.33306645233157983, 0.40543362485014967, 0.42467303409013224, 0.5433322926269865, 0.5189729641709608, 0.6130204906384363, 0.36902645321660066, 0.5174970854301575, 0.7940468032576092, 0.3254897581202141, 0.7843885839557203, 0.01, 0.10350528957439464, 0.01, 0.01, 0.29439891220647463]
[0.08460558922991307, 0.1186383356072947, 0.898226060506633, 0.16205558452344102, 0.6796781683776347, 0.6085386797530551, 0.01, 0.9726040114151334, 0.43271850455662997, 0.0573155419738981, 0.26125024382156675, 0.040922861901262333, 0.14244319306900322, 0.15482921710021086, 0.6771212647615603, 0.3144722733783258, 0.31623868357917806, 0.99, 0.35569525772190613, 0.99, 0.21774770819967393, 0.12398222127029873, 0.6735723071125286, 0.01, 0.42847934247073816, 0.5499931743720872, 0.543975173258262, 0.01, 0.99, 0.5306963339516179, 0.99, 0.99, 0.4925063735277757, 0.2695998588311474, 0.06825332528645647, 0.5927420257688261, 0.01, 0.5117592077062447, 0.8179738860134709, 0.7809012851793358, 0.6345422065694684, 0.01, 0.22804035884993945, 0.24979934583891467, 0.7080198956538485, 0.27267662987357905, 0.01, 0.31905591689557267, 0.9083083326983283, 0.6340495940305544, 0.3834389736108761, 0.4835357447912227, 0.4188700393659902, 0.36266764610202273, 0.7694244759263755, 0.2160108802520851, 0.01, 0.38952207768811736, 0.01, 0.05114898915279355, 0.48104688002115525, 0.4996732600337279, 0.01, 0.952001110939249, 0.741152353386257, 0.5359449113601595, 0.2452381833027673, 0.205505805734748, 0.5722151272998183, 0.679712205665504, 0.5707249729212426, 0.01, 0.3301358140391541, 0.48450856974506784, 0.5070684357860056, 0.01, 0.33306645233157983, 0.40543362485014967, 0.42467303409013224, 0.5433322926269865, 0.5189729641709608, 0.6130204906384363, 0.36902645321660066, 0.5174970854301575, 0.7940468032576092, 0.3254897581202141, 0.7843885839557203, 0.01, 0.10350528957439464, 0.01, 0.01, 0.29439891220647463]
Training loss = 0.033860459725062055
step = 0, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.49125
Training loss = 0.032744041482607525
step = 1, Training Accuracy: 0.51
Training loss = 0.032423826654752096
step = 2, Training Accuracy: 0.47333333333333333
Training loss = 0.03279765844345093
step = 3, Training Accuracy: 0.5
Training loss = 0.03397838771343231
step = 4, Training Accuracy: 0.49
Training loss = 0.03303366760412852
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.4825
Training loss = 0.0327804696559906
step = 6, Training Accuracy: 0.47
Training loss = 0.03268187761306763
step = 7, Training Accuracy: 0.5233333333333333
Training loss = 0.032450856367746986
step = 8, Training Accuracy: 0.5
Training loss = 0.033112511436144514
step = 9, Training Accuracy: 0.4666666666666667
Training loss = 0.033008384307225545
step = 10, Training Accuracy: 0.49
Validation Accuracy: 0.51375
Training loss = 0.0314500367641449
step = 11, Training Accuracy: 0.5233333333333333
Training loss = 0.032936939001083375
step = 12, Training Accuracy: 0.48333333333333334
Training loss = 0.032399159669876096
step = 13, Training Accuracy: 0.43666666666666665
Training loss = 0.0320435897509257
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.4875
params:  [0.1593126857510277, 0.44715096356441997, 0.31055805830520034, 0.99, 0.4156627365167864, 0.3595553841092128, 0.01, 0.8560556060818869, 0.7000433874777858, 0.024543180909866437, 0.10773993032852358, 0.6052690380874071, 0.01, 0.3232922352544047, 0.9288817082550956, 0.4249189105326546, 0.29418006430270216, 0.4075733501907769, 0.6599764921382589, 0.6107647910937385, 0.5282281956429058, 0.9414042610379317, 0.01, 0.22116558218591673, 0.3021705313517427, 0.3578827920999955, 0.99, 0.0500899331620506, 0.3171072352643992, 0.45868640126075544, 0.791220688545885, 0.8269493453284429, 0.2460655535350323, 0.01, 0.3910448422275272, 0.6662190829064087, 0.01, 0.9662346896368278, 0.99, 0.99, 0.8072658487137804, 0.2863741092744391, 0.1744793002077673, 0.27903745326693974, 0.7386767154482963, 0.4181563494477373, 0.04094832519267495, 0.8156315200129434, 0.12548419316609694, 0.99, 0.6164866694844371, 0.8944358656353619, 0.01, 0.8574475755184034, 0.4671098254264703, 0.02652522411411333, 0.06725130060709306, 0.5795053322678346, 0.44064089632944936, 0.18451624588713905, 0.99, 0.7815463680636232, 0.19306617820518032, 0.48101067186860846, 0.5172605995272603, 0.8713224805243577, 0.01, 0.29120141378848263, 0.6129248716337712, 0.6122828096714882, 0.6991206174907624, 0.5474637417234917, 0.26833913431704526, 0.5067698016945896, 0.42208001752511515, 0.4705212297639137, 0.2053040631849131, 0.8107512377761088, 0.01, 0.48370297654042826, 0.3890152615021181, 0.6407701098613705, 0.5288008381074071, 0.468706867894074, 0.5001384608343441, 0.8210134876776232, 0.3284433472599043, 0.2914169543491812, 0.01, 0.01, 0.2959432591987472, 0.32678565647641633]
[0.1593126857510277, 0.44715096356441997, 0.31055805830520034, 0.99, 0.4156627365167864, 0.3595553841092128, 0.01, 0.8560556060818869, 0.7000433874777858, 0.024543180909866437, 0.10773993032852358, 0.6052690380874071, 0.01, 0.3232922352544047, 0.9288817082550956, 0.4249189105326546, 0.29418006430270216, 0.4075733501907769, 0.6599764921382589, 0.6107647910937385, 0.5282281956429058, 0.9414042610379317, 0.01, 0.22116558218591673, 0.3021705313517427, 0.3578827920999955, 0.99, 0.0500899331620506, 0.3171072352643992, 0.45868640126075544, 0.791220688545885, 0.8269493453284429, 0.2460655535350323, 0.01, 0.3910448422275272, 0.6662190829064087, 0.01, 0.9662346896368278, 0.99, 0.99, 0.8072658487137804, 0.2863741092744391, 0.1744793002077673, 0.27903745326693974, 0.7386767154482963, 0.4181563494477373, 0.04094832519267495, 0.8156315200129434, 0.12548419316609694, 0.99, 0.6164866694844371, 0.8944358656353619, 0.01, 0.8574475755184034, 0.4671098254264703, 0.02652522411411333, 0.06725130060709306, 0.5795053322678346, 0.44064089632944936, 0.18451624588713905, 0.99, 0.7815463680636232, 0.19306617820518032, 0.48101067186860846, 0.5172605995272603, 0.8713224805243577, 0.01, 0.29120141378848263, 0.6129248716337712, 0.6122828096714882, 0.6991206174907624, 0.5474637417234917, 0.26833913431704526, 0.5067698016945896, 0.42208001752511515, 0.4705212297639137, 0.2053040631849131, 0.8107512377761088, 0.01, 0.48370297654042826, 0.3890152615021181, 0.6407701098613705, 0.5288008381074071, 0.468706867894074, 0.5001384608343441, 0.8210134876776232, 0.3284433472599043, 0.2914169543491812, 0.01, 0.01, 0.2959432591987472, 0.32678565647641633]
Training loss = 0.03570635795593262
step = 0, Training Accuracy: 0.43
Validation Accuracy: 0.47
Training loss = 0.03471399128437042
step = 1, Training Accuracy: 0.46
Training loss = 0.03480177044868469
step = 2, Training Accuracy: 0.5333333333333333
Training loss = 0.03579151968161265
step = 3, Training Accuracy: 0.44333333333333336
Training loss = 0.034642184376716616
step = 4, Training Accuracy: 0.49333333333333335
Training loss = 0.03474564492702484
step = 5, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.47875
Training loss = 0.033476043740908304
step = 6, Training Accuracy: 0.48333333333333334
Training loss = 0.03336805780728658
step = 7, Training Accuracy: 0.5133333333333333
Training loss = 0.03308424433072408
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.034194525281588235
step = 9, Training Accuracy: 0.47
Training loss = 0.033940554062525434
step = 10, Training Accuracy: 0.5
Validation Accuracy: 0.4975
Training loss = 0.03379721760749817
step = 11, Training Accuracy: 0.48
Training loss = 0.03363928397496541
step = 12, Training Accuracy: 0.4866666666666667
Training loss = 0.03493127405643463
step = 13, Training Accuracy: 0.44666666666666666
Training loss = 0.03577220479647319
step = 14, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.50375
params:  [0.3103324895208534, 0.12326782315689422, 0.8271458963058363, 0.28319763740772214, 0.2612575969714512, 0.9009006781130481, 0.06200634565133872, 0.8352092113553838, 0.99, 0.2257862288940932, 0.01, 0.504863176501291, 0.3460516411187064, 0.31495504227760074, 0.8176462106733218, 0.9410854643258568, 0.01, 0.902539061215051, 0.7899489948464928, 0.1844788869604303, 0.01, 0.5523770521980509, 0.01, 0.3478495649363623, 0.40133591149441356, 0.21788961293086662, 0.19737329195506792, 0.01, 0.5847500466084778, 0.5388390952313755, 0.6213186670548356, 0.99, 0.4965395193921525, 0.01, 0.34308359654356446, 0.6977534164508997, 0.7107399215226187, 0.44671797788131573, 0.7776757541105858, 0.03898016920148878, 0.1931282430810078, 0.259724525607823, 0.01, 0.6931857796845462, 0.682845047510479, 0.4577779119782993, 0.2691530051861848, 0.99, 0.8183391703403287, 0.7886277524482441, 0.5356154797039958, 0.3159154746450187, 0.5764465493021577, 0.9301032222124889, 0.5095779433409602, 0.6273539698794582, 0.01, 0.39428433817073477, 0.01, 0.20250620092901744, 0.7104249211620113, 0.99, 0.21569739423484213, 0.09358324039133359, 0.01, 0.5779346496561443, 0.49929239136352327, 0.45186132216556735, 0.035439530636717814, 0.9125307016158863, 0.5120792791414153, 0.01, 0.8462144626973542, 0.3000743739417805, 0.31558501659194715, 0.5983660488638676, 0.0788459493821222, 0.5081733640641336, 0.07385027515230771, 0.01, 0.5281699657352681, 0.6835303346486922, 0.335234068068008, 0.32165501948782105, 0.22089768826188821, 0.5709631630199504, 0.8129610706225523, 0.386656308417924, 0.4990860080833332, 0.25693277917679613, 0.01, 0.5503549341065846]
[0.3103324895208534, 0.12326782315689422, 0.8271458963058363, 0.28319763740772214, 0.2612575969714512, 0.9009006781130481, 0.06200634565133872, 0.8352092113553838, 0.99, 0.2257862288940932, 0.01, 0.504863176501291, 0.3460516411187064, 0.31495504227760074, 0.8176462106733218, 0.9410854643258568, 0.01, 0.902539061215051, 0.7899489948464928, 0.1844788869604303, 0.01, 0.5523770521980509, 0.01, 0.3478495649363623, 0.40133591149441356, 0.21788961293086662, 0.19737329195506792, 0.01, 0.5847500466084778, 0.5388390952313755, 0.6213186670548356, 0.99, 0.4965395193921525, 0.01, 0.34308359654356446, 0.6977534164508997, 0.7107399215226187, 0.44671797788131573, 0.7776757541105858, 0.03898016920148878, 0.1931282430810078, 0.259724525607823, 0.01, 0.6931857796845462, 0.682845047510479, 0.4577779119782993, 0.2691530051861848, 0.99, 0.8183391703403287, 0.7886277524482441, 0.5356154797039958, 0.3159154746450187, 0.5764465493021577, 0.9301032222124889, 0.5095779433409602, 0.6273539698794582, 0.01, 0.39428433817073477, 0.01, 0.20250620092901744, 0.7104249211620113, 0.99, 0.21569739423484213, 0.09358324039133359, 0.01, 0.5779346496561443, 0.49929239136352327, 0.45186132216556735, 0.035439530636717814, 0.9125307016158863, 0.5120792791414153, 0.01, 0.8462144626973542, 0.3000743739417805, 0.31558501659194715, 0.5983660488638676, 0.0788459493821222, 0.5081733640641336, 0.07385027515230771, 0.01, 0.5281699657352681, 0.6835303346486922, 0.335234068068008, 0.32165501948782105, 0.22089768826188821, 0.5709631630199504, 0.8129610706225523, 0.386656308417924, 0.4990860080833332, 0.25693277917679613, 0.01, 0.5503549341065846]
Training loss = 0.03429143607616424
step = 0, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.48375
Training loss = 0.034362419843673705
step = 1, Training Accuracy: 0.47
Training loss = 0.03487797876199086
step = 2, Training Accuracy: 0.46
Training loss = 0.03221101065476736
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.03421525021394094
step = 4, Training Accuracy: 0.43666666666666665
Training loss = 0.034115950465202334
step = 5, Training Accuracy: 0.46
Validation Accuracy: 0.48875
Training loss = 0.03287796676158905
step = 6, Training Accuracy: 0.49
Training loss = 0.03343006292978923
step = 7, Training Accuracy: 0.4533333333333333
Training loss = 0.034605122605959576
step = 8, Training Accuracy: 0.46
Training loss = 0.033441791335741676
step = 9, Training Accuracy: 0.43
Training loss = 0.0318474672238032
step = 10, Training Accuracy: 0.54
Validation Accuracy: 0.515
Training loss = 0.033477642933527625
step = 11, Training Accuracy: 0.4666666666666667
Training loss = 0.03225408911705017
step = 12, Training Accuracy: 0.56
Training loss = 0.03313031017780304
step = 13, Training Accuracy: 0.49333333333333335
Training loss = 0.032891935308774316
step = 14, Training Accuracy: 0.5
Validation Accuracy: 0.5175
params:  [0.11936705497447256, 0.434283356031335, 0.9806430448759036, 0.2534672048484633, 0.4744737869673884, 0.4171453879238989, 0.01, 0.748238569368844, 0.7619419425501666, 0.1206415598358524, 0.5363620108000507, 0.01, 0.01, 0.4340409938896394, 0.6815164442562301, 0.4098531511493727, 0.1437879071808697, 0.3474766757310981, 0.8086913727719724, 0.6869617614324957, 0.01, 0.2963576787267075, 0.22924474920807486, 0.01, 0.46756963920670785, 0.01, 0.555367626338604, 0.01, 0.4350231119697645, 0.01, 0.3853791000164871, 0.2544215527271393, 0.32653921058617624, 0.1426162733139799, 0.16850031369836335, 0.8785621751176527, 0.1984777386496005, 0.9473923125089607, 0.8443143246923154, 0.4185917322468862, 0.5918582957239316, 0.4001847154908553, 0.01, 0.44068221727848655, 0.3229035818902705, 0.37181930173787336, 0.0786093388735197, 0.99, 0.6863375670445016, 0.8901894652470288, 0.4542794833942055, 0.6937744647037686, 0.7417252466097669, 0.7985033959782813, 0.9514768241440883, 0.32741076240685507, 0.01, 0.2759324973311585, 0.22009887460128547, 0.3194758008055848, 0.6556774598341135, 0.5168713024192646, 0.21196402557201738, 0.6539951502121131, 0.13586824014074964, 0.35312668008475906, 0.01, 0.5206103344300379, 0.3270001440154363, 0.99, 0.01, 0.562985393018859, 0.9388974111527875, 0.99, 0.5699924946629241, 0.01, 0.28479626667884134, 0.01, 0.28862727545457667, 0.2674973225509809, 0.5756999009900587, 0.20924297601292374, 0.893086361077495, 0.5733764975581742, 0.7700970177480282, 0.492695002233374, 0.13443517099807267, 0.01, 0.01, 0.6458868189252891, 0.013917472673107625, 0.5714571328958368]
[0.11936705497447256, 0.434283356031335, 0.9806430448759036, 0.2534672048484633, 0.4744737869673884, 0.4171453879238989, 0.01, 0.748238569368844, 0.7619419425501666, 0.1206415598358524, 0.5363620108000507, 0.01, 0.01, 0.4340409938896394, 0.6815164442562301, 0.4098531511493727, 0.1437879071808697, 0.3474766757310981, 0.8086913727719724, 0.6869617614324957, 0.01, 0.2963576787267075, 0.22924474920807486, 0.01, 0.46756963920670785, 0.01, 0.555367626338604, 0.01, 0.4350231119697645, 0.01, 0.3853791000164871, 0.2544215527271393, 0.32653921058617624, 0.1426162733139799, 0.16850031369836335, 0.8785621751176527, 0.1984777386496005, 0.9473923125089607, 0.8443143246923154, 0.4185917322468862, 0.5918582957239316, 0.4001847154908553, 0.01, 0.44068221727848655, 0.3229035818902705, 0.37181930173787336, 0.0786093388735197, 0.99, 0.6863375670445016, 0.8901894652470288, 0.4542794833942055, 0.6937744647037686, 0.7417252466097669, 0.7985033959782813, 0.9514768241440883, 0.32741076240685507, 0.01, 0.2759324973311585, 0.22009887460128547, 0.3194758008055848, 0.6556774598341135, 0.5168713024192646, 0.21196402557201738, 0.6539951502121131, 0.13586824014074964, 0.35312668008475906, 0.01, 0.5206103344300379, 0.3270001440154363, 0.99, 0.01, 0.562985393018859, 0.9388974111527875, 0.99, 0.5699924946629241, 0.01, 0.28479626667884134, 0.01, 0.28862727545457667, 0.2674973225509809, 0.5756999009900587, 0.20924297601292374, 0.893086361077495, 0.5733764975581742, 0.7700970177480282, 0.492695002233374, 0.13443517099807267, 0.01, 0.01, 0.6458868189252891, 0.013917472673107625, 0.5714571328958368]
Training loss = 0.03274194518725077
step = 0, Training Accuracy: 0.52
Validation Accuracy: 0.52
Training loss = 0.032157731056213376
step = 1, Training Accuracy: 0.5
Training loss = 0.03352082928021749
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.032311883171399436
step = 3, Training Accuracy: 0.53
Training loss = 0.031240736643473307
step = 4, Training Accuracy: 0.56
Training loss = 0.03123041848341624
step = 5, Training Accuracy: 0.5433333333333333
Validation Accuracy: 0.5225
Training loss = 0.0319859250386556
step = 6, Training Accuracy: 0.49333333333333335
Training loss = 0.031895359754562376
step = 7, Training Accuracy: 0.5266666666666666
Training loss = 0.031199294328689575
step = 8, Training Accuracy: 0.5333333333333333
Training loss = 0.032384712696075436
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.030957038799921673
step = 10, Training Accuracy: 0.53
Validation Accuracy: 0.5275
Training loss = 0.03120008130868276
step = 11, Training Accuracy: 0.51
Training loss = 0.031034677227338155
step = 12, Training Accuracy: 0.5433333333333333
Training loss = 0.031772358417510985
step = 13, Training Accuracy: 0.5366666666666666
Training loss = 0.03160959482192993
step = 14, Training Accuracy: 0.5433333333333333
Validation Accuracy: 0.51875
params:  [0.3075101948589885, 0.44474159584245154, 0.9092087370671191, 0.01, 0.661318244252966, 0.5783227916841192, 0.03370191742979833, 0.9695761563159445, 0.42123857377849616, 0.704215081685469, 0.2891188101934702, 0.01, 0.028549789798629488, 0.99, 0.39512143574465874, 0.5979647516919131, 0.5469918060585572, 0.9302987124788432, 0.48706318607670995, 0.7772366128006689, 0.01, 0.4987499804180424, 0.7622230998871296, 0.3758060165611411, 0.21917061031582402, 0.2214717811615573, 0.99, 0.6360925216514389, 0.8134405416680228, 0.17914793504390739, 0.7501440452562204, 0.99, 0.9064981311633621, 0.14972094568493274, 0.01, 0.7276108707116808, 0.5185405169457111, 0.850223570346616, 0.8744986712543107, 0.01, 0.459837552697224, 0.05919015761877666, 0.3415329211074592, 0.29781940323645395, 0.2830740574384085, 0.4214516431578736, 0.21899615954763474, 0.6937042633578414, 0.4956726969427414, 0.3027041994511023, 0.8922646918399856, 0.3783750706021141, 0.27371613267514255, 0.99, 0.36456817736116004, 0.7257581716745325, 0.01, 0.3127402172711866, 0.5007853806903607, 0.08222856323797179, 0.8273925018282922, 0.6711024382597773, 0.3915547005113078, 0.49703231213336635, 0.3463756344527952, 0.7909224447419413, 0.46534461502663016, 0.7627137394183618, 0.4635166403639386, 0.8730622466239406, 0.3697311460431475, 0.12896702882402492, 0.4734006811210791, 0.7250317450326846, 0.5385063100293586, 0.1212112129477029, 0.1148473482927278, 0.3530323354835123, 0.5755580828397114, 0.553272317830325, 0.7716887189293341, 0.99, 0.13504503770632637, 0.4838814639098807, 0.596720608678848, 0.6434619894901954, 0.99, 0.6698233360257887, 0.19054618860245376, 0.4588230696255563, 0.08105097362001264, 0.8070572613914231]
[0.3075101948589885, 0.44474159584245154, 0.9092087370671191, 0.01, 0.661318244252966, 0.5783227916841192, 0.03370191742979833, 0.9695761563159445, 0.42123857377849616, 0.704215081685469, 0.2891188101934702, 0.01, 0.028549789798629488, 0.99, 0.39512143574465874, 0.5979647516919131, 0.5469918060585572, 0.9302987124788432, 0.48706318607670995, 0.7772366128006689, 0.01, 0.4987499804180424, 0.7622230998871296, 0.3758060165611411, 0.21917061031582402, 0.2214717811615573, 0.99, 0.6360925216514389, 0.8134405416680228, 0.17914793504390739, 0.7501440452562204, 0.99, 0.9064981311633621, 0.14972094568493274, 0.01, 0.7276108707116808, 0.5185405169457111, 0.850223570346616, 0.8744986712543107, 0.01, 0.459837552697224, 0.05919015761877666, 0.3415329211074592, 0.29781940323645395, 0.2830740574384085, 0.4214516431578736, 0.21899615954763474, 0.6937042633578414, 0.4956726969427414, 0.3027041994511023, 0.8922646918399856, 0.3783750706021141, 0.27371613267514255, 0.99, 0.36456817736116004, 0.7257581716745325, 0.01, 0.3127402172711866, 0.5007853806903607, 0.08222856323797179, 0.8273925018282922, 0.6711024382597773, 0.3915547005113078, 0.49703231213336635, 0.3463756344527952, 0.7909224447419413, 0.46534461502663016, 0.7627137394183618, 0.4635166403639386, 0.8730622466239406, 0.3697311460431475, 0.12896702882402492, 0.4734006811210791, 0.7250317450326846, 0.5385063100293586, 0.1212112129477029, 0.1148473482927278, 0.3530323354835123, 0.5755580828397114, 0.553272317830325, 0.7716887189293341, 0.99, 0.13504503770632637, 0.4838814639098807, 0.596720608678848, 0.6434619894901954, 0.99, 0.6698233360257887, 0.19054618860245376, 0.4588230696255563, 0.08105097362001264, 0.8070572613914231]
Training loss = 0.03578328768412272
step = 0, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.4675
Training loss = 0.035563323895136514
step = 1, Training Accuracy: 0.4266666666666667
Training loss = 0.035302023688952126
step = 2, Training Accuracy: 0.44666666666666666
Training loss = 0.035253435770670576
step = 3, Training Accuracy: 0.4533333333333333
Training loss = 0.03418407102425893
step = 4, Training Accuracy: 0.43333333333333335
Training loss = 0.03408156077067057
step = 5, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.46375
Training loss = 0.034122052590052285
step = 6, Training Accuracy: 0.4666666666666667
Training loss = 0.03329967260360718
step = 7, Training Accuracy: 0.47
Training loss = 0.033713191350301104
step = 8, Training Accuracy: 0.5233333333333333
Training loss = 0.03366498291492462
step = 9, Training Accuracy: 0.49
Training loss = 0.03334209442138672
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.47875
Training loss = 0.03256211857000987
step = 11, Training Accuracy: 0.4766666666666667
Training loss = 0.034813989798227946
step = 12, Training Accuracy: 0.47
Training loss = 0.03313138723373413
step = 13, Training Accuracy: 0.46
Training loss = 0.034075969457626344
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.475
1  	8     	0.487656	0.0215098	0.46125	0.51875
params:  [0.09585866752337319, 0.15241672710577164, 0.99, 0.5054093615532155, 0.024585681347516097, 0.01, 0.2056503933812418, 0.3543339045190604, 0.99, 0.18420070632241936, 0.18586964960043179, 0.31645845489252705, 0.6084432329469533, 0.5765458567873065, 0.44626309925379304, 0.06515780752006634, 0.36397018333125686, 0.434950780750904, 0.99, 0.01, 0.01, 0.3596722731680176, 0.01, 0.01, 0.6375561209187023, 0.01, 0.22697474174598853, 0.4240248492322583, 0.5969340925188942, 0.01, 0.1514907457365754, 0.99, 0.06835101255289427, 0.01, 0.3190951368294085, 0.99, 0.17088028339543268, 0.7797094058233272, 0.99, 0.7598972834775994, 0.174263026772973, 0.5091349198589054, 0.040947028386310695, 0.5212286206827249, 0.843589802598983, 0.01, 0.1887744233568877, 0.5452823726924925, 0.659885083257846, 0.26014441781447284, 0.3667869420751135, 0.8500571485033322, 0.6190008014107389, 0.45707335557093787, 0.8948889649237723, 0.6171828769079746, 0.3105543382433717, 0.35734673027779584, 0.6668563946833923, 0.062439548681546164, 0.719655005755628, 0.9374328541214123, 0.3952445280760948, 0.7267400157880852, 0.01, 0.900479154220852, 0.13870178274291206, 0.6654327537559849, 0.527550506001384, 0.99, 0.8399008270472414, 0.17045235943252227, 0.5883517579032269, 0.01, 0.4371305558220656, 0.022733356408974198, 0.1272369199174882, 0.4274041376607799, 0.01, 0.6555667847291916, 0.909057919221911, 0.6065841698345212, 0.6861675695217001, 0.7921183457858869, 0.7158141080018262, 0.3325607972398216, 0.5546885540435731, 0.10570844272389948, 0.5786696039648805, 0.2872083301335419, 0.10651698728848732, 0.5180215350608084]
[0.09585866752337319, 0.15241672710577164, 0.99, 0.5054093615532155, 0.024585681347516097, 0.01, 0.2056503933812418, 0.3543339045190604, 0.99, 0.18420070632241936, 0.18586964960043179, 0.31645845489252705, 0.6084432329469533, 0.5765458567873065, 0.44626309925379304, 0.06515780752006634, 0.36397018333125686, 0.434950780750904, 0.99, 0.01, 0.01, 0.3596722731680176, 0.01, 0.01, 0.6375561209187023, 0.01, 0.22697474174598853, 0.4240248492322583, 0.5969340925188942, 0.01, 0.1514907457365754, 0.99, 0.06835101255289427, 0.01, 0.3190951368294085, 0.99, 0.17088028339543268, 0.7797094058233272, 0.99, 0.7598972834775994, 0.174263026772973, 0.5091349198589054, 0.040947028386310695, 0.5212286206827249, 0.843589802598983, 0.01, 0.1887744233568877, 0.5452823726924925, 0.659885083257846, 0.26014441781447284, 0.3667869420751135, 0.8500571485033322, 0.6190008014107389, 0.45707335557093787, 0.8948889649237723, 0.6171828769079746, 0.3105543382433717, 0.35734673027779584, 0.6668563946833923, 0.062439548681546164, 0.719655005755628, 0.9374328541214123, 0.3952445280760948, 0.7267400157880852, 0.01, 0.900479154220852, 0.13870178274291206, 0.6654327537559849, 0.527550506001384, 0.99, 0.8399008270472414, 0.17045235943252227, 0.5883517579032269, 0.01, 0.4371305558220656, 0.022733356408974198, 0.1272369199174882, 0.4274041376607799, 0.01, 0.6555667847291916, 0.909057919221911, 0.6065841698345212, 0.6861675695217001, 0.7921183457858869, 0.7158141080018262, 0.3325607972398216, 0.5546885540435731, 0.10570844272389948, 0.5786696039648805, 0.2872083301335419, 0.10651698728848732, 0.5180215350608084]
Training loss = 0.03328371504942576
step = 0, Training Accuracy: 0.45
Validation Accuracy: 0.47625
Training loss = 0.03340901454289754
step = 1, Training Accuracy: 0.49666666666666665
Training loss = 0.033568668564160666
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.03299126346906026
step = 3, Training Accuracy: 0.5133333333333333
Training loss = 0.03386310120423635
step = 4, Training Accuracy: 0.49
Training loss = 0.03306884646415711
step = 5, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.48875
Training loss = 0.03354417343934377
step = 6, Training Accuracy: 0.5033333333333333
Training loss = 0.033705754478772484
step = 7, Training Accuracy: 0.44666666666666666
Training loss = 0.03321972926457723
step = 8, Training Accuracy: 0.5066666666666667
Training loss = 0.032817975481351215
step = 9, Training Accuracy: 0.51
Training loss = 0.032257984876632693
step = 10, Training Accuracy: 0.5
Validation Accuracy: 0.545
Training loss = 0.03274307827154795
step = 11, Training Accuracy: 0.45666666666666667
Training loss = 0.0333010983467102
step = 12, Training Accuracy: 0.51
Training loss = 0.033498210112253825
step = 13, Training Accuracy: 0.49
Training loss = 0.032479920585950214
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.505
params:  [0.01, 0.5568441725468698, 0.99, 0.1050592063360758, 0.37244360985178493, 0.4522630358115919, 0.01, 0.9021268745928792, 0.8790611594657276, 0.01, 0.5850429463591176, 0.1898216664848123, 0.11536917170011785, 0.3237292116335069, 0.4144510055648492, 0.7895177438877226, 0.2988276054980926, 0.99, 0.6941035958758612, 0.2722562533084063, 0.3804703819426001, 0.41172273839339396, 0.01, 0.08792222019986076, 0.01, 0.611635785192643, 0.5762996437890135, 0.16363954271008457, 0.7345460916233228, 0.30674431030466287, 0.030234378510641924, 0.3006989427111886, 0.49131006436818914, 0.41860328543020914, 0.12582503864804473, 0.99, 0.01, 0.9780285160720933, 0.8899941005298224, 0.01, 0.3799059388974607, 0.7349931016194571, 0.01, 0.7206277728801875, 0.6607873405243048, 0.5130516285758224, 0.26214825988774165, 0.7223094530235085, 0.99, 0.8149107558395566, 0.4306179660295914, 0.499583861826118, 0.17696414170981367, 0.8968234755204637, 0.8476272751337391, 0.99, 0.3906961841559353, 0.6750390241302873, 0.1304793108454459, 0.4304621352053576, 0.4120104504229563, 0.7693336670563767, 0.21119077930890762, 0.3328323817078882, 0.037168384193745074, 0.8357699839642029, 0.4867394286891683, 0.40241715542462153, 0.06295747626054665, 0.4578631301200246, 0.01, 0.3607607274369941, 0.7056005267867504, 0.34361679766355085, 0.07298306826400242, 0.8493549635199742, 0.20299116604225823, 0.527463982237989, 0.2455474555074012, 0.3019373968818021, 0.4845985714958467, 0.44204968310492787, 0.44147203834860904, 0.43388191742228244, 0.7297460641893543, 0.5995306459417148, 0.3743525384706609, 0.2543256545361368, 0.09707047937383692, 0.40636433336464195, 0.01, 0.43442677079196695]
[0.01, 0.5568441725468698, 0.99, 0.1050592063360758, 0.37244360985178493, 0.4522630358115919, 0.01, 0.9021268745928792, 0.8790611594657276, 0.01, 0.5850429463591176, 0.1898216664848123, 0.11536917170011785, 0.3237292116335069, 0.4144510055648492, 0.7895177438877226, 0.2988276054980926, 0.99, 0.6941035958758612, 0.2722562533084063, 0.3804703819426001, 0.41172273839339396, 0.01, 0.08792222019986076, 0.01, 0.611635785192643, 0.5762996437890135, 0.16363954271008457, 0.7345460916233228, 0.30674431030466287, 0.030234378510641924, 0.3006989427111886, 0.49131006436818914, 0.41860328543020914, 0.12582503864804473, 0.99, 0.01, 0.9780285160720933, 0.8899941005298224, 0.01, 0.3799059388974607, 0.7349931016194571, 0.01, 0.7206277728801875, 0.6607873405243048, 0.5130516285758224, 0.26214825988774165, 0.7223094530235085, 0.99, 0.8149107558395566, 0.4306179660295914, 0.499583861826118, 0.17696414170981367, 0.8968234755204637, 0.8476272751337391, 0.99, 0.3906961841559353, 0.6750390241302873, 0.1304793108454459, 0.4304621352053576, 0.4120104504229563, 0.7693336670563767, 0.21119077930890762, 0.3328323817078882, 0.037168384193745074, 0.8357699839642029, 0.4867394286891683, 0.40241715542462153, 0.06295747626054665, 0.4578631301200246, 0.01, 0.3607607274369941, 0.7056005267867504, 0.34361679766355085, 0.07298306826400242, 0.8493549635199742, 0.20299116604225823, 0.527463982237989, 0.2455474555074012, 0.3019373968818021, 0.4845985714958467, 0.44204968310492787, 0.44147203834860904, 0.43388191742228244, 0.7297460641893543, 0.5995306459417148, 0.3743525384706609, 0.2543256545361368, 0.09707047937383692, 0.40636433336464195, 0.01, 0.43442677079196695]
Training loss = 0.0353686378399531
step = 0, Training Accuracy: 0.42
Validation Accuracy: 0.50125
Training loss = 0.03540197213490804
step = 1, Training Accuracy: 0.46
Training loss = 0.03511570294698079
step = 2, Training Accuracy: 0.4066666666666667
Training loss = 0.03423274795214335
step = 3, Training Accuracy: 0.4533333333333333
Training loss = 0.03464133322238922
step = 4, Training Accuracy: 0.42
Training loss = 0.03391242345174154
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.485
Training loss = 0.035222619970639545
step = 6, Training Accuracy: 0.4533333333333333
Training loss = 0.034695019920667015
step = 7, Training Accuracy: 0.43666666666666665
Training loss = 0.035573851267496744
step = 8, Training Accuracy: 0.38333333333333336
Training loss = 0.033093464771906535
step = 9, Training Accuracy: 0.5
Training loss = 0.03372812290986379
step = 10, Training Accuracy: 0.47
Validation Accuracy: 0.50375
Training loss = 0.03519355018933614
step = 11, Training Accuracy: 0.43666666666666665
Training loss = 0.03478570799032847
step = 12, Training Accuracy: 0.43333333333333335
Training loss = 0.03529009580612183
step = 13, Training Accuracy: 0.4166666666666667
Training loss = 0.034195825060208636
step = 14, Training Accuracy: 0.41
Validation Accuracy: 0.51
params:  [0.5166037666952134, 0.021475649193475, 0.6177716772889377, 0.99, 0.8506023681795261, 0.6800359816900853, 0.2815609828795637, 0.6116496226579975, 0.7869976524312556, 0.13070116638071103, 0.5361553033248602, 0.14695065736929389, 0.01, 0.0768656595850638, 0.99, 0.33319165240411885, 0.01, 0.43720762340688835, 0.4996735058960546, 0.7539209572041948, 0.04217840477840819, 0.5393303211325953, 0.17709615189828617, 0.12297050425111523, 0.5536553761660872, 0.01, 0.032943889764687984, 0.07806583509306717, 0.030736101563879348, 0.289974739426401, 0.116899184942381, 0.5160254563667123, 0.18826105460493828, 0.30499402064693315, 0.4012707608746114, 0.7442124985619799, 0.15649175595090867, 0.9040343872910042, 0.9322565433013065, 0.01, 0.01, 0.4250414161053032, 0.26182694539851503, 0.6877371405143973, 0.4088206121204514, 0.34125030190125655, 0.13013657503784132, 0.4307053506903662, 0.7411460114909207, 0.9045898358143651, 0.7469789252353689, 0.4832057759622185, 0.18745769313350458, 0.354967974263518, 0.5740112798315944, 0.01, 0.01, 0.42172824957828586, 0.09707608831650041, 0.28955715978916774, 0.6390380101505777, 0.99, 0.5610280206163947, 0.723059897472178, 0.4326670722680817, 0.06544681656786627, 0.24826015840559001, 0.99, 0.13611009909227983, 0.7228288451094756, 0.01, 0.4845901902427526, 0.5711329391497423, 0.15142859135472275, 0.7388691270259138, 0.01, 0.6784572782795568, 0.7420495652388313, 0.07162274964599309, 0.3090397218881307, 0.4959149365417335, 0.7245344010510375, 0.7452078657625522, 0.32151780497626226, 0.8456025460166379, 0.3249838221850605, 0.28833553241835347, 0.01, 0.1735861222421636, 0.34890094800526994, 0.30153392320458655, 0.38479284821947213]
[0.5166037666952134, 0.021475649193475, 0.6177716772889377, 0.99, 0.8506023681795261, 0.6800359816900853, 0.2815609828795637, 0.6116496226579975, 0.7869976524312556, 0.13070116638071103, 0.5361553033248602, 0.14695065736929389, 0.01, 0.0768656595850638, 0.99, 0.33319165240411885, 0.01, 0.43720762340688835, 0.4996735058960546, 0.7539209572041948, 0.04217840477840819, 0.5393303211325953, 0.17709615189828617, 0.12297050425111523, 0.5536553761660872, 0.01, 0.032943889764687984, 0.07806583509306717, 0.030736101563879348, 0.289974739426401, 0.116899184942381, 0.5160254563667123, 0.18826105460493828, 0.30499402064693315, 0.4012707608746114, 0.7442124985619799, 0.15649175595090867, 0.9040343872910042, 0.9322565433013065, 0.01, 0.01, 0.4250414161053032, 0.26182694539851503, 0.6877371405143973, 0.4088206121204514, 0.34125030190125655, 0.13013657503784132, 0.4307053506903662, 0.7411460114909207, 0.9045898358143651, 0.7469789252353689, 0.4832057759622185, 0.18745769313350458, 0.354967974263518, 0.5740112798315944, 0.01, 0.01, 0.42172824957828586, 0.09707608831650041, 0.28955715978916774, 0.6390380101505777, 0.99, 0.5610280206163947, 0.723059897472178, 0.4326670722680817, 0.06544681656786627, 0.24826015840559001, 0.99, 0.13611009909227983, 0.7228288451094756, 0.01, 0.4845901902427526, 0.5711329391497423, 0.15142859135472275, 0.7388691270259138, 0.01, 0.6784572782795568, 0.7420495652388313, 0.07162274964599309, 0.3090397218881307, 0.4959149365417335, 0.7245344010510375, 0.7452078657625522, 0.32151780497626226, 0.8456025460166379, 0.3249838221850605, 0.28833553241835347, 0.01, 0.1735861222421636, 0.34890094800526994, 0.30153392320458655, 0.38479284821947213]
Training loss = 0.03544062932332357
step = 0, Training Accuracy: 0.42
Validation Accuracy: 0.52125
Training loss = 0.03482070446014404
step = 1, Training Accuracy: 0.45
Training loss = 0.03582158108552297
step = 2, Training Accuracy: 0.4666666666666667
Training loss = 0.03460117379824321
step = 3, Training Accuracy: 0.52
Training loss = 0.03472672045230865
step = 4, Training Accuracy: 0.43
Training loss = 0.03455180903275808
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.53375
Training loss = 0.033950151403745014
step = 6, Training Accuracy: 0.48333333333333334
Training loss = 0.03324679017066955
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.03322895844777425
step = 8, Training Accuracy: 0.49
Training loss = 0.0345726744333903
step = 9, Training Accuracy: 0.46
Training loss = 0.03261627475420634
step = 10, Training Accuracy: 0.52
Validation Accuracy: 0.555
Training loss = 0.03397033154964447
step = 11, Training Accuracy: 0.47333333333333333
Training loss = 0.034531878232955934
step = 12, Training Accuracy: 0.49666666666666665
Training loss = 0.03467414915561676
step = 13, Training Accuracy: 0.4766666666666667
Training loss = 0.03394171516100566
step = 14, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.5325
params:  [0.1893527067638891, 0.5343419226043769, 0.9429847376472329, 0.5484912276374398, 0.7401245459984742, 0.1328731469302703, 0.01, 0.6923346145694732, 0.7463929623109322, 0.10508307498767042, 0.39902054061692155, 0.21406463846615234, 0.01, 0.24544008832958705, 0.8888109622029242, 0.625633796089251, 0.0958353831715609, 0.7878956190475761, 0.99, 0.57392272207619, 0.01, 0.5160338559067519, 0.3078765871291659, 0.19034798888075893, 0.6741886444355389, 0.11071005651808168, 0.1272680865392714, 0.01, 0.04929798826195825, 0.5507576608152532, 0.5836207142398966, 0.6452583058462864, 0.017898890344024643, 0.26120517172863544, 0.40449954097259144, 0.405751665775048, 0.3826482482228657, 0.29910000025522915, 0.6142183355694187, 0.8278172368564931, 0.3708553938693181, 0.4973506419866496, 0.01, 0.5894623476594717, 0.28633249727195575, 0.33560391275514667, 0.01, 0.99, 0.7219749734502441, 0.8705106063919534, 0.7674694397024913, 0.3068814927032517, 0.6751154807421487, 0.99, 0.8015294734131476, 0.5293685821018361, 0.5728300981140323, 0.9028185876424235, 0.1535433859638479, 0.01, 0.99, 0.7605011548448888, 0.09743215777814172, 0.9142052086404545, 0.01, 0.3184544695650885, 0.07661991571903728, 0.48284370682399785, 0.01, 0.99, 0.8952111632535789, 0.46831764346500127, 0.7106297416961428, 0.99, 0.8460568724137982, 0.01, 0.5206149358645824, 0.367566670076244, 0.5073252594310942, 0.01, 0.3386933492523818, 0.46315584662665255, 0.7600639022924169, 0.7936529965301662, 0.8381492245543419, 0.34349194150753665, 0.041628347644324326, 0.01, 0.489966891886866, 0.4289482729703661, 0.013924990775961786, 0.3850824775497992]
[0.1893527067638891, 0.5343419226043769, 0.9429847376472329, 0.5484912276374398, 0.7401245459984742, 0.1328731469302703, 0.01, 0.6923346145694732, 0.7463929623109322, 0.10508307498767042, 0.39902054061692155, 0.21406463846615234, 0.01, 0.24544008832958705, 0.8888109622029242, 0.625633796089251, 0.0958353831715609, 0.7878956190475761, 0.99, 0.57392272207619, 0.01, 0.5160338559067519, 0.3078765871291659, 0.19034798888075893, 0.6741886444355389, 0.11071005651808168, 0.1272680865392714, 0.01, 0.04929798826195825, 0.5507576608152532, 0.5836207142398966, 0.6452583058462864, 0.017898890344024643, 0.26120517172863544, 0.40449954097259144, 0.405751665775048, 0.3826482482228657, 0.29910000025522915, 0.6142183355694187, 0.8278172368564931, 0.3708553938693181, 0.4973506419866496, 0.01, 0.5894623476594717, 0.28633249727195575, 0.33560391275514667, 0.01, 0.99, 0.7219749734502441, 0.8705106063919534, 0.7674694397024913, 0.3068814927032517, 0.6751154807421487, 0.99, 0.8015294734131476, 0.5293685821018361, 0.5728300981140323, 0.9028185876424235, 0.1535433859638479, 0.01, 0.99, 0.7605011548448888, 0.09743215777814172, 0.9142052086404545, 0.01, 0.3184544695650885, 0.07661991571903728, 0.48284370682399785, 0.01, 0.99, 0.8952111632535789, 0.46831764346500127, 0.7106297416961428, 0.99, 0.8460568724137982, 0.01, 0.5206149358645824, 0.367566670076244, 0.5073252594310942, 0.01, 0.3386933492523818, 0.46315584662665255, 0.7600639022924169, 0.7936529965301662, 0.8381492245543419, 0.34349194150753665, 0.041628347644324326, 0.01, 0.489966891886866, 0.4289482729703661, 0.013924990775961786, 0.3850824775497992]
Training loss = 0.036518901983896894
step = 0, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.5175
Training loss = 0.034750475486119585
step = 1, Training Accuracy: 0.46
Training loss = 0.03487793584664663
step = 2, Training Accuracy: 0.44
Training loss = 0.0340681129693985
step = 3, Training Accuracy: 0.48
Training loss = 0.034860041141510006
step = 4, Training Accuracy: 0.4533333333333333
Training loss = 0.03440891683101654
step = 5, Training Accuracy: 0.44333333333333336
Validation Accuracy: 0.4975
Training loss = 0.03327522238095602
step = 6, Training Accuracy: 0.4866666666666667
Training loss = 0.031754933794339496
step = 7, Training Accuracy: 0.5166666666666667
Training loss = 0.03430969178676605
step = 8, Training Accuracy: 0.49666666666666665
Training loss = 0.033554094036420186
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.033340343435605366
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.50625
Training loss = 0.034210150241851804
step = 11, Training Accuracy: 0.47333333333333333
Training loss = 0.03408889730771383
step = 12, Training Accuracy: 0.42
Training loss = 0.03340618471304575
step = 13, Training Accuracy: 0.48
Training loss = 0.034409749110539754
step = 14, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.50875
params:  [0.22019145180768687, 0.4256801205802648, 0.99, 0.38990466615054636, 0.8909679350446202, 0.833167768177125, 0.05398754000713602, 0.4536072662747454, 0.7927049479451055, 0.06933121339875, 0.5653210320064286, 0.48164102126975095, 0.141260445141534, 0.5447917567404694, 0.9146805275797262, 0.529050311718174, 0.07474274041042876, 0.32173957505720463, 0.7913722026177303, 0.575095991099725, 0.01, 0.7413402116638943, 0.04103104998725958, 0.40729349712267143, 0.7233216424279264, 0.33677711971383895, 0.19674943514608723, 0.01, 0.7067487946628316, 0.01, 0.48764367670743247, 0.5672171512095485, 0.39978991040717027, 0.01, 0.05616323235318199, 0.7652982567536217, 0.20752023826781762, 0.99, 0.5886228503717699, 0.15623542661788042, 0.8131682789942716, 0.28410706767913163, 0.5512080662939667, 0.18271231578967967, 0.6178741279365662, 0.5689311914727707, 0.020958956979613447, 0.6525045654800941, 0.593724529050264, 0.3843782677969211, 0.5549589913863735, 0.4467648215087132, 0.3469400672824545, 0.6325617671632301, 0.2970961361134232, 0.5467604353837472, 0.20492107961367867, 0.6678982249154859, 0.337377574321108, 0.01, 0.8890901602739921, 0.36948480144752915, 0.597415160203371, 0.48829841444956806, 0.5068739775930278, 0.06968406725965814, 0.3181061719192039, 0.14947608280339852, 0.09657462931992297, 0.7414927605968779, 0.5415640312992713, 0.9827863654273992, 0.7517353974629997, 0.7053347163844237, 0.32013711417132973, 0.39747949233063323, 0.6819435535535057, 0.42126743248721715, 0.01, 0.39315572329824544, 0.9645689799718808, 0.3157182745528369, 0.39979409168432006, 0.15139073229112282, 0.8381125108785314, 0.5434533381795673, 0.2718512007184845, 0.27869831042460974, 0.2299279535293958, 0.014211742063843624, 0.01, 0.4482275732310158]
[0.22019145180768687, 0.4256801205802648, 0.99, 0.38990466615054636, 0.8909679350446202, 0.833167768177125, 0.05398754000713602, 0.4536072662747454, 0.7927049479451055, 0.06933121339875, 0.5653210320064286, 0.48164102126975095, 0.141260445141534, 0.5447917567404694, 0.9146805275797262, 0.529050311718174, 0.07474274041042876, 0.32173957505720463, 0.7913722026177303, 0.575095991099725, 0.01, 0.7413402116638943, 0.04103104998725958, 0.40729349712267143, 0.7233216424279264, 0.33677711971383895, 0.19674943514608723, 0.01, 0.7067487946628316, 0.01, 0.48764367670743247, 0.5672171512095485, 0.39978991040717027, 0.01, 0.05616323235318199, 0.7652982567536217, 0.20752023826781762, 0.99, 0.5886228503717699, 0.15623542661788042, 0.8131682789942716, 0.28410706767913163, 0.5512080662939667, 0.18271231578967967, 0.6178741279365662, 0.5689311914727707, 0.020958956979613447, 0.6525045654800941, 0.593724529050264, 0.3843782677969211, 0.5549589913863735, 0.4467648215087132, 0.3469400672824545, 0.6325617671632301, 0.2970961361134232, 0.5467604353837472, 0.20492107961367867, 0.6678982249154859, 0.337377574321108, 0.01, 0.8890901602739921, 0.36948480144752915, 0.597415160203371, 0.48829841444956806, 0.5068739775930278, 0.06968406725965814, 0.3181061719192039, 0.14947608280339852, 0.09657462931992297, 0.7414927605968779, 0.5415640312992713, 0.9827863654273992, 0.7517353974629997, 0.7053347163844237, 0.32013711417132973, 0.39747949233063323, 0.6819435535535057, 0.42126743248721715, 0.01, 0.39315572329824544, 0.9645689799718808, 0.3157182745528369, 0.39979409168432006, 0.15139073229112282, 0.8381125108785314, 0.5434533381795673, 0.2718512007184845, 0.27869831042460974, 0.2299279535293958, 0.014211742063843624, 0.01, 0.4482275732310158]
Training loss = 0.03234965304533641
step = 0, Training Accuracy: 0.51
Validation Accuracy: 0.51625
Training loss = 0.03326318939526876
step = 1, Training Accuracy: 0.4766666666666667
Training loss = 0.03186076561609904
step = 2, Training Accuracy: 0.53
Training loss = 0.0318879097700119
step = 3, Training Accuracy: 0.51
Training loss = 0.03135852913061778
step = 4, Training Accuracy: 0.5333333333333333
Training loss = 0.032195829550425215
step = 5, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.54625
Training loss = 0.03300089677174886
step = 6, Training Accuracy: 0.48
Training loss = 0.0318233319123586
step = 7, Training Accuracy: 0.5233333333333333
Training loss = 0.030948259433110557
step = 8, Training Accuracy: 0.52
Training loss = 0.032738571564356486
step = 9, Training Accuracy: 0.5133333333333333
Training loss = 0.03166920741399129
step = 10, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.52875
Training loss = 0.03276195247968038
step = 11, Training Accuracy: 0.5266666666666666
Training loss = 0.0314372589190801
step = 12, Training Accuracy: 0.5766666666666667
Training loss = 0.03305428385734558
step = 13, Training Accuracy: 0.4666666666666667
Training loss = 0.03134450912475586
step = 14, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.52625
params:  [0.01, 0.3036484187385568, 0.7793445814693718, 0.01, 0.7847134692016553, 0.6906334308406973, 0.6107324596372554, 0.99, 0.635037502132187, 0.01, 0.5159390028107302, 0.01, 0.07508481105775566, 0.99, 0.8403582472681836, 0.5701617657872651, 0.08739839893755183, 0.7185651709443364, 0.8545525887457499, 0.9233821755120297, 0.49434226132128045, 0.01, 0.07243968688676476, 0.311152842057255, 0.01, 0.01, 0.8658054359661553, 0.01, 0.7443212861933015, 0.2023846604098427, 0.5144040571628459, 0.3536963520155051, 0.030018923580869217, 0.17115399200813697, 0.27188644494701947, 0.9687131980534944, 0.4710402190082478, 0.5700514227444863, 0.7607049831225029, 0.7672454182520531, 0.9160601043887744, 0.12860087566437264, 0.2389232182982152, 0.23334629645860328, 0.7622021735283953, 0.3059113168927827, 0.01, 0.99, 0.41315068189334087, 0.99, 0.5372560248200539, 0.5263345992680347, 0.6553634045377416, 0.5691407369561967, 0.7566364437097397, 0.6002951291989331, 0.20202186322305477, 0.01, 0.01, 0.288125306855481, 0.4546595936388562, 0.45708798906771947, 0.01, 0.6062772200256743, 0.03864947834819965, 0.9483658985139702, 0.5999199448378634, 0.3470795471368583, 0.20868164068457923, 0.37981799652015447, 0.6271931007609657, 0.17519711426299725, 0.7983352975797443, 0.6332855378871355, 0.8150110544531268, 0.11212439612683475, 0.037872275966890384, 0.4920720744737755, 0.16446448164851152, 0.01, 0.2973180608410945, 0.6238934650093113, 0.13401899276034823, 0.6372977451052464, 0.9566629693614821, 0.450424148702996, 0.4277714478415102, 0.01, 0.01, 0.2810402277407328, 0.01, 0.7773471609426844]
[0.01, 0.3036484187385568, 0.7793445814693718, 0.01, 0.7847134692016553, 0.6906334308406973, 0.6107324596372554, 0.99, 0.635037502132187, 0.01, 0.5159390028107302, 0.01, 0.07508481105775566, 0.99, 0.8403582472681836, 0.5701617657872651, 0.08739839893755183, 0.7185651709443364, 0.8545525887457499, 0.9233821755120297, 0.49434226132128045, 0.01, 0.07243968688676476, 0.311152842057255, 0.01, 0.01, 0.8658054359661553, 0.01, 0.7443212861933015, 0.2023846604098427, 0.5144040571628459, 0.3536963520155051, 0.030018923580869217, 0.17115399200813697, 0.27188644494701947, 0.9687131980534944, 0.4710402190082478, 0.5700514227444863, 0.7607049831225029, 0.7672454182520531, 0.9160601043887744, 0.12860087566437264, 0.2389232182982152, 0.23334629645860328, 0.7622021735283953, 0.3059113168927827, 0.01, 0.99, 0.41315068189334087, 0.99, 0.5372560248200539, 0.5263345992680347, 0.6553634045377416, 0.5691407369561967, 0.7566364437097397, 0.6002951291989331, 0.20202186322305477, 0.01, 0.01, 0.288125306855481, 0.4546595936388562, 0.45708798906771947, 0.01, 0.6062772200256743, 0.03864947834819965, 0.9483658985139702, 0.5999199448378634, 0.3470795471368583, 0.20868164068457923, 0.37981799652015447, 0.6271931007609657, 0.17519711426299725, 0.7983352975797443, 0.6332855378871355, 0.8150110544531268, 0.11212439612683475, 0.037872275966890384, 0.4920720744737755, 0.16446448164851152, 0.01, 0.2973180608410945, 0.6238934650093113, 0.13401899276034823, 0.6372977451052464, 0.9566629693614821, 0.450424148702996, 0.4277714478415102, 0.01, 0.01, 0.2810402277407328, 0.01, 0.7773471609426844]
Training loss = 0.03622740268707275
step = 0, Training Accuracy: 0.4033333333333333
Validation Accuracy: 0.5375
Training loss = 0.035326056480407715
step = 1, Training Accuracy: 0.43
Training loss = 0.03558946371078491
step = 2, Training Accuracy: 0.4
Training loss = 0.03503040830294291
step = 3, Training Accuracy: 0.48
Training loss = 0.034574682712554934
step = 4, Training Accuracy: 0.47333333333333333
Training loss = 0.03414380371570587
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.5075
Training loss = 0.03441884398460388
step = 6, Training Accuracy: 0.42333333333333334
Training loss = 0.0353251451253891
step = 7, Training Accuracy: 0.43666666666666665
Training loss = 0.034283740321795146
step = 8, Training Accuracy: 0.44
Training loss = 0.03407494326432546
step = 9, Training Accuracy: 0.4766666666666667
Training loss = 0.03479797581831614
step = 10, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.53
Training loss = 0.03599531253178914
step = 11, Training Accuracy: 0.4033333333333333
Training loss = 0.03392886618773142
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03359695851802826
step = 13, Training Accuracy: 0.46
Training loss = 0.03390455981095632
step = 14, Training Accuracy: 0.42333333333333334
Validation Accuracy: 0.49
params:  [0.6110385189345264, 0.01, 0.99, 0.5181305358278658, 0.6087446664411746, 0.17747537424954152, 0.01, 0.3440538348188168, 0.9387854539031614, 0.31705826684205, 0.2886225908441381, 0.20105896032558476, 0.01, 0.21235097909772674, 0.5323900897122663, 0.4956835332320856, 0.19174578659489405, 0.565531981728432, 0.8352005273356747, 0.3505208531266779, 0.265215847524572, 0.29689761993850683, 0.6006313251803953, 0.20022316788392955, 0.3812518926395992, 0.14263199234789328, 0.3478539857535927, 0.01, 0.5109817892257297, 0.30428842749900553, 0.99, 0.416174100336791, 0.46453177030394766, 0.01, 0.38557059438007746, 0.6891442549001289, 0.01, 0.8062627451190364, 0.6509867203896778, 0.6576635600026923, 0.558913188644008, 0.18689699014371883, 0.01, 0.41397210942427687, 0.01, 0.25658627362919356, 0.01, 0.906886331064432, 0.6270171084667827, 0.99, 0.6492314650363471, 0.2334212807311723, 0.5400587003167204, 0.99, 0.8499770210203965, 0.7008146525467565, 0.01, 0.31838814091014944, 0.09344227122086911, 0.208424450560379, 0.7841441723490143, 0.5618247169524531, 0.5967700897791481, 0.99, 0.01, 0.06461929539436395, 0.31554315644146236, 0.12770434328417757, 0.5717906498563365, 0.99, 0.5771216797688893, 0.3184738747300739, 0.9427558441192749, 0.49593462500693597, 0.01, 0.4818471352740903, 0.01, 0.29525412262234707, 0.6655145047804771, 0.07804251742935875, 0.4759036002536401, 0.833756372912396, 0.4845863132997841, 0.031018856869959366, 0.4620501793545909, 0.5298025297026953, 0.3415494538081964, 0.26844995159191054, 0.5635683950097929, 0.39316945713713247, 0.25462539887641533, 0.48175971320860417]
[0.6110385189345264, 0.01, 0.99, 0.5181305358278658, 0.6087446664411746, 0.17747537424954152, 0.01, 0.3440538348188168, 0.9387854539031614, 0.31705826684205, 0.2886225908441381, 0.20105896032558476, 0.01, 0.21235097909772674, 0.5323900897122663, 0.4956835332320856, 0.19174578659489405, 0.565531981728432, 0.8352005273356747, 0.3505208531266779, 0.265215847524572, 0.29689761993850683, 0.6006313251803953, 0.20022316788392955, 0.3812518926395992, 0.14263199234789328, 0.3478539857535927, 0.01, 0.5109817892257297, 0.30428842749900553, 0.99, 0.416174100336791, 0.46453177030394766, 0.01, 0.38557059438007746, 0.6891442549001289, 0.01, 0.8062627451190364, 0.6509867203896778, 0.6576635600026923, 0.558913188644008, 0.18689699014371883, 0.01, 0.41397210942427687, 0.01, 0.25658627362919356, 0.01, 0.906886331064432, 0.6270171084667827, 0.99, 0.6492314650363471, 0.2334212807311723, 0.5400587003167204, 0.99, 0.8499770210203965, 0.7008146525467565, 0.01, 0.31838814091014944, 0.09344227122086911, 0.208424450560379, 0.7841441723490143, 0.5618247169524531, 0.5967700897791481, 0.99, 0.01, 0.06461929539436395, 0.31554315644146236, 0.12770434328417757, 0.5717906498563365, 0.99, 0.5771216797688893, 0.3184738747300739, 0.9427558441192749, 0.49593462500693597, 0.01, 0.4818471352740903, 0.01, 0.29525412262234707, 0.6655145047804771, 0.07804251742935875, 0.4759036002536401, 0.833756372912396, 0.4845863132997841, 0.031018856869959366, 0.4620501793545909, 0.5298025297026953, 0.3415494538081964, 0.26844995159191054, 0.5635683950097929, 0.39316945713713247, 0.25462539887641533, 0.48175971320860417]
Training loss = 0.03419832726319631
step = 0, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.5
Training loss = 0.032818278074264524
step = 1, Training Accuracy: 0.5
Training loss = 0.032952332297960914
step = 2, Training Accuracy: 0.5133333333333333
Training loss = 0.031768672664960224
step = 3, Training Accuracy: 0.53
Training loss = 0.034089031219482424
step = 4, Training Accuracy: 0.4866666666666667
Training loss = 0.03309405306975047
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.50375
Training loss = 0.03287637650966644
step = 6, Training Accuracy: 0.49666666666666665
Training loss = 0.033190873265266416
step = 7, Training Accuracy: 0.49
Training loss = 0.03256132900714874
step = 8, Training Accuracy: 0.45666666666666667
Training loss = 0.032965466777483625
step = 9, Training Accuracy: 0.48
Training loss = 0.03372781336307526
step = 10, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.535
Training loss = 0.032770774364471435
step = 11, Training Accuracy: 0.47
Training loss = 0.03300183415412903
step = 12, Training Accuracy: 0.45666666666666667
Training loss = 0.03252182384332021
step = 13, Training Accuracy: 0.5
Training loss = 0.03127770404020945
step = 14, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.5025
params:  [0.3401943324356577, 0.4778444489298968, 0.4839738053036989, 0.5107793251697232, 0.7661817476613699, 0.99, 0.2287315393736798, 0.37686451396289194, 0.6034287936179382, 0.01, 0.21350582379650446, 0.01, 0.36094663972585467, 0.36870416532614253, 0.22319517383480114, 0.37015948218474226, 0.01, 0.5050501590738579, 0.5594659802089895, 0.18367342224103683, 0.24358435231308037, 0.41301869747318726, 0.5753200037437718, 0.01, 0.4747659500957073, 0.2089958025037661, 0.7301787509319575, 0.29199425999212036, 0.3388189806162979, 0.12428509623468238, 0.3713903739809177, 0.3344403469574944, 0.5078755239307018, 0.08328330665229358, 0.3787379402111517, 0.600078098437198, 0.19434473608018804, 0.8567076341025738, 0.6771330130487683, 0.01, 0.32417813579714194, 0.49541661254318686, 0.01, 0.5270669660137526, 0.7005808813564408, 0.45258827335051915, 0.24322325436544587, 0.99, 0.6203437970036375, 0.7519573933661103, 0.8083680090027929, 0.01, 0.39779413469569236, 0.8779375228062591, 0.35838925945836936, 0.30516464816478817, 0.01, 0.02583863585667784, 0.7842792782300401, 0.27414150871550313, 0.7863013466538291, 0.9137985370612166, 0.2205760451368064, 0.37189917703240116, 0.34979057893085763, 0.11730848550845085, 0.6386597344677286, 0.08601092536161525, 0.01, 0.99, 0.4239361330207696, 0.49629950320109706, 0.99, 0.8181394728817333, 0.6072112298843564, 0.10296276139722615, 0.49769316774240013, 0.2843467194395141, 0.1801329459864341, 0.01, 0.7644481776440349, 0.2798849142819546, 0.99, 0.3992883648942185, 0.4138566641615694, 0.5265290691984909, 0.20265205389297086, 0.32087880733920215, 0.21770497391806615, 0.3168260903316173, 0.01, 0.8195623085211692]
[0.3401943324356577, 0.4778444489298968, 0.4839738053036989, 0.5107793251697232, 0.7661817476613699, 0.99, 0.2287315393736798, 0.37686451396289194, 0.6034287936179382, 0.01, 0.21350582379650446, 0.01, 0.36094663972585467, 0.36870416532614253, 0.22319517383480114, 0.37015948218474226, 0.01, 0.5050501590738579, 0.5594659802089895, 0.18367342224103683, 0.24358435231308037, 0.41301869747318726, 0.5753200037437718, 0.01, 0.4747659500957073, 0.2089958025037661, 0.7301787509319575, 0.29199425999212036, 0.3388189806162979, 0.12428509623468238, 0.3713903739809177, 0.3344403469574944, 0.5078755239307018, 0.08328330665229358, 0.3787379402111517, 0.600078098437198, 0.19434473608018804, 0.8567076341025738, 0.6771330130487683, 0.01, 0.32417813579714194, 0.49541661254318686, 0.01, 0.5270669660137526, 0.7005808813564408, 0.45258827335051915, 0.24322325436544587, 0.99, 0.6203437970036375, 0.7519573933661103, 0.8083680090027929, 0.01, 0.39779413469569236, 0.8779375228062591, 0.35838925945836936, 0.30516464816478817, 0.01, 0.02583863585667784, 0.7842792782300401, 0.27414150871550313, 0.7863013466538291, 0.9137985370612166, 0.2205760451368064, 0.37189917703240116, 0.34979057893085763, 0.11730848550845085, 0.6386597344677286, 0.08601092536161525, 0.01, 0.99, 0.4239361330207696, 0.49629950320109706, 0.99, 0.8181394728817333, 0.6072112298843564, 0.10296276139722615, 0.49769316774240013, 0.2843467194395141, 0.1801329459864341, 0.01, 0.7644481776440349, 0.2798849142819546, 0.99, 0.3992883648942185, 0.4138566641615694, 0.5265290691984909, 0.20265205389297086, 0.32087880733920215, 0.21770497391806615, 0.3168260903316173, 0.01, 0.8195623085211692]
Training loss = 0.0340924201409022
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.49625
Training loss = 0.03534150083859761
step = 1, Training Accuracy: 0.43666666666666665
Training loss = 0.03383196949958801
step = 2, Training Accuracy: 0.44333333333333336
Training loss = 0.032914328376452126
step = 3, Training Accuracy: 0.49333333333333335
Training loss = 0.03495115041732788
step = 4, Training Accuracy: 0.47333333333333333
Training loss = 0.03440118153889974
step = 5, Training Accuracy: 0.46
Validation Accuracy: 0.5
Training loss = 0.03309066077073415
step = 6, Training Accuracy: 0.5166666666666667
Training loss = 0.033415337602297465
step = 7, Training Accuracy: 0.47
Training loss = 0.032761065562566125
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03442892928918203
step = 9, Training Accuracy: 0.46
Training loss = 0.033750015497207644
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.49375
Training loss = 0.03391657531261444
step = 11, Training Accuracy: 0.48333333333333334
Training loss = 0.03410322686036428
step = 12, Training Accuracy: 0.5033333333333333
Training loss = 0.034320751229921974
step = 13, Training Accuracy: 0.48
Training loss = 0.03360304037729899
step = 14, Training Accuracy: 0.5
Validation Accuracy: 0.5
2  	8     	0.509375	0.0129904	0.49   	0.5325 
params:  [0.15510737287599377, 0.017506137741622713, 0.804751061586841, 0.8623245817654228, 0.35443425022105524, 0.5802691203385311, 0.3280763497154249, 0.5145072081255613, 0.99, 0.01, 0.49363501744134664, 0.01, 0.07339083786805162, 0.07557803045765327, 0.99, 0.60027778921953, 0.6357653422781283, 0.7871590698951407, 0.99, 0.828361837356143, 0.27282100816697347, 0.5026662902451257, 0.01, 0.5108706833880193, 0.4232223577689035, 0.29937670544280814, 0.4225373386733169, 0.01, 0.6767836656106672, 0.08018878785311406, 0.01, 0.09471800824290466, 0.37085984123333016, 0.01, 0.7540078050787986, 0.5863501682780667, 0.21933874024424957, 0.8482530987269389, 0.9774533841195234, 0.01, 0.2214418420301401, 0.41009015632695944, 0.01, 0.3485940741856558, 0.6110559456716714, 0.42332652713974783, 0.01, 0.4755698139882798, 0.304947473836451, 0.4338439310450942, 0.5189813808422071, 0.1049513297985184, 0.4888605872841445, 0.813094209837753, 0.6788887978711899, 0.6962690746905922, 0.4288541413132138, 0.5119189274948035, 0.6100689043813887, 0.01, 0.7219262108937367, 0.4159346775418757, 0.6175471272930272, 0.6412967745634671, 0.2126895371018056, 0.01, 0.07666722224976996, 0.9825105938843433, 0.12769809361250484, 0.5939054193160511, 0.31266507063596266, 0.8126382608239096, 0.6076526016221799, 0.27997888520054487, 0.5976755320243438, 0.08944781929731371, 0.9474919319520502, 0.3986730823857526, 0.01, 0.35868772074812705, 0.5303040031819891, 0.5718040568694132, 0.99, 0.05945002418410228, 0.4687995185341474, 0.3792700048163846, 0.5080295986899618, 0.04669311048827067, 0.49417294381673227, 0.22706948535648924, 0.01, 0.7867103528791507]
[0.15510737287599377, 0.017506137741622713, 0.804751061586841, 0.8623245817654228, 0.35443425022105524, 0.5802691203385311, 0.3280763497154249, 0.5145072081255613, 0.99, 0.01, 0.49363501744134664, 0.01, 0.07339083786805162, 0.07557803045765327, 0.99, 0.60027778921953, 0.6357653422781283, 0.7871590698951407, 0.99, 0.828361837356143, 0.27282100816697347, 0.5026662902451257, 0.01, 0.5108706833880193, 0.4232223577689035, 0.29937670544280814, 0.4225373386733169, 0.01, 0.6767836656106672, 0.08018878785311406, 0.01, 0.09471800824290466, 0.37085984123333016, 0.01, 0.7540078050787986, 0.5863501682780667, 0.21933874024424957, 0.8482530987269389, 0.9774533841195234, 0.01, 0.2214418420301401, 0.41009015632695944, 0.01, 0.3485940741856558, 0.6110559456716714, 0.42332652713974783, 0.01, 0.4755698139882798, 0.304947473836451, 0.4338439310450942, 0.5189813808422071, 0.1049513297985184, 0.4888605872841445, 0.813094209837753, 0.6788887978711899, 0.6962690746905922, 0.4288541413132138, 0.5119189274948035, 0.6100689043813887, 0.01, 0.7219262108937367, 0.4159346775418757, 0.6175471272930272, 0.6412967745634671, 0.2126895371018056, 0.01, 0.07666722224976996, 0.9825105938843433, 0.12769809361250484, 0.5939054193160511, 0.31266507063596266, 0.8126382608239096, 0.6076526016221799, 0.27997888520054487, 0.5976755320243438, 0.08944781929731371, 0.9474919319520502, 0.3986730823857526, 0.01, 0.35868772074812705, 0.5303040031819891, 0.5718040568694132, 0.99, 0.05945002418410228, 0.4687995185341474, 0.3792700048163846, 0.5080295986899618, 0.04669311048827067, 0.49417294381673227, 0.22706948535648924, 0.01, 0.7867103528791507]
Training loss = 0.033036867380142214
step = 0, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.51625
Training loss = 0.034754350781440735
step = 1, Training Accuracy: 0.4166666666666667
Training loss = 0.033099392851193746
step = 2, Training Accuracy: 0.4666666666666667
Training loss = 0.03368162572383881
step = 3, Training Accuracy: 0.5033333333333333
Training loss = 0.03395397901535034
step = 4, Training Accuracy: 0.45666666666666667
Training loss = 0.03285045524438222
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.5225
Training loss = 0.03271932323773702
step = 6, Training Accuracy: 0.4866666666666667
Training loss = 0.032559781074523925
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.03147030532360077
step = 8, Training Accuracy: 0.5233333333333333
Training loss = 0.03263856172561645
step = 9, Training Accuracy: 0.5466666666666666
Training loss = 0.03211074948310852
step = 10, Training Accuracy: 0.52
Validation Accuracy: 0.5275
Training loss = 0.033671262661616005
step = 11, Training Accuracy: 0.4533333333333333
Training loss = 0.032684658765792844
step = 12, Training Accuracy: 0.5133333333333333
Training loss = 0.033111713131268816
step = 13, Training Accuracy: 0.51
Training loss = 0.03317094246546427
step = 14, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.5375
params:  [0.07616930418238543, 0.2621619093180806, 0.8085438236849323, 0.2890452752405199, 0.6034476136296316, 0.6276891820191566, 0.6754219130313843, 0.8409207454953104, 0.8485302737900737, 0.01, 0.8578210550834073, 0.24937716709251295, 0.01, 0.5521612227958896, 0.7881178556790797, 0.020068786295542262, 0.20046824325406162, 0.2345453927336138, 0.6827802053603096, 0.3466631638787439, 0.013537031296122715, 0.0677512309063476, 0.01, 0.3661438710155598, 0.03854108566393316, 0.11830342780983942, 0.3459306935648653, 0.01, 0.465859036650224, 0.5132819461395107, 0.11373774859283754, 0.5164805598335105, 0.30249802856254737, 0.6168232656490787, 0.6203321237842465, 0.99, 0.2014104509036664, 0.7685225492265344, 0.99, 0.01, 0.8323663950507341, 0.2428702796291245, 0.37305040187706107, 0.6358985122775274, 0.638939203429927, 0.6646140270741059, 0.5857773609294241, 0.558837496606698, 0.99, 0.99, 0.2065009727164595, 0.9189144923609993, 0.14346691796430722, 0.01, 0.4322146272866215, 0.1006892591612524, 0.28960773682138585, 0.6740395367967468, 0.22864795613335828, 0.2967551018418531, 0.99, 0.4636179842941888, 0.4016517014084088, 0.47011950674380365, 0.01, 0.42021767379192154, 0.4119871656327102, 0.44442065548699494, 0.01, 0.40981115388859823, 0.587162117648313, 0.8414250011551101, 0.2337609952119628, 0.13795540843593074, 0.8206974678040665, 0.6283033105690312, 0.32622315061611157, 0.3793226016209492, 0.34535601203220806, 0.16559409364478217, 0.9678438925449766, 0.7422634825523844, 0.99, 0.022144701006745204, 0.7710988718748542, 0.09247234958136952, 0.4197738213122352, 0.4780917722406221, 0.01946678779143865, 0.3334789012946729, 0.01, 0.8048266520213164]
[0.07616930418238543, 0.2621619093180806, 0.8085438236849323, 0.2890452752405199, 0.6034476136296316, 0.6276891820191566, 0.6754219130313843, 0.8409207454953104, 0.8485302737900737, 0.01, 0.8578210550834073, 0.24937716709251295, 0.01, 0.5521612227958896, 0.7881178556790797, 0.020068786295542262, 0.20046824325406162, 0.2345453927336138, 0.6827802053603096, 0.3466631638787439, 0.013537031296122715, 0.0677512309063476, 0.01, 0.3661438710155598, 0.03854108566393316, 0.11830342780983942, 0.3459306935648653, 0.01, 0.465859036650224, 0.5132819461395107, 0.11373774859283754, 0.5164805598335105, 0.30249802856254737, 0.6168232656490787, 0.6203321237842465, 0.99, 0.2014104509036664, 0.7685225492265344, 0.99, 0.01, 0.8323663950507341, 0.2428702796291245, 0.37305040187706107, 0.6358985122775274, 0.638939203429927, 0.6646140270741059, 0.5857773609294241, 0.558837496606698, 0.99, 0.99, 0.2065009727164595, 0.9189144923609993, 0.14346691796430722, 0.01, 0.4322146272866215, 0.1006892591612524, 0.28960773682138585, 0.6740395367967468, 0.22864795613335828, 0.2967551018418531, 0.99, 0.4636179842941888, 0.4016517014084088, 0.47011950674380365, 0.01, 0.42021767379192154, 0.4119871656327102, 0.44442065548699494, 0.01, 0.40981115388859823, 0.587162117648313, 0.8414250011551101, 0.2337609952119628, 0.13795540843593074, 0.8206974678040665, 0.6283033105690312, 0.32622315061611157, 0.3793226016209492, 0.34535601203220806, 0.16559409364478217, 0.9678438925449766, 0.7422634825523844, 0.99, 0.022144701006745204, 0.7710988718748542, 0.09247234958136952, 0.4197738213122352, 0.4780917722406221, 0.01946678779143865, 0.3334789012946729, 0.01, 0.8048266520213164]
Training loss = 0.03503254930178324
step = 0, Training Accuracy: 0.3933333333333333
Validation Accuracy: 0.55
Training loss = 0.03514057477315267
step = 1, Training Accuracy: 0.39
Training loss = 0.03378426651159922
step = 2, Training Accuracy: 0.4766666666666667
Training loss = 0.034951608379681906
step = 3, Training Accuracy: 0.43333333333333335
Training loss = 0.034874884486198424
step = 4, Training Accuracy: 0.4533333333333333
Training loss = 0.034035295844078065
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.55625
Training loss = 0.03536745687325796
step = 6, Training Accuracy: 0.4266666666666667
Training loss = 0.03491390963395437
step = 7, Training Accuracy: 0.4266666666666667
Training loss = 0.03384994526704153
step = 8, Training Accuracy: 0.48333333333333334
Training loss = 0.03316559910774231
step = 9, Training Accuracy: 0.5
Training loss = 0.035898160537083945
step = 10, Training Accuracy: 0.44333333333333336
Validation Accuracy: 0.545
Training loss = 0.03455530921618144
step = 11, Training Accuracy: 0.45
Training loss = 0.03377497772375743
step = 12, Training Accuracy: 0.48
Training loss = 0.03386187016963959
step = 13, Training Accuracy: 0.4766666666666667
Training loss = 0.03490001777807872
step = 14, Training Accuracy: 0.44
Validation Accuracy: 0.54375
params:  [0.7209020313099825, 0.6742534122251003, 0.99, 0.99, 0.99, 0.7601688634190513, 0.01, 0.7807899701567171, 0.4215383779339402, 0.01, 0.8138383467765066, 0.1594093542547153, 0.15097998579054284, 0.2054941365312147, 0.5167805626910835, 0.8317791204282335, 0.13293545114474467, 0.37372517330721766, 0.11236332956390316, 0.35031354863003167, 0.19185136836089467, 0.99, 0.01, 0.01, 0.7784043385713995, 0.37438843266034494, 0.06076201260126808, 0.01, 0.8437861189910066, 0.09721166884543336, 0.08100786322678316, 0.825143773967469, 0.6356949743566949, 0.2538702939236125, 0.6462937005213414, 0.6818679288602285, 0.1285209664633452, 0.99, 0.99, 0.12437733046185756, 0.5520304678249988, 0.772199740711317, 0.8592339820341709, 0.5402899932267315, 0.3758962535350162, 0.22669741600561047, 0.01, 0.45272461757570787, 0.6337704019496797, 0.99, 0.44172131566893014, 0.5879760624861355, 0.01, 0.5155983330750769, 0.7163812324255732, 0.41114541391882126, 0.47042573332609944, 0.654684918336915, 0.2552039988618108, 0.01, 0.99, 0.6720706879204928, 0.3929428133744155, 0.99, 0.5112076684378657, 0.21434375411188455, 0.3392521255882943, 0.8302700694898358, 0.12788622730788987, 0.99, 0.8331459810650156, 0.99, 0.540646878230215, 0.3134431725410424, 0.7230177374873963, 0.6161870026072294, 0.99, 0.7335272229931682, 0.12582953522391477, 0.5708263463924397, 0.7944951809561772, 0.6682515690809665, 0.8333902151938097, 0.40799502867684934, 0.955921507341883, 0.46017461208324184, 0.01, 0.07881132016505829, 0.01, 0.6654109853128798, 0.01, 0.99]
[0.7209020313099825, 0.6742534122251003, 0.99, 0.99, 0.99, 0.7601688634190513, 0.01, 0.7807899701567171, 0.4215383779339402, 0.01, 0.8138383467765066, 0.1594093542547153, 0.15097998579054284, 0.2054941365312147, 0.5167805626910835, 0.8317791204282335, 0.13293545114474467, 0.37372517330721766, 0.11236332956390316, 0.35031354863003167, 0.19185136836089467, 0.99, 0.01, 0.01, 0.7784043385713995, 0.37438843266034494, 0.06076201260126808, 0.01, 0.8437861189910066, 0.09721166884543336, 0.08100786322678316, 0.825143773967469, 0.6356949743566949, 0.2538702939236125, 0.6462937005213414, 0.6818679288602285, 0.1285209664633452, 0.99, 0.99, 0.12437733046185756, 0.5520304678249988, 0.772199740711317, 0.8592339820341709, 0.5402899932267315, 0.3758962535350162, 0.22669741600561047, 0.01, 0.45272461757570787, 0.6337704019496797, 0.99, 0.44172131566893014, 0.5879760624861355, 0.01, 0.5155983330750769, 0.7163812324255732, 0.41114541391882126, 0.47042573332609944, 0.654684918336915, 0.2552039988618108, 0.01, 0.99, 0.6720706879204928, 0.3929428133744155, 0.99, 0.5112076684378657, 0.21434375411188455, 0.3392521255882943, 0.8302700694898358, 0.12788622730788987, 0.99, 0.8331459810650156, 0.99, 0.540646878230215, 0.3134431725410424, 0.7230177374873963, 0.6161870026072294, 0.99, 0.7335272229931682, 0.12582953522391477, 0.5708263463924397, 0.7944951809561772, 0.6682515690809665, 0.8333902151938097, 0.40799502867684934, 0.955921507341883, 0.46017461208324184, 0.01, 0.07881132016505829, 0.01, 0.6654109853128798, 0.01, 0.99]
Training loss = 0.0334996102253596
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.52
Training loss = 0.0330021595954895
step = 1, Training Accuracy: 0.49333333333333335
Training loss = 0.03512070198853811
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.03329974333445231
step = 3, Training Accuracy: 0.4633333333333333
Training loss = 0.03250153839588165
step = 4, Training Accuracy: 0.52
Training loss = 0.03259560823440552
step = 5, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.53875
Training loss = 0.033242921034495033
step = 6, Training Accuracy: 0.47333333333333333
Training loss = 0.03238835712273916
step = 7, Training Accuracy: 0.49333333333333335
Training loss = 0.03317732632160187
step = 8, Training Accuracy: 0.46
Training loss = 0.032745927572250366
step = 9, Training Accuracy: 0.5
Training loss = 0.034060131112734475
step = 10, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.5325
Training loss = 0.033865713477134705
step = 11, Training Accuracy: 0.47333333333333333
Training loss = 0.03316094398498535
step = 12, Training Accuracy: 0.5066666666666667
Training loss = 0.032335654695828754
step = 13, Training Accuracy: 0.51
Training loss = 0.03227549413839976
step = 14, Training Accuracy: 0.51
Validation Accuracy: 0.5425
params:  [0.3882787525969579, 0.08084344518966236, 0.3867216905748173, 0.8350146185463915, 0.7242850334047184, 0.377142146102846, 0.11279546448042728, 0.07451105428221172, 0.4374744277544487, 0.16001343527912348, 0.6964810952477475, 0.25163650217229766, 0.01, 0.26330517715488433, 0.8264206133250842, 0.01, 0.16465633803516905, 0.5066194225381145, 0.8532772874888057, 0.9038742326947486, 0.01, 0.8520883971298618, 0.4730982646877866, 0.3061325999239509, 0.20108019146899397, 0.06744510852703772, 0.48163045169636864, 0.21223485116032617, 0.24401160095842528, 0.21749963172422676, 0.09539608560457163, 0.2804573089747023, 0.4377010738075107, 0.08255698643483375, 0.01, 0.9359832116420002, 0.17623508530687068, 0.7214909722977314, 0.4372689890686436, 0.22212408159035407, 0.18918016089713646, 0.7670278695188922, 0.6245781023896297, 0.6463004999638076, 0.1771867479471912, 0.4922775884815051, 0.18824075766882414, 0.7193387577390806, 0.7497402659958176, 0.8048737400512326, 0.8704220542198922, 0.99, 0.7648163364869679, 0.5169181365499501, 0.99, 0.32713375775302156, 0.01, 0.6969134236367448, 0.01, 0.8418114345689148, 0.21713188036166858, 0.99, 0.024376178011042526, 0.7865309791553328, 0.23078803116645205, 0.08158888847056549, 0.48181880419209394, 0.3312729721690882, 0.01, 0.99, 0.09922784388310514, 0.7063985291548218, 0.333938501949227, 0.5603566425308542, 0.9011071581092567, 0.09078212354207743, 0.99, 0.3030256776179382, 0.2979527528752884, 0.19199272986801805, 0.9292119412022759, 0.8770086481864715, 0.6004003806979065, 0.13589551047794982, 0.9886337295731086, 0.17845350021770462, 0.07827461345711148, 0.5639990408854407, 0.08775842546525427, 0.03623028965604702, 0.12137200124912341, 0.9071109986714199]
[0.3882787525969579, 0.08084344518966236, 0.3867216905748173, 0.8350146185463915, 0.7242850334047184, 0.377142146102846, 0.11279546448042728, 0.07451105428221172, 0.4374744277544487, 0.16001343527912348, 0.6964810952477475, 0.25163650217229766, 0.01, 0.26330517715488433, 0.8264206133250842, 0.01, 0.16465633803516905, 0.5066194225381145, 0.8532772874888057, 0.9038742326947486, 0.01, 0.8520883971298618, 0.4730982646877866, 0.3061325999239509, 0.20108019146899397, 0.06744510852703772, 0.48163045169636864, 0.21223485116032617, 0.24401160095842528, 0.21749963172422676, 0.09539608560457163, 0.2804573089747023, 0.4377010738075107, 0.08255698643483375, 0.01, 0.9359832116420002, 0.17623508530687068, 0.7214909722977314, 0.4372689890686436, 0.22212408159035407, 0.18918016089713646, 0.7670278695188922, 0.6245781023896297, 0.6463004999638076, 0.1771867479471912, 0.4922775884815051, 0.18824075766882414, 0.7193387577390806, 0.7497402659958176, 0.8048737400512326, 0.8704220542198922, 0.99, 0.7648163364869679, 0.5169181365499501, 0.99, 0.32713375775302156, 0.01, 0.6969134236367448, 0.01, 0.8418114345689148, 0.21713188036166858, 0.99, 0.024376178011042526, 0.7865309791553328, 0.23078803116645205, 0.08158888847056549, 0.48181880419209394, 0.3312729721690882, 0.01, 0.99, 0.09922784388310514, 0.7063985291548218, 0.333938501949227, 0.5603566425308542, 0.9011071581092567, 0.09078212354207743, 0.99, 0.3030256776179382, 0.2979527528752884, 0.19199272986801805, 0.9292119412022759, 0.8770086481864715, 0.6004003806979065, 0.13589551047794982, 0.9886337295731086, 0.17845350021770462, 0.07827461345711148, 0.5639990408854407, 0.08775842546525427, 0.03623028965604702, 0.12137200124912341, 0.9071109986714199]
Training loss = 0.032931959629058837
step = 0, Training Accuracy: 0.5
Validation Accuracy: 0.53625
Training loss = 0.03389111459255219
step = 1, Training Accuracy: 0.43666666666666665
Training loss = 0.03389030853907267
step = 2, Training Accuracy: 0.4766666666666667
Training loss = 0.03349202613035838
step = 3, Training Accuracy: 0.44666666666666666
Training loss = 0.03262213230133057
step = 4, Training Accuracy: 0.48333333333333334
Training loss = 0.03356759508450826
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.54625
Training loss = 0.033344715038935345
step = 6, Training Accuracy: 0.48333333333333334
Training loss = 0.032647197047869364
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.033526885906855264
step = 8, Training Accuracy: 0.48333333333333334
Training loss = 0.03276419460773468
step = 9, Training Accuracy: 0.51
Training loss = 0.03281151910622915
step = 10, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.54875
Training loss = 0.033760302265485126
step = 11, Training Accuracy: 0.45666666666666667
Training loss = 0.03337971647580465
step = 12, Training Accuracy: 0.4633333333333333
Training loss = 0.03367787778377533
step = 13, Training Accuracy: 0.49666666666666665
Training loss = 0.03238365908463796
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.53125
params:  [0.5112944501857261, 0.422919637937409, 0.7868787118786099, 0.660172673331586, 0.99, 0.2936172655012391, 0.12032407992990383, 0.431933043735538, 0.6614177397075487, 0.01, 0.7059122672013664, 0.01, 0.16924070168260946, 0.38557805445239834, 0.8122787515440508, 0.8686145911530774, 0.01, 0.7209934606901611, 0.5068054945042086, 0.9565866302071049, 0.01, 0.374926331112339, 0.2630396304511872, 0.16379568039765835, 0.53710300921715, 0.1761163643910209, 0.06324583234701231, 0.04951436369779496, 0.07529215063517836, 0.12358028632338268, 0.01, 0.5630056611721833, 0.01, 0.7191427900509844, 0.01, 0.5448728424132443, 0.13690873345081117, 0.5527626791615368, 0.7651192679323947, 0.4008842848126536, 0.4608035431442372, 0.6045156133620452, 0.3560835764544212, 0.12181772084673503, 0.5104414920384739, 0.029048069541615373, 0.01, 0.6655469450997118, 0.5174551657598822, 0.37783321300231026, 0.99, 0.3863969512657816, 0.19738120511443913, 0.7737217647943815, 0.646446505684027, 0.3480275949818526, 0.2240046033773886, 0.5274473116190846, 0.01, 0.5810105335228721, 0.6694659349275877, 0.36011840517655913, 0.19082312938462037, 0.539810724469898, 0.7467745316677936, 0.20921241094716406, 0.11896225826191825, 0.7282481779623459, 0.01, 0.34400306456954244, 0.23266399868402243, 0.5759706758712207, 0.3619357336963726, 0.17979664094916556, 0.5763662300274746, 0.5506305631907397, 0.5588841750993193, 0.13002115977280793, 0.3691907967400405, 0.2707223526420667, 0.99, 0.6777382808899979, 0.5462067239083624, 0.2981265088329368, 0.99, 0.20417102621688935, 0.06459030531989648, 0.23037506790569454, 0.4340057881510372, 0.14992408561883597, 0.3205858576144849, 0.5047636946529557]
[0.5112944501857261, 0.422919637937409, 0.7868787118786099, 0.660172673331586, 0.99, 0.2936172655012391, 0.12032407992990383, 0.431933043735538, 0.6614177397075487, 0.01, 0.7059122672013664, 0.01, 0.16924070168260946, 0.38557805445239834, 0.8122787515440508, 0.8686145911530774, 0.01, 0.7209934606901611, 0.5068054945042086, 0.9565866302071049, 0.01, 0.374926331112339, 0.2630396304511872, 0.16379568039765835, 0.53710300921715, 0.1761163643910209, 0.06324583234701231, 0.04951436369779496, 0.07529215063517836, 0.12358028632338268, 0.01, 0.5630056611721833, 0.01, 0.7191427900509844, 0.01, 0.5448728424132443, 0.13690873345081117, 0.5527626791615368, 0.7651192679323947, 0.4008842848126536, 0.4608035431442372, 0.6045156133620452, 0.3560835764544212, 0.12181772084673503, 0.5104414920384739, 0.029048069541615373, 0.01, 0.6655469450997118, 0.5174551657598822, 0.37783321300231026, 0.99, 0.3863969512657816, 0.19738120511443913, 0.7737217647943815, 0.646446505684027, 0.3480275949818526, 0.2240046033773886, 0.5274473116190846, 0.01, 0.5810105335228721, 0.6694659349275877, 0.36011840517655913, 0.19082312938462037, 0.539810724469898, 0.7467745316677936, 0.20921241094716406, 0.11896225826191825, 0.7282481779623459, 0.01, 0.34400306456954244, 0.23266399868402243, 0.5759706758712207, 0.3619357336963726, 0.17979664094916556, 0.5763662300274746, 0.5506305631907397, 0.5588841750993193, 0.13002115977280793, 0.3691907967400405, 0.2707223526420667, 0.99, 0.6777382808899979, 0.5462067239083624, 0.2981265088329368, 0.99, 0.20417102621688935, 0.06459030531989648, 0.23037506790569454, 0.4340057881510372, 0.14992408561883597, 0.3205858576144849, 0.5047636946529557]
Training loss = 0.03205543597539266
step = 0, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.52125
Training loss = 0.030630737940470377
step = 1, Training Accuracy: 0.5233333333333333
Training loss = 0.032248423496882124
step = 2, Training Accuracy: 0.5266666666666666
Training loss = 0.030865189631779987
step = 3, Training Accuracy: 0.56
Training loss = 0.03291284342606862
step = 4, Training Accuracy: 0.47
Training loss = 0.030953588485717772
step = 5, Training Accuracy: 0.5433333333333333
Validation Accuracy: 0.545
Training loss = 0.03188696245352427
step = 6, Training Accuracy: 0.5366666666666666
Training loss = 0.031269422372182214
step = 7, Training Accuracy: 0.52
Training loss = 0.031854596138000485
step = 8, Training Accuracy: 0.52
Training loss = 0.0316952778895696
step = 9, Training Accuracy: 0.5266666666666666
Training loss = 0.03260835111141205
step = 10, Training Accuracy: 0.52
Validation Accuracy: 0.53
Training loss = 0.032100434303283694
step = 11, Training Accuracy: 0.5366666666666666
Training loss = 0.032532766461372375
step = 12, Training Accuracy: 0.5333333333333333
Training loss = 0.03186003923416138
step = 13, Training Accuracy: 0.54
Training loss = 0.03224421759446462
step = 14, Training Accuracy: 0.51
Validation Accuracy: 0.5425
params:  [0.99, 0.20178028218983163, 0.5104152449468808, 0.3132584091213566, 0.9354499013331247, 0.9167229841164767, 0.01, 0.5896820225301641, 0.99, 0.3651831652380739, 0.8425409856297881, 0.6340984727685757, 0.01, 0.01, 0.99, 0.5964907068425847, 0.01, 0.8262801235992328, 0.99, 0.6049805349751012, 0.4838172967312391, 0.5709367824417012, 0.01, 0.3336437631263063, 0.30017759793559917, 0.2918694956666754, 0.31844692028283816, 0.43096678613373873, 0.024200299172947748, 0.6153115085753627, 0.01, 0.33991828940482416, 0.01, 0.09662207875903994, 0.01, 0.42290457067609427, 0.17347270733623074, 0.5666466156036418, 0.99, 0.2914768789075677, 0.2129540304306698, 0.31858284877662685, 0.3740585449116139, 0.478819238335275, 0.7014229730429525, 0.2789683230870559, 0.04349520339798152, 0.44805133147034515, 0.7701905799711966, 0.8796344070566461, 0.9413620591815831, 0.6950489165461881, 0.5831103681233287, 0.30779267241162256, 0.11075967515338608, 0.8606787142696687, 0.6584056716344053, 0.46120193437859736, 0.40445082183838743, 0.2749237501645712, 0.6341544974512346, 0.6236436138853356, 0.024363485942586305, 0.99, 0.20494670679011304, 0.07315803395616594, 0.2766996355077389, 0.6143838071853289, 0.01, 0.99, 0.01, 0.8001535981124996, 0.7504035167946802, 0.7429127612807944, 0.6808357187386551, 0.26369831192524024, 0.389540081947816, 0.7712421964677809, 0.38570580731485604, 0.8012227625145045, 0.25992353120203987, 0.8486367576915006, 0.535770695374367, 0.773275557120173, 0.5230721447225829, 0.6150673320721844, 0.10953500579997422, 0.99, 0.09793462147916152, 0.2989410050749034, 0.01, 0.09936781549106455]
[0.99, 0.20178028218983163, 0.5104152449468808, 0.3132584091213566, 0.9354499013331247, 0.9167229841164767, 0.01, 0.5896820225301641, 0.99, 0.3651831652380739, 0.8425409856297881, 0.6340984727685757, 0.01, 0.01, 0.99, 0.5964907068425847, 0.01, 0.8262801235992328, 0.99, 0.6049805349751012, 0.4838172967312391, 0.5709367824417012, 0.01, 0.3336437631263063, 0.30017759793559917, 0.2918694956666754, 0.31844692028283816, 0.43096678613373873, 0.024200299172947748, 0.6153115085753627, 0.01, 0.33991828940482416, 0.01, 0.09662207875903994, 0.01, 0.42290457067609427, 0.17347270733623074, 0.5666466156036418, 0.99, 0.2914768789075677, 0.2129540304306698, 0.31858284877662685, 0.3740585449116139, 0.478819238335275, 0.7014229730429525, 0.2789683230870559, 0.04349520339798152, 0.44805133147034515, 0.7701905799711966, 0.8796344070566461, 0.9413620591815831, 0.6950489165461881, 0.5831103681233287, 0.30779267241162256, 0.11075967515338608, 0.8606787142696687, 0.6584056716344053, 0.46120193437859736, 0.40445082183838743, 0.2749237501645712, 0.6341544974512346, 0.6236436138853356, 0.024363485942586305, 0.99, 0.20494670679011304, 0.07315803395616594, 0.2766996355077389, 0.6143838071853289, 0.01, 0.99, 0.01, 0.8001535981124996, 0.7504035167946802, 0.7429127612807944, 0.6808357187386551, 0.26369831192524024, 0.389540081947816, 0.7712421964677809, 0.38570580731485604, 0.8012227625145045, 0.25992353120203987, 0.8486367576915006, 0.535770695374367, 0.773275557120173, 0.5230721447225829, 0.6150673320721844, 0.10953500579997422, 0.99, 0.09793462147916152, 0.2989410050749034, 0.01, 0.09936781549106455]
Training loss = 0.03747563759485881
step = 0, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.52625
Training loss = 0.03523071050643921
step = 1, Training Accuracy: 0.4166666666666667
Training loss = 0.03495742479960124
step = 2, Training Accuracy: 0.45666666666666667
Training loss = 0.035466942191123965
step = 3, Training Accuracy: 0.43333333333333335
Training loss = 0.03504996081193288
step = 4, Training Accuracy: 0.43333333333333335
Training loss = 0.035580936868985495
step = 5, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.51375
Training loss = 0.03541011810302734
step = 6, Training Accuracy: 0.44333333333333336
Training loss = 0.03579082290331523
step = 7, Training Accuracy: 0.43666666666666665
Training loss = 0.03562388022740682
step = 8, Training Accuracy: 0.4166666666666667
Training loss = 0.03569780985514323
step = 9, Training Accuracy: 0.4066666666666667
Training loss = 0.03576039314270019
step = 10, Training Accuracy: 0.45
Validation Accuracy: 0.52375
Training loss = 0.035942203998565674
step = 11, Training Accuracy: 0.4166666666666667
Training loss = 0.034282666643460594
step = 12, Training Accuracy: 0.47
Training loss = 0.035782803694407145
step = 13, Training Accuracy: 0.4166666666666667
Training loss = 0.03557539840539296
step = 14, Training Accuracy: 0.39
Validation Accuracy: 0.46
params:  [0.08157443694236943, 0.33491057770583327, 0.9257712735902388, 0.99, 0.99, 0.6701918136730671, 0.27016863869452856, 0.18253102161518447, 0.7854134455422417, 0.01, 0.4136144259557987, 0.3459973066222076, 0.10836975808659102, 0.11135766349116158, 0.445028359926256, 0.3551259897412476, 0.5965582353689599, 0.5188924890680653, 0.7990309177254477, 0.5639666354661937, 0.5850038653239038, 0.15912688428361826, 0.52742353224379, 0.6429280124241233, 0.5002080276470489, 0.01, 0.14355539912826443, 0.44763298685534236, 0.16862391509850416, 0.5053118846078589, 0.22484548072695376, 0.32038981633669594, 0.012465859411266544, 0.19926215420103421, 0.5011580172351128, 0.6228572833719916, 0.01, 0.99, 0.9752790973000984, 0.01, 0.6186774701617628, 0.7092066450878522, 0.17721634030184552, 0.2628968620713858, 0.39606898976658667, 0.4448792941627065, 0.06768418308656367, 0.4762090122146033, 0.901827893353901, 0.6209138767203605, 0.6502793009412465, 0.623548162302324, 0.5012403355492006, 0.4704262157261878, 0.29195322703052656, 0.1464617196500692, 0.18158823648780792, 0.5547634715895935, 0.06213217971540809, 0.01, 0.3449591021172771, 0.9888345368207586, 0.5144815273915413, 0.4157193654615022, 0.39113974812098407, 0.11736287702243575, 0.4846709493174258, 0.05746127046980387, 0.01, 0.9100201307225345, 0.3560970253387912, 0.21190656245955491, 0.8237653996544003, 0.8532570150062723, 0.7405974344455207, 0.4479168086411208, 0.5783859754664135, 0.2242657441989619, 0.01, 0.022658560861048116, 0.7562489059499599, 0.9385780227400492, 0.19961270202749526, 0.10391325656003514, 0.99, 0.01, 0.31959196291546904, 0.19668050100761802, 0.2815293831143041, 0.3123232962804645, 0.061478305796212676, 0.3345177382452732]
[0.08157443694236943, 0.33491057770583327, 0.9257712735902388, 0.99, 0.99, 0.6701918136730671, 0.27016863869452856, 0.18253102161518447, 0.7854134455422417, 0.01, 0.4136144259557987, 0.3459973066222076, 0.10836975808659102, 0.11135766349116158, 0.445028359926256, 0.3551259897412476, 0.5965582353689599, 0.5188924890680653, 0.7990309177254477, 0.5639666354661937, 0.5850038653239038, 0.15912688428361826, 0.52742353224379, 0.6429280124241233, 0.5002080276470489, 0.01, 0.14355539912826443, 0.44763298685534236, 0.16862391509850416, 0.5053118846078589, 0.22484548072695376, 0.32038981633669594, 0.012465859411266544, 0.19926215420103421, 0.5011580172351128, 0.6228572833719916, 0.01, 0.99, 0.9752790973000984, 0.01, 0.6186774701617628, 0.7092066450878522, 0.17721634030184552, 0.2628968620713858, 0.39606898976658667, 0.4448792941627065, 0.06768418308656367, 0.4762090122146033, 0.901827893353901, 0.6209138767203605, 0.6502793009412465, 0.623548162302324, 0.5012403355492006, 0.4704262157261878, 0.29195322703052656, 0.1464617196500692, 0.18158823648780792, 0.5547634715895935, 0.06213217971540809, 0.01, 0.3449591021172771, 0.9888345368207586, 0.5144815273915413, 0.4157193654615022, 0.39113974812098407, 0.11736287702243575, 0.4846709493174258, 0.05746127046980387, 0.01, 0.9100201307225345, 0.3560970253387912, 0.21190656245955491, 0.8237653996544003, 0.8532570150062723, 0.7405974344455207, 0.4479168086411208, 0.5783859754664135, 0.2242657441989619, 0.01, 0.022658560861048116, 0.7562489059499599, 0.9385780227400492, 0.19961270202749526, 0.10391325656003514, 0.99, 0.01, 0.31959196291546904, 0.19668050100761802, 0.2815293831143041, 0.3123232962804645, 0.061478305796212676, 0.3345177382452732]
Training loss = 0.03448013921578725
step = 0, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.5175
Training loss = 0.034108078877131146
step = 1, Training Accuracy: 0.44333333333333336
Training loss = 0.03465970039367676
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.03426277716954549
step = 3, Training Accuracy: 0.44333333333333336
Training loss = 0.03443202535311381
step = 4, Training Accuracy: 0.45666666666666667
Training loss = 0.03420963962872823
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.5625
Training loss = 0.03460947652657827
step = 6, Training Accuracy: 0.43333333333333335
Training loss = 0.03457568387190501
step = 7, Training Accuracy: 0.43666666666666665
Training loss = 0.034064374168713885
step = 8, Training Accuracy: 0.4633333333333333
Training loss = 0.03426134983698527
step = 9, Training Accuracy: 0.4533333333333333
Training loss = 0.0349715397755305
step = 10, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.5625
Training loss = 0.03329705476760864
step = 11, Training Accuracy: 0.44333333333333336
Training loss = 0.0352641361951828
step = 12, Training Accuracy: 0.4033333333333333
Training loss = 0.033198921283086144
step = 13, Training Accuracy: 0.48333333333333334
Training loss = 0.0336653463045756
step = 14, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.59625
params:  [0.43832928989880954, 0.5869723418742, 0.6549145705309803, 0.7101076275841903, 0.4007942343013695, 0.7978609856380918, 0.01, 0.6814799650549195, 0.815022264276875, 0.01, 0.6566537237806411, 0.16473068836559324, 0.01, 0.04039045683245562, 0.99, 0.7965689258433899, 0.16404232876187327, 0.25684294828090204, 0.5134752130981046, 0.5190283424727925, 0.01, 0.4441079524596716, 0.34446427334750734, 0.1915962843312581, 0.4532022262073787, 0.01, 0.41455155148137623, 0.01, 0.3098241758860203, 0.01, 0.11833707953311699, 0.5232681414609156, 0.01, 0.5261790720525373, 0.4433000952466349, 0.585245710746946, 0.40552553850660544, 0.8711328955204154, 0.9554424995234255, 0.01, 0.5240812261197745, 0.3447531196143855, 0.20394828483725114, 0.03760741600555273, 0.747471938311326, 0.7505551367852346, 0.14626310111861576, 0.3225762562280109, 0.7501555503316454, 0.789170742940962, 0.99, 0.6515376820055022, 0.01, 0.5483468194380503, 0.36008550651365856, 0.3259770768147891, 0.2742785348793187, 0.8211610079345872, 0.01, 0.01, 0.9002895955961525, 0.3964588264435367, 0.2037191246145698, 0.5647902379909191, 0.8316271828286192, 0.45329857974602034, 0.433035177042293, 0.840642761018182, 0.01, 0.99, 0.033425466766002415, 0.99, 0.25356568536946156, 0.5334712421472916, 0.4763177147823561, 0.1697203790546435, 0.4700682915878561, 0.9047163235431536, 0.0668873315270632, 0.1807526157276894, 0.99, 0.3570165051439221, 0.37741514982225755, 0.23237721166253125, 0.99, 0.5145272344428387, 0.22679313577240906, 0.19250256951517009, 0.28676075055372036, 0.60061265523717, 0.01, 0.47918177030758435]
[0.43832928989880954, 0.5869723418742, 0.6549145705309803, 0.7101076275841903, 0.4007942343013695, 0.7978609856380918, 0.01, 0.6814799650549195, 0.815022264276875, 0.01, 0.6566537237806411, 0.16473068836559324, 0.01, 0.04039045683245562, 0.99, 0.7965689258433899, 0.16404232876187327, 0.25684294828090204, 0.5134752130981046, 0.5190283424727925, 0.01, 0.4441079524596716, 0.34446427334750734, 0.1915962843312581, 0.4532022262073787, 0.01, 0.41455155148137623, 0.01, 0.3098241758860203, 0.01, 0.11833707953311699, 0.5232681414609156, 0.01, 0.5261790720525373, 0.4433000952466349, 0.585245710746946, 0.40552553850660544, 0.8711328955204154, 0.9554424995234255, 0.01, 0.5240812261197745, 0.3447531196143855, 0.20394828483725114, 0.03760741600555273, 0.747471938311326, 0.7505551367852346, 0.14626310111861576, 0.3225762562280109, 0.7501555503316454, 0.789170742940962, 0.99, 0.6515376820055022, 0.01, 0.5483468194380503, 0.36008550651365856, 0.3259770768147891, 0.2742785348793187, 0.8211610079345872, 0.01, 0.01, 0.9002895955961525, 0.3964588264435367, 0.2037191246145698, 0.5647902379909191, 0.8316271828286192, 0.45329857974602034, 0.433035177042293, 0.840642761018182, 0.01, 0.99, 0.033425466766002415, 0.99, 0.25356568536946156, 0.5334712421472916, 0.4763177147823561, 0.1697203790546435, 0.4700682915878561, 0.9047163235431536, 0.0668873315270632, 0.1807526157276894, 0.99, 0.3570165051439221, 0.37741514982225755, 0.23237721166253125, 0.99, 0.5145272344428387, 0.22679313577240906, 0.19250256951517009, 0.28676075055372036, 0.60061265523717, 0.01, 0.47918177030758435]
Training loss = 0.03332506934801738
step = 0, Training Accuracy: 0.47
Validation Accuracy: 0.58
Training loss = 0.032268601655960086
step = 1, Training Accuracy: 0.5066666666666667
Training loss = 0.03157059848308563
step = 2, Training Accuracy: 0.5133333333333333
Training loss = 0.03219018538792928
step = 3, Training Accuracy: 0.5533333333333333
Training loss = 0.03173734466234843
step = 4, Training Accuracy: 0.5533333333333333
Training loss = 0.03124253431955973
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.54375
Training loss = 0.030833651820818583
step = 6, Training Accuracy: 0.5733333333333334
Training loss = 0.03192060470581055
step = 7, Training Accuracy: 0.5533333333333333
Training loss = 0.03224588890870412
step = 8, Training Accuracy: 0.52
Training loss = 0.030303325851758323
step = 9, Training Accuracy: 0.5433333333333333
Training loss = 0.030810947219530743
step = 10, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.54
Training loss = 0.03239378432432811
step = 11, Training Accuracy: 0.54
Training loss = 0.03198210577170054
step = 12, Training Accuracy: 0.5366666666666666
Training loss = 0.030303781827290852
step = 13, Training Accuracy: 0.5533333333333333
Training loss = 0.030011277397473654
step = 14, Training Accuracy: 0.56
Validation Accuracy: 0.54625
3  	8     	0.5375  	0.0347536	0.46   	0.59625
params:  [0.01, 0.28767582342329523, 0.7311324015710017, 0.9075080999619345, 0.6147509742273076, 0.6128221327552934, 0.01, 0.6544947192582613, 0.7305465054038202, 0.01, 0.4757581105769002, 0.5676257409104384, 0.3691601859064105, 0.19068119178900042, 0.7702134267181997, 0.7955876856426194, 0.7438740804241858, 0.3873910606980244, 0.8420469159590054, 0.8894972808713808, 0.031215417342685847, 0.11603656026524886, 0.7145646956158167, 0.8071764695288737, 0.591460252208709, 0.27052614639060985, 0.5070403226112923, 0.32276091867530987, 0.01, 0.29830231049398503, 0.2087708852563248, 0.4635946232864672, 0.25148602883154675, 0.46813242817752665, 0.7848339450030692, 0.7019109705355011, 0.3100163925386732, 0.99, 0.8892666734365511, 0.24064553648028136, 0.9893381208915244, 0.6101371891378689, 0.06083740609402927, 0.7967743809227587, 0.6606010448308629, 0.3396111599396693, 0.28938437513702153, 0.48990575355701954, 0.8683027485467056, 0.99, 0.10471414181134286, 0.4912527365698967, 0.0907549419956512, 0.3395516971727998, 0.5169514684504801, 0.01, 0.304826666570838, 0.5012952851991723, 0.254452789554294, 0.41674286372189107, 0.7562405163487514, 0.44999488459169895, 0.5272134420820387, 0.324710689581811, 0.6442930375234766, 0.01, 0.5753680187051807, 0.47192783194577637, 0.01, 0.99, 0.10051065386133315, 0.5146004208024478, 0.81939877485332, 0.618693181689153, 0.9447746847869848, 0.4502006466411924, 0.3979683219909186, 0.38731097895060196, 0.06087413475101393, 0.01, 0.6364024212581643, 0.99, 0.2675710678858321, 0.14705012094609723, 0.99, 0.17315237045289777, 0.12724637275689749, 0.23011795900311968, 0.1994270159434406, 0.3466628631252284, 0.24329385867907502, 0.451266859526741]
[0.01, 0.28767582342329523, 0.7311324015710017, 0.9075080999619345, 0.6147509742273076, 0.6128221327552934, 0.01, 0.6544947192582613, 0.7305465054038202, 0.01, 0.4757581105769002, 0.5676257409104384, 0.3691601859064105, 0.19068119178900042, 0.7702134267181997, 0.7955876856426194, 0.7438740804241858, 0.3873910606980244, 0.8420469159590054, 0.8894972808713808, 0.031215417342685847, 0.11603656026524886, 0.7145646956158167, 0.8071764695288737, 0.591460252208709, 0.27052614639060985, 0.5070403226112923, 0.32276091867530987, 0.01, 0.29830231049398503, 0.2087708852563248, 0.4635946232864672, 0.25148602883154675, 0.46813242817752665, 0.7848339450030692, 0.7019109705355011, 0.3100163925386732, 0.99, 0.8892666734365511, 0.24064553648028136, 0.9893381208915244, 0.6101371891378689, 0.06083740609402927, 0.7967743809227587, 0.6606010448308629, 0.3396111599396693, 0.28938437513702153, 0.48990575355701954, 0.8683027485467056, 0.99, 0.10471414181134286, 0.4912527365698967, 0.0907549419956512, 0.3395516971727998, 0.5169514684504801, 0.01, 0.304826666570838, 0.5012952851991723, 0.254452789554294, 0.41674286372189107, 0.7562405163487514, 0.44999488459169895, 0.5272134420820387, 0.324710689581811, 0.6442930375234766, 0.01, 0.5753680187051807, 0.47192783194577637, 0.01, 0.99, 0.10051065386133315, 0.5146004208024478, 0.81939877485332, 0.618693181689153, 0.9447746847869848, 0.4502006466411924, 0.3979683219909186, 0.38731097895060196, 0.06087413475101393, 0.01, 0.6364024212581643, 0.99, 0.2675710678858321, 0.14705012094609723, 0.99, 0.17315237045289777, 0.12724637275689749, 0.23011795900311968, 0.1994270159434406, 0.3466628631252284, 0.24329385867907502, 0.451266859526741]
Training loss = 0.035676204164822894
step = 0, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.55
Training loss = 0.03465874056021372
step = 1, Training Accuracy: 0.4166666666666667
Training loss = 0.03442934731642405
step = 2, Training Accuracy: 0.43666666666666665
Training loss = 0.03501927435398102
step = 3, Training Accuracy: 0.43
Training loss = 0.03350194136301676
step = 4, Training Accuracy: 0.43666666666666665
Training loss = 0.0327128928899765
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.54875
Training loss = 0.033716546893119814
step = 6, Training Accuracy: 0.5
Training loss = 0.033804744879404706
step = 7, Training Accuracy: 0.48
Training loss = 0.034447384675343834
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03321601490179698
step = 9, Training Accuracy: 0.5233333333333333
Training loss = 0.03472500662008921
step = 10, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.5625
Training loss = 0.03268813133239746
step = 11, Training Accuracy: 0.5033333333333333
Training loss = 0.03316304802894592
step = 12, Training Accuracy: 0.4766666666666667
Training loss = 0.035176493128140765
step = 13, Training Accuracy: 0.4533333333333333
Training loss = 0.03310718337694804
step = 14, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.53625
params:  [0.029323990986566545, 0.12031800709128287, 0.41445696351392036, 0.7246539636496058, 0.6562084341315064, 0.5095957958244643, 0.268794126089854, 0.47457082530306594, 0.7473177953826456, 0.01, 0.7155972321912504, 0.1285297451027339, 0.22778737084120843, 0.06888394670375377, 0.1989850041614677, 0.3502054583632388, 0.4393074387919366, 0.3495537657326753, 0.5424837689472576, 0.2999109579926546, 0.4568174221828544, 0.21401528152516128, 0.5542386030076928, 0.17385587147745496, 0.4095124336849809, 0.01, 0.1556408758492675, 0.15134646736848795, 0.01, 0.2958024828152962, 0.6100494383287656, 0.9744850730935141, 0.10551026435210066, 0.30279002572147434, 0.3175472014945312, 0.9656059222699482, 0.3056016031382349, 0.7405878093899746, 0.839452891459918, 0.01, 0.36853981785729883, 0.9020064581866416, 0.4029199181618279, 0.07810385057955127, 0.01, 0.99, 0.15264461810491042, 0.9407772283884365, 0.99, 0.5889453467988972, 0.99, 0.6388290355901489, 0.2647537850083102, 0.03503280535619946, 0.6459732265304114, 0.10107374656048253, 0.01, 0.9711244446045703, 0.01, 0.06550659179242738, 0.7442319326139424, 0.99, 0.9572422336380485, 0.6024657334556728, 0.47476283555543347, 0.8636089019919846, 0.515880064139964, 0.6809317985193781, 0.08359413397894644, 0.99, 0.20202610362249368, 0.99, 0.12382981159502277, 0.7589458979184736, 0.5356907207137019, 0.02843678489449214, 0.5310803628976922, 0.21117515652162194, 0.3095045959592987, 0.29824698831059304, 0.5777478570762737, 0.7553667160348974, 0.11306192985503544, 0.01, 0.99, 0.1704755834528722, 0.4810922330109316, 0.01, 0.35489610492980506, 0.5921728927986669, 0.1382012653250763, 0.28700481397967453]
[0.029323990986566545, 0.12031800709128287, 0.41445696351392036, 0.7246539636496058, 0.6562084341315064, 0.5095957958244643, 0.268794126089854, 0.47457082530306594, 0.7473177953826456, 0.01, 0.7155972321912504, 0.1285297451027339, 0.22778737084120843, 0.06888394670375377, 0.1989850041614677, 0.3502054583632388, 0.4393074387919366, 0.3495537657326753, 0.5424837689472576, 0.2999109579926546, 0.4568174221828544, 0.21401528152516128, 0.5542386030076928, 0.17385587147745496, 0.4095124336849809, 0.01, 0.1556408758492675, 0.15134646736848795, 0.01, 0.2958024828152962, 0.6100494383287656, 0.9744850730935141, 0.10551026435210066, 0.30279002572147434, 0.3175472014945312, 0.9656059222699482, 0.3056016031382349, 0.7405878093899746, 0.839452891459918, 0.01, 0.36853981785729883, 0.9020064581866416, 0.4029199181618279, 0.07810385057955127, 0.01, 0.99, 0.15264461810491042, 0.9407772283884365, 0.99, 0.5889453467988972, 0.99, 0.6388290355901489, 0.2647537850083102, 0.03503280535619946, 0.6459732265304114, 0.10107374656048253, 0.01, 0.9711244446045703, 0.01, 0.06550659179242738, 0.7442319326139424, 0.99, 0.9572422336380485, 0.6024657334556728, 0.47476283555543347, 0.8636089019919846, 0.515880064139964, 0.6809317985193781, 0.08359413397894644, 0.99, 0.20202610362249368, 0.99, 0.12382981159502277, 0.7589458979184736, 0.5356907207137019, 0.02843678489449214, 0.5310803628976922, 0.21117515652162194, 0.3095045959592987, 0.29824698831059304, 0.5777478570762737, 0.7553667160348974, 0.11306192985503544, 0.01, 0.99, 0.1704755834528722, 0.4810922330109316, 0.01, 0.35489610492980506, 0.5921728927986669, 0.1382012653250763, 0.28700481397967453]
Training loss = 0.03208148717880249
step = 0, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.5425
Training loss = 0.030700198411941527
step = 1, Training Accuracy: 0.52
Training loss = 0.03054750104745229
step = 2, Training Accuracy: 0.57
Training loss = 0.030732060273488362
step = 3, Training Accuracy: 0.5333333333333333
Training loss = 0.029554850657780966
step = 4, Training Accuracy: 0.5333333333333333
Training loss = 0.02874349812666575
step = 5, Training Accuracy: 0.61
Validation Accuracy: 0.54
Training loss = 0.029656998912493387
step = 6, Training Accuracy: 0.5933333333333334
Training loss = 0.03064464271068573
step = 7, Training Accuracy: 0.5333333333333333
Training loss = 0.030262141823768615
step = 8, Training Accuracy: 0.58
Training loss = 0.02970328708489736
step = 9, Training Accuracy: 0.5566666666666666
Training loss = 0.030336794257164002
step = 10, Training Accuracy: 0.5933333333333334
Validation Accuracy: 0.54625
Training loss = 0.029423153201738994
step = 11, Training Accuracy: 0.57
Training loss = 0.030653466780980427
step = 12, Training Accuracy: 0.5533333333333333
Training loss = 0.02926030178864797
step = 13, Training Accuracy: 0.62
Training loss = 0.03177459955215454
step = 14, Training Accuracy: 0.5733333333333334
Validation Accuracy: 0.54125
params:  [0.12404595617838964, 0.8498514123584732, 0.99, 0.8466487161655873, 0.9246887262440265, 0.6304443355848122, 0.23056769485529582, 0.801611070483253, 0.5321945716697056, 0.15012358470821774, 0.08899508306030418, 0.01, 0.0910901405349212, 0.3588981090374531, 0.99, 0.5371141053627088, 0.43139106232064905, 0.12715070857266353, 0.5767783732316079, 0.15359157985418748, 0.2788605753441251, 0.6833824462171412, 0.33426456728822385, 0.5903603988957769, 0.7872683876444171, 0.6375328221812936, 0.25824172050244937, 0.4354357089424761, 0.3336943673633842, 0.0671220970547845, 0.1660613433064545, 0.558021410361272, 0.172223199843338, 0.3866471257137881, 0.15657900851836204, 0.8942543842766194, 0.578823312964602, 0.6024151162565727, 0.8493914881641138, 0.1378421842623725, 0.22207442813118777, 0.6256211932818198, 0.037650658764508904, 0.5727591021732346, 0.11698887385146933, 0.44370162779281275, 0.32695606026239665, 0.7423696814950433, 0.9457807458576608, 0.5224645617706459, 0.99, 0.8934041097653252, 0.12208577965229037, 0.8985006841575599, 0.516148392766795, 0.2146466648718643, 0.27061543827297596, 0.984886275210602, 0.08118233914416167, 0.0631963002059126, 0.3694640005751484, 0.6083822865898565, 0.4921545208897084, 0.5022239435566921, 0.2951672248632472, 0.3153084369770296, 0.5764226968166811, 0.9153148308036491, 0.01, 0.99, 0.46838315774565265, 0.9623035900434773, 0.5660465071293451, 0.99, 0.99, 0.5589105346653869, 0.5656387712200324, 0.581181295160914, 0.01, 0.01, 0.8829035717229229, 0.9261118920438115, 0.8991138318620401, 0.01, 0.99, 0.30901452183430667, 0.44650041076573316, 0.07779505494529737, 0.4033008308630125, 0.3897441702818476, 0.01, 0.6907540492321871]
[0.12404595617838964, 0.8498514123584732, 0.99, 0.8466487161655873, 0.9246887262440265, 0.6304443355848122, 0.23056769485529582, 0.801611070483253, 0.5321945716697056, 0.15012358470821774, 0.08899508306030418, 0.01, 0.0910901405349212, 0.3588981090374531, 0.99, 0.5371141053627088, 0.43139106232064905, 0.12715070857266353, 0.5767783732316079, 0.15359157985418748, 0.2788605753441251, 0.6833824462171412, 0.33426456728822385, 0.5903603988957769, 0.7872683876444171, 0.6375328221812936, 0.25824172050244937, 0.4354357089424761, 0.3336943673633842, 0.0671220970547845, 0.1660613433064545, 0.558021410361272, 0.172223199843338, 0.3866471257137881, 0.15657900851836204, 0.8942543842766194, 0.578823312964602, 0.6024151162565727, 0.8493914881641138, 0.1378421842623725, 0.22207442813118777, 0.6256211932818198, 0.037650658764508904, 0.5727591021732346, 0.11698887385146933, 0.44370162779281275, 0.32695606026239665, 0.7423696814950433, 0.9457807458576608, 0.5224645617706459, 0.99, 0.8934041097653252, 0.12208577965229037, 0.8985006841575599, 0.516148392766795, 0.2146466648718643, 0.27061543827297596, 0.984886275210602, 0.08118233914416167, 0.0631963002059126, 0.3694640005751484, 0.6083822865898565, 0.4921545208897084, 0.5022239435566921, 0.2951672248632472, 0.3153084369770296, 0.5764226968166811, 0.9153148308036491, 0.01, 0.99, 0.46838315774565265, 0.9623035900434773, 0.5660465071293451, 0.99, 0.99, 0.5589105346653869, 0.5656387712200324, 0.581181295160914, 0.01, 0.01, 0.8829035717229229, 0.9261118920438115, 0.8991138318620401, 0.01, 0.99, 0.30901452183430667, 0.44650041076573316, 0.07779505494529737, 0.4033008308630125, 0.3897441702818476, 0.01, 0.6907540492321871]
Training loss = 0.034080533186594646
step = 0, Training Accuracy: 0.48
Validation Accuracy: 0.54
Training loss = 0.03391716400782267
step = 1, Training Accuracy: 0.4533333333333333
Training loss = 0.03355873088041941
step = 2, Training Accuracy: 0.5
Training loss = 0.033071514964103696
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.034202064673105874
step = 4, Training Accuracy: 0.45
Training loss = 0.03328417400519053
step = 5, Training Accuracy: 0.5
Validation Accuracy: 0.54875
Training loss = 0.03235928356647491
step = 6, Training Accuracy: 0.51
Training loss = 0.03482939044634501
step = 7, Training Accuracy: 0.44333333333333336
Training loss = 0.033622850775718686
step = 8, Training Accuracy: 0.46
Training loss = 0.032350579500198366
step = 9, Training Accuracy: 0.52
Training loss = 0.03347507258256276
step = 10, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.54875
Training loss = 0.0335546217362086
step = 11, Training Accuracy: 0.44666666666666666
Training loss = 0.032723652323087056
step = 12, Training Accuracy: 0.5066666666666667
Training loss = 0.03265122632185618
step = 13, Training Accuracy: 0.5333333333333333
Training loss = 0.03304403404394785
step = 14, Training Accuracy: 0.49
Validation Accuracy: 0.56
params:  [0.01, 0.3320813603589295, 0.37154597864366373, 0.99, 0.929319889552457, 0.6309124019576626, 0.01, 0.99, 0.6152232084751053, 0.6346548880717913, 0.3855382862246408, 0.01, 0.01, 0.16018416251770426, 0.8499804036948118, 0.7229865033000942, 0.26543236686894955, 0.7733023954459777, 0.5518863007193298, 0.579687799815366, 0.01, 0.4397892760007932, 0.7905130521457862, 0.19632737815616563, 0.1026388750227083, 0.16438319129542778, 0.3885338111823706, 0.33640214982354855, 0.7001597598982245, 0.4690745073570783, 0.01, 0.5762650769197155, 0.01, 0.399194778725732, 0.5394078527128464, 0.6345108262066286, 0.01, 0.8918714689447531, 0.7244100856866283, 0.5312869197274918, 0.670536631946585, 0.5583296136564692, 0.6357507260702766, 0.01, 0.8421165090805529, 0.727582792626349, 0.01, 0.573324514452894, 0.99, 0.8537632318759673, 0.0282355736614206, 0.5973395108334165, 0.10080703180981049, 0.36628710784834273, 0.5148437621399462, 0.1985061018923448, 0.42475954323211057, 0.33239988763642625, 0.5071158430326373, 0.01, 0.20025321465326468, 0.737590543987778, 0.560968317066844, 0.6795261256693992, 0.52586687066053, 0.5423675589330388, 0.01, 0.4915099152056714, 0.13301122866797624, 0.8698827926918332, 0.07521611549216173, 0.7031638395820454, 0.7188952678729141, 0.5110578911916317, 0.2921325997476936, 0.5873247209580307, 0.49343976945770796, 0.99, 0.01, 0.29482610917557095, 0.9624397097657108, 0.9763085262449517, 0.5495883321483062, 0.01, 0.8622955718043293, 0.5930664100678585, 0.45721371011107115, 0.11843587615446773, 0.053176007873473013, 0.5313208930274506, 0.01, 0.0961127459013354]
[0.01, 0.3320813603589295, 0.37154597864366373, 0.99, 0.929319889552457, 0.6309124019576626, 0.01, 0.99, 0.6152232084751053, 0.6346548880717913, 0.3855382862246408, 0.01, 0.01, 0.16018416251770426, 0.8499804036948118, 0.7229865033000942, 0.26543236686894955, 0.7733023954459777, 0.5518863007193298, 0.579687799815366, 0.01, 0.4397892760007932, 0.7905130521457862, 0.19632737815616563, 0.1026388750227083, 0.16438319129542778, 0.3885338111823706, 0.33640214982354855, 0.7001597598982245, 0.4690745073570783, 0.01, 0.5762650769197155, 0.01, 0.399194778725732, 0.5394078527128464, 0.6345108262066286, 0.01, 0.8918714689447531, 0.7244100856866283, 0.5312869197274918, 0.670536631946585, 0.5583296136564692, 0.6357507260702766, 0.01, 0.8421165090805529, 0.727582792626349, 0.01, 0.573324514452894, 0.99, 0.8537632318759673, 0.0282355736614206, 0.5973395108334165, 0.10080703180981049, 0.36628710784834273, 0.5148437621399462, 0.1985061018923448, 0.42475954323211057, 0.33239988763642625, 0.5071158430326373, 0.01, 0.20025321465326468, 0.737590543987778, 0.560968317066844, 0.6795261256693992, 0.52586687066053, 0.5423675589330388, 0.01, 0.4915099152056714, 0.13301122866797624, 0.8698827926918332, 0.07521611549216173, 0.7031638395820454, 0.7188952678729141, 0.5110578911916317, 0.2921325997476936, 0.5873247209580307, 0.49343976945770796, 0.99, 0.01, 0.29482610917557095, 0.9624397097657108, 0.9763085262449517, 0.5495883321483062, 0.01, 0.8622955718043293, 0.5930664100678585, 0.45721371011107115, 0.11843587615446773, 0.053176007873473013, 0.5313208930274506, 0.01, 0.0961127459013354]
Training loss = 0.03370044986406962
step = 0, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.5525
Training loss = 0.03423402428627014
step = 1, Training Accuracy: 0.4666666666666667
Training loss = 0.03436608155568441
step = 2, Training Accuracy: 0.4533333333333333
Training loss = 0.03383120159308116
step = 3, Training Accuracy: 0.46
Training loss = 0.03430946211020152
step = 4, Training Accuracy: 0.43
Training loss = 0.03573447326819102
step = 5, Training Accuracy: 0.44
Validation Accuracy: 0.575
Training loss = 0.033245199124018354
step = 6, Training Accuracy: 0.5033333333333333
Training loss = 0.032623149156570434
step = 7, Training Accuracy: 0.48
Training loss = 0.03362977027893067
step = 8, Training Accuracy: 0.5133333333333333
Training loss = 0.0335664709409078
step = 9, Training Accuracy: 0.5066666666666667
Training loss = 0.033518389860788984
step = 10, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.545
Training loss = 0.03301191469033559
step = 11, Training Accuracy: 0.46
Training loss = 0.03385447084903717
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03374887188275655
step = 13, Training Accuracy: 0.44666666666666666
Training loss = 0.033160449465115864
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.5525
params:  [0.3325467741135763, 0.15025737155735608, 0.38753392410513493, 0.5248885131759766, 0.6737848223418712, 0.99, 0.4922311676419622, 0.4587931716607159, 0.874153935522153, 0.19708734794651456, 0.34406676600475394, 0.3282265569521894, 0.3531338463593632, 0.2572770631159056, 0.26607805073658636, 0.06976624619864302, 0.5233363475531454, 0.4291962444443095, 0.7267901563469561, 0.28909117790368366, 0.3689571254078544, 0.43281566805940075, 0.604755860749987, 0.3317024389495477, 0.4156628743757142, 0.1630762083102527, 0.43191160371517284, 0.5954606920841676, 0.059416293390027686, 0.07932654338543549, 0.2047623478514785, 0.30803548823661925, 0.01, 0.16895845225140754, 0.01, 0.8289682999951362, 0.32821648366826883, 0.969235214741474, 0.99, 0.21241789260416344, 0.5184871665487877, 0.21740416047015676, 0.40842248925952607, 0.6117687495302642, 0.8280717860236662, 0.45107034797458556, 0.14268454232788513, 0.99, 0.99, 0.8822604579349775, 0.99, 0.5674167136341263, 0.2665352480247708, 0.6489906183791071, 0.062080229162328526, 0.01, 0.3770184107443163, 0.8670637274942536, 0.31970948688666606, 0.01, 0.3456896456362576, 0.34168247273210345, 0.11878458444536366, 0.3371757946988828, 0.9147628514289752, 0.3317024900698733, 0.39688708197478595, 0.2307708044647208, 0.01, 0.99, 0.5635843079549562, 0.347548592878083, 0.32064771735002007, 0.6122345643514617, 0.8657562037464263, 0.829315669297362, 0.38656182002747563, 0.20710652983804223, 0.01, 0.1435656188192564, 0.8239516020539488, 0.7345818149407414, 0.7364341305309613, 0.23212027753959347, 0.99, 0.34839968872300686, 0.6233567349656375, 0.6867035524859519, 0.0263523525948737, 0.47751554463948515, 0.01, 0.2599114254060607]
[0.3325467741135763, 0.15025737155735608, 0.38753392410513493, 0.5248885131759766, 0.6737848223418712, 0.99, 0.4922311676419622, 0.4587931716607159, 0.874153935522153, 0.19708734794651456, 0.34406676600475394, 0.3282265569521894, 0.3531338463593632, 0.2572770631159056, 0.26607805073658636, 0.06976624619864302, 0.5233363475531454, 0.4291962444443095, 0.7267901563469561, 0.28909117790368366, 0.3689571254078544, 0.43281566805940075, 0.604755860749987, 0.3317024389495477, 0.4156628743757142, 0.1630762083102527, 0.43191160371517284, 0.5954606920841676, 0.059416293390027686, 0.07932654338543549, 0.2047623478514785, 0.30803548823661925, 0.01, 0.16895845225140754, 0.01, 0.8289682999951362, 0.32821648366826883, 0.969235214741474, 0.99, 0.21241789260416344, 0.5184871665487877, 0.21740416047015676, 0.40842248925952607, 0.6117687495302642, 0.8280717860236662, 0.45107034797458556, 0.14268454232788513, 0.99, 0.99, 0.8822604579349775, 0.99, 0.5674167136341263, 0.2665352480247708, 0.6489906183791071, 0.062080229162328526, 0.01, 0.3770184107443163, 0.8670637274942536, 0.31970948688666606, 0.01, 0.3456896456362576, 0.34168247273210345, 0.11878458444536366, 0.3371757946988828, 0.9147628514289752, 0.3317024900698733, 0.39688708197478595, 0.2307708044647208, 0.01, 0.99, 0.5635843079549562, 0.347548592878083, 0.32064771735002007, 0.6122345643514617, 0.8657562037464263, 0.829315669297362, 0.38656182002747563, 0.20710652983804223, 0.01, 0.1435656188192564, 0.8239516020539488, 0.7345818149407414, 0.7364341305309613, 0.23212027753959347, 0.99, 0.34839968872300686, 0.6233567349656375, 0.6867035524859519, 0.0263523525948737, 0.47751554463948515, 0.01, 0.2599114254060607]
Training loss = 0.03373772422472636
step = 0, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.54875
Training loss = 0.034298559228579203
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.03369248509407043
step = 2, Training Accuracy: 0.48
Training loss = 0.0339142374197642
step = 3, Training Accuracy: 0.44666666666666666
Training loss = 0.03429798146088918
step = 4, Training Accuracy: 0.45666666666666667
Training loss = 0.03372667908668518
step = 5, Training Accuracy: 0.46
Validation Accuracy: 0.54
Training loss = 0.03391104380289713
step = 6, Training Accuracy: 0.46
Training loss = 0.03438733299573263
step = 7, Training Accuracy: 0.42333333333333334
Training loss = 0.03376705189545949
step = 8, Training Accuracy: 0.48
Training loss = 0.032847216725349425
step = 9, Training Accuracy: 0.4666666666666667
Training loss = 0.032785886327425635
step = 10, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.565
Training loss = 0.032215738097826636
step = 11, Training Accuracy: 0.5133333333333333
Training loss = 0.0325410133600235
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03262809713681539
step = 13, Training Accuracy: 0.49
Training loss = 0.03346142629782359
step = 14, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.54125
params:  [0.011418092980262168, 0.7012153567546322, 0.6986123138905489, 0.99, 0.9639419168764325, 0.6259624570626462, 0.01, 0.2675741695808395, 0.7168543336309566, 0.037473841602605196, 0.99, 0.1762240725004528, 0.22336815364658713, 0.01, 0.7267297403941881, 0.46213154868630507, 0.1122775570756463, 0.3782350573090623, 0.9546467089043404, 0.4038011474762339, 0.0854769309882838, 0.1696007313523461, 0.47317289682658326, 0.7656704981927464, 0.20572762920950627, 0.01, 0.0791588227675861, 0.08293640613472775, 0.5545527322953892, 0.23316503416652168, 0.7274687837648451, 0.60355189867291, 0.3993709941529382, 0.2302993716329638, 0.4474581488472952, 0.5230424864478125, 0.01, 0.99, 0.892140392069006, 0.5632274729831469, 0.6092299838170826, 0.3482611567012532, 0.22778487120269936, 0.4824238430758433, 0.458311224245721, 0.8400603945765936, 0.3211742854804587, 0.5641158971307748, 0.99, 0.99, 0.3537564826889442, 0.44123720060053406, 0.5101761806914702, 0.3696291110021048, 0.2292456580623498, 0.35012678779797923, 0.22088676131170637, 0.267157372981494, 0.01, 0.11448863272545709, 0.8904986530444389, 0.99, 0.4319443245533724, 0.6836804222011468, 0.404476712183243, 0.01, 0.01, 0.42069883844734646, 0.050326238567593995, 0.8381395528213155, 0.13956459378988964, 0.5090830741555088, 0.09722500188167177, 0.99, 0.8797477498555109, 0.7881754822666305, 0.2617026536840755, 0.6089050623475449, 0.01, 0.11223063560645669, 0.8463458993014931, 0.6210245833802457, 0.7508442360827239, 0.01, 0.6138733000390424, 0.01, 0.7987839395818035, 0.7382208525897553, 0.01, 0.33105422824125225, 0.18669059531547444, 0.33805475966569043]
[0.011418092980262168, 0.7012153567546322, 0.6986123138905489, 0.99, 0.9639419168764325, 0.6259624570626462, 0.01, 0.2675741695808395, 0.7168543336309566, 0.037473841602605196, 0.99, 0.1762240725004528, 0.22336815364658713, 0.01, 0.7267297403941881, 0.46213154868630507, 0.1122775570756463, 0.3782350573090623, 0.9546467089043404, 0.4038011474762339, 0.0854769309882838, 0.1696007313523461, 0.47317289682658326, 0.7656704981927464, 0.20572762920950627, 0.01, 0.0791588227675861, 0.08293640613472775, 0.5545527322953892, 0.23316503416652168, 0.7274687837648451, 0.60355189867291, 0.3993709941529382, 0.2302993716329638, 0.4474581488472952, 0.5230424864478125, 0.01, 0.99, 0.892140392069006, 0.5632274729831469, 0.6092299838170826, 0.3482611567012532, 0.22778487120269936, 0.4824238430758433, 0.458311224245721, 0.8400603945765936, 0.3211742854804587, 0.5641158971307748, 0.99, 0.99, 0.3537564826889442, 0.44123720060053406, 0.5101761806914702, 0.3696291110021048, 0.2292456580623498, 0.35012678779797923, 0.22088676131170637, 0.267157372981494, 0.01, 0.11448863272545709, 0.8904986530444389, 0.99, 0.4319443245533724, 0.6836804222011468, 0.404476712183243, 0.01, 0.01, 0.42069883844734646, 0.050326238567593995, 0.8381395528213155, 0.13956459378988964, 0.5090830741555088, 0.09722500188167177, 0.99, 0.8797477498555109, 0.7881754822666305, 0.2617026536840755, 0.6089050623475449, 0.01, 0.11223063560645669, 0.8463458993014931, 0.6210245833802457, 0.7508442360827239, 0.01, 0.6138733000390424, 0.01, 0.7987839395818035, 0.7382208525897553, 0.01, 0.33105422824125225, 0.18669059531547444, 0.33805475966569043]
Training loss = 0.03306884765625
step = 0, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.54625
Training loss = 0.031803343494733176
step = 1, Training Accuracy: 0.5366666666666666
Training loss = 0.03239683369795481
step = 2, Training Accuracy: 0.51
Training loss = 0.031220224897066752
step = 3, Training Accuracy: 0.52
Training loss = 0.02984709858894348
step = 4, Training Accuracy: 0.5633333333333334
Training loss = 0.032611198623975116
step = 5, Training Accuracy: 0.52
Validation Accuracy: 0.55875
Training loss = 0.0306471182902654
step = 6, Training Accuracy: 0.5066666666666667
Training loss = 0.03185034076372782
step = 7, Training Accuracy: 0.5366666666666666
Training loss = 0.03167608002821604
step = 8, Training Accuracy: 0.5933333333333334
Training loss = 0.03246314922968547
step = 9, Training Accuracy: 0.52
Training loss = 0.03109737515449524
step = 10, Training Accuracy: 0.59
Validation Accuracy: 0.57875
Training loss = 0.03125340938568115
step = 11, Training Accuracy: 0.5366666666666666
Training loss = 0.02966665267944336
step = 12, Training Accuracy: 0.5666666666666667
Training loss = 0.03151043991247813
step = 13, Training Accuracy: 0.58
Training loss = 0.030668230056762696
step = 14, Training Accuracy: 0.5733333333333334
Validation Accuracy: 0.585
params:  [0.2318939875236275, 0.8044483970714791, 0.7752190817036472, 0.566730137041696, 0.9686697681515894, 0.8723168261890187, 0.26193631171416154, 0.32663215630123804, 0.99, 0.03134859934293866, 0.04265960697947735, 0.21899758492840954, 0.24687980676634058, 0.2917349553228626, 0.6226443030742985, 0.01, 0.18362017999737837, 0.07259396201369994, 0.712541379287013, 0.5732152959633408, 0.407136267287986, 0.15823835439647238, 0.17153494440493816, 0.4013401935859607, 0.5513454237060208, 0.01, 0.4741648739601455, 0.19497707947455056, 0.268080562229657, 0.24929932499750562, 0.01, 0.5650689884981264, 0.037489672147420584, 0.23905064853487673, 0.5839100168529353, 0.99, 0.39319959965115164, 0.9726523217095379, 0.99, 0.13056463579871147, 0.599698388204865, 0.5329153700507634, 0.29878957952691443, 0.2284494502234741, 0.8324416375161803, 0.8644892799056094, 0.5988231192887046, 0.5432377291550533, 0.9061365432897938, 0.7760733497074265, 0.8607586182863295, 0.6718729286582817, 0.08904837243364006, 0.4033940944849083, 0.21707813316787697, 0.4215708853677832, 0.10171382065148113, 0.99, 0.10090000750488685, 0.41425376629005606, 0.6478192801331562, 0.99, 0.7697687488580129, 0.18724992076998526, 0.2269424187954576, 0.6025400995257117, 0.7058992029055926, 0.31114890652229527, 0.3227739199596163, 0.9234110116756143, 0.33412362583225685, 0.3301585135720596, 0.4514825486858315, 0.99, 0.8642212162408329, 0.6481828302349114, 0.6058490998316, 0.3509537720365686, 0.023868843025102504, 0.5998892929018474, 0.8598372300528784, 0.6566054551695552, 0.5339894363907002, 0.01, 0.99, 0.46939923183292026, 0.03546598173568899, 0.27493175343160875, 0.32877634170820436, 0.01, 0.01, 0.0578252426423293]
[0.2318939875236275, 0.8044483970714791, 0.7752190817036472, 0.566730137041696, 0.9686697681515894, 0.8723168261890187, 0.26193631171416154, 0.32663215630123804, 0.99, 0.03134859934293866, 0.04265960697947735, 0.21899758492840954, 0.24687980676634058, 0.2917349553228626, 0.6226443030742985, 0.01, 0.18362017999737837, 0.07259396201369994, 0.712541379287013, 0.5732152959633408, 0.407136267287986, 0.15823835439647238, 0.17153494440493816, 0.4013401935859607, 0.5513454237060208, 0.01, 0.4741648739601455, 0.19497707947455056, 0.268080562229657, 0.24929932499750562, 0.01, 0.5650689884981264, 0.037489672147420584, 0.23905064853487673, 0.5839100168529353, 0.99, 0.39319959965115164, 0.9726523217095379, 0.99, 0.13056463579871147, 0.599698388204865, 0.5329153700507634, 0.29878957952691443, 0.2284494502234741, 0.8324416375161803, 0.8644892799056094, 0.5988231192887046, 0.5432377291550533, 0.9061365432897938, 0.7760733497074265, 0.8607586182863295, 0.6718729286582817, 0.08904837243364006, 0.4033940944849083, 0.21707813316787697, 0.4215708853677832, 0.10171382065148113, 0.99, 0.10090000750488685, 0.41425376629005606, 0.6478192801331562, 0.99, 0.7697687488580129, 0.18724992076998526, 0.2269424187954576, 0.6025400995257117, 0.7058992029055926, 0.31114890652229527, 0.3227739199596163, 0.9234110116756143, 0.33412362583225685, 0.3301585135720596, 0.4514825486858315, 0.99, 0.8642212162408329, 0.6481828302349114, 0.6058490998316, 0.3509537720365686, 0.023868843025102504, 0.5998892929018474, 0.8598372300528784, 0.6566054551695552, 0.5339894363907002, 0.01, 0.99, 0.46939923183292026, 0.03546598173568899, 0.27493175343160875, 0.32877634170820436, 0.01, 0.01, 0.0578252426423293]
Training loss = 0.03363991677761078
step = 0, Training Accuracy: 0.45
Validation Accuracy: 0.57
Training loss = 0.03234415451685588
step = 1, Training Accuracy: 0.5233333333333333
Training loss = 0.03257538576920827
step = 2, Training Accuracy: 0.52
Training loss = 0.032025436957677206
step = 3, Training Accuracy: 0.49
Training loss = 0.03267123838265737
step = 4, Training Accuracy: 0.48333333333333334
Training loss = 0.03170409977436066
step = 5, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.57375
Training loss = 0.03334295690059662
step = 6, Training Accuracy: 0.5233333333333333
Training loss = 0.03229273756345113
step = 7, Training Accuracy: 0.5033333333333333
Training loss = 0.032268910606702166
step = 8, Training Accuracy: 0.4766666666666667
Training loss = 0.03192413330078125
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.03070539116859436
step = 10, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.58875
Training loss = 0.031464515328407286
step = 11, Training Accuracy: 0.5266666666666666
Training loss = 0.034435590505599974
step = 12, Training Accuracy: 0.47
Training loss = 0.03416793763637543
step = 13, Training Accuracy: 0.46
Training loss = 0.03275446911652883
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.5775
params:  [0.01, 0.3884425604644672, 0.99, 0.9486530794655887, 0.785036080338219, 0.9177439827976093, 0.5742615316708559, 0.8592061917612108, 0.99, 0.01, 0.6407255879956048, 0.13491613730400595, 0.08998989705558932, 0.5371229245750347, 0.42784751790024594, 0.7120651761872425, 0.579642039530245, 0.945522948407944, 0.5634275380222981, 0.5045922499419762, 0.6490989026928974, 0.4527642690281352, 0.4132192858555631, 0.5623748770899909, 0.8690977288014856, 0.5566636835992131, 0.0966268794942661, 0.3848511392356314, 0.014410235395469484, 0.4796805756249639, 0.01, 0.4425400301024291, 0.4305332395725038, 0.5173725301464986, 0.8058867984910553, 0.8470705933611349, 0.01, 0.3044333375033055, 0.8756895417894439, 0.18334626684942248, 0.9591476720206709, 0.01, 0.45686517005469685, 0.01, 0.35657133467738145, 0.12125878581545729, 0.46045171317253625, 0.4178618417713208, 0.99, 0.7730915165525011, 0.99, 0.8349883574587101, 0.5289037502631161, 0.6167024144373653, 0.829534726504916, 0.17598798529802667, 0.5869403998927116, 0.8875976386719715, 0.01, 0.5400794291515296, 0.378675785533364, 0.6194229471495563, 0.99, 0.6380306135461457, 0.37112987060723857, 0.01, 0.3190942507825789, 0.18319146581598175, 0.01, 0.99, 0.027082936679866942, 0.7822427361574742, 0.6799017491141407, 0.4714432463596576, 0.5657616494190976, 0.02705025570563324, 0.7539877288655217, 0.620320808432452, 0.17913301145390678, 0.12067204460125255, 0.95117721237655, 0.8960327914032344, 0.15604808999483988, 0.2663577210054994, 0.7691316028453229, 0.01, 0.3975410298572343, 0.01, 0.01, 0.3883418695948347, 0.34571401840611515, 0.5417392283014822]
[0.01, 0.3884425604644672, 0.99, 0.9486530794655887, 0.785036080338219, 0.9177439827976093, 0.5742615316708559, 0.8592061917612108, 0.99, 0.01, 0.6407255879956048, 0.13491613730400595, 0.08998989705558932, 0.5371229245750347, 0.42784751790024594, 0.7120651761872425, 0.579642039530245, 0.945522948407944, 0.5634275380222981, 0.5045922499419762, 0.6490989026928974, 0.4527642690281352, 0.4132192858555631, 0.5623748770899909, 0.8690977288014856, 0.5566636835992131, 0.0966268794942661, 0.3848511392356314, 0.014410235395469484, 0.4796805756249639, 0.01, 0.4425400301024291, 0.4305332395725038, 0.5173725301464986, 0.8058867984910553, 0.8470705933611349, 0.01, 0.3044333375033055, 0.8756895417894439, 0.18334626684942248, 0.9591476720206709, 0.01, 0.45686517005469685, 0.01, 0.35657133467738145, 0.12125878581545729, 0.46045171317253625, 0.4178618417713208, 0.99, 0.7730915165525011, 0.99, 0.8349883574587101, 0.5289037502631161, 0.6167024144373653, 0.829534726504916, 0.17598798529802667, 0.5869403998927116, 0.8875976386719715, 0.01, 0.5400794291515296, 0.378675785533364, 0.6194229471495563, 0.99, 0.6380306135461457, 0.37112987060723857, 0.01, 0.3190942507825789, 0.18319146581598175, 0.01, 0.99, 0.027082936679866942, 0.7822427361574742, 0.6799017491141407, 0.4714432463596576, 0.5657616494190976, 0.02705025570563324, 0.7539877288655217, 0.620320808432452, 0.17913301145390678, 0.12067204460125255, 0.95117721237655, 0.8960327914032344, 0.15604808999483988, 0.2663577210054994, 0.7691316028453229, 0.01, 0.3975410298572343, 0.01, 0.01, 0.3883418695948347, 0.34571401840611515, 0.5417392283014822]
Training loss = 0.03508407572905223
step = 0, Training Accuracy: 0.46
Validation Accuracy: 0.565
Training loss = 0.03600913166999817
step = 1, Training Accuracy: 0.41333333333333333
Training loss = 0.03635400295257568
step = 2, Training Accuracy: 0.4
Training loss = 0.03494451383749644
step = 3, Training Accuracy: 0.43333333333333335
Training loss = 0.03535180528958638
step = 4, Training Accuracy: 0.4533333333333333
Training loss = 0.03507695257663727
step = 5, Training Accuracy: 0.44
Validation Accuracy: 0.52875
Training loss = 0.03530165473620097
step = 6, Training Accuracy: 0.38666666666666666
Training loss = 0.03532804846763611
step = 7, Training Accuracy: 0.4033333333333333
Training loss = 0.035806591908137
step = 8, Training Accuracy: 0.45
Training loss = 0.03531215965747833
step = 9, Training Accuracy: 0.45
Training loss = 0.034407595793406166
step = 10, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.5325
Training loss = 0.03450526734193166
step = 11, Training Accuracy: 0.43333333333333335
Training loss = 0.03466124852498372
step = 12, Training Accuracy: 0.47333333333333333
Training loss = 0.03499005933602651
step = 13, Training Accuracy: 0.44
Training loss = 0.03551392118136088
step = 14, Training Accuracy: 0.4166666666666667
Validation Accuracy: 0.57
4  	8     	0.557969	0.0170355	0.53625	0.585  
params:  [0.25134522130022363, 0.6201028178844215, 0.5994020860940426, 0.6038108372543831, 0.9564803659516964, 0.99, 0.01, 0.99, 0.8029590891517732, 0.045760337769491136, 0.45921637229737133, 0.2530742856286355, 0.2657113210120562, 0.15229993401344047, 0.8489947881901114, 0.28351224352671295, 0.2204381116385908, 0.6616953620102611, 0.4297864788049769, 0.49951324977296246, 0.2524306319767524, 0.01, 0.42269909740405054, 0.5286948635058836, 0.19973335613933982, 0.37686747045755886, 0.7245574319530542, 0.07960746811229732, 0.23254897621746093, 0.31686265889162557, 0.38927911286719125, 0.39306805746742507, 0.6080234974211939, 0.01, 0.29319371889856344, 0.26225845802004655, 0.3096101438774571, 0.6483305796503471, 0.99, 0.23277577574075964, 0.8588947971837825, 0.3993326706250795, 0.19372071977391148, 0.1183084053839134, 0.2595936544273161, 0.4965876713983287, 0.14211748874073254, 0.9680615277857736, 0.8379767469093906, 0.5629782538042227, 0.7941371536530633, 0.4511891964240338, 0.07124388616947597, 0.5381603334665699, 0.01, 0.434892498095521, 0.3601916757353498, 0.774685001978769, 0.01, 0.508080026334754, 0.7352487299089464, 0.6644910619872955, 0.4708638127418041, 0.99, 0.29527796873966977, 0.5183291839378847, 0.10514034303522338, 0.6916272028126965, 0.05436641561176722, 0.99, 0.20515845577533393, 0.01, 0.19685946438224025, 0.99, 0.8311365004679592, 0.7721383111869322, 0.6697085123278791, 0.9133087864461755, 0.2960017802005521, 0.38056491601929393, 0.9285141804079896, 0.4414803617124978, 0.99, 0.01, 0.7776018084515925, 0.01, 0.15909019243321132, 0.4982044619434538, 0.17415779687630442, 0.3165490784992572, 0.01, 0.22314061819447112]
[0.25134522130022363, 0.6201028178844215, 0.5994020860940426, 0.6038108372543831, 0.9564803659516964, 0.99, 0.01, 0.99, 0.8029590891517732, 0.045760337769491136, 0.45921637229737133, 0.2530742856286355, 0.2657113210120562, 0.15229993401344047, 0.8489947881901114, 0.28351224352671295, 0.2204381116385908, 0.6616953620102611, 0.4297864788049769, 0.49951324977296246, 0.2524306319767524, 0.01, 0.42269909740405054, 0.5286948635058836, 0.19973335613933982, 0.37686747045755886, 0.7245574319530542, 0.07960746811229732, 0.23254897621746093, 0.31686265889162557, 0.38927911286719125, 0.39306805746742507, 0.6080234974211939, 0.01, 0.29319371889856344, 0.26225845802004655, 0.3096101438774571, 0.6483305796503471, 0.99, 0.23277577574075964, 0.8588947971837825, 0.3993326706250795, 0.19372071977391148, 0.1183084053839134, 0.2595936544273161, 0.4965876713983287, 0.14211748874073254, 0.9680615277857736, 0.8379767469093906, 0.5629782538042227, 0.7941371536530633, 0.4511891964240338, 0.07124388616947597, 0.5381603334665699, 0.01, 0.434892498095521, 0.3601916757353498, 0.774685001978769, 0.01, 0.508080026334754, 0.7352487299089464, 0.6644910619872955, 0.4708638127418041, 0.99, 0.29527796873966977, 0.5183291839378847, 0.10514034303522338, 0.6916272028126965, 0.05436641561176722, 0.99, 0.20515845577533393, 0.01, 0.19685946438224025, 0.99, 0.8311365004679592, 0.7721383111869322, 0.6697085123278791, 0.9133087864461755, 0.2960017802005521, 0.38056491601929393, 0.9285141804079896, 0.4414803617124978, 0.99, 0.01, 0.7776018084515925, 0.01, 0.15909019243321132, 0.4982044619434538, 0.17415779687630442, 0.3165490784992572, 0.01, 0.22314061819447112]
Training loss = 0.03451755185921987
step = 0, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.57125
Training loss = 0.035138258139292396
step = 1, Training Accuracy: 0.4633333333333333
Training loss = 0.03522152145703634
step = 2, Training Accuracy: 0.42
Training loss = 0.03479918579260508
step = 3, Training Accuracy: 0.44666666666666666
Training loss = 0.03564318994681041
step = 4, Training Accuracy: 0.41333333333333333
Training loss = 0.034646912813186645
step = 5, Training Accuracy: 0.42333333333333334
Validation Accuracy: 0.5625
Training loss = 0.0338281911611557
step = 6, Training Accuracy: 0.46
Training loss = 0.03390795330206553
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.033605328996976214
step = 8, Training Accuracy: 0.43
Training loss = 0.03458132922649384
step = 9, Training Accuracy: 0.48
Training loss = 0.034833261966705324
step = 10, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.555
Training loss = 0.03539552410443624
step = 11, Training Accuracy: 0.44
Training loss = 0.035070547064145405
step = 12, Training Accuracy: 0.39666666666666667
Training loss = 0.03390527367591858
step = 13, Training Accuracy: 0.51
Training loss = 0.03460524221261342
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.5475
params:  [0.6247878748176268, 0.722429680766525, 0.8712269169005291, 0.99, 0.99, 0.19693095038899833, 0.5906266453224631, 0.3889489498559739, 0.8280947648096685, 0.01, 0.36455409008045286, 0.3044644813212952, 0.5107727293965691, 0.4570167470466344, 0.5888365351716736, 0.05373224320499265, 0.18807650915477672, 0.6251890890154271, 0.6003126213388613, 0.07179860396747662, 0.19361165740236636, 0.13088458896492414, 0.99, 0.9391847532664286, 0.3294704534816188, 0.01, 0.7195230017399021, 0.5068743415483645, 0.4657413561858645, 0.6415213452273968, 0.4407191345141622, 0.6522129581531195, 0.01, 0.26962945377064484, 0.48801860833224414, 0.9411797583974442, 0.14292303421106514, 0.8784277627497715, 0.99, 0.8292775822929979, 0.49317737775268167, 0.6910295097722701, 0.139415165721694, 0.7137894938409892, 0.44192043279658844, 0.6200563565413226, 0.5339408783799752, 0.0201733537369172, 0.9280763524890658, 0.7467856859245358, 0.6312552688362293, 0.01, 0.01, 0.021618459146757363, 0.6618635917571638, 0.4165653638821883, 0.6727204765131739, 0.6644188111074426, 0.17609138628202747, 0.25004835929489616, 0.6506814509385478, 0.99, 0.99, 0.34371267790716437, 0.01, 0.34505702989269205, 0.01, 0.23453089918678185, 0.01, 0.9734628535396801, 0.01, 0.4807569858474863, 0.8542740853866909, 0.9260405539423646, 0.6727808054395663, 0.3853917026923602, 0.99, 0.836918802152933, 0.47581131283461653, 0.20682279874847667, 0.7254457641612264, 0.99, 0.7330611843020131, 0.06112036009785418, 0.24267353647540513, 0.01, 0.4794330818662945, 0.4182267674772189, 0.01, 0.5805387128509187, 0.7408489769681603, 0.10385031457724161]
[0.6247878748176268, 0.722429680766525, 0.8712269169005291, 0.99, 0.99, 0.19693095038899833, 0.5906266453224631, 0.3889489498559739, 0.8280947648096685, 0.01, 0.36455409008045286, 0.3044644813212952, 0.5107727293965691, 0.4570167470466344, 0.5888365351716736, 0.05373224320499265, 0.18807650915477672, 0.6251890890154271, 0.6003126213388613, 0.07179860396747662, 0.19361165740236636, 0.13088458896492414, 0.99, 0.9391847532664286, 0.3294704534816188, 0.01, 0.7195230017399021, 0.5068743415483645, 0.4657413561858645, 0.6415213452273968, 0.4407191345141622, 0.6522129581531195, 0.01, 0.26962945377064484, 0.48801860833224414, 0.9411797583974442, 0.14292303421106514, 0.8784277627497715, 0.99, 0.8292775822929979, 0.49317737775268167, 0.6910295097722701, 0.139415165721694, 0.7137894938409892, 0.44192043279658844, 0.6200563565413226, 0.5339408783799752, 0.0201733537369172, 0.9280763524890658, 0.7467856859245358, 0.6312552688362293, 0.01, 0.01, 0.021618459146757363, 0.6618635917571638, 0.4165653638821883, 0.6727204765131739, 0.6644188111074426, 0.17609138628202747, 0.25004835929489616, 0.6506814509385478, 0.99, 0.99, 0.34371267790716437, 0.01, 0.34505702989269205, 0.01, 0.23453089918678185, 0.01, 0.9734628535396801, 0.01, 0.4807569858474863, 0.8542740853866909, 0.9260405539423646, 0.6727808054395663, 0.3853917026923602, 0.99, 0.836918802152933, 0.47581131283461653, 0.20682279874847667, 0.7254457641612264, 0.99, 0.7330611843020131, 0.06112036009785418, 0.24267353647540513, 0.01, 0.4794330818662945, 0.4182267674772189, 0.01, 0.5805387128509187, 0.7408489769681603, 0.10385031457724161]
Training loss = 0.0377105712890625
step = 0, Training Accuracy: 0.39666666666666667
Validation Accuracy: 0.53125
Training loss = 0.03668963491916657
step = 1, Training Accuracy: 0.3433333333333333
Training loss = 0.03572513182957967
step = 2, Training Accuracy: 0.3566666666666667
Training loss = 0.03580510934193929
step = 3, Training Accuracy: 0.4033333333333333
Training loss = 0.0353680682182312
step = 4, Training Accuracy: 0.4033333333333333
Training loss = 0.03585437536239624
step = 5, Training Accuracy: 0.35333333333333333
Validation Accuracy: 0.50125
Training loss = 0.03538448214530945
step = 6, Training Accuracy: 0.43333333333333335
Training loss = 0.03681769688924154
step = 7, Training Accuracy: 0.36
Training loss = 0.03591465373833974
step = 8, Training Accuracy: 0.36666666666666664
Training loss = 0.03583960254987081
step = 9, Training Accuracy: 0.33
Training loss = 0.03611000140508016
step = 10, Training Accuracy: 0.37
Validation Accuracy: 0.515
Training loss = 0.03668028195699056
step = 11, Training Accuracy: 0.36
Training loss = 0.036496790250142415
step = 12, Training Accuracy: 0.38
Training loss = 0.036291470527648924
step = 13, Training Accuracy: 0.36666666666666664
Training loss = 0.035725318988164265
step = 14, Training Accuracy: 0.4033333333333333
Validation Accuracy: 0.51125
params:  [0.294952090425461, 0.4257904363786098, 0.99, 0.8498873052998985, 0.8310576527676568, 0.5876571678976383, 0.3513929098944468, 0.5549917728773038, 0.8948923594511125, 0.20585683471325988, 0.7077531848702988, 0.11380612809897087, 0.08452049449060055, 0.13592803258178415, 0.7550070287485446, 0.22598581926837769, 0.43670354504038145, 0.570141827365219, 0.8601581656316171, 0.3667684483061807, 0.5366771295191588, 0.5238411777054843, 0.08492767965241615, 0.4750250079271701, 0.49073295735895617, 0.01, 0.6255376709433726, 0.01, 0.99, 0.49919841815655164, 0.3281389598227524, 0.7917647888449915, 0.44825458299828846, 0.18715790266770088, 0.1976273655730278, 0.8736760132715179, 0.5083710521105603, 0.99, 0.99, 0.21313427113450062, 0.3934299897953207, 0.2513852425642339, 0.18335166382050738, 0.02243409948088748, 0.7419626524850896, 0.29925226198752025, 0.35883423555382465, 0.48582310728781386, 0.99, 0.99, 0.9792390940989326, 0.9768041199417477, 0.4250303924762246, 0.739459692490709, 0.01, 0.15208938432729258, 0.01, 0.9070387225211555, 0.01, 0.09026022405016335, 0.4639684312831543, 0.4893785707603412, 0.5508875511869187, 0.5878079774985497, 0.07452965597972072, 0.10030834383649093, 0.01, 0.644356654434648, 0.01, 0.99, 0.27999660101967283, 0.22511188671393334, 0.13842072043687173, 0.7936215982076952, 0.9040281518640629, 0.7190744586794173, 0.08662543636800019, 0.8529854071014303, 0.01, 0.20433318413236784, 0.99, 0.9130123585030794, 0.7343603910746164, 0.01, 0.6644383595831036, 0.3876651069371596, 0.47731860801798764, 0.3235299090508605, 0.01, 0.3143491784880389, 0.12053188977262413, 0.0917674201819636]
[0.294952090425461, 0.4257904363786098, 0.99, 0.8498873052998985, 0.8310576527676568, 0.5876571678976383, 0.3513929098944468, 0.5549917728773038, 0.8948923594511125, 0.20585683471325988, 0.7077531848702988, 0.11380612809897087, 0.08452049449060055, 0.13592803258178415, 0.7550070287485446, 0.22598581926837769, 0.43670354504038145, 0.570141827365219, 0.8601581656316171, 0.3667684483061807, 0.5366771295191588, 0.5238411777054843, 0.08492767965241615, 0.4750250079271701, 0.49073295735895617, 0.01, 0.6255376709433726, 0.01, 0.99, 0.49919841815655164, 0.3281389598227524, 0.7917647888449915, 0.44825458299828846, 0.18715790266770088, 0.1976273655730278, 0.8736760132715179, 0.5083710521105603, 0.99, 0.99, 0.21313427113450062, 0.3934299897953207, 0.2513852425642339, 0.18335166382050738, 0.02243409948088748, 0.7419626524850896, 0.29925226198752025, 0.35883423555382465, 0.48582310728781386, 0.99, 0.99, 0.9792390940989326, 0.9768041199417477, 0.4250303924762246, 0.739459692490709, 0.01, 0.15208938432729258, 0.01, 0.9070387225211555, 0.01, 0.09026022405016335, 0.4639684312831543, 0.4893785707603412, 0.5508875511869187, 0.5878079774985497, 0.07452965597972072, 0.10030834383649093, 0.01, 0.644356654434648, 0.01, 0.99, 0.27999660101967283, 0.22511188671393334, 0.13842072043687173, 0.7936215982076952, 0.9040281518640629, 0.7190744586794173, 0.08662543636800019, 0.8529854071014303, 0.01, 0.20433318413236784, 0.99, 0.9130123585030794, 0.7343603910746164, 0.01, 0.6644383595831036, 0.3876651069371596, 0.47731860801798764, 0.3235299090508605, 0.01, 0.3143491784880389, 0.12053188977262413, 0.0917674201819636]
Training loss = 0.03368050754070282
step = 0, Training Accuracy: 0.41333333333333333
Validation Accuracy: 0.54
Training loss = 0.03470226506392161
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.0345994093020757
step = 2, Training Accuracy: 0.45666666666666667
Training loss = 0.03494342267513275
step = 3, Training Accuracy: 0.46
Training loss = 0.033850020964940386
step = 4, Training Accuracy: 0.4633333333333333
Training loss = 0.033466844757397966
step = 5, Training Accuracy: 0.48
Validation Accuracy: 0.57
Training loss = 0.03335954705874125
step = 6, Training Accuracy: 0.5033333333333333
Training loss = 0.03347554703553517
step = 7, Training Accuracy: 0.46
Training loss = 0.03391674915949504
step = 8, Training Accuracy: 0.49
Training loss = 0.03321463425954183
step = 9, Training Accuracy: 0.44666666666666666
Training loss = 0.03485762000083923
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.56875
Training loss = 0.03175273060798645
step = 11, Training Accuracy: 0.5033333333333333
Training loss = 0.03336862087249756
step = 12, Training Accuracy: 0.49666666666666665
Training loss = 0.03454316020011902
step = 13, Training Accuracy: 0.4266666666666667
Training loss = 0.032133482297261554
step = 14, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.57125
params:  [0.4758759103716327, 0.7376681438253608, 0.6572726235235824, 0.99, 0.7792874595884435, 0.7489180442500557, 0.28059764984845226, 0.8327102141534897, 0.9404968487898131, 0.13948921228917938, 0.22680446053806103, 0.3025637722732261, 0.2551942690474968, 0.08994476292366894, 0.99, 0.0846884277779184, 0.27609217705652866, 0.8432968246266612, 0.8972256921670241, 0.19922023214406448, 0.01, 0.1896709619324635, 0.4752703922725906, 0.23534584182776108, 0.5021735308119265, 0.4172626997698686, 0.2971974458606475, 0.01, 0.01, 0.6905823819282841, 0.35910711902497894, 0.99, 0.5746130259084998, 0.12909825556694154, 0.4323721272845006, 0.8456054015446456, 0.483270978424164, 0.7496297955285742, 0.99, 0.411052302891099, 0.726894313455205, 0.40475865262484906, 0.17695588617228628, 0.4014377061530488, 0.6050298827120166, 0.7462128533907455, 0.5067910319174179, 0.6765789876989908, 0.99, 0.5381401428087895, 0.39299276134757644, 0.7446507238112308, 0.01, 0.7212569535419796, 0.3088926322108658, 0.11114322714941552, 0.21809601231209433, 0.4401142225145081, 0.01, 0.09702506579658338, 0.6121030725094316, 0.7159259721763862, 0.6593145446566381, 0.20587395161960986, 0.1307170212402506, 0.01, 0.33171923863170016, 0.2458361820432923, 0.01, 0.938464478985156, 0.5683028441659943, 0.99, 0.608864487501769, 0.8640016440315554, 0.99, 0.5653430360945546, 0.40992366518083945, 0.7127339472397275, 0.32470055736406717, 0.35305433978851225, 0.99, 0.8407764216218641, 0.4898580764078799, 0.14040276893986905, 0.3873538993997449, 0.34968341284480314, 0.3803552139809872, 0.2519926466353164, 0.3188942077321544, 0.28512439163609893, 0.21743722155185918, 0.7401691454669548]
[0.4758759103716327, 0.7376681438253608, 0.6572726235235824, 0.99, 0.7792874595884435, 0.7489180442500557, 0.28059764984845226, 0.8327102141534897, 0.9404968487898131, 0.13948921228917938, 0.22680446053806103, 0.3025637722732261, 0.2551942690474968, 0.08994476292366894, 0.99, 0.0846884277779184, 0.27609217705652866, 0.8432968246266612, 0.8972256921670241, 0.19922023214406448, 0.01, 0.1896709619324635, 0.4752703922725906, 0.23534584182776108, 0.5021735308119265, 0.4172626997698686, 0.2971974458606475, 0.01, 0.01, 0.6905823819282841, 0.35910711902497894, 0.99, 0.5746130259084998, 0.12909825556694154, 0.4323721272845006, 0.8456054015446456, 0.483270978424164, 0.7496297955285742, 0.99, 0.411052302891099, 0.726894313455205, 0.40475865262484906, 0.17695588617228628, 0.4014377061530488, 0.6050298827120166, 0.7462128533907455, 0.5067910319174179, 0.6765789876989908, 0.99, 0.5381401428087895, 0.39299276134757644, 0.7446507238112308, 0.01, 0.7212569535419796, 0.3088926322108658, 0.11114322714941552, 0.21809601231209433, 0.4401142225145081, 0.01, 0.09702506579658338, 0.6121030725094316, 0.7159259721763862, 0.6593145446566381, 0.20587395161960986, 0.1307170212402506, 0.01, 0.33171923863170016, 0.2458361820432923, 0.01, 0.938464478985156, 0.5683028441659943, 0.99, 0.608864487501769, 0.8640016440315554, 0.99, 0.5653430360945546, 0.40992366518083945, 0.7127339472397275, 0.32470055736406717, 0.35305433978851225, 0.99, 0.8407764216218641, 0.4898580764078799, 0.14040276893986905, 0.3873538993997449, 0.34968341284480314, 0.3803552139809872, 0.2519926466353164, 0.3188942077321544, 0.28512439163609893, 0.21743722155185918, 0.7401691454669548]
Training loss = 0.033730534513791405
step = 0, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.58
Training loss = 0.03359354197978973
step = 1, Training Accuracy: 0.47
Training loss = 0.03369226972262065
step = 2, Training Accuracy: 0.46
Training loss = 0.03383430997530619
step = 3, Training Accuracy: 0.4633333333333333
Training loss = 0.033467098871866864
step = 4, Training Accuracy: 0.5066666666666667
Training loss = 0.03426222622394562
step = 5, Training Accuracy: 0.41
Validation Accuracy: 0.57125
Training loss = 0.03307922641436259
step = 6, Training Accuracy: 0.47
Training loss = 0.033325170079867045
step = 7, Training Accuracy: 0.4666666666666667
Training loss = 0.03341443598270416
step = 8, Training Accuracy: 0.45666666666666667
Training loss = 0.03336293876171112
step = 9, Training Accuracy: 0.4666666666666667
Training loss = 0.03455527504285177
step = 10, Training Accuracy: 0.47
Validation Accuracy: 0.5925
Training loss = 0.033672038118044534
step = 11, Training Accuracy: 0.46
Training loss = 0.03148776928583781
step = 12, Training Accuracy: 0.5333333333333333
Training loss = 0.0331744247674942
step = 13, Training Accuracy: 0.4633333333333333
Training loss = 0.033370131452878316
step = 14, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.5875
params:  [0.3434676249437483, 0.8933165225731468, 0.8207507646041343, 0.7720392600236559, 0.8393712131927503, 0.5311630729187078, 0.38843709573840973, 0.4416780201070108, 0.6593586639055591, 0.032376603602226016, 0.4926647330142703, 0.22677152045410814, 0.6259082491717223, 0.0783609941903688, 0.99, 0.14255369030968326, 0.11240213948419171, 0.44196216908851044, 0.99, 0.4863835057022385, 0.08322860126062906, 0.5707930682362341, 0.928907385817122, 0.936890372824778, 0.31103706184154145, 0.01, 0.5947039447356282, 0.3638045496194876, 0.5076565056957644, 0.21432134275839365, 0.04045825395002278, 0.888549737208918, 0.3584074321499708, 0.6836368127867821, 0.8118062765426937, 0.7985786924470224, 0.26499958124322637, 0.8889250356402988, 0.9750938094634595, 0.6340070931414016, 0.5262217494452933, 0.09150694582152252, 0.01, 0.21865974589467063, 0.7668209469958291, 0.8800683331198556, 0.7289738602432929, 0.7172165864456193, 0.8315335386016743, 0.99, 0.7391584122194268, 0.99, 0.10791470036891326, 0.757333565837079, 0.11916141622021806, 0.32228200103667426, 0.01, 0.7586739294247855, 0.2583440126282074, 0.21800853538575798, 0.6860778879271812, 0.7920972242557812, 0.4484717359914657, 0.40088336324467094, 0.6250950053518615, 0.3731372669270847, 0.09375656608591185, 0.3501665634831065, 0.01, 0.99, 0.16785964076834844, 0.5446139736950735, 0.6003642588173266, 0.99, 0.052554348483868085, 0.30157703080003356, 0.6149755599410438, 0.17364262851835277, 0.17517097922492694, 0.20552907397186554, 0.8246646868479061, 0.699369165404948, 0.6749318300330934, 0.22806163797233545, 0.8467919130414234, 0.01, 0.26309767430260395, 0.28412722693672243, 0.04356855892909137, 0.01, 0.01, 0.21866719181305025]
[0.3434676249437483, 0.8933165225731468, 0.8207507646041343, 0.7720392600236559, 0.8393712131927503, 0.5311630729187078, 0.38843709573840973, 0.4416780201070108, 0.6593586639055591, 0.032376603602226016, 0.4926647330142703, 0.22677152045410814, 0.6259082491717223, 0.0783609941903688, 0.99, 0.14255369030968326, 0.11240213948419171, 0.44196216908851044, 0.99, 0.4863835057022385, 0.08322860126062906, 0.5707930682362341, 0.928907385817122, 0.936890372824778, 0.31103706184154145, 0.01, 0.5947039447356282, 0.3638045496194876, 0.5076565056957644, 0.21432134275839365, 0.04045825395002278, 0.888549737208918, 0.3584074321499708, 0.6836368127867821, 0.8118062765426937, 0.7985786924470224, 0.26499958124322637, 0.8889250356402988, 0.9750938094634595, 0.6340070931414016, 0.5262217494452933, 0.09150694582152252, 0.01, 0.21865974589467063, 0.7668209469958291, 0.8800683331198556, 0.7289738602432929, 0.7172165864456193, 0.8315335386016743, 0.99, 0.7391584122194268, 0.99, 0.10791470036891326, 0.757333565837079, 0.11916141622021806, 0.32228200103667426, 0.01, 0.7586739294247855, 0.2583440126282074, 0.21800853538575798, 0.6860778879271812, 0.7920972242557812, 0.4484717359914657, 0.40088336324467094, 0.6250950053518615, 0.3731372669270847, 0.09375656608591185, 0.3501665634831065, 0.01, 0.99, 0.16785964076834844, 0.5446139736950735, 0.6003642588173266, 0.99, 0.052554348483868085, 0.30157703080003356, 0.6149755599410438, 0.17364262851835277, 0.17517097922492694, 0.20552907397186554, 0.8246646868479061, 0.699369165404948, 0.6749318300330934, 0.22806163797233545, 0.8467919130414234, 0.01, 0.26309767430260395, 0.28412722693672243, 0.04356855892909137, 0.01, 0.01, 0.21866719181305025]
Training loss = 0.03243069132169088
step = 0, Training Accuracy: 0.5533333333333333
Validation Accuracy: 0.575
Training loss = 0.03307327429453532
step = 1, Training Accuracy: 0.49666666666666665
Training loss = 0.033411553899447125
step = 2, Training Accuracy: 0.49666666666666665
Training loss = 0.03433658361434937
step = 3, Training Accuracy: 0.5033333333333333
Training loss = 0.03526996076107025
step = 4, Training Accuracy: 0.44
Training loss = 0.0319100699822108
step = 5, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.58375
Training loss = 0.03379869202772776
step = 6, Training Accuracy: 0.47
Training loss = 0.032739919424057004
step = 7, Training Accuracy: 0.5
Training loss = 0.0324721215168635
step = 8, Training Accuracy: 0.52
Training loss = 0.033798816402753194
step = 9, Training Accuracy: 0.4866666666666667
Training loss = 0.03306628008683522
step = 10, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.5875
Training loss = 0.03330227275689443
step = 11, Training Accuracy: 0.5266666666666666
Training loss = 0.033165252208709715
step = 12, Training Accuracy: 0.5233333333333333
Training loss = 0.033444098631540936
step = 13, Training Accuracy: 0.48
Training loss = 0.03277864555517832
step = 14, Training Accuracy: 0.52
Validation Accuracy: 0.6025
params:  [0.22949439059667784, 0.576211791032063, 0.99, 0.99, 0.5816873478468345, 0.6744592519951376, 0.13457419666293635, 0.9334066810786878, 0.99, 0.01, 0.9259068520309007, 0.38890723512588565, 0.5738362546706011, 0.43069089711705777, 0.8931569788548402, 0.28149138259150464, 0.1040202646438209, 0.6717762191983416, 0.99, 0.4780911292790354, 0.0918234016673046, 0.27328083268184067, 0.7453392519055669, 0.8325183845907085, 0.19598847808864842, 0.01, 0.2755094697779966, 0.01, 0.19670987007460278, 0.43999950215735684, 0.2676078482278239, 0.5826331377933763, 0.15865397369838355, 0.01, 0.2058265539059172, 0.8958258012990832, 0.2226164568929852, 0.99, 0.99, 0.1345307146499616, 0.9148444297181424, 0.5996580107850529, 0.10151327325578408, 0.08390500432522224, 0.3542007719310659, 0.99, 0.35328588347374273, 0.8011641555866085, 0.9231380180100722, 0.7723512920874513, 0.940728610305225, 0.37230692438297547, 0.2779342440536165, 0.2475185214348154, 0.01, 0.3517230634673727, 0.10906945810263272, 0.3712062059469257, 0.01, 0.6973988894640659, 0.6469708286253384, 0.5885558839991015, 0.7923861346541953, 0.4893437963179017, 0.7529669527712108, 0.23553205957982992, 0.42021792739763664, 0.40267341525143185, 0.01, 0.99, 0.3074362723238643, 0.12986301996030936, 0.15572648901383593, 0.99, 0.8738462172430281, 0.8576229529695512, 0.4339495600045004, 0.7096240984879743, 0.4793354562721847, 0.10338969341130091, 0.7385051498460865, 0.18620199717450076, 0.99, 0.01, 0.5546273731446438, 0.11248203295159419, 0.5028018465110279, 0.2086171051109758, 0.01, 0.4215105137947851, 0.26578797832356105, 0.14231329131167347]
[0.22949439059667784, 0.576211791032063, 0.99, 0.99, 0.5816873478468345, 0.6744592519951376, 0.13457419666293635, 0.9334066810786878, 0.99, 0.01, 0.9259068520309007, 0.38890723512588565, 0.5738362546706011, 0.43069089711705777, 0.8931569788548402, 0.28149138259150464, 0.1040202646438209, 0.6717762191983416, 0.99, 0.4780911292790354, 0.0918234016673046, 0.27328083268184067, 0.7453392519055669, 0.8325183845907085, 0.19598847808864842, 0.01, 0.2755094697779966, 0.01, 0.19670987007460278, 0.43999950215735684, 0.2676078482278239, 0.5826331377933763, 0.15865397369838355, 0.01, 0.2058265539059172, 0.8958258012990832, 0.2226164568929852, 0.99, 0.99, 0.1345307146499616, 0.9148444297181424, 0.5996580107850529, 0.10151327325578408, 0.08390500432522224, 0.3542007719310659, 0.99, 0.35328588347374273, 0.8011641555866085, 0.9231380180100722, 0.7723512920874513, 0.940728610305225, 0.37230692438297547, 0.2779342440536165, 0.2475185214348154, 0.01, 0.3517230634673727, 0.10906945810263272, 0.3712062059469257, 0.01, 0.6973988894640659, 0.6469708286253384, 0.5885558839991015, 0.7923861346541953, 0.4893437963179017, 0.7529669527712108, 0.23553205957982992, 0.42021792739763664, 0.40267341525143185, 0.01, 0.99, 0.3074362723238643, 0.12986301996030936, 0.15572648901383593, 0.99, 0.8738462172430281, 0.8576229529695512, 0.4339495600045004, 0.7096240984879743, 0.4793354562721847, 0.10338969341130091, 0.7385051498460865, 0.18620199717450076, 0.99, 0.01, 0.5546273731446438, 0.11248203295159419, 0.5028018465110279, 0.2086171051109758, 0.01, 0.4215105137947851, 0.26578797832356105, 0.14231329131167347]
Training loss = 0.03424143036206563
step = 0, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.59
Training loss = 0.03332920432090759
step = 1, Training Accuracy: 0.48333333333333334
Training loss = 0.034896911780039466
step = 2, Training Accuracy: 0.44666666666666666
Training loss = 0.033776779572168986
step = 3, Training Accuracy: 0.44666666666666666
Training loss = 0.03335295339425405
step = 4, Training Accuracy: 0.44
Training loss = 0.03436889350414276
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.59625
Training loss = 0.0339173146088918
step = 6, Training Accuracy: 0.5066666666666667
Training loss = 0.03250035206476847
step = 7, Training Accuracy: 0.5
Training loss = 0.033053802053133644
step = 8, Training Accuracy: 0.5033333333333333
Training loss = 0.03261166135470073
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.0332904189825058
step = 10, Training Accuracy: 0.46
Validation Accuracy: 0.57
Training loss = 0.03366623302300771
step = 11, Training Accuracy: 0.49
Training loss = 0.034044946829477944
step = 12, Training Accuracy: 0.48
Training loss = 0.03255420962969462
step = 13, Training Accuracy: 0.49666666666666665
Training loss = 0.03430982788403829
step = 14, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.59625
params:  [0.19728433627821984, 0.8386721895588171, 0.700087594400572, 0.7551192055446385, 0.45009398206179746, 0.31240120267875865, 0.4190716216857884, 0.3436950431954115, 0.5838904749177619, 0.01, 0.7765973445956943, 0.29681604125030564, 0.07805320393612611, 0.07017400618453992, 0.3269695348972916, 0.38039905056793766, 0.5363530258466743, 0.23466552895663023, 0.99, 0.33762308481014713, 0.01, 0.7521836108640367, 0.09097058644077999, 0.3926147933154968, 0.7866858409271563, 0.42157373444519863, 0.01, 0.21743120357058376, 0.5092434802654177, 0.6419415359872432, 0.6978717244722135, 0.4062049526267364, 0.2731365015020765, 0.17174861885913278, 0.10106593322054819, 0.7404782176241915, 0.24650499509735557, 0.99, 0.4571308303698953, 0.5506666662064799, 0.37203594244836224, 0.5011273714804925, 0.44875390306277596, 0.6736365462285432, 0.5939935843781258, 0.9600324121016879, 0.33231602589822, 0.6129447286415364, 0.99, 0.99, 0.99, 0.6606737903037445, 0.8371901725393716, 0.8034786748360042, 0.37495128678995016, 0.01, 0.2717308570115065, 0.5179313290866885, 0.14689474433350422, 0.43014178248562907, 0.37646234129592515, 0.9683327064268588, 0.7097116821305924, 0.48847422998295803, 0.46148596753719195, 0.6781823460545626, 0.13045312967398648, 0.13460758016504132, 0.20626667763848383, 0.44876573302990735, 0.38824203409470004, 0.31422732439373335, 0.2831242505314221, 0.637823646031114, 0.7039292120199879, 0.5101504944441595, 0.7804306838386463, 0.8212377487689377, 0.05766785577413662, 0.6119915370930865, 0.99, 0.9112678729576387, 0.7783643680090379, 0.38979121725283106, 0.3658632535093221, 0.3805162913355038, 0.39283614364494013, 0.3232457179308903, 0.01, 0.6827132515976011, 0.01, 0.23982022610750872]
[0.19728433627821984, 0.8386721895588171, 0.700087594400572, 0.7551192055446385, 0.45009398206179746, 0.31240120267875865, 0.4190716216857884, 0.3436950431954115, 0.5838904749177619, 0.01, 0.7765973445956943, 0.29681604125030564, 0.07805320393612611, 0.07017400618453992, 0.3269695348972916, 0.38039905056793766, 0.5363530258466743, 0.23466552895663023, 0.99, 0.33762308481014713, 0.01, 0.7521836108640367, 0.09097058644077999, 0.3926147933154968, 0.7866858409271563, 0.42157373444519863, 0.01, 0.21743120357058376, 0.5092434802654177, 0.6419415359872432, 0.6978717244722135, 0.4062049526267364, 0.2731365015020765, 0.17174861885913278, 0.10106593322054819, 0.7404782176241915, 0.24650499509735557, 0.99, 0.4571308303698953, 0.5506666662064799, 0.37203594244836224, 0.5011273714804925, 0.44875390306277596, 0.6736365462285432, 0.5939935843781258, 0.9600324121016879, 0.33231602589822, 0.6129447286415364, 0.99, 0.99, 0.99, 0.6606737903037445, 0.8371901725393716, 0.8034786748360042, 0.37495128678995016, 0.01, 0.2717308570115065, 0.5179313290866885, 0.14689474433350422, 0.43014178248562907, 0.37646234129592515, 0.9683327064268588, 0.7097116821305924, 0.48847422998295803, 0.46148596753719195, 0.6781823460545626, 0.13045312967398648, 0.13460758016504132, 0.20626667763848383, 0.44876573302990735, 0.38824203409470004, 0.31422732439373335, 0.2831242505314221, 0.637823646031114, 0.7039292120199879, 0.5101504944441595, 0.7804306838386463, 0.8212377487689377, 0.05766785577413662, 0.6119915370930865, 0.99, 0.9112678729576387, 0.7783643680090379, 0.38979121725283106, 0.3658632535093221, 0.3805162913355038, 0.39283614364494013, 0.3232457179308903, 0.01, 0.6827132515976011, 0.01, 0.23982022610750872]
Training loss = 0.032168603738149004
step = 0, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.60125
Training loss = 0.033629898031552634
step = 1, Training Accuracy: 0.49333333333333335
Training loss = 0.033954889575640364
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.03352506021658579
step = 3, Training Accuracy: 0.5
Training loss = 0.032784064412117
step = 4, Training Accuracy: 0.5
Training loss = 0.03254857381184896
step = 5, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.5875
Training loss = 0.032626543243726096
step = 6, Training Accuracy: 0.49666666666666665
Training loss = 0.034913262923558556
step = 7, Training Accuracy: 0.43666666666666665
Training loss = 0.0337655250231425
step = 8, Training Accuracy: 0.4666666666666667
Training loss = 0.032727443377176924
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.0335180672009786
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.60125
Training loss = 0.03363863329092662
step = 11, Training Accuracy: 0.46
Training loss = 0.032588910460472104
step = 12, Training Accuracy: 0.5066666666666667
Training loss = 0.033327789306640626
step = 13, Training Accuracy: 0.45666666666666667
Training loss = 0.03204144815603892
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.59625
params:  [0.32300533531051173, 0.2101048311327131, 0.9240444312640503, 0.731547570250342, 0.912257051958047, 0.660829062110817, 0.01, 0.33592146715180893, 0.4419136785119971, 0.03998642834341742, 0.7157194596011549, 0.12542627182473093, 0.042299051971277674, 0.11499958417720704, 0.7589114976863091, 0.4972618584757419, 0.01, 0.42109216250740494, 0.4954054942871851, 0.3098645465939873, 0.18117955043644993, 0.015799627122506654, 0.294439802380522, 0.19986589614551004, 0.01, 0.07430078630758125, 0.1933366465407809, 0.04011867787628062, 0.45743190743944506, 0.103359321664865, 0.8846798190722863, 0.7988167513074959, 0.018363722186201692, 0.01, 0.8781747574182246, 0.9019229124518644, 0.3699316248064207, 0.4439825751222776, 0.6793955268499479, 0.5260830779764486, 0.3730408920791263, 0.673324020293232, 0.10663782062392355, 0.01, 0.4698568817607164, 0.99, 0.8053766987451008, 0.5200139073324073, 0.99, 0.7338954169432256, 0.5316125019446006, 0.49394962724525737, 0.5005657754240674, 0.3559503019342432, 0.765076330508812, 0.6579629561826921, 0.40024788619896856, 0.7463676605900634, 0.01, 0.43999274455517645, 0.5288522823365105, 0.9283703502742855, 0.7030618669249128, 0.5227599754536498, 0.37563758067454617, 0.216005117330834, 0.2682990055916174, 0.15549040207152376, 0.01, 0.99, 0.99, 0.6845095458840953, 0.34504168966830356, 0.7819318978691119, 0.99, 0.5224762231306477, 0.08018594167162185, 0.8684619736599809, 0.14101142606092718, 0.5887510029644831, 0.6683095884637679, 0.7382056794741814, 0.6499816415688465, 0.5249179503531632, 0.7284489782040533, 0.01, 0.09298972306290176, 0.8152131875246076, 0.23608879660661247, 0.5032972494306865, 0.1475457535566011, 0.32693220251133076]
[0.32300533531051173, 0.2101048311327131, 0.9240444312640503, 0.731547570250342, 0.912257051958047, 0.660829062110817, 0.01, 0.33592146715180893, 0.4419136785119971, 0.03998642834341742, 0.7157194596011549, 0.12542627182473093, 0.042299051971277674, 0.11499958417720704, 0.7589114976863091, 0.4972618584757419, 0.01, 0.42109216250740494, 0.4954054942871851, 0.3098645465939873, 0.18117955043644993, 0.015799627122506654, 0.294439802380522, 0.19986589614551004, 0.01, 0.07430078630758125, 0.1933366465407809, 0.04011867787628062, 0.45743190743944506, 0.103359321664865, 0.8846798190722863, 0.7988167513074959, 0.018363722186201692, 0.01, 0.8781747574182246, 0.9019229124518644, 0.3699316248064207, 0.4439825751222776, 0.6793955268499479, 0.5260830779764486, 0.3730408920791263, 0.673324020293232, 0.10663782062392355, 0.01, 0.4698568817607164, 0.99, 0.8053766987451008, 0.5200139073324073, 0.99, 0.7338954169432256, 0.5316125019446006, 0.49394962724525737, 0.5005657754240674, 0.3559503019342432, 0.765076330508812, 0.6579629561826921, 0.40024788619896856, 0.7463676605900634, 0.01, 0.43999274455517645, 0.5288522823365105, 0.9283703502742855, 0.7030618669249128, 0.5227599754536498, 0.37563758067454617, 0.216005117330834, 0.2682990055916174, 0.15549040207152376, 0.01, 0.99, 0.99, 0.6845095458840953, 0.34504168966830356, 0.7819318978691119, 0.99, 0.5224762231306477, 0.08018594167162185, 0.8684619736599809, 0.14101142606092718, 0.5887510029644831, 0.6683095884637679, 0.7382056794741814, 0.6499816415688465, 0.5249179503531632, 0.7284489782040533, 0.01, 0.09298972306290176, 0.8152131875246076, 0.23608879660661247, 0.5032972494306865, 0.1475457535566011, 0.32693220251133076]
Training loss = 0.03434062639872233
step = 0, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.56375
Training loss = 0.0327225661277771
step = 1, Training Accuracy: 0.5033333333333333
Training loss = 0.032438206473986306
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.033503419160842894
step = 3, Training Accuracy: 0.49666666666666665
Training loss = 0.03240443865458171
step = 4, Training Accuracy: 0.47333333333333333
Training loss = 0.03354381799697876
step = 5, Training Accuracy: 0.48
Validation Accuracy: 0.57125
Training loss = 0.033683934807777406
step = 6, Training Accuracy: 0.46
Training loss = 0.0327035524447759
step = 7, Training Accuracy: 0.47333333333333333
Training loss = 0.032688528696695966
step = 8, Training Accuracy: 0.5233333333333333
Training loss = 0.03304084658622742
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.032598048249880475
step = 10, Training Accuracy: 0.51
Validation Accuracy: 0.57875
Training loss = 0.03292073051134745
step = 11, Training Accuracy: 0.52
Training loss = 0.0326004034280777
step = 12, Training Accuracy: 0.5
Training loss = 0.03331787089506785
step = 13, Training Accuracy: 0.5066666666666667
Training loss = 0.03357688148816427
step = 14, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.58
5  	8     	0.574062	0.0288703	0.51125	0.6025 
params:  [0.37625172142289515, 0.3996832314731658, 0.7432776495460708, 0.9594436609520798, 0.21435649508223042, 0.9214636428536057, 0.40775168715535365, 0.5809823878985239, 0.8853972354226733, 0.01, 0.7782485415114923, 0.30631736606728577, 0.590757996630595, 0.15717557472991767, 0.99, 0.24218959530762302, 0.44094579182870597, 0.25650409257177875, 0.99, 0.3132590410604099, 0.16768742353553118, 0.8223711906916076, 0.46241441809526795, 0.9034318916033203, 0.24349886502606638, 0.44635505675194187, 0.01, 0.0883551931686759, 0.028119741804963627, 0.5687658247294477, 0.01, 0.99, 0.18058992864516926, 0.26089858232131025, 0.30121101741329726, 0.99, 0.19736679262252602, 0.3509070500729685, 0.7221361334549387, 0.4689586653913814, 0.5536706904177908, 0.4454618146622339, 0.47519071936106194, 0.0992052218550922, 0.5516128031801413, 0.99, 0.3905874584408129, 0.9099484400872675, 0.99, 0.7261158596145953, 0.9496572078779508, 0.4564185965685921, 0.6263259840460887, 0.7781851337787219, 0.390415473581394, 0.7008750753059843, 0.01, 0.9072362093811754, 0.03393830769591291, 0.31754822322706877, 0.5950020973423084, 0.99, 0.1754629889022163, 0.043520744533338485, 0.6408795480825049, 0.3580408944923003, 0.5352422021475703, 0.01, 0.01, 0.9724065923593913, 0.7786680251322916, 0.39826503453823237, 0.24922483180210758, 0.5267634011645272, 0.33922731491339003, 0.2990888265274497, 0.6823108301673297, 0.16375951311668224, 0.49954670719479266, 0.15648417779477664, 0.6554213792343686, 0.8606296705997931, 0.8353128947913767, 0.01, 0.6108106904488028, 0.01, 0.4271937915547701, 0.4534829470954174, 0.03344168939716184, 0.5224557027982586, 0.4066606865661734, 0.22294981627518348]
[0.37625172142289515, 0.3996832314731658, 0.7432776495460708, 0.9594436609520798, 0.21435649508223042, 0.9214636428536057, 0.40775168715535365, 0.5809823878985239, 0.8853972354226733, 0.01, 0.7782485415114923, 0.30631736606728577, 0.590757996630595, 0.15717557472991767, 0.99, 0.24218959530762302, 0.44094579182870597, 0.25650409257177875, 0.99, 0.3132590410604099, 0.16768742353553118, 0.8223711906916076, 0.46241441809526795, 0.9034318916033203, 0.24349886502606638, 0.44635505675194187, 0.01, 0.0883551931686759, 0.028119741804963627, 0.5687658247294477, 0.01, 0.99, 0.18058992864516926, 0.26089858232131025, 0.30121101741329726, 0.99, 0.19736679262252602, 0.3509070500729685, 0.7221361334549387, 0.4689586653913814, 0.5536706904177908, 0.4454618146622339, 0.47519071936106194, 0.0992052218550922, 0.5516128031801413, 0.99, 0.3905874584408129, 0.9099484400872675, 0.99, 0.7261158596145953, 0.9496572078779508, 0.4564185965685921, 0.6263259840460887, 0.7781851337787219, 0.390415473581394, 0.7008750753059843, 0.01, 0.9072362093811754, 0.03393830769591291, 0.31754822322706877, 0.5950020973423084, 0.99, 0.1754629889022163, 0.043520744533338485, 0.6408795480825049, 0.3580408944923003, 0.5352422021475703, 0.01, 0.01, 0.9724065923593913, 0.7786680251322916, 0.39826503453823237, 0.24922483180210758, 0.5267634011645272, 0.33922731491339003, 0.2990888265274497, 0.6823108301673297, 0.16375951311668224, 0.49954670719479266, 0.15648417779477664, 0.6554213792343686, 0.8606296705997931, 0.8353128947913767, 0.01, 0.6108106904488028, 0.01, 0.4271937915547701, 0.4534829470954174, 0.03344168939716184, 0.5224557027982586, 0.4066606865661734, 0.22294981627518348]
Training loss = 0.03455021440982819
step = 0, Training Accuracy: 0.45
Validation Accuracy: 0.57625
Training loss = 0.03467210193475088
step = 1, Training Accuracy: 0.4666666666666667
Training loss = 0.034323463241259254
step = 2, Training Accuracy: 0.5166666666666667
Training loss = 0.03199074685573578
step = 3, Training Accuracy: 0.5166666666666667
Training loss = 0.03388475477695465
step = 4, Training Accuracy: 0.5033333333333333
Training loss = 0.03284073173999787
step = 5, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.5725
Training loss = 0.03270686407883962
step = 6, Training Accuracy: 0.54
Training loss = 0.03424220522244771
step = 7, Training Accuracy: 0.4633333333333333
Training loss = 0.034346005519231164
step = 8, Training Accuracy: 0.47333333333333333
Training loss = 0.03403208533922831
step = 9, Training Accuracy: 0.4266666666666667
Training loss = 0.033028321862220766
step = 10, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.57625
Training loss = 0.03243781844774882
step = 11, Training Accuracy: 0.53
Training loss = 0.03203917801380157
step = 12, Training Accuracy: 0.55
Training loss = 0.03336742103099823
step = 13, Training Accuracy: 0.5033333333333333
Training loss = 0.03270772874355316
step = 14, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.57375
params:  [0.5070484439168864, 0.8901085219664188, 0.8170442940135503, 0.9255851519566514, 0.11156646794157665, 0.48132313473549876, 0.4111859005564631, 0.37437188706549734, 0.8648976788284218, 0.47216955960278933, 0.7257366588012603, 0.063212193758828, 0.3070203544711021, 0.5795129586753979, 0.39050823755492636, 0.21214500634237968, 0.18357711329598864, 0.6899882803548435, 0.99, 0.6682158324023268, 0.3011669181272027, 0.6211929652078274, 0.7378719106646281, 0.9106199472743938, 0.8040221409519739, 0.29483873271988464, 0.29128793118503693, 0.37680239273548255, 0.600271354278937, 0.6226055058003546, 0.1323008644355056, 0.99, 0.25588029118179817, 0.01, 0.9590691499598736, 0.99, 0.12492764671618523, 0.99, 0.9224190989550891, 0.2906112063627539, 0.70462680545701, 0.08136488961765137, 0.4368773840879441, 0.09989536148949904, 0.44076676804210335, 0.5778497274382937, 0.8376544762310285, 0.9734040973052738, 0.99, 0.8711149610083714, 0.99, 0.99, 0.5019371486357894, 0.8608682340360657, 0.01, 0.5548184968500935, 0.01, 0.7725709782106998, 0.2262135341083344, 0.3394442778173294, 0.5930079115332182, 0.697850123363078, 0.40650597617671336, 0.38196794767854314, 0.99, 0.5487812007490103, 0.5431151869370496, 0.26850642573378247, 0.01, 0.5054021874436662, 0.01, 0.055623366157830034, 0.5394422562161506, 0.99, 0.20447881560923914, 0.2251514349600725, 0.5512172938037351, 0.327350733312045, 0.01, 0.5850081021343986, 0.99, 0.6805741578218985, 0.7895069696944752, 0.2657033255313355, 0.9238766951884585, 0.01, 0.4756216293643018, 0.6377417982692583, 0.13346961184793432, 0.7552642816555366, 0.21719917619380785, 0.09250969499926787]
[0.5070484439168864, 0.8901085219664188, 0.8170442940135503, 0.9255851519566514, 0.11156646794157665, 0.48132313473549876, 0.4111859005564631, 0.37437188706549734, 0.8648976788284218, 0.47216955960278933, 0.7257366588012603, 0.063212193758828, 0.3070203544711021, 0.5795129586753979, 0.39050823755492636, 0.21214500634237968, 0.18357711329598864, 0.6899882803548435, 0.99, 0.6682158324023268, 0.3011669181272027, 0.6211929652078274, 0.7378719106646281, 0.9106199472743938, 0.8040221409519739, 0.29483873271988464, 0.29128793118503693, 0.37680239273548255, 0.600271354278937, 0.6226055058003546, 0.1323008644355056, 0.99, 0.25588029118179817, 0.01, 0.9590691499598736, 0.99, 0.12492764671618523, 0.99, 0.9224190989550891, 0.2906112063627539, 0.70462680545701, 0.08136488961765137, 0.4368773840879441, 0.09989536148949904, 0.44076676804210335, 0.5778497274382937, 0.8376544762310285, 0.9734040973052738, 0.99, 0.8711149610083714, 0.99, 0.99, 0.5019371486357894, 0.8608682340360657, 0.01, 0.5548184968500935, 0.01, 0.7725709782106998, 0.2262135341083344, 0.3394442778173294, 0.5930079115332182, 0.697850123363078, 0.40650597617671336, 0.38196794767854314, 0.99, 0.5487812007490103, 0.5431151869370496, 0.26850642573378247, 0.01, 0.5054021874436662, 0.01, 0.055623366157830034, 0.5394422562161506, 0.99, 0.20447881560923914, 0.2251514349600725, 0.5512172938037351, 0.327350733312045, 0.01, 0.5850081021343986, 0.99, 0.6805741578218985, 0.7895069696944752, 0.2657033255313355, 0.9238766951884585, 0.01, 0.4756216293643018, 0.6377417982692583, 0.13346961184793432, 0.7552642816555366, 0.21719917619380785, 0.09250969499926787]
Training loss = 0.03481836597124736
step = 0, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.56375
Training loss = 0.03633401989936828
step = 1, Training Accuracy: 0.36666666666666664
Training loss = 0.033879107038180034
step = 2, Training Accuracy: 0.48
Training loss = 0.03443651020526886
step = 3, Training Accuracy: 0.44333333333333336
Training loss = 0.03411792993545532
step = 4, Training Accuracy: 0.4533333333333333
Training loss = 0.03491832236448924
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.56
Training loss = 0.03469754974047343
step = 6, Training Accuracy: 0.4633333333333333
Training loss = 0.03370704889297485
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.03382068435351054
step = 8, Training Accuracy: 0.47
Training loss = 0.03480420231819153
step = 9, Training Accuracy: 0.43333333333333335
Training loss = 0.035120312770207725
step = 10, Training Accuracy: 0.41
Validation Accuracy: 0.55875
Training loss = 0.03517465035120646
step = 11, Training Accuracy: 0.45666666666666667
Training loss = 0.033849700689315795
step = 12, Training Accuracy: 0.48333333333333334
Training loss = 0.03344957709312439
step = 13, Training Accuracy: 0.4866666666666667
Training loss = 0.03471071163813273
step = 14, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.54125
params:  [0.4958893295040577, 0.24661544086600207, 0.968935294362302, 0.6728193358686412, 0.14554768902560244, 0.5801296245221973, 0.42758294464701807, 0.5418284264625279, 0.99, 0.2730054518001808, 0.9124957399245015, 0.16545954749314376, 0.23569879993007664, 0.15179606774752769, 0.7640419657821611, 0.30158489596961263, 0.441801833330726, 0.4013091780772813, 0.47340965867824647, 0.99, 0.3913490483567099, 0.3811142723786463, 0.3266787575154709, 0.5096362349952277, 0.5810038627899554, 0.15652145169259363, 0.4577488966621378, 0.2942125759130602, 0.4491157107245182, 0.01, 0.18967114418561362, 0.7922112721239709, 0.36331021540091196, 0.27915146186809314, 0.4837218046500945, 0.9642170435099198, 0.10586246318974787, 0.9342543136666266, 0.9577712583479255, 0.9374763488856488, 0.3845237445749481, 0.5875619494358284, 0.11123585795364949, 0.08973431877388482, 0.6355262194821376, 0.6352697090711554, 0.7407463752187606, 0.7928436310101442, 0.8883564103743155, 0.9848769590397173, 0.6978683159393474, 0.5186256505867431, 0.01, 0.99, 0.3257723304680522, 0.01, 0.22749627145097484, 0.10840565357685544, 0.2166943825300801, 0.09172087635153137, 0.5578107613635792, 0.9550438859862914, 0.2815445562401888, 0.42793793890544024, 0.5262368599730293, 0.2728262168762383, 0.3831699018445006, 0.19619511589383443, 0.030528078384375063, 0.99, 0.45742807646209943, 0.11083530188040824, 0.13275954905104292, 0.99, 0.2948390670655487, 0.05883006717400008, 0.56268620505443, 0.3807998151285545, 0.16049454084772496, 0.6092248757607914, 0.8097440670709013, 0.3288067675546849, 0.631607356328973, 0.01, 0.535800238573273, 0.18315818305142834, 0.7760496933225238, 0.09185374198008364, 0.01, 0.4483995197113806, 0.01, 0.01]
[0.4958893295040577, 0.24661544086600207, 0.968935294362302, 0.6728193358686412, 0.14554768902560244, 0.5801296245221973, 0.42758294464701807, 0.5418284264625279, 0.99, 0.2730054518001808, 0.9124957399245015, 0.16545954749314376, 0.23569879993007664, 0.15179606774752769, 0.7640419657821611, 0.30158489596961263, 0.441801833330726, 0.4013091780772813, 0.47340965867824647, 0.99, 0.3913490483567099, 0.3811142723786463, 0.3266787575154709, 0.5096362349952277, 0.5810038627899554, 0.15652145169259363, 0.4577488966621378, 0.2942125759130602, 0.4491157107245182, 0.01, 0.18967114418561362, 0.7922112721239709, 0.36331021540091196, 0.27915146186809314, 0.4837218046500945, 0.9642170435099198, 0.10586246318974787, 0.9342543136666266, 0.9577712583479255, 0.9374763488856488, 0.3845237445749481, 0.5875619494358284, 0.11123585795364949, 0.08973431877388482, 0.6355262194821376, 0.6352697090711554, 0.7407463752187606, 0.7928436310101442, 0.8883564103743155, 0.9848769590397173, 0.6978683159393474, 0.5186256505867431, 0.01, 0.99, 0.3257723304680522, 0.01, 0.22749627145097484, 0.10840565357685544, 0.2166943825300801, 0.09172087635153137, 0.5578107613635792, 0.9550438859862914, 0.2815445562401888, 0.42793793890544024, 0.5262368599730293, 0.2728262168762383, 0.3831699018445006, 0.19619511589383443, 0.030528078384375063, 0.99, 0.45742807646209943, 0.11083530188040824, 0.13275954905104292, 0.99, 0.2948390670655487, 0.05883006717400008, 0.56268620505443, 0.3807998151285545, 0.16049454084772496, 0.6092248757607914, 0.8097440670709013, 0.3288067675546849, 0.631607356328973, 0.01, 0.535800238573273, 0.18315818305142834, 0.7760496933225238, 0.09185374198008364, 0.01, 0.4483995197113806, 0.01, 0.01]
Training loss = 0.032442368666330976
step = 0, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.56125
Training loss = 0.03466080109278361
step = 1, Training Accuracy: 0.5033333333333333
Training loss = 0.03147577782471975
step = 2, Training Accuracy: 0.5066666666666667
Training loss = 0.03195726752281189
step = 3, Training Accuracy: 0.5133333333333333
Training loss = 0.03272144456704457
step = 4, Training Accuracy: 0.5033333333333333
Training loss = 0.0335060981909434
step = 5, Training Accuracy: 0.5
Validation Accuracy: 0.5775
Training loss = 0.034196553428967796
step = 6, Training Accuracy: 0.4866666666666667
Training loss = 0.0329582409063975
step = 7, Training Accuracy: 0.5333333333333333
Training loss = 0.03140435477097829
step = 8, Training Accuracy: 0.51
Training loss = 0.03190444608529409
step = 9, Training Accuracy: 0.5
Training loss = 0.03285444418589274
step = 10, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.57375
Training loss = 0.031106236974398294
step = 11, Training Accuracy: 0.5466666666666666
Training loss = 0.03120060682296753
step = 12, Training Accuracy: 0.5
Training loss = 0.031460806528727216
step = 13, Training Accuracy: 0.5133333333333333
Training loss = 0.03160134494304657
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.5675
params:  [0.01, 0.3527659463296336, 0.796067064278576, 0.99, 0.7145954084490552, 0.4595314247518012, 0.38900071510846157, 0.1583333913480967, 0.4516736685128627, 0.01, 0.31306799208996694, 0.01, 0.3242433834764078, 0.16626999122455324, 0.7621251055702363, 0.3436283628516497, 0.18773213864324773, 0.5232870518952613, 0.9183029512393369, 0.35987400537446684, 0.01, 0.4040971904729208, 0.5718155222554924, 0.99, 0.6214745745651155, 0.01, 0.5440710623822931, 0.3544406679900523, 0.5966454783029389, 0.32051760908615345, 0.3456432373297397, 0.9225929629634924, 0.36819196394740417, 0.3661317806595454, 0.7465294601269181, 0.99, 0.01, 0.99, 0.5966693291309058, 0.2149959778539759, 0.5990926195876867, 0.5603950125655779, 0.5452371362322754, 0.5087303822144174, 0.906948431412165, 0.7030948805701829, 0.6966734980242562, 0.3852004540799165, 0.7868147217587237, 0.5815079712377813, 0.7659975669871781, 0.7819409234057563, 0.739252110429504, 0.3020505335341763, 0.08947969818486534, 0.5892254494813643, 0.01, 0.28612438450051914, 0.36733393419004645, 0.45230075138636816, 0.39321535441562094, 0.8309894266269091, 0.9139876519286958, 0.18726952863125387, 0.39575212008166405, 0.37126194644782484, 0.5069676899290395, 0.42403070515621044, 0.01, 0.7746934482279256, 0.569573189408842, 0.10640683718594102, 0.7447690265143473, 0.6095170605285908, 0.3706809990804424, 0.6661658186778983, 0.9861046487846328, 0.3214857341296896, 0.01, 0.32388627581139817, 0.39434276222202597, 0.8214917438938658, 0.7376021375265611, 0.5809056217923158, 0.6885172187321583, 0.03153901994743573, 0.622967581034123, 0.01, 0.01, 0.32409911061157054, 0.09387240697024758, 0.6346260403798867]
[0.01, 0.3527659463296336, 0.796067064278576, 0.99, 0.7145954084490552, 0.4595314247518012, 0.38900071510846157, 0.1583333913480967, 0.4516736685128627, 0.01, 0.31306799208996694, 0.01, 0.3242433834764078, 0.16626999122455324, 0.7621251055702363, 0.3436283628516497, 0.18773213864324773, 0.5232870518952613, 0.9183029512393369, 0.35987400537446684, 0.01, 0.4040971904729208, 0.5718155222554924, 0.99, 0.6214745745651155, 0.01, 0.5440710623822931, 0.3544406679900523, 0.5966454783029389, 0.32051760908615345, 0.3456432373297397, 0.9225929629634924, 0.36819196394740417, 0.3661317806595454, 0.7465294601269181, 0.99, 0.01, 0.99, 0.5966693291309058, 0.2149959778539759, 0.5990926195876867, 0.5603950125655779, 0.5452371362322754, 0.5087303822144174, 0.906948431412165, 0.7030948805701829, 0.6966734980242562, 0.3852004540799165, 0.7868147217587237, 0.5815079712377813, 0.7659975669871781, 0.7819409234057563, 0.739252110429504, 0.3020505335341763, 0.08947969818486534, 0.5892254494813643, 0.01, 0.28612438450051914, 0.36733393419004645, 0.45230075138636816, 0.39321535441562094, 0.8309894266269091, 0.9139876519286958, 0.18726952863125387, 0.39575212008166405, 0.37126194644782484, 0.5069676899290395, 0.42403070515621044, 0.01, 0.7746934482279256, 0.569573189408842, 0.10640683718594102, 0.7447690265143473, 0.6095170605285908, 0.3706809990804424, 0.6661658186778983, 0.9861046487846328, 0.3214857341296896, 0.01, 0.32388627581139817, 0.39434276222202597, 0.8214917438938658, 0.7376021375265611, 0.5809056217923158, 0.6885172187321583, 0.03153901994743573, 0.622967581034123, 0.01, 0.01, 0.32409911061157054, 0.09387240697024758, 0.6346260403798867]
Training loss = 0.03297081152598063
step = 0, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.5725
Training loss = 0.03184071401755015
step = 1, Training Accuracy: 0.5033333333333333
Training loss = 0.03133404990037282
step = 2, Training Accuracy: 0.5133333333333333
Training loss = 0.030419104099273682
step = 3, Training Accuracy: 0.54
Training loss = 0.03249114632606506
step = 4, Training Accuracy: 0.5366666666666666
Training loss = 0.0331116384267807
step = 5, Training Accuracy: 0.52
Validation Accuracy: 0.565
Training loss = 0.03163307011127472
step = 6, Training Accuracy: 0.5433333333333333
Training loss = 0.03190013607343038
step = 7, Training Accuracy: 0.49
Training loss = 0.03293288429578145
step = 8, Training Accuracy: 0.51
Training loss = 0.031172648072242737
step = 9, Training Accuracy: 0.52
Training loss = 0.03170925259590149
step = 10, Training Accuracy: 0.53
Validation Accuracy: 0.575
Training loss = 0.03196417212486267
step = 11, Training Accuracy: 0.5233333333333333
Training loss = 0.03060140351454417
step = 12, Training Accuracy: 0.51
Training loss = 0.030490902463595072
step = 13, Training Accuracy: 0.5566666666666666
Training loss = 0.031250159740448
step = 14, Training Accuracy: 0.54
Validation Accuracy: 0.585
params:  [0.01, 0.7978679057667593, 0.8208240831434399, 0.07110285545532646, 0.5747364704201567, 0.3646037221472778, 0.3579195273230814, 0.6140971446673261, 0.7397641954649364, 0.15250213065459967, 0.618782227919705, 0.12287783325226473, 0.44087474427454443, 0.13914984676356862, 0.760259625459013, 0.4517759469810983, 0.363025159334575, 0.3429973257125124, 0.776580578677356, 0.01, 0.19903693454194452, 0.58814828065717, 0.7052588524516363, 0.60124322391734, 0.2543473508431522, 0.01, 0.10739027565936188, 0.01, 0.5297312324902052, 0.5236804218384656, 0.31950295079744745, 0.7636003573370919, 0.20250630633138925, 0.11414010956902437, 0.3757036640432051, 0.7519927452960626, 0.12069085060472498, 0.99, 0.8674954897933864, 0.16096626642795953, 0.5049988596925276, 0.3981783655729954, 0.2297852481824666, 0.2109878159534963, 0.5531120566975744, 0.6898303920284264, 0.3494740446523471, 0.99, 0.99, 0.99, 0.9135736884230486, 0.9864182714912464, 0.5573379350833063, 0.16076344950976773, 0.01, 0.5279111820300493, 0.4909869616418374, 0.7173365854405113, 0.21974163279547088, 0.4471137753530177, 0.99, 0.5958854431070431, 0.5890860289061143, 0.6418541417632326, 0.9267406184981091, 0.16558840244358133, 0.3553963144974392, 0.24701451377887912, 0.01, 0.99, 0.09470341640715735, 0.363513170321141, 0.1485403481866731, 0.66321381985731, 0.31748972699163464, 0.27831692613623427, 0.24685009344142378, 0.04238489496215264, 0.23920328543400637, 0.8896459381754255, 0.7890056545079454, 0.7559834845674502, 0.5800449274143943, 0.6665111925015808, 0.499954477704432, 0.29274028568568466, 0.47088941504556914, 0.01, 0.36583866509753027, 0.244925762909126, 0.01, 0.25672745052198387]
[0.01, 0.7978679057667593, 0.8208240831434399, 0.07110285545532646, 0.5747364704201567, 0.3646037221472778, 0.3579195273230814, 0.6140971446673261, 0.7397641954649364, 0.15250213065459967, 0.618782227919705, 0.12287783325226473, 0.44087474427454443, 0.13914984676356862, 0.760259625459013, 0.4517759469810983, 0.363025159334575, 0.3429973257125124, 0.776580578677356, 0.01, 0.19903693454194452, 0.58814828065717, 0.7052588524516363, 0.60124322391734, 0.2543473508431522, 0.01, 0.10739027565936188, 0.01, 0.5297312324902052, 0.5236804218384656, 0.31950295079744745, 0.7636003573370919, 0.20250630633138925, 0.11414010956902437, 0.3757036640432051, 0.7519927452960626, 0.12069085060472498, 0.99, 0.8674954897933864, 0.16096626642795953, 0.5049988596925276, 0.3981783655729954, 0.2297852481824666, 0.2109878159534963, 0.5531120566975744, 0.6898303920284264, 0.3494740446523471, 0.99, 0.99, 0.99, 0.9135736884230486, 0.9864182714912464, 0.5573379350833063, 0.16076344950976773, 0.01, 0.5279111820300493, 0.4909869616418374, 0.7173365854405113, 0.21974163279547088, 0.4471137753530177, 0.99, 0.5958854431070431, 0.5890860289061143, 0.6418541417632326, 0.9267406184981091, 0.16558840244358133, 0.3553963144974392, 0.24701451377887912, 0.01, 0.99, 0.09470341640715735, 0.363513170321141, 0.1485403481866731, 0.66321381985731, 0.31748972699163464, 0.27831692613623427, 0.24685009344142378, 0.04238489496215264, 0.23920328543400637, 0.8896459381754255, 0.7890056545079454, 0.7559834845674502, 0.5800449274143943, 0.6665111925015808, 0.499954477704432, 0.29274028568568466, 0.47088941504556914, 0.01, 0.36583866509753027, 0.244925762909126, 0.01, 0.25672745052198387]
Training loss = 0.033664657672246294
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.58875
Training loss = 0.033095691402753195
step = 1, Training Accuracy: 0.53
Training loss = 0.03313466668128967
step = 2, Training Accuracy: 0.5166666666666667
Training loss = 0.03136934737364451
step = 3, Training Accuracy: 0.5433333333333333
Training loss = 0.033898083368937175
step = 4, Training Accuracy: 0.47333333333333333
Training loss = 0.031868847807248434
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.57125
Training loss = 0.03227431972821553
step = 6, Training Accuracy: 0.5033333333333333
Training loss = 0.033544169267018635
step = 7, Training Accuracy: 0.4866666666666667
Training loss = 0.031083643237749734
step = 8, Training Accuracy: 0.54
Training loss = 0.03262287179629008
step = 9, Training Accuracy: 0.5266666666666666
Training loss = 0.03208949625492096
step = 10, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.595
Training loss = 0.0326388543844223
step = 11, Training Accuracy: 0.52
Training loss = 0.032693267663319904
step = 12, Training Accuracy: 0.48
Training loss = 0.03143273770809173
step = 13, Training Accuracy: 0.5366666666666666
Training loss = 0.0313341341416041
step = 14, Training Accuracy: 0.54
Validation Accuracy: 0.60125
params:  [0.4288714894113972, 0.99, 0.99, 0.6379306197520718, 0.40560346053513585, 0.26176792361691736, 0.7451835576576277, 0.7513086810768222, 0.7259529535327355, 0.01, 0.46016772403523193, 0.2356284514302027, 0.5916661499391678, 0.28060817291043005, 0.7209190160708069, 0.3515543081370869, 0.0771555018412641, 0.8029179486790967, 0.834471020286391, 0.43134848826099664, 0.01, 0.4096610564111325, 0.8162644975445031, 0.8182771484449352, 0.534678692023576, 0.01, 0.30887913313208437, 0.37687003835673294, 0.2858697605134269, 0.46349753389552123, 0.13436213318355306, 0.8205313214936367, 0.046752827500447014, 0.6119222247049634, 0.9486684227176683, 0.99, 0.27931131343536447, 0.4856552236323906, 0.5565819408577324, 0.11438576692520436, 0.2826041908783697, 0.20787920626768663, 0.01026304622406933, 0.33464963136076126, 0.473184597478261, 0.9786606843911183, 0.3842285108568337, 0.6568331869758423, 0.99, 0.6986878307506086, 0.9746503778847072, 0.6086341310327076, 0.01, 0.31407445172907816, 0.21953132009606763, 0.8309274228779013, 0.01, 0.775943201982532, 0.01, 0.01, 0.6302789012239731, 0.11494523428645032, 0.2599513205550918, 0.7488000689501588, 0.8713373326702418, 0.4979676221525033, 0.3986303370233839, 0.2665449589306289, 0.03798480011465012, 0.99, 0.05482463425032216, 0.27271410840195576, 0.5490254398937522, 0.4991313163709535, 0.2578961386803702, 0.4363734738449688, 0.7826101862395688, 0.36371567846419967, 0.7091342539069954, 0.21640381005630113, 0.8542356686161083, 0.5881938030455058, 0.7443249767477943, 0.01, 0.563385891266274, 0.01770504460912213, 0.19999406910523218, 0.10270687598441053, 0.01, 0.40303961456867043, 0.4964917068357676, 0.01]
[0.4288714894113972, 0.99, 0.99, 0.6379306197520718, 0.40560346053513585, 0.26176792361691736, 0.7451835576576277, 0.7513086810768222, 0.7259529535327355, 0.01, 0.46016772403523193, 0.2356284514302027, 0.5916661499391678, 0.28060817291043005, 0.7209190160708069, 0.3515543081370869, 0.0771555018412641, 0.8029179486790967, 0.834471020286391, 0.43134848826099664, 0.01, 0.4096610564111325, 0.8162644975445031, 0.8182771484449352, 0.534678692023576, 0.01, 0.30887913313208437, 0.37687003835673294, 0.2858697605134269, 0.46349753389552123, 0.13436213318355306, 0.8205313214936367, 0.046752827500447014, 0.6119222247049634, 0.9486684227176683, 0.99, 0.27931131343536447, 0.4856552236323906, 0.5565819408577324, 0.11438576692520436, 0.2826041908783697, 0.20787920626768663, 0.01026304622406933, 0.33464963136076126, 0.473184597478261, 0.9786606843911183, 0.3842285108568337, 0.6568331869758423, 0.99, 0.6986878307506086, 0.9746503778847072, 0.6086341310327076, 0.01, 0.31407445172907816, 0.21953132009606763, 0.8309274228779013, 0.01, 0.775943201982532, 0.01, 0.01, 0.6302789012239731, 0.11494523428645032, 0.2599513205550918, 0.7488000689501588, 0.8713373326702418, 0.4979676221525033, 0.3986303370233839, 0.2665449589306289, 0.03798480011465012, 0.99, 0.05482463425032216, 0.27271410840195576, 0.5490254398937522, 0.4991313163709535, 0.2578961386803702, 0.4363734738449688, 0.7826101862395688, 0.36371567846419967, 0.7091342539069954, 0.21640381005630113, 0.8542356686161083, 0.5881938030455058, 0.7443249767477943, 0.01, 0.563385891266274, 0.01770504460912213, 0.19999406910523218, 0.10270687598441053, 0.01, 0.40303961456867043, 0.4964917068357676, 0.01]
Training loss = 0.033185084660847984
step = 0, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.59
Training loss = 0.03362421989440918
step = 1, Training Accuracy: 0.5033333333333333
Training loss = 0.03422847390174866
step = 2, Training Accuracy: 0.47
Training loss = 0.03355045338471731
step = 3, Training Accuracy: 0.51
Training loss = 0.034751240809758506
step = 4, Training Accuracy: 0.4766666666666667
Training loss = 0.034190685351689655
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.59875
Training loss = 0.03365548014640808
step = 6, Training Accuracy: 0.5166666666666667
Training loss = 0.034703993399937946
step = 7, Training Accuracy: 0.49
Training loss = 0.03358208100001017
step = 8, Training Accuracy: 0.5333333333333333
Training loss = 0.03415705700715383
step = 9, Training Accuracy: 0.44666666666666666
Training loss = 0.032229861617088316
step = 10, Training Accuracy: 0.51
Validation Accuracy: 0.5925
Training loss = 0.03273570398489634
step = 11, Training Accuracy: 0.49333333333333335
Training loss = 0.03150125523408254
step = 12, Training Accuracy: 0.5466666666666666
Training loss = 0.03337588926156362
step = 13, Training Accuracy: 0.49333333333333335
Training loss = 0.03250152389208476
step = 14, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.59875
params:  [0.6934015740401368, 0.99, 0.99, 0.845632149486179, 0.38057881027417284, 0.5939880188347565, 0.29610865714167406, 0.42472197145561685, 0.7333123799386418, 0.01, 0.517140216920048, 0.14335750757107502, 0.39291256161534704, 0.01, 0.6511668320834612, 0.1631440788596693, 0.2600155746804993, 0.5150735272450403, 0.7510925425295283, 0.37162125896868936, 0.0820723274398763, 0.5160194491473953, 0.5513988071288409, 0.3785683955714365, 0.4307895026379752, 0.01, 0.5827934690087312, 0.21281924806687735, 0.030842147637074213, 0.7012902283815658, 0.17642876556650033, 0.4572568560322458, 0.18878462955803713, 0.99, 0.1504355724521455, 0.6605487440924382, 0.026951999127521636, 0.9002322552002123, 0.99, 0.54912814576383, 0.7904367088923232, 0.4109547282067863, 0.18505696827720558, 0.1984522461422773, 0.49882702662648676, 0.99, 0.6092591973076003, 0.4658691899611109, 0.8837089382750215, 0.99, 0.9349454428817557, 0.8171512773410028, 0.8201040942732071, 0.7265537321129975, 0.2955991513805482, 0.20881401077481349, 0.15574636108742518, 0.6324923902987069, 0.6375567907855636, 0.5919225762029553, 0.40416451994855346, 0.99, 0.5779456085605664, 0.02781443033699299, 0.4481255457588261, 0.07873086725436929, 0.01, 0.6196622026896177, 0.01, 0.7138490573090965, 0.49900840457160767, 0.689714149995863, 0.24064561215197422, 0.5584347986905096, 0.7791608325985353, 0.295794738594936, 0.5972593618613301, 0.7732921895169433, 0.3035455540906238, 0.29759186435714313, 0.7969455279380135, 0.5175334558965562, 0.6011782033766134, 0.3370451867890437, 0.3708133885266344, 0.2806704802944848, 0.34729823252849595, 0.02297203519136909, 0.10131209974934177, 0.24193011974627482, 0.1719313315195998, 0.30581199216049654]
[0.6934015740401368, 0.99, 0.99, 0.845632149486179, 0.38057881027417284, 0.5939880188347565, 0.29610865714167406, 0.42472197145561685, 0.7333123799386418, 0.01, 0.517140216920048, 0.14335750757107502, 0.39291256161534704, 0.01, 0.6511668320834612, 0.1631440788596693, 0.2600155746804993, 0.5150735272450403, 0.7510925425295283, 0.37162125896868936, 0.0820723274398763, 0.5160194491473953, 0.5513988071288409, 0.3785683955714365, 0.4307895026379752, 0.01, 0.5827934690087312, 0.21281924806687735, 0.030842147637074213, 0.7012902283815658, 0.17642876556650033, 0.4572568560322458, 0.18878462955803713, 0.99, 0.1504355724521455, 0.6605487440924382, 0.026951999127521636, 0.9002322552002123, 0.99, 0.54912814576383, 0.7904367088923232, 0.4109547282067863, 0.18505696827720558, 0.1984522461422773, 0.49882702662648676, 0.99, 0.6092591973076003, 0.4658691899611109, 0.8837089382750215, 0.99, 0.9349454428817557, 0.8171512773410028, 0.8201040942732071, 0.7265537321129975, 0.2955991513805482, 0.20881401077481349, 0.15574636108742518, 0.6324923902987069, 0.6375567907855636, 0.5919225762029553, 0.40416451994855346, 0.99, 0.5779456085605664, 0.02781443033699299, 0.4481255457588261, 0.07873086725436929, 0.01, 0.6196622026896177, 0.01, 0.7138490573090965, 0.49900840457160767, 0.689714149995863, 0.24064561215197422, 0.5584347986905096, 0.7791608325985353, 0.295794738594936, 0.5972593618613301, 0.7732921895169433, 0.3035455540906238, 0.29759186435714313, 0.7969455279380135, 0.5175334558965562, 0.6011782033766134, 0.3370451867890437, 0.3708133885266344, 0.2806704802944848, 0.34729823252849595, 0.02297203519136909, 0.10131209974934177, 0.24193011974627482, 0.1719313315195998, 0.30581199216049654]
Training loss = 0.03549765169620514
step = 0, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.545
Training loss = 0.03617385903994242
step = 1, Training Accuracy: 0.4066666666666667
Training loss = 0.03530677556991577
step = 2, Training Accuracy: 0.43333333333333335
Training loss = 0.033941697080930075
step = 3, Training Accuracy: 0.47333333333333333
Training loss = 0.03467142601807912
step = 4, Training Accuracy: 0.45666666666666667
Training loss = 0.03327851633230845
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.58125
Training loss = 0.03374835789203644
step = 6, Training Accuracy: 0.43666666666666665
Training loss = 0.03396432677904765
step = 7, Training Accuracy: 0.49
Training loss = 0.03383849799633026
step = 8, Training Accuracy: 0.4633333333333333
Training loss = 0.034382418990135194
step = 9, Training Accuracy: 0.47333333333333333
Training loss = 0.03406731287638346
step = 10, Training Accuracy: 0.47
Validation Accuracy: 0.5525
Training loss = 0.03391255180040995
step = 11, Training Accuracy: 0.46
Training loss = 0.03346005499362945
step = 12, Training Accuracy: 0.4766666666666667
Training loss = 0.034334778785705566
step = 13, Training Accuracy: 0.4666666666666667
Training loss = 0.0340508242448171
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.58125
params:  [0.01, 0.8688540966523256, 0.8007139494011637, 0.6431401201778112, 0.9874464634982941, 0.2839608287010785, 0.4266393629397167, 0.38958598893825724, 0.5944611802772239, 0.3290616158008738, 0.7735226504443768, 0.01, 0.5275738005571152, 0.01, 0.8075283967619928, 0.422197119595734, 0.38899979516179817, 0.2349993500392365, 0.8869361804888499, 0.27523227138792083, 0.015678980511677203, 0.31216902518693695, 0.8366565346720167, 0.99, 0.18743396453555156, 0.20737425096022577, 0.72177883261629, 0.49855247692739135, 0.5834980310487861, 0.11550631594787372, 0.45004232399162514, 0.9586677045642585, 0.01, 0.36269395973225327, 0.2619918379452532, 0.9554339119393773, 0.4750236994829894, 0.9461866438307326, 0.803777750684189, 0.99, 0.7316422422060995, 0.5178806604126911, 0.01, 0.3244752892489069, 0.7782988199759416, 0.7883202422649408, 0.4435587124402486, 0.6587869880028738, 0.99, 0.99, 0.8278569624978431, 0.6593788231137523, 0.1823572870614154, 0.6777326086320404, 0.025238316524195295, 0.2534052821378127, 0.01, 0.9303395744939309, 0.1076256382682563, 0.4692680095685859, 0.7516932887123327, 0.99, 0.8400820208523464, 0.6009754535000409, 0.44845832619307446, 0.3695212608989443, 0.01, 0.25242947509645575, 0.01, 0.8883356486684445, 0.47538350945122343, 0.05812531973855789, 0.15651881964190872, 0.99, 0.40041149991720904, 0.3101580599445427, 0.28241103835655795, 0.3013257450715341, 0.314890730854749, 0.2721964408532952, 0.4353972673340695, 0.49389304039611914, 0.99, 0.5040254189734025, 0.5123687415024136, 0.3454361518806828, 0.1554120487648006, 0.01, 0.01, 0.06429876767980142, 0.11747633519629053, 0.21134029835697407]
[0.01, 0.8688540966523256, 0.8007139494011637, 0.6431401201778112, 0.9874464634982941, 0.2839608287010785, 0.4266393629397167, 0.38958598893825724, 0.5944611802772239, 0.3290616158008738, 0.7735226504443768, 0.01, 0.5275738005571152, 0.01, 0.8075283967619928, 0.422197119595734, 0.38899979516179817, 0.2349993500392365, 0.8869361804888499, 0.27523227138792083, 0.015678980511677203, 0.31216902518693695, 0.8366565346720167, 0.99, 0.18743396453555156, 0.20737425096022577, 0.72177883261629, 0.49855247692739135, 0.5834980310487861, 0.11550631594787372, 0.45004232399162514, 0.9586677045642585, 0.01, 0.36269395973225327, 0.2619918379452532, 0.9554339119393773, 0.4750236994829894, 0.9461866438307326, 0.803777750684189, 0.99, 0.7316422422060995, 0.5178806604126911, 0.01, 0.3244752892489069, 0.7782988199759416, 0.7883202422649408, 0.4435587124402486, 0.6587869880028738, 0.99, 0.99, 0.8278569624978431, 0.6593788231137523, 0.1823572870614154, 0.6777326086320404, 0.025238316524195295, 0.2534052821378127, 0.01, 0.9303395744939309, 0.1076256382682563, 0.4692680095685859, 0.7516932887123327, 0.99, 0.8400820208523464, 0.6009754535000409, 0.44845832619307446, 0.3695212608989443, 0.01, 0.25242947509645575, 0.01, 0.8883356486684445, 0.47538350945122343, 0.05812531973855789, 0.15651881964190872, 0.99, 0.40041149991720904, 0.3101580599445427, 0.28241103835655795, 0.3013257450715341, 0.314890730854749, 0.2721964408532952, 0.4353972673340695, 0.49389304039611914, 0.99, 0.5040254189734025, 0.5123687415024136, 0.3454361518806828, 0.1554120487648006, 0.01, 0.01, 0.06429876767980142, 0.11747633519629053, 0.21134029835697407]
Training loss = 0.03271704951922099
step = 0, Training Accuracy: 0.51
Validation Accuracy: 0.56875
Training loss = 0.031798102855682374
step = 1, Training Accuracy: 0.5
Training loss = 0.032123059034347534
step = 2, Training Accuracy: 0.5166666666666667
Training loss = 0.031189927458763124
step = 3, Training Accuracy: 0.5633333333333334
Training loss = 0.031510513027509054
step = 4, Training Accuracy: 0.49666666666666665
Training loss = 0.030576748649279277
step = 5, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.56125
Training loss = 0.030752692619959512
step = 6, Training Accuracy: 0.55
Training loss = 0.030988948146502177
step = 7, Training Accuracy: 0.54
Training loss = 0.03043622096379598
step = 8, Training Accuracy: 0.5766666666666667
Training loss = 0.02959959348042806
step = 9, Training Accuracy: 0.58
Training loss = 0.03015301247437795
step = 10, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.57625
Training loss = 0.030587024490038552
step = 11, Training Accuracy: 0.5333333333333333
Training loss = 0.030235152045885724
step = 12, Training Accuracy: 0.5833333333333334
Training loss = 0.029591273069381713
step = 13, Training Accuracy: 0.5533333333333333
Training loss = 0.028462398648262024
step = 14, Training Accuracy: 0.62
Validation Accuracy: 0.56875
6  	8     	0.577187	0.0179925	0.54125	0.60125
params:  [0.38973222283164954, 0.8938866398850087, 0.4195209391588055, 0.2577151818454293, 0.17415965316460624, 0.5059120888740171, 0.39848777491067233, 0.8014859841652722, 0.5926017537313002, 0.01, 0.42503549713158995, 0.08654519940817923, 0.41807361940174526, 0.6389862198275372, 0.9018334150335, 0.34149558091981846, 0.014645255565281151, 0.5950936017699511, 0.8862382752090694, 0.3334265072315282, 0.3513329315265241, 0.5912318765838108, 0.97621216132461, 0.714454939125823, 0.4176305966890889, 0.03776594316354154, 0.2594916933478127, 0.01, 0.7317457781733736, 0.4390571690231128, 0.3206491053815571, 0.947336436263037, 0.12319507808009175, 0.01, 0.8367428550734528, 0.6574080782422855, 0.01, 0.9394768031364087, 0.7671009551111823, 0.151497806217676, 0.5630028848173251, 0.4121509518097823, 0.2588229233403875, 0.43828671858408186, 0.8592268433591634, 0.8370624073586663, 0.254658018394504, 0.5671227960653631, 0.99, 0.8405386259095197, 0.99, 0.8095575180772772, 0.01, 0.36341197138758513, 0.12559345207494244, 0.6672119879145147, 0.49740913505552153, 0.3752384931657288, 0.7793429640921875, 0.34451203235608346, 0.3897678375137799, 0.47205507037478694, 0.3000578282266813, 0.697609532214162, 0.8423075583041129, 0.7820616438215898, 0.36257442305163645, 0.010955449731157807, 0.12050991141358605, 0.8396530250761242, 0.01, 0.01, 0.20804417539192144, 0.5344575983082451, 0.21611328551398015, 0.6628670318681565, 0.6920982740212527, 0.1926193177765167, 0.1518754386272321, 0.5883951396085787, 0.99, 0.9349715659721115, 0.7709565594281809, 0.17568301498067201, 0.42734180648028985, 0.22943143653480635, 0.37782196561422665, 0.01, 0.01, 0.1334815685186061, 0.01, 0.01]
[0.38973222283164954, 0.8938866398850087, 0.4195209391588055, 0.2577151818454293, 0.17415965316460624, 0.5059120888740171, 0.39848777491067233, 0.8014859841652722, 0.5926017537313002, 0.01, 0.42503549713158995, 0.08654519940817923, 0.41807361940174526, 0.6389862198275372, 0.9018334150335, 0.34149558091981846, 0.014645255565281151, 0.5950936017699511, 0.8862382752090694, 0.3334265072315282, 0.3513329315265241, 0.5912318765838108, 0.97621216132461, 0.714454939125823, 0.4176305966890889, 0.03776594316354154, 0.2594916933478127, 0.01, 0.7317457781733736, 0.4390571690231128, 0.3206491053815571, 0.947336436263037, 0.12319507808009175, 0.01, 0.8367428550734528, 0.6574080782422855, 0.01, 0.9394768031364087, 0.7671009551111823, 0.151497806217676, 0.5630028848173251, 0.4121509518097823, 0.2588229233403875, 0.43828671858408186, 0.8592268433591634, 0.8370624073586663, 0.254658018394504, 0.5671227960653631, 0.99, 0.8405386259095197, 0.99, 0.8095575180772772, 0.01, 0.36341197138758513, 0.12559345207494244, 0.6672119879145147, 0.49740913505552153, 0.3752384931657288, 0.7793429640921875, 0.34451203235608346, 0.3897678375137799, 0.47205507037478694, 0.3000578282266813, 0.697609532214162, 0.8423075583041129, 0.7820616438215898, 0.36257442305163645, 0.010955449731157807, 0.12050991141358605, 0.8396530250761242, 0.01, 0.01, 0.20804417539192144, 0.5344575983082451, 0.21611328551398015, 0.6628670318681565, 0.6920982740212527, 0.1926193177765167, 0.1518754386272321, 0.5883951396085787, 0.99, 0.9349715659721115, 0.7709565594281809, 0.17568301498067201, 0.42734180648028985, 0.22943143653480635, 0.37782196561422665, 0.01, 0.01, 0.1334815685186061, 0.01, 0.01]
Training loss = 0.036424337824185686
step = 0, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.59
Training loss = 0.03378082970778147
step = 1, Training Accuracy: 0.45
Training loss = 0.03304820160071055
step = 2, Training Accuracy: 0.49333333333333335
Training loss = 0.03268511136372884
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.03320649405320485
step = 4, Training Accuracy: 0.47
Training loss = 0.03460576097170512
step = 5, Training Accuracy: 0.42333333333333334
Validation Accuracy: 0.54375
Training loss = 0.03413293997446696
step = 6, Training Accuracy: 0.44666666666666666
Training loss = 0.032439392209053036
step = 7, Training Accuracy: 0.49
Training loss = 0.031297061840693155
step = 8, Training Accuracy: 0.5366666666666666
Training loss = 0.03250651220480601
step = 9, Training Accuracy: 0.51
Training loss = 0.0322495440642039
step = 10, Training Accuracy: 0.49
Validation Accuracy: 0.565
Training loss = 0.03261981924374898
step = 11, Training Accuracy: 0.5033333333333333
Training loss = 0.033696797688802085
step = 12, Training Accuracy: 0.47333333333333333
Training loss = 0.033463627099990845
step = 13, Training Accuracy: 0.49
Training loss = 0.03256094296773275
step = 14, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.56625
params:  [0.15229503462133945, 0.5867155833246146, 0.99, 0.25199785425056864, 0.3048319981952525, 0.2581190685381982, 0.2497274450818728, 0.5407210893632065, 0.7957218158833795, 0.10728914564182468, 0.2891864712546913, 0.09773429192354335, 0.2173368354368495, 0.01, 0.8975366935711347, 0.9037232895181261, 0.2526239707878372, 0.5201465427030961, 0.5930019966100223, 0.7106208929461808, 0.3696997318228907, 0.570559122919584, 0.6768453160799641, 0.5258518165194976, 0.6401552264884045, 0.01, 0.12494305853131768, 0.6601478366389815, 0.13832558967353237, 0.7830618159369958, 0.3350691163099685, 0.659758279305017, 0.21921328294411813, 0.4109707373120573, 0.6377329081453457, 0.11907525625650395, 0.01, 0.3788158408630239, 0.6320589857937494, 0.05309438307345912, 0.39694394854545745, 0.11945919320112117, 0.01, 0.37387461465712596, 0.99, 0.9848574277158773, 0.7561067356392499, 0.8812417089086233, 0.99, 0.99, 0.99, 0.8551909322010474, 0.29201138485465605, 0.01, 0.022945936028757677, 0.8183400262427752, 0.44767008059057645, 0.32850473791703216, 0.46840096896997707, 0.45350972948877033, 0.5137407680183405, 0.01, 0.30901303507457234, 0.456471923571077, 0.7255119043372787, 0.25258348005095654, 0.6443711199121311, 0.01, 0.5239189062227003, 0.6604653823832165, 0.15745941043020592, 0.01, 0.5842780614117429, 0.7280625309276262, 0.6991793086476351, 0.7118496742219066, 0.7365567550938361, 0.280971217299096, 0.08195343487410245, 0.45176650686267733, 0.99, 0.99, 0.99, 0.3278893164051191, 0.7100312855821823, 0.01, 0.41277142082356866, 0.026724817031661838, 0.32748541150619737, 0.19261380092456387, 0.4394461622380477, 0.01]
[0.15229503462133945, 0.5867155833246146, 0.99, 0.25199785425056864, 0.3048319981952525, 0.2581190685381982, 0.2497274450818728, 0.5407210893632065, 0.7957218158833795, 0.10728914564182468, 0.2891864712546913, 0.09773429192354335, 0.2173368354368495, 0.01, 0.8975366935711347, 0.9037232895181261, 0.2526239707878372, 0.5201465427030961, 0.5930019966100223, 0.7106208929461808, 0.3696997318228907, 0.570559122919584, 0.6768453160799641, 0.5258518165194976, 0.6401552264884045, 0.01, 0.12494305853131768, 0.6601478366389815, 0.13832558967353237, 0.7830618159369958, 0.3350691163099685, 0.659758279305017, 0.21921328294411813, 0.4109707373120573, 0.6377329081453457, 0.11907525625650395, 0.01, 0.3788158408630239, 0.6320589857937494, 0.05309438307345912, 0.39694394854545745, 0.11945919320112117, 0.01, 0.37387461465712596, 0.99, 0.9848574277158773, 0.7561067356392499, 0.8812417089086233, 0.99, 0.99, 0.99, 0.8551909322010474, 0.29201138485465605, 0.01, 0.022945936028757677, 0.8183400262427752, 0.44767008059057645, 0.32850473791703216, 0.46840096896997707, 0.45350972948877033, 0.5137407680183405, 0.01, 0.30901303507457234, 0.456471923571077, 0.7255119043372787, 0.25258348005095654, 0.6443711199121311, 0.01, 0.5239189062227003, 0.6604653823832165, 0.15745941043020592, 0.01, 0.5842780614117429, 0.7280625309276262, 0.6991793086476351, 0.7118496742219066, 0.7365567550938361, 0.280971217299096, 0.08195343487410245, 0.45176650686267733, 0.99, 0.99, 0.99, 0.3278893164051191, 0.7100312855821823, 0.01, 0.41277142082356866, 0.026724817031661838, 0.32748541150619737, 0.19261380092456387, 0.4394461622380477, 0.01]
Training loss = 0.03478573679924011
step = 0, Training Accuracy: 0.47
Validation Accuracy: 0.5975
Training loss = 0.034971487323443094
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.0345594847202301
step = 2, Training Accuracy: 0.46
Training loss = 0.0345471986134847
step = 3, Training Accuracy: 0.45
Training loss = 0.033987908363342284
step = 4, Training Accuracy: 0.44
Training loss = 0.03415229399998983
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.60125
Training loss = 0.0335463817914327
step = 6, Training Accuracy: 0.47333333333333333
Training loss = 0.036218149463335673
step = 7, Training Accuracy: 0.4266666666666667
Training loss = 0.03343885918458303
step = 8, Training Accuracy: 0.4666666666666667
Training loss = 0.0344806985060374
step = 9, Training Accuracy: 0.4066666666666667
Training loss = 0.03465313990910848
step = 10, Training Accuracy: 0.45
Validation Accuracy: 0.5725
Training loss = 0.03397386431694031
step = 11, Training Accuracy: 0.4533333333333333
Training loss = 0.03456787705421448
step = 12, Training Accuracy: 0.43333333333333335
Training loss = 0.03454878290494283
step = 13, Training Accuracy: 0.43
Training loss = 0.0335251514116923
step = 14, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.5675
params:  [0.01, 0.81570425028051, 0.7557578995279242, 0.6499655449548112, 0.3749517057594624, 0.01, 0.25595314235220157, 0.9645612565155043, 0.904168889255577, 0.18288625923195095, 0.5302498518474065, 0.3489919488105485, 0.500631166728887, 0.0808335786089102, 0.93082242170957, 0.506134356047638, 0.22847342277082905, 0.4482315255069537, 0.7944877141345852, 0.7324884644267199, 0.05014844196500608, 0.4675335808630865, 0.5017731633477853, 0.5003458674887702, 0.41050912235506665, 0.08194815474878009, 0.01, 0.01, 0.5840971825718668, 0.2626686089542443, 0.27139923288942547, 0.3336708678079096, 0.46330565735624374, 0.01, 0.8034114716472783, 0.7494083311474302, 0.4155125849524446, 0.8086206068865947, 0.6122318072009489, 0.2805511556685788, 0.7325838842126992, 0.2873442648481162, 0.01, 0.37856783952815454, 0.3016927717348043, 0.8670776115975356, 0.05295477577104757, 0.6205150866042404, 0.99, 0.99, 0.99, 0.99, 0.2957025417329672, 0.3385983732639438, 0.23563390866980272, 0.6569048397171745, 0.10845181394876355, 0.7633667026727201, 0.36214280931618703, 0.1689757367283877, 0.99, 0.8297244660791271, 0.3255528813517856, 0.8165001434522117, 0.9188132343233594, 0.6262412747981584, 0.1922831666884246, 0.17503571391728884, 0.3272300419349302, 0.9352040529172253, 0.031135495154586523, 0.28354506602693247, 0.35329232226126606, 0.5997102957594176, 0.8792459461617155, 0.21309304997737621, 0.614766773300673, 0.4032294667762122, 0.7141742938794846, 0.4246455045229174, 0.685406286237756, 0.8433525835688356, 0.5621777041202197, 0.7810582554210581, 0.4180858944226627, 0.3339923676711942, 0.6318911307778918, 0.01, 0.01, 0.11391617489706307, 0.46838800585999224, 0.23725111929520099]
[0.01, 0.81570425028051, 0.7557578995279242, 0.6499655449548112, 0.3749517057594624, 0.01, 0.25595314235220157, 0.9645612565155043, 0.904168889255577, 0.18288625923195095, 0.5302498518474065, 0.3489919488105485, 0.500631166728887, 0.0808335786089102, 0.93082242170957, 0.506134356047638, 0.22847342277082905, 0.4482315255069537, 0.7944877141345852, 0.7324884644267199, 0.05014844196500608, 0.4675335808630865, 0.5017731633477853, 0.5003458674887702, 0.41050912235506665, 0.08194815474878009, 0.01, 0.01, 0.5840971825718668, 0.2626686089542443, 0.27139923288942547, 0.3336708678079096, 0.46330565735624374, 0.01, 0.8034114716472783, 0.7494083311474302, 0.4155125849524446, 0.8086206068865947, 0.6122318072009489, 0.2805511556685788, 0.7325838842126992, 0.2873442648481162, 0.01, 0.37856783952815454, 0.3016927717348043, 0.8670776115975356, 0.05295477577104757, 0.6205150866042404, 0.99, 0.99, 0.99, 0.99, 0.2957025417329672, 0.3385983732639438, 0.23563390866980272, 0.6569048397171745, 0.10845181394876355, 0.7633667026727201, 0.36214280931618703, 0.1689757367283877, 0.99, 0.8297244660791271, 0.3255528813517856, 0.8165001434522117, 0.9188132343233594, 0.6262412747981584, 0.1922831666884246, 0.17503571391728884, 0.3272300419349302, 0.9352040529172253, 0.031135495154586523, 0.28354506602693247, 0.35329232226126606, 0.5997102957594176, 0.8792459461617155, 0.21309304997737621, 0.614766773300673, 0.4032294667762122, 0.7141742938794846, 0.4246455045229174, 0.685406286237756, 0.8433525835688356, 0.5621777041202197, 0.7810582554210581, 0.4180858944226627, 0.3339923676711942, 0.6318911307778918, 0.01, 0.01, 0.11391617489706307, 0.46838800585999224, 0.23725111929520099]
Training loss = 0.032568733096122744
step = 0, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.55875
Training loss = 0.032192547917366025
step = 1, Training Accuracy: 0.5133333333333333
Training loss = 0.033450857996940614
step = 2, Training Accuracy: 0.47333333333333333
Training loss = 0.03251420021057129
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03203231374422709
step = 4, Training Accuracy: 0.5233333333333333
Training loss = 0.03261141498883565
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.585
Training loss = 0.031472869714101154
step = 6, Training Accuracy: 0.49
Training loss = 0.031806699832280474
step = 7, Training Accuracy: 0.5166666666666667
Training loss = 0.03227995832761129
step = 8, Training Accuracy: 0.5166666666666667
Training loss = 0.03271023452281952
step = 9, Training Accuracy: 0.5066666666666667
Training loss = 0.032086132168769835
step = 10, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.6025
Training loss = 0.03299079279104868
step = 11, Training Accuracy: 0.51
Training loss = 0.03150294284025828
step = 12, Training Accuracy: 0.5266666666666666
Training loss = 0.031303935647010804
step = 13, Training Accuracy: 0.5033333333333333
Training loss = 0.031992817322413124
step = 14, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.61125
params:  [0.04804071775595531, 0.7314002261013577, 0.9510363292384282, 0.12289443037417946, 0.5077331013404048, 0.17513341097468174, 0.99, 0.9536533367632649, 0.8722390619531778, 0.01, 0.23145221025170337, 0.01, 0.5075704083794839, 0.2786180427435401, 0.6318000307655692, 0.22228925570215805, 0.01, 0.48459612482860626, 0.99, 0.01, 0.2135980430897238, 0.7757162205372561, 0.4873928305805195, 0.6673437565630136, 0.5503568340518011, 0.10086541861702246, 0.3304905497375467, 0.01, 0.5134916058883914, 0.4245885981219834, 0.37502498358628744, 0.5850009009369692, 0.052385692360467334, 0.2674706851229949, 0.7432232113986373, 0.9238845949337547, 0.03382702552232458, 0.6991514368333526, 0.44349267410636845, 0.35251313074335744, 0.38945175791451386, 0.4489702931254873, 0.01, 0.06605982810055197, 0.49074616479224864, 0.5843580584351908, 0.36225332566872714, 0.7143654656254188, 0.5953833901181254, 0.7404346635313421, 0.99, 0.99, 0.6511375437976725, 0.7052794224652769, 0.28573030424152873, 0.7263829504033621, 0.4210555347190098, 0.829161555020396, 0.3078772582649689, 0.01, 0.6985394576936531, 0.4461292909194648, 0.3396030875923993, 0.4428655955388351, 0.8857730920381335, 0.11194447303223648, 0.8115625426032966, 0.2072605681584544, 0.18412363945340682, 0.99, 0.1499513076362929, 0.7534507796229364, 0.6388274328716241, 0.7219125712465383, 0.5690370124053016, 0.6424216718265523, 0.5748653011258912, 0.1945026513929832, 0.2453232061435613, 0.593793484684142, 0.8173113043368908, 0.4428890637086419, 0.5936849185787072, 0.4742696644201179, 0.5922750280246984, 0.01, 0.46727506366856847, 0.1889602616811677, 0.4842832297147578, 0.011612551663122805, 0.13688790972235468, 0.1788756544072907]
[0.04804071775595531, 0.7314002261013577, 0.9510363292384282, 0.12289443037417946, 0.5077331013404048, 0.17513341097468174, 0.99, 0.9536533367632649, 0.8722390619531778, 0.01, 0.23145221025170337, 0.01, 0.5075704083794839, 0.2786180427435401, 0.6318000307655692, 0.22228925570215805, 0.01, 0.48459612482860626, 0.99, 0.01, 0.2135980430897238, 0.7757162205372561, 0.4873928305805195, 0.6673437565630136, 0.5503568340518011, 0.10086541861702246, 0.3304905497375467, 0.01, 0.5134916058883914, 0.4245885981219834, 0.37502498358628744, 0.5850009009369692, 0.052385692360467334, 0.2674706851229949, 0.7432232113986373, 0.9238845949337547, 0.03382702552232458, 0.6991514368333526, 0.44349267410636845, 0.35251313074335744, 0.38945175791451386, 0.4489702931254873, 0.01, 0.06605982810055197, 0.49074616479224864, 0.5843580584351908, 0.36225332566872714, 0.7143654656254188, 0.5953833901181254, 0.7404346635313421, 0.99, 0.99, 0.6511375437976725, 0.7052794224652769, 0.28573030424152873, 0.7263829504033621, 0.4210555347190098, 0.829161555020396, 0.3078772582649689, 0.01, 0.6985394576936531, 0.4461292909194648, 0.3396030875923993, 0.4428655955388351, 0.8857730920381335, 0.11194447303223648, 0.8115625426032966, 0.2072605681584544, 0.18412363945340682, 0.99, 0.1499513076362929, 0.7534507796229364, 0.6388274328716241, 0.7219125712465383, 0.5690370124053016, 0.6424216718265523, 0.5748653011258912, 0.1945026513929832, 0.2453232061435613, 0.593793484684142, 0.8173113043368908, 0.4428890637086419, 0.5936849185787072, 0.4742696644201179, 0.5922750280246984, 0.01, 0.46727506366856847, 0.1889602616811677, 0.4842832297147578, 0.011612551663122805, 0.13688790972235468, 0.1788756544072907]
Training loss = 0.031798408031463624
step = 0, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.61
Training loss = 0.03296253840128581
step = 1, Training Accuracy: 0.49333333333333335
Training loss = 0.0328684808810552
step = 2, Training Accuracy: 0.49
Training loss = 0.033059564431508384
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03337130924065908
step = 4, Training Accuracy: 0.5
Training loss = 0.031231439113616942
step = 5, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.5975
Training loss = 0.03214729309082031
step = 6, Training Accuracy: 0.51
Training loss = 0.032737727562586465
step = 7, Training Accuracy: 0.4666666666666667
Training loss = 0.03334464609622955
step = 8, Training Accuracy: 0.47
Training loss = 0.03296712358792623
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.03381815791130066
step = 10, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.59375
Training loss = 0.03223674098650615
step = 11, Training Accuracy: 0.51
Training loss = 0.032060439189275106
step = 12, Training Accuracy: 0.5133333333333333
Training loss = 0.032505841453870137
step = 13, Training Accuracy: 0.5233333333333333
Training loss = 0.033181917071342465
step = 14, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.59125
params:  [0.32000515648774175, 0.99, 0.99, 0.41149209486400634, 0.44476362943720205, 0.01, 0.4325148754676919, 0.3119841047985285, 0.3833852484743444, 0.06419405677560547, 0.7305828762867067, 0.23465240908647975, 0.18057815787398923, 0.01, 0.9584139555613305, 0.01, 0.2998422687512989, 0.08859280074688175, 0.99, 0.12066569864737078, 0.4230458036381233, 0.3281373298974608, 0.6152851177438954, 0.4892842269043747, 0.3199489860449889, 0.14501619691809423, 0.41315548837275695, 0.19354026161508603, 0.8308340485698685, 0.49769927657640267, 0.02121368112024216, 0.5229019916483493, 0.08027016434364935, 0.22412907474226798, 0.7129752186013103, 0.99, 0.06965161949420741, 0.6999039528008841, 0.7455895692654819, 0.36493342055604855, 0.574878141440979, 0.7918457427107367, 0.46007423580528606, 0.6977666746193647, 0.6413109219838767, 0.626549569192731, 0.6022560964621537, 0.8658140524704561, 0.6773133031744636, 0.8475775028154994, 0.6556332694603408, 0.8955151793434307, 0.44756411853941236, 0.15114169391206447, 0.15639386609890388, 0.2975434192544794, 0.012887642200090477, 0.6665264194697218, 0.20293131611183704, 0.8248998610553221, 0.5069705695243085, 0.9804297655364815, 0.7056023520098675, 0.48057732118835667, 0.8138865393216503, 0.034880333612980485, 0.07763646565661919, 0.28425129701104884, 0.3740584203218855, 0.9356008230559607, 0.01, 0.46381337796548383, 0.017407212146065554, 0.99, 0.556314995360201, 0.4271308147566425, 0.8383076495692268, 0.14990196818686685, 0.28009695987123545, 0.5923067654091952, 0.99, 0.8218387172351048, 0.16052249098316312, 0.4599010353450496, 0.037694872582302974, 0.01, 0.4481036701801133, 0.18770019497017235, 0.13963506031223305, 0.2334487867166019, 0.2968287895368784, 0.038646499976536186]
[0.32000515648774175, 0.99, 0.99, 0.41149209486400634, 0.44476362943720205, 0.01, 0.4325148754676919, 0.3119841047985285, 0.3833852484743444, 0.06419405677560547, 0.7305828762867067, 0.23465240908647975, 0.18057815787398923, 0.01, 0.9584139555613305, 0.01, 0.2998422687512989, 0.08859280074688175, 0.99, 0.12066569864737078, 0.4230458036381233, 0.3281373298974608, 0.6152851177438954, 0.4892842269043747, 0.3199489860449889, 0.14501619691809423, 0.41315548837275695, 0.19354026161508603, 0.8308340485698685, 0.49769927657640267, 0.02121368112024216, 0.5229019916483493, 0.08027016434364935, 0.22412907474226798, 0.7129752186013103, 0.99, 0.06965161949420741, 0.6999039528008841, 0.7455895692654819, 0.36493342055604855, 0.574878141440979, 0.7918457427107367, 0.46007423580528606, 0.6977666746193647, 0.6413109219838767, 0.626549569192731, 0.6022560964621537, 0.8658140524704561, 0.6773133031744636, 0.8475775028154994, 0.6556332694603408, 0.8955151793434307, 0.44756411853941236, 0.15114169391206447, 0.15639386609890388, 0.2975434192544794, 0.012887642200090477, 0.6665264194697218, 0.20293131611183704, 0.8248998610553221, 0.5069705695243085, 0.9804297655364815, 0.7056023520098675, 0.48057732118835667, 0.8138865393216503, 0.034880333612980485, 0.07763646565661919, 0.28425129701104884, 0.3740584203218855, 0.9356008230559607, 0.01, 0.46381337796548383, 0.017407212146065554, 0.99, 0.556314995360201, 0.4271308147566425, 0.8383076495692268, 0.14990196818686685, 0.28009695987123545, 0.5923067654091952, 0.99, 0.8218387172351048, 0.16052249098316312, 0.4599010353450496, 0.037694872582302974, 0.01, 0.4481036701801133, 0.18770019497017235, 0.13963506031223305, 0.2334487867166019, 0.2968287895368784, 0.038646499976536186]
Training loss = 0.033822863300641375
step = 0, Training Accuracy: 0.48
Validation Accuracy: 0.60125
Training loss = 0.03299642304579417
step = 1, Training Accuracy: 0.4766666666666667
Training loss = 0.03396322707335154
step = 2, Training Accuracy: 0.4766666666666667
Training loss = 0.03295754591623942
step = 3, Training Accuracy: 0.45666666666666667
Training loss = 0.03427981952826182
step = 4, Training Accuracy: 0.4666666666666667
Training loss = 0.03204598883787791
step = 5, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.58625
Training loss = 0.033431598941485084
step = 6, Training Accuracy: 0.49666666666666665
Training loss = 0.03227725585301717
step = 7, Training Accuracy: 0.49666666666666665
Training loss = 0.03301277180512746
step = 8, Training Accuracy: 0.48
Training loss = 0.0336691685517629
step = 9, Training Accuracy: 0.5
Training loss = 0.031515852212905884
step = 10, Training Accuracy: 0.5466666666666666
Validation Accuracy: 0.595
Training loss = 0.03263905425866445
step = 11, Training Accuracy: 0.4766666666666667
Training loss = 0.03311217804749807
step = 12, Training Accuracy: 0.45666666666666667
Training loss = 0.03276899000008901
step = 13, Training Accuracy: 0.5
Training loss = 0.03212285657723745
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.59875
params:  [0.151954544381475, 0.99, 0.6676630346314568, 0.8110689936107653, 0.37960431361930724, 0.14638518801626424, 0.5170144826897342, 0.99, 0.8646037209760102, 0.09723439853061694, 0.8266287484828607, 0.5692566992695489, 0.7850479182452935, 0.19442975842369017, 0.8200961629010548, 0.25948155209956614, 0.5756065386074616, 0.576833868996115, 0.9190367895312317, 0.8322382882192185, 0.01, 0.01, 0.5877097922731984, 0.795229276773008, 0.325787465249565, 0.12724572778320192, 0.4172236788119855, 0.30879082667406643, 0.25744034859087006, 0.19425245438607025, 0.2470611594211249, 0.7722665296852637, 0.20913834965993927, 0.1154125606087065, 0.5382710787184053, 0.7151362770317515, 0.01, 0.846412155899456, 0.6195512042480246, 0.029024157883456886, 0.99, 0.1426304976951209, 0.01, 0.3799897517168489, 0.5582201448250331, 0.7400791460478214, 0.725344994489963, 0.40486554311476597, 0.99, 0.5492724536776613, 0.5749763105767849, 0.8580146155310837, 0.34460438468205484, 0.3176336153398997, 0.48066095697539796, 0.7568878698279597, 0.3902849033433219, 0.9466781410364387, 0.3935472856482458, 0.11433785768383858, 0.5052100092661279, 0.3644979266645539, 0.3957627050888893, 0.3954259835297842, 0.99, 0.5466164700913695, 0.6707859346493359, 0.01, 0.01, 0.5923114928661196, 0.01, 0.01, 0.3370823029491262, 0.4795200270054126, 0.6656271525184048, 0.5503458187864498, 0.822756634180049, 0.40999497116157535, 0.5572373586207799, 0.8112951203613381, 0.6249919336031526, 0.6342725907015309, 0.7187535223708139, 0.2503159908637052, 0.01, 0.4318366589462427, 0.01, 0.01, 0.36960558530202514, 0.5796390980838569, 0.11073523169998467, 0.01]
[0.151954544381475, 0.99, 0.6676630346314568, 0.8110689936107653, 0.37960431361930724, 0.14638518801626424, 0.5170144826897342, 0.99, 0.8646037209760102, 0.09723439853061694, 0.8266287484828607, 0.5692566992695489, 0.7850479182452935, 0.19442975842369017, 0.8200961629010548, 0.25948155209956614, 0.5756065386074616, 0.576833868996115, 0.9190367895312317, 0.8322382882192185, 0.01, 0.01, 0.5877097922731984, 0.795229276773008, 0.325787465249565, 0.12724572778320192, 0.4172236788119855, 0.30879082667406643, 0.25744034859087006, 0.19425245438607025, 0.2470611594211249, 0.7722665296852637, 0.20913834965993927, 0.1154125606087065, 0.5382710787184053, 0.7151362770317515, 0.01, 0.846412155899456, 0.6195512042480246, 0.029024157883456886, 0.99, 0.1426304976951209, 0.01, 0.3799897517168489, 0.5582201448250331, 0.7400791460478214, 0.725344994489963, 0.40486554311476597, 0.99, 0.5492724536776613, 0.5749763105767849, 0.8580146155310837, 0.34460438468205484, 0.3176336153398997, 0.48066095697539796, 0.7568878698279597, 0.3902849033433219, 0.9466781410364387, 0.3935472856482458, 0.11433785768383858, 0.5052100092661279, 0.3644979266645539, 0.3957627050888893, 0.3954259835297842, 0.99, 0.5466164700913695, 0.6707859346493359, 0.01, 0.01, 0.5923114928661196, 0.01, 0.01, 0.3370823029491262, 0.4795200270054126, 0.6656271525184048, 0.5503458187864498, 0.822756634180049, 0.40999497116157535, 0.5572373586207799, 0.8112951203613381, 0.6249919336031526, 0.6342725907015309, 0.7187535223708139, 0.2503159908637052, 0.01, 0.4318366589462427, 0.01, 0.01, 0.36960558530202514, 0.5796390980838569, 0.11073523169998467, 0.01]
Training loss = 0.03217052718003591
step = 0, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.6125
Training loss = 0.0330691796541214
step = 1, Training Accuracy: 0.5166666666666667
Training loss = 0.03290010074774424
step = 2, Training Accuracy: 0.47333333333333333
Training loss = 0.032968949675559994
step = 3, Training Accuracy: 0.47333333333333333
Training loss = 0.030882320205370586
step = 4, Training Accuracy: 0.5466666666666666
Training loss = 0.03198985040187836
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.59375
Training loss = 0.03225186228752136
step = 6, Training Accuracy: 0.49666666666666665
Training loss = 0.031784225503603616
step = 7, Training Accuracy: 0.4866666666666667
Training loss = 0.031197725534439086
step = 8, Training Accuracy: 0.5
Training loss = 0.03246273418267568
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.03264204720656077
step = 10, Training Accuracy: 0.48
Validation Accuracy: 0.61375
Training loss = 0.03197795331478119
step = 11, Training Accuracy: 0.5366666666666666
Training loss = 0.031119938691457114
step = 12, Training Accuracy: 0.55
Training loss = 0.03004418353239695
step = 13, Training Accuracy: 0.5966666666666667
Training loss = 0.031215833624204
step = 14, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.61125
params:  [0.12597775664110022, 0.42681402247901545, 0.99, 0.6693029763738085, 0.6033614067287802, 0.35204066286830343, 0.395436376009405, 0.5892760677931215, 0.7014903735038625, 0.016060843962613647, 0.5976441760197182, 0.01, 0.3174918105963651, 0.11786096037260294, 0.7787463676198239, 0.47767278352665954, 0.7168525506788357, 0.39913637697884613, 0.8236723177660662, 0.13121571696755752, 0.1387239192348481, 0.5566668779891912, 0.5428823538933361, 0.6317482168588514, 0.07783040070865099, 0.23182845231926977, 0.4048298703024098, 0.08276205337683623, 0.6598211605364803, 0.4717526030293266, 0.48642694385476604, 0.3908686225237833, 0.16318753208528042, 0.01, 0.829901705991555, 0.99, 0.2004935557232186, 0.99, 0.7533560141545663, 0.3543422984623127, 0.18574891099829993, 0.8903989144799425, 0.13304596013769546, 0.12189731662785541, 0.617692824030771, 0.977351331151097, 0.43055796558382003, 0.6310767060666337, 0.9796913568414556, 0.8182087095378484, 0.99, 0.7678209384049883, 0.12488686339034344, 0.6380903754432441, 0.294736713611154, 0.45252562379849387, 0.24616189335154243, 0.3391793922793671, 0.04258163513287966, 0.20954690325140563, 0.9021168683662645, 0.5986726227992729, 0.6800364558033819, 0.7586736620014689, 0.9372570706639625, 0.3049555237619588, 0.125056901864185, 0.01, 0.19972781260184053, 0.6642900887430616, 0.01, 0.5856991898344739, 0.01, 0.40443147407168567, 0.7849844174697562, 0.6073010464168058, 0.8002921768326607, 0.01, 0.22738745716135955, 0.4849325392655577, 0.6328716435814035, 0.8377429003485131, 0.99, 0.03172623319148066, 0.6394115146283228, 0.4958079315131336, 0.3791575754163278, 0.01, 0.08658809724238845, 0.2559123668213249, 0.22193760311229876, 0.3964288622786122]
[0.12597775664110022, 0.42681402247901545, 0.99, 0.6693029763738085, 0.6033614067287802, 0.35204066286830343, 0.395436376009405, 0.5892760677931215, 0.7014903735038625, 0.016060843962613647, 0.5976441760197182, 0.01, 0.3174918105963651, 0.11786096037260294, 0.7787463676198239, 0.47767278352665954, 0.7168525506788357, 0.39913637697884613, 0.8236723177660662, 0.13121571696755752, 0.1387239192348481, 0.5566668779891912, 0.5428823538933361, 0.6317482168588514, 0.07783040070865099, 0.23182845231926977, 0.4048298703024098, 0.08276205337683623, 0.6598211605364803, 0.4717526030293266, 0.48642694385476604, 0.3908686225237833, 0.16318753208528042, 0.01, 0.829901705991555, 0.99, 0.2004935557232186, 0.99, 0.7533560141545663, 0.3543422984623127, 0.18574891099829993, 0.8903989144799425, 0.13304596013769546, 0.12189731662785541, 0.617692824030771, 0.977351331151097, 0.43055796558382003, 0.6310767060666337, 0.9796913568414556, 0.8182087095378484, 0.99, 0.7678209384049883, 0.12488686339034344, 0.6380903754432441, 0.294736713611154, 0.45252562379849387, 0.24616189335154243, 0.3391793922793671, 0.04258163513287966, 0.20954690325140563, 0.9021168683662645, 0.5986726227992729, 0.6800364558033819, 0.7586736620014689, 0.9372570706639625, 0.3049555237619588, 0.125056901864185, 0.01, 0.19972781260184053, 0.6642900887430616, 0.01, 0.5856991898344739, 0.01, 0.40443147407168567, 0.7849844174697562, 0.6073010464168058, 0.8002921768326607, 0.01, 0.22738745716135955, 0.4849325392655577, 0.6328716435814035, 0.8377429003485131, 0.99, 0.03172623319148066, 0.6394115146283228, 0.4958079315131336, 0.3791575754163278, 0.01, 0.08658809724238845, 0.2559123668213249, 0.22193760311229876, 0.3964288622786122]
Training loss = 0.03274391273657481
step = 0, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.61375
Training loss = 0.03263896067937215
step = 1, Training Accuracy: 0.4766666666666667
Training loss = 0.03104583462079366
step = 2, Training Accuracy: 0.5266666666666666
Training loss = 0.033941115538279214
step = 3, Training Accuracy: 0.4866666666666667
Training loss = 0.031381219029426574
step = 4, Training Accuracy: 0.5233333333333333
Training loss = 0.03131890098253886
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.61
Training loss = 0.032253843545913694
step = 6, Training Accuracy: 0.52
Training loss = 0.033474592765172326
step = 7, Training Accuracy: 0.4666666666666667
Training loss = 0.030590105851491294
step = 8, Training Accuracy: 0.53
Training loss = 0.03222410261631012
step = 9, Training Accuracy: 0.52
Training loss = 0.03299702286720276
step = 10, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.62
Training loss = 0.03169184386730194
step = 11, Training Accuracy: 0.55
Training loss = 0.031339203317960106
step = 12, Training Accuracy: 0.5366666666666666
Training loss = 0.03198310077190399
step = 13, Training Accuracy: 0.5166666666666667
Training loss = 0.03231298327445984
step = 14, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.615
params:  [0.3628954320421518, 0.5307166501285957, 0.61672772218471, 0.020494358248673183, 0.4972985632153989, 0.5936219344936967, 0.2903432976697885, 0.6700168288761835, 0.9545770899180833, 0.01, 0.452572398779585, 0.03723569446260655, 0.4797746826955893, 0.1561778507366209, 0.8519648661772814, 0.3899174423360533, 0.01, 0.44470223457453806, 0.8277004867834372, 0.18747458293455752, 0.38412356663193087, 0.3958848302379585, 0.7352475447412056, 0.99, 0.19302561540458568, 0.08600316864263696, 0.17310532973962106, 0.01, 0.3699124614714788, 0.6114382290045636, 0.01, 0.8706501038998657, 0.1251933965052806, 0.2468413231835564, 0.01, 0.6963827048029132, 0.01, 0.7180303458745497, 0.9354169444949878, 0.38159533709466126, 0.40162323272538725, 0.4102743690682851, 0.1005754380333736, 0.9889583299712519, 0.5548815844489596, 0.6106978562675431, 0.2488930998868968, 0.99, 0.7716490717010288, 0.42354276536122354, 0.6262598024405173, 0.99, 0.7286166789952961, 0.31897722844731324, 0.25977850064367375, 0.7926165312392585, 0.45846952625803294, 0.4205092550210281, 0.4900079598706517, 0.2648012590367712, 0.9059382380886415, 0.7023997378927539, 0.7330063027460827, 0.5336253488546547, 0.7880533321591765, 0.5060218568459244, 0.5503937329634474, 0.3980882344018658, 0.01, 0.99, 0.4186434592515366, 0.3528788841679163, 0.28460311000534344, 0.39955551834289904, 0.4291392405489762, 0.3131170557800077, 0.968057061997476, 0.48226230758650257, 0.6555738509958604, 0.7492030971329577, 0.49691754884099754, 0.8828715302925463, 0.6204436812935658, 0.31369830856735925, 0.4352961138346261, 0.01, 0.3986443638023622, 0.01, 0.19264223547332396, 0.2877457995550471, 0.2910823527866324, 0.42323018733766404]
[0.3628954320421518, 0.5307166501285957, 0.61672772218471, 0.020494358248673183, 0.4972985632153989, 0.5936219344936967, 0.2903432976697885, 0.6700168288761835, 0.9545770899180833, 0.01, 0.452572398779585, 0.03723569446260655, 0.4797746826955893, 0.1561778507366209, 0.8519648661772814, 0.3899174423360533, 0.01, 0.44470223457453806, 0.8277004867834372, 0.18747458293455752, 0.38412356663193087, 0.3958848302379585, 0.7352475447412056, 0.99, 0.19302561540458568, 0.08600316864263696, 0.17310532973962106, 0.01, 0.3699124614714788, 0.6114382290045636, 0.01, 0.8706501038998657, 0.1251933965052806, 0.2468413231835564, 0.01, 0.6963827048029132, 0.01, 0.7180303458745497, 0.9354169444949878, 0.38159533709466126, 0.40162323272538725, 0.4102743690682851, 0.1005754380333736, 0.9889583299712519, 0.5548815844489596, 0.6106978562675431, 0.2488930998868968, 0.99, 0.7716490717010288, 0.42354276536122354, 0.6262598024405173, 0.99, 0.7286166789952961, 0.31897722844731324, 0.25977850064367375, 0.7926165312392585, 0.45846952625803294, 0.4205092550210281, 0.4900079598706517, 0.2648012590367712, 0.9059382380886415, 0.7023997378927539, 0.7330063027460827, 0.5336253488546547, 0.7880533321591765, 0.5060218568459244, 0.5503937329634474, 0.3980882344018658, 0.01, 0.99, 0.4186434592515366, 0.3528788841679163, 0.28460311000534344, 0.39955551834289904, 0.4291392405489762, 0.3131170557800077, 0.968057061997476, 0.48226230758650257, 0.6555738509958604, 0.7492030971329577, 0.49691754884099754, 0.8828715302925463, 0.6204436812935658, 0.31369830856735925, 0.4352961138346261, 0.01, 0.3986443638023622, 0.01, 0.19264223547332396, 0.2877457995550471, 0.2910823527866324, 0.42323018733766404]
Training loss = 0.03579515337944031
step = 0, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.61125
Training loss = 0.0361473689476649
step = 1, Training Accuracy: 0.42333333333333334
Training loss = 0.035072187781333926
step = 2, Training Accuracy: 0.44
Training loss = 0.034998915394147234
step = 3, Training Accuracy: 0.4066666666666667
Training loss = 0.034677539269129434
step = 4, Training Accuracy: 0.45
Training loss = 0.03390947937965393
step = 5, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.61
Training loss = 0.03368749916553497
step = 6, Training Accuracy: 0.4533333333333333
Training loss = 0.03409484068552653
step = 7, Training Accuracy: 0.4166666666666667
Training loss = 0.03349863986174265
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03386000653107961
step = 9, Training Accuracy: 0.48
Training loss = 0.033438689708709717
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.6025
Training loss = 0.035232818126678465
step = 11, Training Accuracy: 0.42333333333333334
Training loss = 0.034435898661613465
step = 12, Training Accuracy: 0.47
Training loss = 0.0329770690202713
step = 13, Training Accuracy: 0.52
Training loss = 0.03362147092819214
step = 14, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.59625
7  	8     	0.594688	0.017818 	0.56625	0.615  
params:  [0.4072895246613194, 0.6824221061569303, 0.99, 0.8115111775154122, 0.9301279982231981, 0.29155304143100413, 0.15365794576120703, 0.6065970790468396, 0.9664221031076126, 0.3286704097501234, 0.8144500461667123, 0.18210718453794164, 0.5665019969535554, 0.01, 0.7322101889697985, 0.1209185160173597, 0.7407428576347963, 0.3604937258794521, 0.7279863579297757, 0.31761686356479624, 0.08334612359247608, 0.4855961124360292, 0.6495673944385199, 0.4552418823657203, 0.15549601611591857, 0.175448070777145, 0.01, 0.2295175074998756, 0.3053556192055295, 0.5276279567849955, 0.6696634166065116, 0.4214011422501314, 0.4410667600354692, 0.01, 0.99, 0.8945738226779977, 0.32795502278647315, 0.99, 0.6834229113705375, 0.3860989465613037, 0.32837462676693463, 0.6823689120058701, 0.01, 0.2585976002366464, 0.0809866472038327, 0.863860732873318, 0.2659500919003662, 0.99, 0.99, 0.4292726370036302, 0.9150841415774603, 0.823527970510614, 0.2967355998257258, 0.8450317065251258, 0.01, 0.5500546386961329, 0.22610797127266558, 0.8969542104168425, 0.12505238482140013, 0.06530862367417084, 0.99, 0.6135985164970531, 0.2316409594579366, 0.32644434664559635, 0.99, 0.25001135034168875, 0.21694441115439655, 0.01, 0.053930509217320954, 0.8048568502177312, 0.17600214868884115, 0.09237099498107165, 0.01, 0.34714340848573033, 0.99, 0.25655789383096184, 0.5460655266162423, 0.47067664118743213, 0.2565955870348753, 0.16388662031293072, 0.5997146279503321, 0.99, 0.8569568023073904, 0.2456538199598923, 0.29518665457360177, 0.31796664684906206, 0.6086540559912725, 0.033263035552279274, 0.01, 0.01, 0.5088532974333699, 0.31942948488002]
[0.4072895246613194, 0.6824221061569303, 0.99, 0.8115111775154122, 0.9301279982231981, 0.29155304143100413, 0.15365794576120703, 0.6065970790468396, 0.9664221031076126, 0.3286704097501234, 0.8144500461667123, 0.18210718453794164, 0.5665019969535554, 0.01, 0.7322101889697985, 0.1209185160173597, 0.7407428576347963, 0.3604937258794521, 0.7279863579297757, 0.31761686356479624, 0.08334612359247608, 0.4855961124360292, 0.6495673944385199, 0.4552418823657203, 0.15549601611591857, 0.175448070777145, 0.01, 0.2295175074998756, 0.3053556192055295, 0.5276279567849955, 0.6696634166065116, 0.4214011422501314, 0.4410667600354692, 0.01, 0.99, 0.8945738226779977, 0.32795502278647315, 0.99, 0.6834229113705375, 0.3860989465613037, 0.32837462676693463, 0.6823689120058701, 0.01, 0.2585976002366464, 0.0809866472038327, 0.863860732873318, 0.2659500919003662, 0.99, 0.99, 0.4292726370036302, 0.9150841415774603, 0.823527970510614, 0.2967355998257258, 0.8450317065251258, 0.01, 0.5500546386961329, 0.22610797127266558, 0.8969542104168425, 0.12505238482140013, 0.06530862367417084, 0.99, 0.6135985164970531, 0.2316409594579366, 0.32644434664559635, 0.99, 0.25001135034168875, 0.21694441115439655, 0.01, 0.053930509217320954, 0.8048568502177312, 0.17600214868884115, 0.09237099498107165, 0.01, 0.34714340848573033, 0.99, 0.25655789383096184, 0.5460655266162423, 0.47067664118743213, 0.2565955870348753, 0.16388662031293072, 0.5997146279503321, 0.99, 0.8569568023073904, 0.2456538199598923, 0.29518665457360177, 0.31796664684906206, 0.6086540559912725, 0.033263035552279274, 0.01, 0.01, 0.5088532974333699, 0.31942948488002]
Training loss = 0.034532105724016826
step = 0, Training Accuracy: 0.44333333333333336
Validation Accuracy: 0.5975
Training loss = 0.034492817918459574
step = 1, Training Accuracy: 0.45
Training loss = 0.03440594534079234
step = 2, Training Accuracy: 0.44666666666666666
Training loss = 0.03373610933621724
step = 3, Training Accuracy: 0.47333333333333333
Training loss = 0.03399143278598785
step = 4, Training Accuracy: 0.4766666666666667
Training loss = 0.03336643894513448
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.62125
Training loss = 0.034367561141649884
step = 6, Training Accuracy: 0.4866666666666667
Training loss = 0.033575648665428164
step = 7, Training Accuracy: 0.43666666666666665
Training loss = 0.033732124964396155
step = 8, Training Accuracy: 0.47333333333333333
Training loss = 0.033224443793296816
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.033571328520774844
step = 10, Training Accuracy: 0.49
Validation Accuracy: 0.61625
Training loss = 0.033205069104830426
step = 11, Training Accuracy: 0.48
Training loss = 0.03423032482465108
step = 12, Training Accuracy: 0.45666666666666667
Training loss = 0.03358981152375539
step = 13, Training Accuracy: 0.45666666666666667
Training loss = 0.03297779122988383
step = 14, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.615
params:  [0.01, 0.8591472990091731, 0.9183757098081521, 0.5014051371840913, 0.5789983987483356, 0.14352903297354125, 0.3688065769364722, 0.659473552697179, 0.36683656616035504, 0.14707047407595297, 0.888953381309848, 0.5383924397988125, 0.13281574541000052, 0.01, 0.99, 0.5918844876943886, 0.4824891234971986, 0.2060123419212367, 0.5552778772780211, 0.5392017663560957, 0.3024806025644476, 0.5720818488623645, 0.2420645908473062, 0.41460583734647627, 0.16212370129508666, 0.16484982455416852, 0.09439955413129919, 0.16637710284318652, 0.99, 0.563637772993849, 0.24888058542988853, 0.30462273068108603, 0.20555183255158613, 0.11970326116686683, 0.99, 0.99, 0.01, 0.9663200269386389, 0.8538726148122988, 0.8431704471997344, 0.6016157138884883, 0.7851994543668626, 0.01, 0.27475436131032643, 0.32872777877755766, 0.99, 0.30926765969283765, 0.6668966741902707, 0.976060110066053, 0.8189405199999837, 0.6715020342294312, 0.730401899390656, 0.13172129458335158, 0.6587721713602751, 0.09219365802170565, 0.8550618103058794, 0.6107416472271212, 0.43583612861440824, 0.01, 0.31957884361854055, 0.99, 0.6810368096631068, 0.9223169934007737, 0.6189333708685363, 0.9393332935324666, 0.5937419283452412, 0.37056304155289516, 0.01, 0.2561711716312809, 0.9268317111310984, 0.01, 0.01, 0.2628834445905106, 0.011364316567325117, 0.9326873004214778, 0.5673312539233595, 0.6698322823805072, 0.6078624745938107, 0.3676538407178198, 0.39091300037415116, 0.5112761392908796, 0.7546729372457059, 0.8254238769024448, 0.10754626207912993, 0.30880406727921206, 0.3374399830378521, 0.47473325541866385, 0.01, 0.5465333890701184, 0.030576498736814756, 0.5093240209903507, 0.01]
[0.01, 0.8591472990091731, 0.9183757098081521, 0.5014051371840913, 0.5789983987483356, 0.14352903297354125, 0.3688065769364722, 0.659473552697179, 0.36683656616035504, 0.14707047407595297, 0.888953381309848, 0.5383924397988125, 0.13281574541000052, 0.01, 0.99, 0.5918844876943886, 0.4824891234971986, 0.2060123419212367, 0.5552778772780211, 0.5392017663560957, 0.3024806025644476, 0.5720818488623645, 0.2420645908473062, 0.41460583734647627, 0.16212370129508666, 0.16484982455416852, 0.09439955413129919, 0.16637710284318652, 0.99, 0.563637772993849, 0.24888058542988853, 0.30462273068108603, 0.20555183255158613, 0.11970326116686683, 0.99, 0.99, 0.01, 0.9663200269386389, 0.8538726148122988, 0.8431704471997344, 0.6016157138884883, 0.7851994543668626, 0.01, 0.27475436131032643, 0.32872777877755766, 0.99, 0.30926765969283765, 0.6668966741902707, 0.976060110066053, 0.8189405199999837, 0.6715020342294312, 0.730401899390656, 0.13172129458335158, 0.6587721713602751, 0.09219365802170565, 0.8550618103058794, 0.6107416472271212, 0.43583612861440824, 0.01, 0.31957884361854055, 0.99, 0.6810368096631068, 0.9223169934007737, 0.6189333708685363, 0.9393332935324666, 0.5937419283452412, 0.37056304155289516, 0.01, 0.2561711716312809, 0.9268317111310984, 0.01, 0.01, 0.2628834445905106, 0.011364316567325117, 0.9326873004214778, 0.5673312539233595, 0.6698322823805072, 0.6078624745938107, 0.3676538407178198, 0.39091300037415116, 0.5112761392908796, 0.7546729372457059, 0.8254238769024448, 0.10754626207912993, 0.30880406727921206, 0.3374399830378521, 0.47473325541866385, 0.01, 0.5465333890701184, 0.030576498736814756, 0.5093240209903507, 0.01]
Training loss = 0.03454699079195658
step = 0, Training Accuracy: 0.46
Validation Accuracy: 0.58875
Training loss = 0.03420811673005422
step = 1, Training Accuracy: 0.46
Training loss = 0.03468807578086853
step = 2, Training Accuracy: 0.44
Training loss = 0.03388950188954671
step = 3, Training Accuracy: 0.49666666666666665
Training loss = 0.03394099533557892
step = 4, Training Accuracy: 0.45
Training loss = 0.03568795800209045
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.605
Training loss = 0.03352005461851756
step = 6, Training Accuracy: 0.48333333333333334
Training loss = 0.0340896741549174
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.0342889674504598
step = 8, Training Accuracy: 0.48
Training loss = 0.034450088342030845
step = 9, Training Accuracy: 0.48
Training loss = 0.033689354260762534
step = 10, Training Accuracy: 0.51
Validation Accuracy: 0.59
Training loss = 0.033737480243047076
step = 11, Training Accuracy: 0.48
Training loss = 0.03379047075907389
step = 12, Training Accuracy: 0.5
Training loss = 0.033889304200808205
step = 13, Training Accuracy: 0.46
Training loss = 0.03392711758613586
step = 14, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.60875
params:  [0.4951930818370541, 0.7369334892786699, 0.9042487790516319, 0.512259952019515, 0.654193031814593, 0.01, 0.48505676406948556, 0.9443958586037249, 0.8444241735694112, 0.08941326294991671, 0.99, 0.058889654115582446, 0.99, 0.01, 0.8200944367973249, 0.46042467206916265, 0.2506874394037911, 0.29585415318572617, 0.4060700103452169, 0.10624205672683151, 0.26424228045050535, 0.17000481052298305, 0.8547192811087261, 0.7546403272543566, 0.3755780626015508, 0.01, 0.3255754772612208, 0.10193393666086921, 0.34159540633907803, 0.3047996519546614, 0.6966002158524581, 0.2860951346585735, 0.5379633137796169, 0.03769451901107366, 0.7057920669917171, 0.99, 0.11200313730920058, 0.7823830997226834, 0.8419870947883721, 0.2696998120690495, 0.18546508508530635, 0.789333602706008, 0.01, 0.45654609213130826, 0.964729235192454, 0.8783107696886508, 0.5609440160768544, 0.5310356573125878, 0.7316013685047185, 0.99, 0.99, 0.9617572071534861, 0.3045352587167584, 0.29550174515805927, 0.44240836389329885, 0.45917468551655494, 0.35477121742765927, 0.9432193221917033, 0.5008327490715462, 0.26501041126929126, 0.99, 0.99, 0.8345383700044147, 0.9798035445136549, 0.99, 0.037799410735227135, 0.01, 0.637412284770358, 0.01, 0.8684671870700382, 0.01, 0.6730426604024425, 0.01, 0.36601018844091404, 0.6540773768561738, 0.5543077335416149, 0.4772268048432752, 0.13980284135446935, 0.32881602689143785, 0.7136308345517348, 0.7722680389565851, 0.8765537856836444, 0.49287928189048497, 0.2848358731001684, 0.6950912184995581, 0.4383359286405961, 0.587231569438, 0.19146538996264967, 0.21293816846031144, 0.26205234906519953, 0.41983224658525875, 0.99]
[0.4951930818370541, 0.7369334892786699, 0.9042487790516319, 0.512259952019515, 0.654193031814593, 0.01, 0.48505676406948556, 0.9443958586037249, 0.8444241735694112, 0.08941326294991671, 0.99, 0.058889654115582446, 0.99, 0.01, 0.8200944367973249, 0.46042467206916265, 0.2506874394037911, 0.29585415318572617, 0.4060700103452169, 0.10624205672683151, 0.26424228045050535, 0.17000481052298305, 0.8547192811087261, 0.7546403272543566, 0.3755780626015508, 0.01, 0.3255754772612208, 0.10193393666086921, 0.34159540633907803, 0.3047996519546614, 0.6966002158524581, 0.2860951346585735, 0.5379633137796169, 0.03769451901107366, 0.7057920669917171, 0.99, 0.11200313730920058, 0.7823830997226834, 0.8419870947883721, 0.2696998120690495, 0.18546508508530635, 0.789333602706008, 0.01, 0.45654609213130826, 0.964729235192454, 0.8783107696886508, 0.5609440160768544, 0.5310356573125878, 0.7316013685047185, 0.99, 0.99, 0.9617572071534861, 0.3045352587167584, 0.29550174515805927, 0.44240836389329885, 0.45917468551655494, 0.35477121742765927, 0.9432193221917033, 0.5008327490715462, 0.26501041126929126, 0.99, 0.99, 0.8345383700044147, 0.9798035445136549, 0.99, 0.037799410735227135, 0.01, 0.637412284770358, 0.01, 0.8684671870700382, 0.01, 0.6730426604024425, 0.01, 0.36601018844091404, 0.6540773768561738, 0.5543077335416149, 0.4772268048432752, 0.13980284135446935, 0.32881602689143785, 0.7136308345517348, 0.7722680389565851, 0.8765537856836444, 0.49287928189048497, 0.2848358731001684, 0.6950912184995581, 0.4383359286405961, 0.587231569438, 0.19146538996264967, 0.21293816846031144, 0.26205234906519953, 0.41983224658525875, 0.99]
Training loss = 0.03274447719256083
step = 0, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.60625
Training loss = 0.0340805455048879
step = 1, Training Accuracy: 0.47
Training loss = 0.035507610638936364
step = 2, Training Accuracy: 0.47
Training loss = 0.03496402045090993
step = 3, Training Accuracy: 0.4266666666666667
Training loss = 0.03424531161785126
step = 4, Training Accuracy: 0.4666666666666667
Training loss = 0.03355375170707703
step = 5, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.61
Training loss = 0.0349793150027593
step = 6, Training Accuracy: 0.42
Training loss = 0.033384893536567685
step = 7, Training Accuracy: 0.5
Training loss = 0.032831209699312844
step = 8, Training Accuracy: 0.5266666666666666
Training loss = 0.03384362479050954
step = 9, Training Accuracy: 0.45
Training loss = 0.0335891991853714
step = 10, Training Accuracy: 0.44333333333333336
Validation Accuracy: 0.5875
Training loss = 0.03317159910996755
step = 11, Training Accuracy: 0.5
Training loss = 0.03238008558750152
step = 12, Training Accuracy: 0.48333333333333334
Training loss = 0.034043410619099934
step = 13, Training Accuracy: 0.4766666666666667
Training loss = 0.034268911282221474
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.60375
params:  [0.01, 0.4343457982092145, 0.4929757174453555, 0.6000631627796845, 0.501732696199434, 0.36540016712061707, 0.10990334964015641, 0.3266949643439589, 0.4867263330557011, 0.01, 0.3991405705684177, 0.017640116678353246, 0.40566182043331045, 0.3182088028508448, 0.6435388699053767, 0.4137914316409759, 0.7435343140351588, 0.25889571466945727, 0.99, 0.41687564326367493, 0.2173511105511869, 0.2602821401040515, 0.46623893517418685, 0.6530591314761254, 0.23093330788199723, 0.173891618024804, 0.01, 0.09984655608138962, 0.5974496313133625, 0.4361701175198546, 0.39723380887378756, 0.3198845021182448, 0.3680636798950037, 0.08650402101814036, 0.36260167016027584, 0.6714420698807074, 0.13291645947694192, 0.3091563101793714, 0.8873067352183359, 0.01, 0.11339827942404668, 0.8980914442475825, 0.01, 0.01, 0.99, 0.99, 0.3588701819848858, 0.7175386885833832, 0.7010862618541438, 0.99, 0.7980456943723309, 0.8346201940261563, 0.3924952973358212, 0.2637770589258086, 0.2778160999712933, 0.5201369507180402, 0.40801364625901926, 0.6785624015219057, 0.03115234596090008, 0.15734397627616228, 0.99, 0.08489224741116352, 0.42469446658728516, 0.7315156066272092, 0.99, 0.5040626033482883, 0.01, 0.01, 0.01, 0.5676979814631313, 0.01, 0.2305701844897268, 0.121229625891557, 0.4368300048785589, 0.7221067701657439, 0.5997326697571074, 0.7793015435942137, 0.3891458403000454, 0.99, 0.2394505347194974, 0.6045848293160118, 0.6665314736711749, 0.737572512357567, 0.46311852697443373, 0.6646018723151894, 0.1598935321192162, 0.35070845785228144, 0.272924823473058, 0.0932612632887795, 0.6638954116346474, 0.050448868409514736, 0.6877105941404027]
[0.01, 0.4343457982092145, 0.4929757174453555, 0.6000631627796845, 0.501732696199434, 0.36540016712061707, 0.10990334964015641, 0.3266949643439589, 0.4867263330557011, 0.01, 0.3991405705684177, 0.017640116678353246, 0.40566182043331045, 0.3182088028508448, 0.6435388699053767, 0.4137914316409759, 0.7435343140351588, 0.25889571466945727, 0.99, 0.41687564326367493, 0.2173511105511869, 0.2602821401040515, 0.46623893517418685, 0.6530591314761254, 0.23093330788199723, 0.173891618024804, 0.01, 0.09984655608138962, 0.5974496313133625, 0.4361701175198546, 0.39723380887378756, 0.3198845021182448, 0.3680636798950037, 0.08650402101814036, 0.36260167016027584, 0.6714420698807074, 0.13291645947694192, 0.3091563101793714, 0.8873067352183359, 0.01, 0.11339827942404668, 0.8980914442475825, 0.01, 0.01, 0.99, 0.99, 0.3588701819848858, 0.7175386885833832, 0.7010862618541438, 0.99, 0.7980456943723309, 0.8346201940261563, 0.3924952973358212, 0.2637770589258086, 0.2778160999712933, 0.5201369507180402, 0.40801364625901926, 0.6785624015219057, 0.03115234596090008, 0.15734397627616228, 0.99, 0.08489224741116352, 0.42469446658728516, 0.7315156066272092, 0.99, 0.5040626033482883, 0.01, 0.01, 0.01, 0.5676979814631313, 0.01, 0.2305701844897268, 0.121229625891557, 0.4368300048785589, 0.7221067701657439, 0.5997326697571074, 0.7793015435942137, 0.3891458403000454, 0.99, 0.2394505347194974, 0.6045848293160118, 0.6665314736711749, 0.737572512357567, 0.46311852697443373, 0.6646018723151894, 0.1598935321192162, 0.35070845785228144, 0.272924823473058, 0.0932612632887795, 0.6638954116346474, 0.050448868409514736, 0.6877105941404027]
Training loss = 0.031568672060966495
step = 0, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.6
Training loss = 0.031409512956937155
step = 1, Training Accuracy: 0.54
Training loss = 0.03184278627236684
step = 2, Training Accuracy: 0.5
Training loss = 0.03127062181631724
step = 3, Training Accuracy: 0.5566666666666666
Training loss = 0.031298376123110455
step = 4, Training Accuracy: 0.5466666666666666
Training loss = 0.03217842360337575
step = 5, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.62375
Training loss = 0.03240474422772725
step = 6, Training Accuracy: 0.5
Training loss = 0.031189462939898174
step = 7, Training Accuracy: 0.53
Training loss = 0.03139879028002421
step = 8, Training Accuracy: 0.5533333333333333
Training loss = 0.031334651708602904
step = 9, Training Accuracy: 0.5666666666666667
Training loss = 0.0321997062365214
step = 10, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.61125
Training loss = 0.03145130852858225
step = 11, Training Accuracy: 0.5366666666666666
Training loss = 0.030635924339294435
step = 12, Training Accuracy: 0.5633333333333334
Training loss = 0.03095781405766805
step = 13, Training Accuracy: 0.5433333333333333
Training loss = 0.030626249313354493
step = 14, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.5975
params:  [0.01, 0.8003957660102005, 0.7662000295756427, 0.2764463573878819, 0.416659386923237, 0.21104136858252504, 0.2327099298333952, 0.99, 0.99, 0.01, 0.3046051816818319, 0.346348649204089, 0.24214293011885857, 0.37563262907373907, 0.36806253383097126, 0.48315549636361405, 0.7434372644264802, 0.29274787948781156, 0.6883798219663984, 0.7320863635785957, 0.01, 0.3319005292311051, 0.40106935730020443, 0.7842595365596747, 0.02011926884433146, 0.2116793392036579, 0.4149337959623088, 0.01, 0.7918213179216671, 0.3163023247718893, 0.3434598937821244, 0.1531982238927343, 0.01, 0.01, 0.5746412541724565, 0.99, 0.020682413245084075, 0.8993156591938085, 0.8605070842292397, 0.01, 0.7847330927511876, 0.4712260683362352, 0.056936705389998545, 0.01, 0.7450982613707007, 0.9568453238334803, 0.4105372443828064, 0.6972909964231071, 0.99, 0.8250692023936019, 0.99, 0.99, 0.280503763258852, 0.33199718945127854, 0.5146081596869472, 0.6035438985673561, 0.2898117199559076, 0.871754634519468, 0.34068818960534736, 0.1999691615821409, 0.7742838325509254, 0.8547769805131245, 0.5739445540418137, 0.5496096529362223, 0.6794799642795578, 0.184849343574676, 0.01, 0.10562808493141328, 0.1505389839671401, 0.6693003408569848, 0.29349257013493035, 0.6032115758775806, 0.21628873406280133, 0.7928550857070473, 0.99, 0.7141129614751328, 0.7185480516533757, 0.01, 0.7162940341452133, 0.8265702189815373, 0.5492525248551859, 0.5865795017280809, 0.5277148275021493, 0.3287128675184757, 0.19238493691662856, 0.01, 0.3900141805641657, 0.01, 0.27940787663626987, 0.4397037599179565, 0.6797630289742049, 0.01]
[0.01, 0.8003957660102005, 0.7662000295756427, 0.2764463573878819, 0.416659386923237, 0.21104136858252504, 0.2327099298333952, 0.99, 0.99, 0.01, 0.3046051816818319, 0.346348649204089, 0.24214293011885857, 0.37563262907373907, 0.36806253383097126, 0.48315549636361405, 0.7434372644264802, 0.29274787948781156, 0.6883798219663984, 0.7320863635785957, 0.01, 0.3319005292311051, 0.40106935730020443, 0.7842595365596747, 0.02011926884433146, 0.2116793392036579, 0.4149337959623088, 0.01, 0.7918213179216671, 0.3163023247718893, 0.3434598937821244, 0.1531982238927343, 0.01, 0.01, 0.5746412541724565, 0.99, 0.020682413245084075, 0.8993156591938085, 0.8605070842292397, 0.01, 0.7847330927511876, 0.4712260683362352, 0.056936705389998545, 0.01, 0.7450982613707007, 0.9568453238334803, 0.4105372443828064, 0.6972909964231071, 0.99, 0.8250692023936019, 0.99, 0.99, 0.280503763258852, 0.33199718945127854, 0.5146081596869472, 0.6035438985673561, 0.2898117199559076, 0.871754634519468, 0.34068818960534736, 0.1999691615821409, 0.7742838325509254, 0.8547769805131245, 0.5739445540418137, 0.5496096529362223, 0.6794799642795578, 0.184849343574676, 0.01, 0.10562808493141328, 0.1505389839671401, 0.6693003408569848, 0.29349257013493035, 0.6032115758775806, 0.21628873406280133, 0.7928550857070473, 0.99, 0.7141129614751328, 0.7185480516533757, 0.01, 0.7162940341452133, 0.8265702189815373, 0.5492525248551859, 0.5865795017280809, 0.5277148275021493, 0.3287128675184757, 0.19238493691662856, 0.01, 0.3900141805641657, 0.01, 0.27940787663626987, 0.4397037599179565, 0.6797630289742049, 0.01]
Training loss = 0.0335514227549235
step = 0, Training Accuracy: 0.51
Validation Accuracy: 0.60625
Training loss = 0.031124932567278545
step = 1, Training Accuracy: 0.5533333333333333
Training loss = 0.03149866123994192
step = 2, Training Accuracy: 0.5033333333333333
Training loss = 0.03191411296526591
step = 3, Training Accuracy: 0.5166666666666667
Training loss = 0.030857877731323244
step = 4, Training Accuracy: 0.52
Training loss = 0.03166991194089254
step = 5, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.625
Training loss = 0.031135124762852986
step = 6, Training Accuracy: 0.5233333333333333
Training loss = 0.031640438238779704
step = 7, Training Accuracy: 0.53
Training loss = 0.03180599808692932
step = 8, Training Accuracy: 0.51
Training loss = 0.03163962264855703
step = 9, Training Accuracy: 0.51
Training loss = 0.03262444694836934
step = 10, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.6325
Training loss = 0.030515592694282532
step = 11, Training Accuracy: 0.57
Training loss = 0.03085671822230021
step = 12, Training Accuracy: 0.53
Training loss = 0.03132035970687866
step = 13, Training Accuracy: 0.5033333333333333
Training loss = 0.032188384532928466
step = 14, Training Accuracy: 0.51
Validation Accuracy: 0.63625
params:  [0.01, 0.629998159853393, 0.9000003687353586, 0.6616955164582398, 0.3711090539458938, 0.5710797932098985, 0.6036670820602318, 0.7692251853282521, 0.9277674870441219, 0.01407348635566634, 0.4413396293018156, 0.09548562335551346, 0.380808300682779, 0.1824596674300939, 0.868732389709575, 0.36218991918639454, 0.529191679638422, 0.5172071927894488, 0.7907905311436256, 0.41475936974851685, 0.12719546336660484, 0.4664035790232928, 0.9810641988882451, 0.4198864307984871, 0.2698193709805962, 0.22376329469972864, 0.4540498733466363, 0.24105772918129345, 0.7260277138672891, 0.03595382827391913, 0.4881281494987729, 0.24735968359563767, 0.01, 0.17622562618161663, 0.99, 0.2413313751144177, 0.5516899003082875, 0.9473997847490256, 0.41591526976646404, 0.9067283844953529, 0.5049661720947749, 0.5472109746924122, 0.12524631131670672, 0.01, 0.43800021868817113, 0.99, 0.6843469549411278, 0.26203697600708964, 0.9091068220985764, 0.99, 0.8204909681705235, 0.5578743726136008, 0.38533833632199077, 0.22005675857729434, 0.0321356188979694, 0.8004216474787216, 0.20159356297517117, 0.2522295517219699, 0.24303531710316909, 0.16325984815065717, 0.6879377551802127, 0.4503984541298508, 0.04921686993243807, 0.5216304375794247, 0.99, 0.01, 0.022403584323965664, 0.03545449098130303, 0.07471144083244644, 0.7989082728370794, 0.08769541153768276, 0.15483282969163392, 0.2475632147655351, 0.7317721441038381, 0.7634832019498592, 0.2917806447831567, 0.99, 0.01, 0.5270930607981716, 0.28345219779231673, 0.5044175942450093, 0.5357401973642633, 0.9560548404640881, 0.6060054193483215, 0.2586047977804413, 0.16166287526541834, 0.7139319906834732, 0.24609147862942743, 0.01, 0.36269874507294547, 0.2428453817864386, 0.01]
[0.01, 0.629998159853393, 0.9000003687353586, 0.6616955164582398, 0.3711090539458938, 0.5710797932098985, 0.6036670820602318, 0.7692251853282521, 0.9277674870441219, 0.01407348635566634, 0.4413396293018156, 0.09548562335551346, 0.380808300682779, 0.1824596674300939, 0.868732389709575, 0.36218991918639454, 0.529191679638422, 0.5172071927894488, 0.7907905311436256, 0.41475936974851685, 0.12719546336660484, 0.4664035790232928, 0.9810641988882451, 0.4198864307984871, 0.2698193709805962, 0.22376329469972864, 0.4540498733466363, 0.24105772918129345, 0.7260277138672891, 0.03595382827391913, 0.4881281494987729, 0.24735968359563767, 0.01, 0.17622562618161663, 0.99, 0.2413313751144177, 0.5516899003082875, 0.9473997847490256, 0.41591526976646404, 0.9067283844953529, 0.5049661720947749, 0.5472109746924122, 0.12524631131670672, 0.01, 0.43800021868817113, 0.99, 0.6843469549411278, 0.26203697600708964, 0.9091068220985764, 0.99, 0.8204909681705235, 0.5578743726136008, 0.38533833632199077, 0.22005675857729434, 0.0321356188979694, 0.8004216474787216, 0.20159356297517117, 0.2522295517219699, 0.24303531710316909, 0.16325984815065717, 0.6879377551802127, 0.4503984541298508, 0.04921686993243807, 0.5216304375794247, 0.99, 0.01, 0.022403584323965664, 0.03545449098130303, 0.07471144083244644, 0.7989082728370794, 0.08769541153768276, 0.15483282969163392, 0.2475632147655351, 0.7317721441038381, 0.7634832019498592, 0.2917806447831567, 0.99, 0.01, 0.5270930607981716, 0.28345219779231673, 0.5044175942450093, 0.5357401973642633, 0.9560548404640881, 0.6060054193483215, 0.2586047977804413, 0.16166287526541834, 0.7139319906834732, 0.24609147862942743, 0.01, 0.36269874507294547, 0.2428453817864386, 0.01]
Training loss = 0.0342102712392807
step = 0, Training Accuracy: 0.43666666666666665
Validation Accuracy: 0.625
Training loss = 0.03251702109972636
step = 1, Training Accuracy: 0.49666666666666665
Training loss = 0.03277596394220988
step = 2, Training Accuracy: 0.5
Training loss = 0.03426272928714752
step = 3, Training Accuracy: 0.49
Training loss = 0.03362398306528727
step = 4, Training Accuracy: 0.49
Training loss = 0.03243456999460856
step = 5, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.55875
Training loss = 0.03256596843401591
step = 6, Training Accuracy: 0.5566666666666666
Training loss = 0.03218049605687459
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.03180403292179108
step = 8, Training Accuracy: 0.57
Training loss = 0.03274896264076233
step = 9, Training Accuracy: 0.5466666666666666
Training loss = 0.0332833323876063
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.58
Training loss = 0.03210202912489573
step = 11, Training Accuracy: 0.5233333333333333
Training loss = 0.03316578845183055
step = 12, Training Accuracy: 0.48333333333333334
Training loss = 0.031815486351648964
step = 13, Training Accuracy: 0.5166666666666667
Training loss = 0.03285335123538971
step = 14, Training Accuracy: 0.48
Validation Accuracy: 0.60375
params:  [0.01, 0.9384693493581588, 0.6531525538627656, 0.7717658636482624, 0.01, 0.23630163509711746, 0.30385056191835935, 0.7673389528268468, 0.4676094336483609, 0.019528616138806992, 0.8210244662502889, 0.5346025523880404, 0.01, 0.01, 0.6764109764148778, 0.31841503938113414, 0.7782451754333968, 0.49653578801965825, 0.776635073342668, 0.445875358226294, 0.01, 0.8751920964127404, 0.758356684155357, 0.7212537051785508, 0.01, 0.01, 0.6399464774909288, 0.01, 0.8020884677992386, 0.6423827380945855, 0.6543186758136414, 0.42923675491629, 0.1353237653014887, 0.1171925999275756, 0.817250860472729, 0.99, 0.5594621474027298, 0.99, 0.99, 0.08382157211688882, 0.5627030463849586, 0.35322853403389415, 0.24228848506124628, 0.5419443317173995, 0.6789357952853697, 0.99, 0.4941024040800851, 0.6098616670359643, 0.99, 0.6723661378115535, 0.8778869798762182, 0.6482368264549476, 0.1692545754414041, 0.5846172886161092, 0.3747956864871569, 0.5323478434543761, 0.15252809044321458, 0.9198785207131003, 0.01, 0.25130365420548173, 0.99, 0.3462223138983921, 0.4706340179931431, 0.5065449774847105, 0.99, 0.6482764239573204, 0.2984476440478488, 0.1007979548991257, 0.24977364263800883, 0.8072972383673306, 0.01, 0.4533481555100956, 0.30687744406034756, 0.7073991571983226, 0.6740428896969901, 0.8639492430999334, 0.28672675586858504, 0.37709228089125574, 0.5574933533147844, 0.05855751244967772, 0.99, 0.4082302760274426, 0.8326989483070167, 0.5721038993519763, 0.49317053508556524, 0.4150084505331287, 0.29988316496494427, 0.01, 0.01, 0.17906746132630397, 0.762555586265147, 0.78106147331985]
[0.01, 0.9384693493581588, 0.6531525538627656, 0.7717658636482624, 0.01, 0.23630163509711746, 0.30385056191835935, 0.7673389528268468, 0.4676094336483609, 0.019528616138806992, 0.8210244662502889, 0.5346025523880404, 0.01, 0.01, 0.6764109764148778, 0.31841503938113414, 0.7782451754333968, 0.49653578801965825, 0.776635073342668, 0.445875358226294, 0.01, 0.8751920964127404, 0.758356684155357, 0.7212537051785508, 0.01, 0.01, 0.6399464774909288, 0.01, 0.8020884677992386, 0.6423827380945855, 0.6543186758136414, 0.42923675491629, 0.1353237653014887, 0.1171925999275756, 0.817250860472729, 0.99, 0.5594621474027298, 0.99, 0.99, 0.08382157211688882, 0.5627030463849586, 0.35322853403389415, 0.24228848506124628, 0.5419443317173995, 0.6789357952853697, 0.99, 0.4941024040800851, 0.6098616670359643, 0.99, 0.6723661378115535, 0.8778869798762182, 0.6482368264549476, 0.1692545754414041, 0.5846172886161092, 0.3747956864871569, 0.5323478434543761, 0.15252809044321458, 0.9198785207131003, 0.01, 0.25130365420548173, 0.99, 0.3462223138983921, 0.4706340179931431, 0.5065449774847105, 0.99, 0.6482764239573204, 0.2984476440478488, 0.1007979548991257, 0.24977364263800883, 0.8072972383673306, 0.01, 0.4533481555100956, 0.30687744406034756, 0.7073991571983226, 0.6740428896969901, 0.8639492430999334, 0.28672675586858504, 0.37709228089125574, 0.5574933533147844, 0.05855751244967772, 0.99, 0.4082302760274426, 0.8326989483070167, 0.5721038993519763, 0.49317053508556524, 0.4150084505331287, 0.29988316496494427, 0.01, 0.01, 0.17906746132630397, 0.762555586265147, 0.78106147331985]
Training loss = 0.03381742378075918
step = 0, Training Accuracy: 0.49
Validation Accuracy: 0.61875
Training loss = 0.0319209102789561
step = 1, Training Accuracy: 0.5133333333333333
Training loss = 0.0318662965297699
step = 2, Training Accuracy: 0.5066666666666667
Training loss = 0.03118342181046804
step = 3, Training Accuracy: 0.5333333333333333
Training loss = 0.030925923585891725
step = 4, Training Accuracy: 0.5366666666666666
Training loss = 0.031158947944641115
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.5975
Training loss = 0.030210447112719217
step = 6, Training Accuracy: 0.5633333333333334
Training loss = 0.030790164868036905
step = 7, Training Accuracy: 0.54
Training loss = 0.02988195836544037
step = 8, Training Accuracy: 0.5666666666666667
Training loss = 0.03276793460051219
step = 9, Training Accuracy: 0.5233333333333333
Training loss = 0.02941421667734782
step = 10, Training Accuracy: 0.55
Validation Accuracy: 0.61
Training loss = 0.030991781751314798
step = 11, Training Accuracy: 0.5333333333333333
Training loss = 0.02985313137372335
step = 12, Training Accuracy: 0.56
Training loss = 0.029945672750473024
step = 13, Training Accuracy: 0.56
Training loss = 0.029618139465649923
step = 14, Training Accuracy: 0.5866666666666667
Validation Accuracy: 0.605
params:  [0.27303807140807, 0.6411680505069322, 0.99, 0.5512349634156672, 0.5598846904829915, 0.1412823387715717, 0.792301943878333, 0.99, 0.99, 0.4653042499444457, 0.567675941002983, 0.6979596366911005, 0.3194617747528302, 0.28575267409514854, 0.99, 0.8122411009441648, 0.6905129291803644, 0.6224707801570191, 0.7079153297095512, 0.2255138574508405, 0.23108258563334128, 0.41036746151243986, 0.4467058291353269, 0.6894551790647411, 0.7722696251086805, 0.23641868167291713, 0.25191558412958903, 0.42261662511018205, 0.8455554131649619, 0.2195586207218751, 0.5667413354027142, 0.1952427980948526, 0.29167575769407744, 0.1134586992792336, 0.4121758974594558, 0.6194312235646473, 0.47058974077364996, 0.9123057141449553, 0.5966034879877182, 0.01, 0.39351194876467355, 0.5560254335444657, 0.04453570412646434, 0.5900284297330103, 0.3313984847425322, 0.8059118515304359, 0.3379450237775945, 0.5295577171430904, 0.9015570968820972, 0.677949511961379, 0.6595646313067913, 0.6192532952376977, 0.2675294870729502, 0.5172328469535183, 0.357524243059129, 0.99, 0.060701556818996666, 0.5800440789812958, 0.1579976057747618, 0.4879260421588213, 0.09744074578361706, 0.5363247677765585, 0.34954509912472076, 0.5833469129949671, 0.9814677978191835, 0.2177276467581081, 0.17512257240831874, 0.3029190971825515, 0.4069122035150272, 0.6089878020817471, 0.01, 0.6240836150482754, 0.01, 0.4217818491655619, 0.99, 0.7535880642177314, 0.8963379631562465, 0.17406729774066734, 0.6411739296939167, 0.062267477576556984, 0.3101345118957697, 0.6749633023685467, 0.9309310045303149, 0.6239519168377192, 0.5588299040086481, 0.11758806069790106, 0.4281585842581225, 0.044814670440618314, 0.3772345684605265, 0.18930421210988674, 0.23174465407727401, 0.14844569116083398]
[0.27303807140807, 0.6411680505069322, 0.99, 0.5512349634156672, 0.5598846904829915, 0.1412823387715717, 0.792301943878333, 0.99, 0.99, 0.4653042499444457, 0.567675941002983, 0.6979596366911005, 0.3194617747528302, 0.28575267409514854, 0.99, 0.8122411009441648, 0.6905129291803644, 0.6224707801570191, 0.7079153297095512, 0.2255138574508405, 0.23108258563334128, 0.41036746151243986, 0.4467058291353269, 0.6894551790647411, 0.7722696251086805, 0.23641868167291713, 0.25191558412958903, 0.42261662511018205, 0.8455554131649619, 0.2195586207218751, 0.5667413354027142, 0.1952427980948526, 0.29167575769407744, 0.1134586992792336, 0.4121758974594558, 0.6194312235646473, 0.47058974077364996, 0.9123057141449553, 0.5966034879877182, 0.01, 0.39351194876467355, 0.5560254335444657, 0.04453570412646434, 0.5900284297330103, 0.3313984847425322, 0.8059118515304359, 0.3379450237775945, 0.5295577171430904, 0.9015570968820972, 0.677949511961379, 0.6595646313067913, 0.6192532952376977, 0.2675294870729502, 0.5172328469535183, 0.357524243059129, 0.99, 0.060701556818996666, 0.5800440789812958, 0.1579976057747618, 0.4879260421588213, 0.09744074578361706, 0.5363247677765585, 0.34954509912472076, 0.5833469129949671, 0.9814677978191835, 0.2177276467581081, 0.17512257240831874, 0.3029190971825515, 0.4069122035150272, 0.6089878020817471, 0.01, 0.6240836150482754, 0.01, 0.4217818491655619, 0.99, 0.7535880642177314, 0.8963379631562465, 0.17406729774066734, 0.6411739296939167, 0.062267477576556984, 0.3101345118957697, 0.6749633023685467, 0.9309310045303149, 0.6239519168377192, 0.5588299040086481, 0.11758806069790106, 0.4281585842581225, 0.044814670440618314, 0.3772345684605265, 0.18930421210988674, 0.23174465407727401, 0.14844569116083398]
Training loss = 0.034832218885421755
step = 0, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.5775
Training loss = 0.03316419998804728
step = 1, Training Accuracy: 0.49333333333333335
Training loss = 0.033419639865557356
step = 2, Training Accuracy: 0.5266666666666666
Training loss = 0.032872727115949
step = 3, Training Accuracy: 0.5033333333333333
Training loss = 0.032385584314664206
step = 4, Training Accuracy: 0.49666666666666665
Training loss = 0.03143379827340444
step = 5, Training Accuracy: 0.57
Validation Accuracy: 0.62
Training loss = 0.03252748429775238
step = 6, Training Accuracy: 0.5166666666666667
Training loss = 0.03236088474591573
step = 7, Training Accuracy: 0.5266666666666666
Training loss = 0.03379039684931437
step = 8, Training Accuracy: 0.5133333333333333
Training loss = 0.032962842186292016
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.0319204447666804
step = 10, Training Accuracy: 0.54
Validation Accuracy: 0.60125
Training loss = 0.032276838421821594
step = 11, Training Accuracy: 0.5333333333333333
Training loss = 0.03212430079778036
step = 12, Training Accuracy: 0.54
Training loss = 0.03157043516635895
step = 13, Training Accuracy: 0.5666666666666667
Training loss = 0.033016733328501385
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.59875
8  	8     	0.608594	0.0116498	0.5975 	0.63625
params:  [0.10180430991603491, 0.7001371494184611, 0.99, 0.7611495777746263, 0.931772805449442, 0.2232466879127206, 0.11510145129231755, 0.99, 0.7912725052480892, 0.01, 0.37682256512137413, 0.5111734040850797, 0.01, 0.19706315033751873, 0.6980982804892535, 0.5214224300774355, 0.99, 0.05419265149681185, 0.5181927016055717, 0.8882210952996616, 0.01, 0.5126994643501951, 0.31530017079862394, 0.6151516967735304, 0.01, 0.682868997088317, 0.5039844143667709, 0.2954473451112899, 0.6034264647798533, 0.5194373889416162, 0.806603273555101, 0.4985610087088387, 0.4108671184727589, 0.01, 0.9848870558002301, 0.99, 0.18904091312093743, 0.6944001155921502, 0.7375051538673296, 0.01, 0.4756678347106488, 0.6739372372795593, 0.01, 0.46584163186442507, 0.6721787758735159, 0.99, 0.33421325750380215, 0.8881507941833462, 0.99, 0.7869915625899839, 0.99, 0.4988864647610204, 0.23932507478461928, 0.7082088654578657, 0.4869316628812762, 0.532463979863703, 0.06551396438877452, 0.99, 0.23968770680955814, 0.36334170720290804, 0.6213955649428644, 0.6093433594276738, 0.5974808367187013, 0.6332198907064022, 0.99, 0.1687311872681831, 0.09608786899186726, 0.07461682102107407, 0.01, 0.7808189733217631, 0.4739285145572111, 0.28120069654904734, 0.3962854188527629, 0.7865049748678044, 0.9380321172297598, 0.43144278460269725, 0.6474420511905042, 0.6359734264654405, 0.765521602685417, 0.7083768827304222, 0.3518995455489723, 0.6906040344610075, 0.9147603422433023, 0.49877175812979835, 0.42887767168050894, 0.16526838711465405, 0.01, 0.05220193942928435, 0.43095812975079834, 0.024633773036817463, 0.7933488744795278, 0.6520764243893804]
[0.10180430991603491, 0.7001371494184611, 0.99, 0.7611495777746263, 0.931772805449442, 0.2232466879127206, 0.11510145129231755, 0.99, 0.7912725052480892, 0.01, 0.37682256512137413, 0.5111734040850797, 0.01, 0.19706315033751873, 0.6980982804892535, 0.5214224300774355, 0.99, 0.05419265149681185, 0.5181927016055717, 0.8882210952996616, 0.01, 0.5126994643501951, 0.31530017079862394, 0.6151516967735304, 0.01, 0.682868997088317, 0.5039844143667709, 0.2954473451112899, 0.6034264647798533, 0.5194373889416162, 0.806603273555101, 0.4985610087088387, 0.4108671184727589, 0.01, 0.9848870558002301, 0.99, 0.18904091312093743, 0.6944001155921502, 0.7375051538673296, 0.01, 0.4756678347106488, 0.6739372372795593, 0.01, 0.46584163186442507, 0.6721787758735159, 0.99, 0.33421325750380215, 0.8881507941833462, 0.99, 0.7869915625899839, 0.99, 0.4988864647610204, 0.23932507478461928, 0.7082088654578657, 0.4869316628812762, 0.532463979863703, 0.06551396438877452, 0.99, 0.23968770680955814, 0.36334170720290804, 0.6213955649428644, 0.6093433594276738, 0.5974808367187013, 0.6332198907064022, 0.99, 0.1687311872681831, 0.09608786899186726, 0.07461682102107407, 0.01, 0.7808189733217631, 0.4739285145572111, 0.28120069654904734, 0.3962854188527629, 0.7865049748678044, 0.9380321172297598, 0.43144278460269725, 0.6474420511905042, 0.6359734264654405, 0.765521602685417, 0.7083768827304222, 0.3518995455489723, 0.6906040344610075, 0.9147603422433023, 0.49877175812979835, 0.42887767168050894, 0.16526838711465405, 0.01, 0.05220193942928435, 0.43095812975079834, 0.024633773036817463, 0.7933488744795278, 0.6520764243893804]
Training loss = 0.0321078364054362
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.6
Training loss = 0.03345473349094391
step = 1, Training Accuracy: 0.49333333333333335
Training loss = 0.033490718603134156
step = 2, Training Accuracy: 0.47
Training loss = 0.03212277809778849
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.0327304079135259
step = 4, Training Accuracy: 0.49666666666666665
Training loss = 0.031903804143269855
step = 5, Training Accuracy: 0.55
Validation Accuracy: 0.61
Training loss = 0.03256956160068512
step = 6, Training Accuracy: 0.51
Training loss = 0.03234532773494721
step = 7, Training Accuracy: 0.49
Training loss = 0.032260847886403404
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.032225524385770164
step = 9, Training Accuracy: 0.5333333333333333
Training loss = 0.0323302427927653
step = 10, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.6175
Training loss = 0.03221988101800283
step = 11, Training Accuracy: 0.49333333333333335
Training loss = 0.032468027273813885
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03246214071909587
step = 13, Training Accuracy: 0.5266666666666666
Training loss = 0.0325354407231013
step = 14, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.6075
params:  [0.01, 0.99, 0.5720633842760818, 0.5268204506871712, 0.5032031016733509, 0.29001794880434173, 0.01, 0.8051271295699465, 0.6566846925377, 0.01, 0.7543162106266167, 0.46964443138479645, 0.4340402135294681, 0.24875904583595226, 0.7071468145778897, 0.20615239468140892, 0.6585197791410567, 0.1625496456283428, 0.6391334197357011, 0.18680454343366565, 0.0396732257846531, 0.4623148308476259, 0.30901038619589755, 0.6140513517726225, 0.42068981238561964, 0.01, 0.01, 0.020724128937844352, 0.40524212453493746, 0.43435731227941426, 0.99, 0.01, 0.06144863646500741, 0.01, 0.6186838920686044, 0.99, 0.01, 0.99, 0.8538083755774774, 0.6110728334387717, 0.4185754048616649, 0.9068573541029601, 0.29738044474891645, 0.21378651748628436, 0.18648110541491825, 0.9712592323821203, 0.752309345019551, 0.6730588408409519, 0.99, 0.5204942198658962, 0.99, 0.99, 0.03792887014227095, 0.32936590087348316, 0.4078940945240716, 0.7109417045377471, 0.6578848942993236, 0.4460833435177155, 0.47738943535467865, 0.3145200707762281, 0.7194280199100258, 0.6836525312530778, 0.26818765524936167, 0.7900391860323631, 0.99, 0.7142213285883174, 0.09500339223087761, 0.01, 0.20605984900728036, 0.99, 0.3330278594754993, 0.70649933168543, 0.10780593633660451, 0.7493138378051459, 0.5847054971873062, 0.5666117392877044, 0.7252985379125845, 0.01, 0.4127335938519956, 0.6276279291314338, 0.5235910902382973, 0.8494160243726354, 0.26360178704935977, 0.4216433847821256, 0.01, 0.01, 0.4741301514774395, 0.5694454148973058, 0.1355498892971692, 0.5202965429542781, 0.6451276276288928, 0.0754445956008746]
[0.01, 0.99, 0.5720633842760818, 0.5268204506871712, 0.5032031016733509, 0.29001794880434173, 0.01, 0.8051271295699465, 0.6566846925377, 0.01, 0.7543162106266167, 0.46964443138479645, 0.4340402135294681, 0.24875904583595226, 0.7071468145778897, 0.20615239468140892, 0.6585197791410567, 0.1625496456283428, 0.6391334197357011, 0.18680454343366565, 0.0396732257846531, 0.4623148308476259, 0.30901038619589755, 0.6140513517726225, 0.42068981238561964, 0.01, 0.01, 0.020724128937844352, 0.40524212453493746, 0.43435731227941426, 0.99, 0.01, 0.06144863646500741, 0.01, 0.6186838920686044, 0.99, 0.01, 0.99, 0.8538083755774774, 0.6110728334387717, 0.4185754048616649, 0.9068573541029601, 0.29738044474891645, 0.21378651748628436, 0.18648110541491825, 0.9712592323821203, 0.752309345019551, 0.6730588408409519, 0.99, 0.5204942198658962, 0.99, 0.99, 0.03792887014227095, 0.32936590087348316, 0.4078940945240716, 0.7109417045377471, 0.6578848942993236, 0.4460833435177155, 0.47738943535467865, 0.3145200707762281, 0.7194280199100258, 0.6836525312530778, 0.26818765524936167, 0.7900391860323631, 0.99, 0.7142213285883174, 0.09500339223087761, 0.01, 0.20605984900728036, 0.99, 0.3330278594754993, 0.70649933168543, 0.10780593633660451, 0.7493138378051459, 0.5847054971873062, 0.5666117392877044, 0.7252985379125845, 0.01, 0.4127335938519956, 0.6276279291314338, 0.5235910902382973, 0.8494160243726354, 0.26360178704935977, 0.4216433847821256, 0.01, 0.01, 0.4741301514774395, 0.5694454148973058, 0.1355498892971692, 0.5202965429542781, 0.6451276276288928, 0.0754445956008746]
Training loss = 0.03273256818453471
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.61125
Training loss = 0.03205895860989889
step = 1, Training Accuracy: 0.5466666666666666
Training loss = 0.03376149038473765
step = 2, Training Accuracy: 0.49333333333333335
Training loss = 0.03157751142978668
step = 3, Training Accuracy: 0.5033333333333333
Training loss = 0.032210617065429686
step = 4, Training Accuracy: 0.49
Training loss = 0.032177357276280724
step = 5, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.6175
Training loss = 0.03264823913574219
step = 6, Training Accuracy: 0.5333333333333333
Training loss = 0.03268445392449697
step = 7, Training Accuracy: 0.5033333333333333
Training loss = 0.031321629881858826
step = 8, Training Accuracy: 0.54
Training loss = 0.03266071995099386
step = 9, Training Accuracy: 0.4866666666666667
Training loss = 0.031161710818608603
step = 10, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.63375
Training loss = 0.03124490757783254
step = 11, Training Accuracy: 0.52
Training loss = 0.03229048768679301
step = 12, Training Accuracy: 0.53
Training loss = 0.030167357921600343
step = 13, Training Accuracy: 0.5666666666666667
Training loss = 0.031753526131312056
step = 14, Training Accuracy: 0.5966666666666667
Validation Accuracy: 0.60875
params:  [0.15105167802947359, 0.783223626553451, 0.99, 0.5068214454781921, 0.6292348543149162, 0.3485829593742713, 0.01, 0.99, 0.6257495858195541, 0.01, 0.46049424382717, 0.4587947484318224, 0.10492754062788831, 0.09623486010060683, 0.99, 0.11864116889847603, 0.848058376805444, 0.16451398852404764, 0.712813857397308, 0.7378139497410697, 0.09774488084371959, 0.563196172033541, 0.5899029971888122, 0.5133990683156955, 0.06497896761782775, 0.3538922651052464, 0.30674399423229703, 0.05892520791559779, 0.99, 0.25012769240697286, 0.19533002296342827, 0.1778770591492646, 0.01, 0.01, 0.3501421037661306, 0.8613932057815644, 0.07662002545979407, 0.99, 0.99, 0.15338688054701807, 0.05460833746360727, 0.6354691140592188, 0.01, 0.19883057953802577, 0.7295762450532977, 0.6945756646156047, 0.36190638706057265, 0.7775090997760735, 0.99, 0.8429638613221592, 0.9859762247842324, 0.99, 0.5091239291439352, 0.28731053299059545, 0.4154034789882466, 0.9056745400068019, 0.26637278950245086, 0.13497279487785885, 0.36786920763832975, 0.3127747192326341, 0.99, 0.8294571245017349, 0.3433960224933946, 0.21617481024461632, 0.99, 0.3543451827905154, 0.12100238087092946, 0.02380909083314075, 0.12838977241986244, 0.99, 0.17613339094378672, 0.6324284154601845, 0.04643094637531037, 0.7681864989226275, 0.99, 0.8614530740594657, 0.40527993996046774, 0.2557197293139816, 0.4141873020560005, 0.6379526614695816, 0.36611292737280404, 0.6029196142116638, 0.6594970311892906, 0.2354050832587524, 0.1217545457498434, 0.09173205489034147, 0.7006763294625721, 0.01, 0.07507417715337397, 0.5477245146060097, 0.9114159844373619, 0.26669039927960964]
[0.15105167802947359, 0.783223626553451, 0.99, 0.5068214454781921, 0.6292348543149162, 0.3485829593742713, 0.01, 0.99, 0.6257495858195541, 0.01, 0.46049424382717, 0.4587947484318224, 0.10492754062788831, 0.09623486010060683, 0.99, 0.11864116889847603, 0.848058376805444, 0.16451398852404764, 0.712813857397308, 0.7378139497410697, 0.09774488084371959, 0.563196172033541, 0.5899029971888122, 0.5133990683156955, 0.06497896761782775, 0.3538922651052464, 0.30674399423229703, 0.05892520791559779, 0.99, 0.25012769240697286, 0.19533002296342827, 0.1778770591492646, 0.01, 0.01, 0.3501421037661306, 0.8613932057815644, 0.07662002545979407, 0.99, 0.99, 0.15338688054701807, 0.05460833746360727, 0.6354691140592188, 0.01, 0.19883057953802577, 0.7295762450532977, 0.6945756646156047, 0.36190638706057265, 0.7775090997760735, 0.99, 0.8429638613221592, 0.9859762247842324, 0.99, 0.5091239291439352, 0.28731053299059545, 0.4154034789882466, 0.9056745400068019, 0.26637278950245086, 0.13497279487785885, 0.36786920763832975, 0.3127747192326341, 0.99, 0.8294571245017349, 0.3433960224933946, 0.21617481024461632, 0.99, 0.3543451827905154, 0.12100238087092946, 0.02380909083314075, 0.12838977241986244, 0.99, 0.17613339094378672, 0.6324284154601845, 0.04643094637531037, 0.7681864989226275, 0.99, 0.8614530740594657, 0.40527993996046774, 0.2557197293139816, 0.4141873020560005, 0.6379526614695816, 0.36611292737280404, 0.6029196142116638, 0.6594970311892906, 0.2354050832587524, 0.1217545457498434, 0.09173205489034147, 0.7006763294625721, 0.01, 0.07507417715337397, 0.5477245146060097, 0.9114159844373619, 0.26669039927960964]
Training loss = 0.031987425883611045
step = 0, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.615
Training loss = 0.03147985716660817
step = 1, Training Accuracy: 0.4666666666666667
Training loss = 0.03142959614594777
step = 2, Training Accuracy: 0.5266666666666666
Training loss = 0.03218883832295736
step = 3, Training Accuracy: 0.52
Training loss = 0.030542876919110618
step = 4, Training Accuracy: 0.5133333333333333
Training loss = 0.030933887759844462
step = 5, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.63375
Training loss = 0.03260910371939341
step = 6, Training Accuracy: 0.5366666666666666
Training loss = 0.03317864199479421
step = 7, Training Accuracy: 0.49
Training loss = 0.03058812181154887
step = 8, Training Accuracy: 0.5533333333333333
Training loss = 0.03016812602678935
step = 9, Training Accuracy: 0.5733333333333334
Training loss = 0.030519344607988993
step = 10, Training Accuracy: 0.55
Validation Accuracy: 0.61625
Training loss = 0.03221850673357646
step = 11, Training Accuracy: 0.5233333333333333
Training loss = 0.02997363011042277
step = 12, Training Accuracy: 0.5666666666666667
Training loss = 0.028287489612897235
step = 13, Training Accuracy: 0.5866666666666667
Training loss = 0.03034959395726522
step = 14, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.6
params:  [0.40443894069404895, 0.6175840017967176, 0.46886879442279766, 0.06942721306074812, 0.4683189210487644, 0.3678994616947313, 0.01, 0.99, 0.8600144104908707, 0.5617348579090612, 0.4713295685447126, 0.8549627039367934, 0.8657210040898158, 0.01, 0.99, 0.3815379030805142, 0.6712706311802288, 0.3488775316093752, 0.7055753021325991, 0.21514441430654768, 0.39264274292508583, 0.6521005307805274, 0.2934167003954322, 0.5246387514792534, 0.09253008211670483, 0.35585630633368404, 0.6449185136369486, 0.2590128798435054, 0.9296684927313406, 0.34066827130247007, 0.6068568532392877, 0.280158132308523, 0.4376999502887886, 0.1470653730549882, 0.9886371925351828, 0.99, 0.22852196825312152, 0.6882074056988654, 0.9556613901456574, 0.20078206393357922, 0.4559841650803317, 0.6141410579780204, 0.10519021013142138, 0.01, 0.6531166272569393, 0.8047817218039728, 0.666758451231122, 0.3730117044188402, 0.8932711357189964, 0.7263627619933013, 0.6017203410629037, 0.8951345897023766, 0.16255753607540663, 0.7716704989111904, 0.12638976068023378, 0.4058791765245128, 0.40402910439222117, 0.99, 0.01, 0.04855982102920628, 0.7788709951357264, 0.99, 0.26243593426586254, 0.3521303799226819, 0.8258122892303543, 0.12520655786673493, 0.20008071081040318, 0.0760610427923705, 0.01, 0.7372235886406276, 0.44767044572835324, 0.3241796352843969, 0.029213858516875607, 0.20280587451129473, 0.7252352502707463, 0.8361446784924116, 0.6588291114107114, 0.362906527011743, 0.6093680497155138, 0.7639502803689548, 0.4182331217203644, 0.896025427870117, 0.5128911384034506, 0.0535122125866436, 0.5188362472515184, 0.01, 0.2438139210492339, 0.25513848122072696, 0.41221693610863674, 0.03847277515551867, 0.5021774837962265, 0.2379161803947127]
[0.40443894069404895, 0.6175840017967176, 0.46886879442279766, 0.06942721306074812, 0.4683189210487644, 0.3678994616947313, 0.01, 0.99, 0.8600144104908707, 0.5617348579090612, 0.4713295685447126, 0.8549627039367934, 0.8657210040898158, 0.01, 0.99, 0.3815379030805142, 0.6712706311802288, 0.3488775316093752, 0.7055753021325991, 0.21514441430654768, 0.39264274292508583, 0.6521005307805274, 0.2934167003954322, 0.5246387514792534, 0.09253008211670483, 0.35585630633368404, 0.6449185136369486, 0.2590128798435054, 0.9296684927313406, 0.34066827130247007, 0.6068568532392877, 0.280158132308523, 0.4376999502887886, 0.1470653730549882, 0.9886371925351828, 0.99, 0.22852196825312152, 0.6882074056988654, 0.9556613901456574, 0.20078206393357922, 0.4559841650803317, 0.6141410579780204, 0.10519021013142138, 0.01, 0.6531166272569393, 0.8047817218039728, 0.666758451231122, 0.3730117044188402, 0.8932711357189964, 0.7263627619933013, 0.6017203410629037, 0.8951345897023766, 0.16255753607540663, 0.7716704989111904, 0.12638976068023378, 0.4058791765245128, 0.40402910439222117, 0.99, 0.01, 0.04855982102920628, 0.7788709951357264, 0.99, 0.26243593426586254, 0.3521303799226819, 0.8258122892303543, 0.12520655786673493, 0.20008071081040318, 0.0760610427923705, 0.01, 0.7372235886406276, 0.44767044572835324, 0.3241796352843969, 0.029213858516875607, 0.20280587451129473, 0.7252352502707463, 0.8361446784924116, 0.6588291114107114, 0.362906527011743, 0.6093680497155138, 0.7639502803689548, 0.4182331217203644, 0.896025427870117, 0.5128911384034506, 0.0535122125866436, 0.5188362472515184, 0.01, 0.2438139210492339, 0.25513848122072696, 0.41221693610863674, 0.03847277515551867, 0.5021774837962265, 0.2379161803947127]
Training loss = 0.03505605399608612
step = 0, Training Accuracy: 0.45666666666666667
Validation Accuracy: 0.60125
Training loss = 0.035569228927294416
step = 1, Training Accuracy: 0.43333333333333335
Training loss = 0.034597295920054116
step = 2, Training Accuracy: 0.43666666666666665
Training loss = 0.03426034649213155
step = 3, Training Accuracy: 0.46
Training loss = 0.03588903109232584
step = 4, Training Accuracy: 0.35333333333333333
Training loss = 0.03342717289924622
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.60375
Training loss = 0.03362460335095723
step = 6, Training Accuracy: 0.47333333333333333
Training loss = 0.03371661166350047
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.036063460310300194
step = 8, Training Accuracy: 0.43
Training loss = 0.03341033260027568
step = 9, Training Accuracy: 0.49666666666666665
Training loss = 0.03372526963551839
step = 10, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.5925
Training loss = 0.033091352184613544
step = 11, Training Accuracy: 0.5166666666666667
Training loss = 0.033701829115549725
step = 12, Training Accuracy: 0.44666666666666666
Training loss = 0.03355360647042593
step = 13, Training Accuracy: 0.44666666666666666
Training loss = 0.03409463246663411
step = 14, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.59
params:  [0.45749611603645896, 0.99, 0.8711325100616593, 0.5007835936882852, 0.33626449539239645, 0.08362644770876743, 0.38549676631417773, 0.27845327767529604, 0.7022918230282374, 0.060191503767259014, 0.5054934126094157, 0.15434883524588947, 0.05507855866186334, 0.01, 0.46417320625159714, 0.46698336506934324, 0.5651124205820012, 0.7039076351552407, 0.8875516292235323, 0.5876518827665956, 0.01, 0.4360755377858394, 0.26822065299192643, 0.568491237153225, 0.01, 0.01, 0.20145142327850596, 0.30636314809039367, 0.6885260529769269, 0.6902877840241911, 0.5111683372908917, 0.5742162601063665, 0.01, 0.01, 0.7343267463165788, 0.99, 0.05030158605344913, 0.9504845584765177, 0.99, 0.5037543920613992, 0.5674223845277057, 0.34181810369093746, 0.01, 0.01, 0.4725960759074265, 0.99, 0.0934506416932705, 0.4235518940779177, 0.99, 0.99, 0.99, 0.5819858132471953, 0.01, 0.6907620498742457, 0.444008224521331, 0.4746704528004114, 0.21348696488237742, 0.8184167751240959, 0.41374795427978484, 0.6998384728602851, 0.7025022061287405, 0.99, 0.3187879915370986, 0.3358870276852153, 0.6747329352714457, 0.3745297267627736, 0.5080013226479779, 0.15823441587002773, 0.3915527945701389, 0.35487697790765127, 0.46022870846128194, 0.1731997548190576, 0.08452177358203548, 0.4312834362400928, 0.99, 0.6329128814479749, 0.6334625185635742, 0.2285784621589573, 0.6899440006715489, 0.468337089559858, 0.6346053021165903, 0.6197687297220975, 0.4788494024436783, 0.1764206682488621, 0.31244549362234286, 0.29368921303765905, 0.6428572922709561, 0.01, 0.360883943603014, 0.4128120207926729, 0.8928690409861384, 0.01]
[0.45749611603645896, 0.99, 0.8711325100616593, 0.5007835936882852, 0.33626449539239645, 0.08362644770876743, 0.38549676631417773, 0.27845327767529604, 0.7022918230282374, 0.060191503767259014, 0.5054934126094157, 0.15434883524588947, 0.05507855866186334, 0.01, 0.46417320625159714, 0.46698336506934324, 0.5651124205820012, 0.7039076351552407, 0.8875516292235323, 0.5876518827665956, 0.01, 0.4360755377858394, 0.26822065299192643, 0.568491237153225, 0.01, 0.01, 0.20145142327850596, 0.30636314809039367, 0.6885260529769269, 0.6902877840241911, 0.5111683372908917, 0.5742162601063665, 0.01, 0.01, 0.7343267463165788, 0.99, 0.05030158605344913, 0.9504845584765177, 0.99, 0.5037543920613992, 0.5674223845277057, 0.34181810369093746, 0.01, 0.01, 0.4725960759074265, 0.99, 0.0934506416932705, 0.4235518940779177, 0.99, 0.99, 0.99, 0.5819858132471953, 0.01, 0.6907620498742457, 0.444008224521331, 0.4746704528004114, 0.21348696488237742, 0.8184167751240959, 0.41374795427978484, 0.6998384728602851, 0.7025022061287405, 0.99, 0.3187879915370986, 0.3358870276852153, 0.6747329352714457, 0.3745297267627736, 0.5080013226479779, 0.15823441587002773, 0.3915527945701389, 0.35487697790765127, 0.46022870846128194, 0.1731997548190576, 0.08452177358203548, 0.4312834362400928, 0.99, 0.6329128814479749, 0.6334625185635742, 0.2285784621589573, 0.6899440006715489, 0.468337089559858, 0.6346053021165903, 0.6197687297220975, 0.4788494024436783, 0.1764206682488621, 0.31244549362234286, 0.29368921303765905, 0.6428572922709561, 0.01, 0.360883943603014, 0.4128120207926729, 0.8928690409861384, 0.01]
Training loss = 0.03402984062830607
step = 0, Training Accuracy: 0.5
Validation Accuracy: 0.61
Training loss = 0.032244959473609926
step = 1, Training Accuracy: 0.5266666666666666
Training loss = 0.03223437150319417
step = 2, Training Accuracy: 0.5333333333333333
Training loss = 0.032032667597134905
step = 3, Training Accuracy: 0.5133333333333333
Training loss = 0.032268450260162354
step = 4, Training Accuracy: 0.5133333333333333
Training loss = 0.032881721059481304
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.59125
Training loss = 0.033631977438926694
step = 6, Training Accuracy: 0.5
Training loss = 0.031941941181818645
step = 7, Training Accuracy: 0.54
Training loss = 0.03206385652224223
step = 8, Training Accuracy: 0.5366666666666666
Training loss = 0.032533724109331766
step = 9, Training Accuracy: 0.5366666666666666
Training loss = 0.03277368088563283
step = 10, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.57375
Training loss = 0.03107287307580312
step = 11, Training Accuracy: 0.53
Training loss = 0.031872204343477886
step = 12, Training Accuracy: 0.5233333333333333
Training loss = 0.03134387850761414
step = 13, Training Accuracy: 0.5
Training loss = 0.030637702743212383
step = 14, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.58
params:  [0.19585710475830115, 0.6203687260563076, 0.690179741523397, 0.34264833460252153, 0.40057557923012554, 0.10878856972708631, 0.32360395808789677, 0.433931441512144, 0.8571800395874589, 0.024111295385612713, 0.99, 0.9254815711929008, 0.6118515757250079, 0.31357477495938857, 0.26367440000365694, 0.032349769158044606, 0.6998224901995097, 0.8689617072522687, 0.8849259671927635, 0.549429459062504, 0.41804881053939746, 0.6146645509038456, 0.18132500872968005, 0.740905443831247, 0.1295465367126337, 0.2157669287117155, 0.2683494874276785, 0.5446150858504941, 0.5546427079348981, 0.01, 0.3940528123445609, 0.1351193605103633, 0.0881763294716596, 0.12436333413488687, 0.4788577553966538, 0.99, 0.3529999064047905, 0.99, 0.9034666709756395, 0.39661183330476807, 0.5269025555531692, 0.3743243828089362, 0.38783273209850583, 0.01, 0.29923368645948606, 0.8870164155604894, 0.30961124049580674, 0.79411697418139, 0.99, 0.5853321980574403, 0.8876096433872381, 0.8664047279297113, 0.36366624445552054, 0.5578669879206667, 0.01, 0.5834539574439636, 0.01, 0.8201507516481115, 0.01, 0.5937820475443059, 0.99, 0.8716731028564503, 0.4071245347175432, 0.31078196286121373, 0.8938074952191428, 0.6439716053947182, 0.653972223739286, 0.16817166891713697, 0.2415882470832877, 0.5239268879423481, 0.4738494200452362, 0.5120195403155547, 0.14247915185107468, 0.5733406036528309, 0.9538877761334799, 0.24391993314711274, 0.696715358026955, 0.01, 0.6660523333217665, 0.23913865557911135, 0.15278657106801874, 0.7936718603485805, 0.8410155163997963, 0.7214872765826098, 0.4116911121306076, 0.01, 0.6491651026444714, 0.6336297740318204, 0.45437182824384253, 0.01, 0.38918591068717673, 0.14083418569170963]
[0.19585710475830115, 0.6203687260563076, 0.690179741523397, 0.34264833460252153, 0.40057557923012554, 0.10878856972708631, 0.32360395808789677, 0.433931441512144, 0.8571800395874589, 0.024111295385612713, 0.99, 0.9254815711929008, 0.6118515757250079, 0.31357477495938857, 0.26367440000365694, 0.032349769158044606, 0.6998224901995097, 0.8689617072522687, 0.8849259671927635, 0.549429459062504, 0.41804881053939746, 0.6146645509038456, 0.18132500872968005, 0.740905443831247, 0.1295465367126337, 0.2157669287117155, 0.2683494874276785, 0.5446150858504941, 0.5546427079348981, 0.01, 0.3940528123445609, 0.1351193605103633, 0.0881763294716596, 0.12436333413488687, 0.4788577553966538, 0.99, 0.3529999064047905, 0.99, 0.9034666709756395, 0.39661183330476807, 0.5269025555531692, 0.3743243828089362, 0.38783273209850583, 0.01, 0.29923368645948606, 0.8870164155604894, 0.30961124049580674, 0.79411697418139, 0.99, 0.5853321980574403, 0.8876096433872381, 0.8664047279297113, 0.36366624445552054, 0.5578669879206667, 0.01, 0.5834539574439636, 0.01, 0.8201507516481115, 0.01, 0.5937820475443059, 0.99, 0.8716731028564503, 0.4071245347175432, 0.31078196286121373, 0.8938074952191428, 0.6439716053947182, 0.653972223739286, 0.16817166891713697, 0.2415882470832877, 0.5239268879423481, 0.4738494200452362, 0.5120195403155547, 0.14247915185107468, 0.5733406036528309, 0.9538877761334799, 0.24391993314711274, 0.696715358026955, 0.01, 0.6660523333217665, 0.23913865557911135, 0.15278657106801874, 0.7936718603485805, 0.8410155163997963, 0.7214872765826098, 0.4116911121306076, 0.01, 0.6491651026444714, 0.6336297740318204, 0.45437182824384253, 0.01, 0.38918591068717673, 0.14083418569170963]
Training loss = 0.03392411828041077
step = 0, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.59
Training loss = 0.033713444868723554
step = 1, Training Accuracy: 0.4533333333333333
Training loss = 0.034785658319791156
step = 2, Training Accuracy: 0.47
Training loss = 0.03415213704109192
step = 3, Training Accuracy: 0.4633333333333333
Training loss = 0.03352245231469472
step = 4, Training Accuracy: 0.46
Training loss = 0.03270853718121847
step = 5, Training Accuracy: 0.51
Validation Accuracy: 0.5975
Training loss = 0.0331141193707784
step = 6, Training Accuracy: 0.49333333333333335
Training loss = 0.0326938651005427
step = 7, Training Accuracy: 0.5133333333333333
Training loss = 0.03187941292921702
step = 8, Training Accuracy: 0.5266666666666666
Training loss = 0.032637397050857546
step = 9, Training Accuracy: 0.49
Training loss = 0.0336284069220225
step = 10, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.60125
Training loss = 0.03314729154109955
step = 11, Training Accuracy: 0.49666666666666665
Training loss = 0.032883086601893104
step = 12, Training Accuracy: 0.51
Training loss = 0.032951451142628985
step = 13, Training Accuracy: 0.4633333333333333
Training loss = 0.032627801299095156
step = 14, Training Accuracy: 0.46
Validation Accuracy: 0.59875
params:  [0.24909448537217588, 0.7211875225011233, 0.8864273341435002, 0.01, 0.8500829856681704, 0.25682354183538725, 0.1457025219534984, 0.939557495891772, 0.99, 0.13075197639586253, 0.4426558160517256, 0.08530578722056498, 0.33800018378661684, 0.01, 0.5036847848826871, 0.16374005417441279, 0.5098372544480081, 0.2724348411853039, 0.6626695333719806, 0.5778296567540878, 0.09395240487477977, 0.6838695529296648, 0.5850376270261086, 0.7391031008427624, 0.01, 0.12061598920359591, 0.6863049915035033, 0.01, 0.99, 0.27208318908691226, 0.7651433166548414, 0.17708205170600305, 0.01, 0.04085833091820214, 0.99, 0.9776192632412521, 0.1452340299348204, 0.8833751948146362, 0.8041565859835822, 0.01, 0.9849818398657376, 0.8247885760796019, 0.01, 0.24223116524773003, 0.43838073245396775, 0.8338381409608164, 0.476515712265739, 0.3962499212134004, 0.99, 0.7866269880553037, 0.585963432631884, 0.8278515585362005, 0.39644439695887457, 0.5458051139328121, 0.22173265352270188, 0.5958846156536632, 0.4738166164418812, 0.7385008619316165, 0.06607675055453816, 0.01, 0.9198865835809327, 0.47122581622227594, 0.42571463088255795, 0.49525031815371423, 0.9783723006940059, 0.8093127033814955, 0.01, 0.01, 0.3287173369560962, 0.99, 0.214188223922739, 0.042566947535287336, 0.01, 0.7036444516572893, 0.99, 0.654203920549782, 0.6978432257616394, 0.401569338544049, 0.560899339786306, 0.713003592336014, 0.5924991429645572, 0.44971999178413186, 0.6010893963755379, 0.17963762923492882, 0.2804089236018856, 0.2039070498198751, 0.5820983312047313, 0.01, 0.3938446446138507, 0.5099500772887756, 0.5542237968484511, 0.01]
[0.24909448537217588, 0.7211875225011233, 0.8864273341435002, 0.01, 0.8500829856681704, 0.25682354183538725, 0.1457025219534984, 0.939557495891772, 0.99, 0.13075197639586253, 0.4426558160517256, 0.08530578722056498, 0.33800018378661684, 0.01, 0.5036847848826871, 0.16374005417441279, 0.5098372544480081, 0.2724348411853039, 0.6626695333719806, 0.5778296567540878, 0.09395240487477977, 0.6838695529296648, 0.5850376270261086, 0.7391031008427624, 0.01, 0.12061598920359591, 0.6863049915035033, 0.01, 0.99, 0.27208318908691226, 0.7651433166548414, 0.17708205170600305, 0.01, 0.04085833091820214, 0.99, 0.9776192632412521, 0.1452340299348204, 0.8833751948146362, 0.8041565859835822, 0.01, 0.9849818398657376, 0.8247885760796019, 0.01, 0.24223116524773003, 0.43838073245396775, 0.8338381409608164, 0.476515712265739, 0.3962499212134004, 0.99, 0.7866269880553037, 0.585963432631884, 0.8278515585362005, 0.39644439695887457, 0.5458051139328121, 0.22173265352270188, 0.5958846156536632, 0.4738166164418812, 0.7385008619316165, 0.06607675055453816, 0.01, 0.9198865835809327, 0.47122581622227594, 0.42571463088255795, 0.49525031815371423, 0.9783723006940059, 0.8093127033814955, 0.01, 0.01, 0.3287173369560962, 0.99, 0.214188223922739, 0.042566947535287336, 0.01, 0.7036444516572893, 0.99, 0.654203920549782, 0.6978432257616394, 0.401569338544049, 0.560899339786306, 0.713003592336014, 0.5924991429645572, 0.44971999178413186, 0.6010893963755379, 0.17963762923492882, 0.2804089236018856, 0.2039070498198751, 0.5820983312047313, 0.01, 0.3938446446138507, 0.5099500772887756, 0.5542237968484511, 0.01]
Training loss = 0.03289858400821686
step = 0, Training Accuracy: 0.52
Validation Accuracy: 0.61375
Training loss = 0.031864169836044315
step = 1, Training Accuracy: 0.53
Training loss = 0.03183823108673096
step = 2, Training Accuracy: 0.49333333333333335
Training loss = 0.034005559881528216
step = 3, Training Accuracy: 0.5
Training loss = 0.03380879461765289
step = 4, Training Accuracy: 0.48
Training loss = 0.032436401049296064
step = 5, Training Accuracy: 0.5466666666666666
Validation Accuracy: 0.62
Training loss = 0.03270303706328074
step = 6, Training Accuracy: 0.53
Training loss = 0.03320571660995483
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.031470121145248414
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03174520432949066
step = 9, Training Accuracy: 0.5133333333333333
Training loss = 0.03250990867614746
step = 10, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.61625
Training loss = 0.032154431144396464
step = 11, Training Accuracy: 0.5233333333333333
Training loss = 0.03140260775883993
step = 12, Training Accuracy: 0.52
Training loss = 0.03188764929771423
step = 13, Training Accuracy: 0.51
Training loss = 0.031528732776641845
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.6225
params:  [0.13674335720590064, 0.99, 0.8505513249560597, 0.6484220326928676, 0.911576570216921, 0.5153518927253922, 0.02498602443885764, 0.8173517069865214, 0.555150850892196, 0.04082218748188414, 0.2471852658976224, 0.4504672410479009, 0.34588316590402096, 0.01, 0.7593709205360342, 0.5989035707632058, 0.5028450442176688, 0.3841632242662901, 0.8627473365037746, 0.8261246117587004, 0.14882426178721267, 0.44008558239458967, 0.07257992544651215, 0.7408467221336651, 0.05859888802461366, 0.4116246055292493, 0.3718947995135949, 0.45733905484461485, 0.44764650064080624, 0.6560581841561051, 0.7503637565536174, 0.01, 0.12219403116498817, 0.01, 0.7245365266882363, 0.7182899964213585, 0.24709303451267514, 0.9321475237245765, 0.3280235051740188, 0.23362009703162898, 0.18287614629533677, 0.42845771631171936, 0.5231736009475362, 0.01, 0.5003440296790063, 0.6762759081295601, 0.26847767493594965, 0.8332426352557925, 0.99, 0.6462229024915458, 0.99, 0.903526518945233, 0.13784476560052428, 0.8628405414114708, 0.36540611613195223, 0.5721648451955286, 0.40577413723824696, 0.9016010172510072, 0.49530573614286555, 0.42895417890120136, 0.8087565760388364, 0.64435307701592, 0.24282462365141638, 0.553470038655327, 0.99, 0.377356358167415, 0.21217377953949704, 0.2785659061489769, 0.3973125267072276, 0.99, 0.01, 0.7892813456950485, 0.01, 0.5822253409732021, 0.99, 0.44972672728991286, 0.42353942502081965, 0.34790870672657603, 0.6714309180776178, 0.7037662112955543, 0.7748103203662609, 0.6132061765232784, 0.617812143218047, 0.5856817174896565, 0.1200638769850107, 0.01, 0.4124398369350581, 0.01, 0.47773477460996217, 0.38583683099344046, 0.7885868371611437, 0.12071851234039867]
[0.13674335720590064, 0.99, 0.8505513249560597, 0.6484220326928676, 0.911576570216921, 0.5153518927253922, 0.02498602443885764, 0.8173517069865214, 0.555150850892196, 0.04082218748188414, 0.2471852658976224, 0.4504672410479009, 0.34588316590402096, 0.01, 0.7593709205360342, 0.5989035707632058, 0.5028450442176688, 0.3841632242662901, 0.8627473365037746, 0.8261246117587004, 0.14882426178721267, 0.44008558239458967, 0.07257992544651215, 0.7408467221336651, 0.05859888802461366, 0.4116246055292493, 0.3718947995135949, 0.45733905484461485, 0.44764650064080624, 0.6560581841561051, 0.7503637565536174, 0.01, 0.12219403116498817, 0.01, 0.7245365266882363, 0.7182899964213585, 0.24709303451267514, 0.9321475237245765, 0.3280235051740188, 0.23362009703162898, 0.18287614629533677, 0.42845771631171936, 0.5231736009475362, 0.01, 0.5003440296790063, 0.6762759081295601, 0.26847767493594965, 0.8332426352557925, 0.99, 0.6462229024915458, 0.99, 0.903526518945233, 0.13784476560052428, 0.8628405414114708, 0.36540611613195223, 0.5721648451955286, 0.40577413723824696, 0.9016010172510072, 0.49530573614286555, 0.42895417890120136, 0.8087565760388364, 0.64435307701592, 0.24282462365141638, 0.553470038655327, 0.99, 0.377356358167415, 0.21217377953949704, 0.2785659061489769, 0.3973125267072276, 0.99, 0.01, 0.7892813456950485, 0.01, 0.5822253409732021, 0.99, 0.44972672728991286, 0.42353942502081965, 0.34790870672657603, 0.6714309180776178, 0.7037662112955543, 0.7748103203662609, 0.6132061765232784, 0.617812143218047, 0.5856817174896565, 0.1200638769850107, 0.01, 0.4124398369350581, 0.01, 0.47773477460996217, 0.38583683099344046, 0.7885868371611437, 0.12071851234039867]
Training loss = 0.03270999789237976
step = 0, Training Accuracy: 0.49
Validation Accuracy: 0.61
Training loss = 0.032878457109133404
step = 1, Training Accuracy: 0.49
Training loss = 0.03338719546794891
step = 2, Training Accuracy: 0.5133333333333333
Training loss = 0.03321183681488037
step = 3, Training Accuracy: 0.47
Training loss = 0.03383407990137736
step = 4, Training Accuracy: 0.43666666666666665
Training loss = 0.031871747175852456
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.6025
Training loss = 0.034071136514345804
step = 6, Training Accuracy: 0.4633333333333333
Training loss = 0.03386009176572164
step = 7, Training Accuracy: 0.4533333333333333
Training loss = 0.03286604603131612
step = 8, Training Accuracy: 0.5133333333333333
Training loss = 0.03264221429824829
step = 9, Training Accuracy: 0.48333333333333334
Training loss = 0.03451803247133891
step = 10, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.60125
Training loss = 0.035028326908747354
step = 11, Training Accuracy: 0.44
Training loss = 0.032252185940742494
step = 12, Training Accuracy: 0.5033333333333333
Training loss = 0.03383743941783905
step = 13, Training Accuracy: 0.4666666666666667
Training loss = 0.03418990770975749
step = 14, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.58625
9  	8     	0.599219	0.0128686	0.58   	0.6225 
params:  [0.01, 0.99, 0.5956920553561771, 0.01, 0.6630010184429047, 0.4159240660013177, 0.2215840937548247, 0.7629042515593949, 0.99, 0.01, 0.3131458385038294, 0.33727291949954186, 0.20177302320842383, 0.12096381390560898, 0.5931339811276798, 0.01, 0.31123264882172685, 0.44073187953202064, 0.3100621507461533, 0.8585033146573133, 0.01, 0.3890310578384216, 0.13264418787938997, 0.4788538811279716, 0.01, 0.01, 0.47923278973642625, 0.2597953731620817, 0.49431393418824515, 0.25441472298308065, 0.5956525785618494, 0.11951270152862235, 0.01, 0.01, 0.6584667432151152, 0.99, 0.1972315915170464, 0.99, 0.7451536049530298, 0.01, 0.701590672420847, 0.7216710794442405, 0.45136904619563734, 0.6602721643217526, 0.39231210901562247, 0.99, 0.936218242017367, 0.5509539101574763, 0.99, 0.600029941926676, 0.7935199507379064, 0.99, 0.37356419359978044, 0.4309888444126987, 0.3768378156259922, 0.7086986554194958, 0.6876506938967005, 0.6668716696521952, 0.20832865511891893, 0.23521035812451802, 0.9469717902658505, 0.6890724186010418, 0.611745576717226, 0.8101131421667684, 0.99, 0.99, 0.01, 0.09012283891400603, 0.38872599950409314, 0.99, 0.3362097271164992, 0.5061950907219686, 0.11916402993153055, 0.4555321191171897, 0.99, 0.5328032183555755, 0.8160113924785731, 0.47945134656213717, 0.8401506375852288, 0.6421757734348332, 0.6227629853005415, 0.5471227365866858, 0.6406763784637461, 0.5407458559218247, 0.01, 0.01, 0.6486126891383873, 0.06667339877811544, 0.13847811076492297, 0.34475837233930673, 0.7489005763903795, 0.21008637588553716]
[0.01, 0.99, 0.5956920553561771, 0.01, 0.6630010184429047, 0.4159240660013177, 0.2215840937548247, 0.7629042515593949, 0.99, 0.01, 0.3131458385038294, 0.33727291949954186, 0.20177302320842383, 0.12096381390560898, 0.5931339811276798, 0.01, 0.31123264882172685, 0.44073187953202064, 0.3100621507461533, 0.8585033146573133, 0.01, 0.3890310578384216, 0.13264418787938997, 0.4788538811279716, 0.01, 0.01, 0.47923278973642625, 0.2597953731620817, 0.49431393418824515, 0.25441472298308065, 0.5956525785618494, 0.11951270152862235, 0.01, 0.01, 0.6584667432151152, 0.99, 0.1972315915170464, 0.99, 0.7451536049530298, 0.01, 0.701590672420847, 0.7216710794442405, 0.45136904619563734, 0.6602721643217526, 0.39231210901562247, 0.99, 0.936218242017367, 0.5509539101574763, 0.99, 0.600029941926676, 0.7935199507379064, 0.99, 0.37356419359978044, 0.4309888444126987, 0.3768378156259922, 0.7086986554194958, 0.6876506938967005, 0.6668716696521952, 0.20832865511891893, 0.23521035812451802, 0.9469717902658505, 0.6890724186010418, 0.611745576717226, 0.8101131421667684, 0.99, 0.99, 0.01, 0.09012283891400603, 0.38872599950409314, 0.99, 0.3362097271164992, 0.5061950907219686, 0.11916402993153055, 0.4555321191171897, 0.99, 0.5328032183555755, 0.8160113924785731, 0.47945134656213717, 0.8401506375852288, 0.6421757734348332, 0.6227629853005415, 0.5471227365866858, 0.6406763784637461, 0.5407458559218247, 0.01, 0.01, 0.6486126891383873, 0.06667339877811544, 0.13847811076492297, 0.34475837233930673, 0.7489005763903795, 0.21008637588553716]
Training loss = 0.03390606939792633
step = 0, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.5975
Training loss = 0.034410297473271685
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.033161777257919314
step = 2, Training Accuracy: 0.5066666666666667
Training loss = 0.032767370144526166
step = 3, Training Accuracy: 0.53
Training loss = 0.03473406493663788
step = 4, Training Accuracy: 0.47333333333333333
Training loss = 0.033969812591870624
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.60875
Training loss = 0.03286200284957886
step = 6, Training Accuracy: 0.5033333333333333
Training loss = 0.033224419951438905
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.033926557103792825
step = 8, Training Accuracy: 0.4766666666666667
Training loss = 0.03243570446968078
step = 9, Training Accuracy: 0.4866666666666667
Training loss = 0.032639376918474836
step = 10, Training Accuracy: 0.49
Validation Accuracy: 0.595
Training loss = 0.03366822838783264
step = 11, Training Accuracy: 0.5066666666666667
Training loss = 0.031182271043459574
step = 12, Training Accuracy: 0.5166666666666667
Training loss = 0.03371423343817393
step = 13, Training Accuracy: 0.46
Training loss = 0.03292917052904765
step = 14, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.59875
params:  [0.2856011772852685, 0.7594370791220381, 0.7126004341741866, 0.12517313820011905, 0.8883634235194923, 0.21619299601149236, 0.5298404139943921, 0.99, 0.99, 0.33112286792348433, 0.43953586962989905, 0.407655082313708, 0.3435766894168632, 0.01, 0.4316731572233542, 0.12392292474574558, 0.5624710527833429, 0.4795405447428924, 0.4558923474102585, 0.48646669839791845, 0.12343618208426725, 0.5498227468555575, 0.470826055848143, 0.5772418754723526, 0.04490133500177863, 0.01, 0.4750020145953645, 0.36595079290401833, 0.5358010218311031, 0.48633698001458686, 0.6157362591070228, 0.011970391893472876, 0.01, 0.01, 0.7068180979691112, 0.99, 0.01, 0.99, 0.9245161161506169, 0.16661417287924393, 0.99, 0.7588624567229408, 0.05377288687795673, 0.3222514761837433, 0.23638063500809126, 0.99, 0.11961710753980564, 0.9085386297329625, 0.8559222983499581, 0.9168682527808456, 0.5609909767066577, 0.99, 0.01, 0.22531372334439603, 0.6855933090275528, 0.8840009339311004, 0.4526406500662867, 0.7741300993173608, 0.6594651406100611, 0.01, 0.99, 0.9518078023616635, 0.45245606613382316, 0.6445102292603415, 0.99, 0.6189971875136244, 0.03276701169820813, 0.01, 0.01, 0.99, 0.06515252272198, 0.3683118112165697, 0.01, 0.5429490383398776, 0.99, 0.5373658454060022, 0.4891796102072564, 0.11009067815132353, 0.4432869088530619, 0.7800245735902086, 0.99, 0.30636364815092854, 0.3898089708152732, 0.01, 0.24802699096107722, 0.01, 0.430374024764827, 0.36494297763524586, 0.47534674641835084, 0.6765330244502005, 0.4359412336087437, 0.013433673353915779]
[0.2856011772852685, 0.7594370791220381, 0.7126004341741866, 0.12517313820011905, 0.8883634235194923, 0.21619299601149236, 0.5298404139943921, 0.99, 0.99, 0.33112286792348433, 0.43953586962989905, 0.407655082313708, 0.3435766894168632, 0.01, 0.4316731572233542, 0.12392292474574558, 0.5624710527833429, 0.4795405447428924, 0.4558923474102585, 0.48646669839791845, 0.12343618208426725, 0.5498227468555575, 0.470826055848143, 0.5772418754723526, 0.04490133500177863, 0.01, 0.4750020145953645, 0.36595079290401833, 0.5358010218311031, 0.48633698001458686, 0.6157362591070228, 0.011970391893472876, 0.01, 0.01, 0.7068180979691112, 0.99, 0.01, 0.99, 0.9245161161506169, 0.16661417287924393, 0.99, 0.7588624567229408, 0.05377288687795673, 0.3222514761837433, 0.23638063500809126, 0.99, 0.11961710753980564, 0.9085386297329625, 0.8559222983499581, 0.9168682527808456, 0.5609909767066577, 0.99, 0.01, 0.22531372334439603, 0.6855933090275528, 0.8840009339311004, 0.4526406500662867, 0.7741300993173608, 0.6594651406100611, 0.01, 0.99, 0.9518078023616635, 0.45245606613382316, 0.6445102292603415, 0.99, 0.6189971875136244, 0.03276701169820813, 0.01, 0.01, 0.99, 0.06515252272198, 0.3683118112165697, 0.01, 0.5429490383398776, 0.99, 0.5373658454060022, 0.4891796102072564, 0.11009067815132353, 0.4432869088530619, 0.7800245735902086, 0.99, 0.30636364815092854, 0.3898089708152732, 0.01, 0.24802699096107722, 0.01, 0.430374024764827, 0.36494297763524586, 0.47534674641835084, 0.6765330244502005, 0.4359412336087437, 0.013433673353915779]
Training loss = 0.033805948495864865
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.59125
Training loss = 0.03336376786231995
step = 1, Training Accuracy: 0.49
Training loss = 0.034026351571083066
step = 2, Training Accuracy: 0.4766666666666667
Training loss = 0.033931215604146324
step = 3, Training Accuracy: 0.4866666666666667
Training loss = 0.03360523521900177
step = 4, Training Accuracy: 0.5033333333333333
Training loss = 0.033448816736539204
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.59375
Training loss = 0.03364989737669627
step = 6, Training Accuracy: 0.4666666666666667
Training loss = 0.03385242482026418
step = 7, Training Accuracy: 0.45
Training loss = 0.03234637538592021
step = 8, Training Accuracy: 0.49
Training loss = 0.033449012438456216
step = 9, Training Accuracy: 0.47333333333333333
Training loss = 0.03385027945041656
step = 10, Training Accuracy: 0.45666666666666667
Validation Accuracy: 0.59125
Training loss = 0.034331133166948954
step = 11, Training Accuracy: 0.49
Training loss = 0.03308188736438751
step = 12, Training Accuracy: 0.4666666666666667
Training loss = 0.03404382367928823
step = 13, Training Accuracy: 0.4533333333333333
Training loss = 0.034343918959299724
step = 14, Training Accuracy: 0.46
Validation Accuracy: 0.6
params:  [0.13169544294810667, 0.7458263952857174, 0.6364353106421278, 0.3867281497898732, 0.9720529049216817, 0.06905820498257328, 0.01, 0.9416880672679876, 0.7758388416639423, 0.2881420831765797, 0.45338364239312584, 0.23645129424204825, 0.2880412532736845, 0.22932400286357463, 0.7789226425493622, 0.12297928936385452, 0.8116553395715689, 0.22787527737020624, 0.8727634785189418, 0.5738517358061064, 0.22105428177107328, 0.6290543111038243, 0.278722161189464, 0.5690215492804489, 0.01, 0.27158820041897225, 0.5996589035364459, 0.11801750685429749, 0.8722520992266024, 0.714919561454163, 0.6555111917370419, 0.4760711784559061, 0.01, 0.01, 0.7330754396079144, 0.99, 0.20511727588667816, 0.6012676822762801, 0.9095513105818744, 0.01, 0.39113625562360904, 0.6442174976823312, 0.17303600184055873, 0.2492133983801749, 0.17027826578302271, 0.8826209102894568, 0.41973952924619085, 0.2793281024695953, 0.9368519047315795, 0.45471240061145907, 0.9148364066718403, 0.9233886089514277, 0.06261266748799268, 0.8944761362143167, 0.2678524519559406, 0.5703591369728765, 0.138478372956565, 0.6832603592321567, 0.6688266293734096, 0.01, 0.8479659529336078, 0.268640000158588, 0.3844840028483928, 0.3211200155293806, 0.5724483898983788, 0.48791229906898226, 0.08552917083955168, 0.18869822101054223, 0.19132140407327908, 0.9408443264067715, 0.021293954822927508, 0.05485966531166908, 0.42134186433092546, 0.99, 0.7906741260686945, 0.7777883419305611, 0.7512584737503918, 0.08158198920450571, 0.46643328023755026, 0.9418327497264929, 0.1881282901340227, 0.42389197120535094, 0.7211636738651676, 0.46863744299860155, 0.18334226109712431, 0.01, 0.2924812738182566, 0.30096258653692387, 0.47777353249030075, 0.45104425306938234, 0.4535208907329521, 0.01]
[0.13169544294810667, 0.7458263952857174, 0.6364353106421278, 0.3867281497898732, 0.9720529049216817, 0.06905820498257328, 0.01, 0.9416880672679876, 0.7758388416639423, 0.2881420831765797, 0.45338364239312584, 0.23645129424204825, 0.2880412532736845, 0.22932400286357463, 0.7789226425493622, 0.12297928936385452, 0.8116553395715689, 0.22787527737020624, 0.8727634785189418, 0.5738517358061064, 0.22105428177107328, 0.6290543111038243, 0.278722161189464, 0.5690215492804489, 0.01, 0.27158820041897225, 0.5996589035364459, 0.11801750685429749, 0.8722520992266024, 0.714919561454163, 0.6555111917370419, 0.4760711784559061, 0.01, 0.01, 0.7330754396079144, 0.99, 0.20511727588667816, 0.6012676822762801, 0.9095513105818744, 0.01, 0.39113625562360904, 0.6442174976823312, 0.17303600184055873, 0.2492133983801749, 0.17027826578302271, 0.8826209102894568, 0.41973952924619085, 0.2793281024695953, 0.9368519047315795, 0.45471240061145907, 0.9148364066718403, 0.9233886089514277, 0.06261266748799268, 0.8944761362143167, 0.2678524519559406, 0.5703591369728765, 0.138478372956565, 0.6832603592321567, 0.6688266293734096, 0.01, 0.8479659529336078, 0.268640000158588, 0.3844840028483928, 0.3211200155293806, 0.5724483898983788, 0.48791229906898226, 0.08552917083955168, 0.18869822101054223, 0.19132140407327908, 0.9408443264067715, 0.021293954822927508, 0.05485966531166908, 0.42134186433092546, 0.99, 0.7906741260686945, 0.7777883419305611, 0.7512584737503918, 0.08158198920450571, 0.46643328023755026, 0.9418327497264929, 0.1881282901340227, 0.42389197120535094, 0.7211636738651676, 0.46863744299860155, 0.18334226109712431, 0.01, 0.2924812738182566, 0.30096258653692387, 0.47777353249030075, 0.45104425306938234, 0.4535208907329521, 0.01]
Training loss = 0.03476580957571666
step = 0, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.60125
Training loss = 0.03345805088678996
step = 1, Training Accuracy: 0.47333333333333333
Training loss = 0.03438120643297831
step = 2, Training Accuracy: 0.43666666666666665
Training loss = 0.03456035534540812
step = 3, Training Accuracy: 0.43333333333333335
Training loss = 0.032680155436197914
step = 4, Training Accuracy: 0.5266666666666666
Training loss = 0.03340367952982585
step = 5, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.60375
Training loss = 0.032617930769920346
step = 6, Training Accuracy: 0.5066666666666667
Training loss = 0.03291727880636851
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.033858461181322734
step = 8, Training Accuracy: 0.46
Training loss = 0.03330523649851481
step = 9, Training Accuracy: 0.48333333333333334
Training loss = 0.03384273747603098
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.615
Training loss = 0.03358480215072632
step = 11, Training Accuracy: 0.45
Training loss = 0.0326686563094457
step = 12, Training Accuracy: 0.5
Training loss = 0.03398503720760346
step = 13, Training Accuracy: 0.49
Training loss = 0.03195814490318298
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.59875
params:  [0.27070576974440635, 0.7707997937443023, 0.7103090104326215, 0.7873676931476584, 0.2121466962333195, 0.019375153115003096, 0.06432633093817555, 0.4810882281941192, 0.8919138049431529, 0.21310086605118933, 0.33553679828769234, 0.2719596269476677, 0.3897478474088091, 0.21573028982840248, 0.4408113910908626, 0.01, 0.7092726191098153, 0.4199232331166733, 0.5914732700831186, 0.4404424545419893, 0.12257659448771, 0.32404031219598756, 0.6064104460988428, 0.5657324922293983, 0.06097853961475849, 0.20065389961050797, 0.3881038836052074, 0.12873242857390266, 0.99, 0.013576772724574193, 0.99, 0.325816549686167, 0.2272963074023095, 0.3932319990996283, 0.554747831041227, 0.830248633398645, 0.01, 0.99, 0.8021031879681002, 0.08258586608921732, 0.99, 0.7801625792064675, 0.01, 0.25709488837284167, 0.6494406020856155, 0.99, 0.5889630249977295, 0.851753929422173, 0.99, 0.9355005634410801, 0.8268295753101981, 0.6761177261160012, 0.28340231003719357, 0.01, 0.12015466841786032, 0.6487032867557735, 0.0926574348353279, 0.880644061151141, 0.18529767310214706, 0.4782876281381974, 0.99, 0.9678794937765623, 0.6027368923587392, 0.99, 0.99, 0.41141809111175875, 0.01, 0.01, 0.1982157493629499, 0.99, 0.49393214616339465, 0.01, 0.41000595237677295, 0.45198309244496443, 0.8193459680492955, 0.3571853863625205, 0.5831464827817575, 0.34434635852571616, 0.17964933643711134, 0.9747483649951151, 0.4639953538230708, 0.5232582653502156, 0.8819374285505457, 0.39979922672137, 0.16069161351734557, 0.01210928443619641, 0.7072107366612563, 0.1981705990367071, 0.6093797993404779, 0.6459132103411184, 0.38704114024010994, 0.01]
[0.27070576974440635, 0.7707997937443023, 0.7103090104326215, 0.7873676931476584, 0.2121466962333195, 0.019375153115003096, 0.06432633093817555, 0.4810882281941192, 0.8919138049431529, 0.21310086605118933, 0.33553679828769234, 0.2719596269476677, 0.3897478474088091, 0.21573028982840248, 0.4408113910908626, 0.01, 0.7092726191098153, 0.4199232331166733, 0.5914732700831186, 0.4404424545419893, 0.12257659448771, 0.32404031219598756, 0.6064104460988428, 0.5657324922293983, 0.06097853961475849, 0.20065389961050797, 0.3881038836052074, 0.12873242857390266, 0.99, 0.013576772724574193, 0.99, 0.325816549686167, 0.2272963074023095, 0.3932319990996283, 0.554747831041227, 0.830248633398645, 0.01, 0.99, 0.8021031879681002, 0.08258586608921732, 0.99, 0.7801625792064675, 0.01, 0.25709488837284167, 0.6494406020856155, 0.99, 0.5889630249977295, 0.851753929422173, 0.99, 0.9355005634410801, 0.8268295753101981, 0.6761177261160012, 0.28340231003719357, 0.01, 0.12015466841786032, 0.6487032867557735, 0.0926574348353279, 0.880644061151141, 0.18529767310214706, 0.4782876281381974, 0.99, 0.9678794937765623, 0.6027368923587392, 0.99, 0.99, 0.41141809111175875, 0.01, 0.01, 0.1982157493629499, 0.99, 0.49393214616339465, 0.01, 0.41000595237677295, 0.45198309244496443, 0.8193459680492955, 0.3571853863625205, 0.5831464827817575, 0.34434635852571616, 0.17964933643711134, 0.9747483649951151, 0.4639953538230708, 0.5232582653502156, 0.8819374285505457, 0.39979922672137, 0.16069161351734557, 0.01210928443619641, 0.7072107366612563, 0.1981705990367071, 0.6093797993404779, 0.6459132103411184, 0.38704114024010994, 0.01]
Training loss = 0.03154765725135803
step = 0, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.6025
Training loss = 0.03054599165916443
step = 1, Training Accuracy: 0.5333333333333333
Training loss = 0.030183810591697693
step = 2, Training Accuracy: 0.5933333333333334
Training loss = 0.030782742500305174
step = 3, Training Accuracy: 0.5433333333333333
Training loss = 0.030964770515759785
step = 4, Training Accuracy: 0.5333333333333333
Training loss = 0.03065111438433329
step = 5, Training Accuracy: 0.55
Validation Accuracy: 0.615
Training loss = 0.030360395709673565
step = 6, Training Accuracy: 0.5866666666666667
Training loss = 0.031454970637957255
step = 7, Training Accuracy: 0.5366666666666666
Training loss = 0.030780637661616008
step = 8, Training Accuracy: 0.5666666666666667
Training loss = 0.029914289315541586
step = 9, Training Accuracy: 0.5733333333333334
Training loss = 0.0297408127784729
step = 10, Training Accuracy: 0.6033333333333334
Validation Accuracy: 0.62125
Training loss = 0.030692967971165976
step = 11, Training Accuracy: 0.5333333333333333
Training loss = 0.03009977420171102
step = 12, Training Accuracy: 0.5366666666666666
Training loss = 0.030479597846666973
step = 13, Training Accuracy: 0.5566666666666666
Training loss = 0.030947668155034382
step = 14, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.62125
params:  [0.2534570950443946, 0.99, 0.5567244358725805, 0.36013439319771684, 0.6160838168552296, 0.0754886402785874, 0.3168024298041993, 0.8904087752988524, 0.9147906650208111, 0.1693854077440669, 0.3822697137470572, 0.17549693841771866, 0.35193768227305927, 0.01, 0.52552770190481, 0.26446493010455147, 0.6663637229264041, 0.47028739038775413, 0.6752905797834491, 0.3100569936274659, 0.06497448392611399, 0.2118242826929282, 0.376388870781016, 0.4586245998285481, 0.015016546061054209, 0.26615621267170064, 0.3148552154161329, 0.16046084472286004, 0.686207159615637, 0.468232890270202, 0.9530467727008356, 0.04943536388711797, 0.01, 0.25511266987430775, 0.9185007467199081, 0.99, 0.39519932357599974, 0.7055528099988505, 0.99, 0.01, 0.5240230946625566, 0.9704661630765514, 0.34531759201691403, 0.11577667511834328, 0.10724922223693567, 0.99, 0.6642140335402711, 0.9492534760903358, 0.9811853587051995, 0.98481172400112, 0.99, 0.7327855935871207, 0.46091186807245943, 0.5715808673192472, 0.3009824387446199, 0.7494694768260401, 0.5137798857915916, 0.21788316790158258, 0.2725298551551453, 0.32608620094077184, 0.894392849763684, 0.47253460381499546, 0.613227785394059, 0.5915679609950222, 0.9594802336906935, 0.99, 0.06295626180688944, 0.36397475254635336, 0.01, 0.8507195410516922, 0.12914663886267336, 0.31331021916756935, 0.01, 0.6753362228242399, 0.9823240474814727, 0.01, 0.4371721823901936, 0.051908153944757396, 0.5464110207370452, 0.5875652958717792, 0.6633497184880387, 0.8459190274482113, 0.056730598700720614, 0.41218498832003003, 0.3680084315440031, 0.22670253179244282, 0.2434840592039161, 0.5324045103564805, 0.8405718625719232, 0.2601051744640849, 0.4125846717163426, 0.1531822271622428]
[0.2534570950443946, 0.99, 0.5567244358725805, 0.36013439319771684, 0.6160838168552296, 0.0754886402785874, 0.3168024298041993, 0.8904087752988524, 0.9147906650208111, 0.1693854077440669, 0.3822697137470572, 0.17549693841771866, 0.35193768227305927, 0.01, 0.52552770190481, 0.26446493010455147, 0.6663637229264041, 0.47028739038775413, 0.6752905797834491, 0.3100569936274659, 0.06497448392611399, 0.2118242826929282, 0.376388870781016, 0.4586245998285481, 0.015016546061054209, 0.26615621267170064, 0.3148552154161329, 0.16046084472286004, 0.686207159615637, 0.468232890270202, 0.9530467727008356, 0.04943536388711797, 0.01, 0.25511266987430775, 0.9185007467199081, 0.99, 0.39519932357599974, 0.7055528099988505, 0.99, 0.01, 0.5240230946625566, 0.9704661630765514, 0.34531759201691403, 0.11577667511834328, 0.10724922223693567, 0.99, 0.6642140335402711, 0.9492534760903358, 0.9811853587051995, 0.98481172400112, 0.99, 0.7327855935871207, 0.46091186807245943, 0.5715808673192472, 0.3009824387446199, 0.7494694768260401, 0.5137798857915916, 0.21788316790158258, 0.2725298551551453, 0.32608620094077184, 0.894392849763684, 0.47253460381499546, 0.613227785394059, 0.5915679609950222, 0.9594802336906935, 0.99, 0.06295626180688944, 0.36397475254635336, 0.01, 0.8507195410516922, 0.12914663886267336, 0.31331021916756935, 0.01, 0.6753362228242399, 0.9823240474814727, 0.01, 0.4371721823901936, 0.051908153944757396, 0.5464110207370452, 0.5875652958717792, 0.6633497184880387, 0.8459190274482113, 0.056730598700720614, 0.41218498832003003, 0.3680084315440031, 0.22670253179244282, 0.2434840592039161, 0.5324045103564805, 0.8405718625719232, 0.2601051744640849, 0.4125846717163426, 0.1531822271622428]
Training loss = 0.034392159581184384
step = 0, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.625
Training loss = 0.031799307266871135
step = 1, Training Accuracy: 0.5133333333333333
Training loss = 0.03359237730503082
step = 2, Training Accuracy: 0.48
Training loss = 0.032087844808896385
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.03169012308120728
step = 4, Training Accuracy: 0.52
Training loss = 0.03313131014506022
step = 5, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.6125
Training loss = 0.03197951416174571
step = 6, Training Accuracy: 0.49
Training loss = 0.03204636494318644
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.03291311283906301
step = 8, Training Accuracy: 0.52
Training loss = 0.033399778405825295
step = 9, Training Accuracy: 0.44333333333333336
Training loss = 0.03355119486649831
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.61625
Training loss = 0.03282208601633708
step = 11, Training Accuracy: 0.51
Training loss = 0.032109726468722025
step = 12, Training Accuracy: 0.5266666666666666
Training loss = 0.034027155041694644
step = 13, Training Accuracy: 0.49666666666666665
Training loss = 0.0333135586977005
step = 14, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.62125
params:  [0.35072764851650795, 0.9338635872736323, 0.6661116538548122, 0.22122407178079784, 0.9141833228931868, 0.26454309677589133, 0.08147019000482034, 0.7431768097712366, 0.779359970196542, 0.3674242569391465, 0.6812787958781966, 0.01, 0.5809945418023552, 0.36864128237691435, 0.4870070964979131, 0.3150183592559438, 0.3152561426253506, 0.2557270701650434, 0.6411261448893821, 0.08099058555980165, 0.01, 0.4077005383004977, 0.3515163842337565, 0.34192089639242, 0.4241941830280245, 0.5295961915468835, 0.5512975601314933, 0.01, 0.7284564086141284, 0.2562437655910898, 0.99, 0.4020711010579173, 0.01, 0.01, 0.9733059737639761, 0.8632191603411712, 0.01, 0.9816676796998494, 0.5936337168631086, 0.38642548251421627, 0.7375653512427975, 0.48444761576971657, 0.01, 0.48024066566013923, 0.09766994025227799, 0.8399134071011154, 0.24399780221732748, 0.15422605725272504, 0.99, 0.7070180803590025, 0.966902480574239, 0.4722642094037401, 0.3237688107226328, 0.22840565180992722, 0.195093680671687, 0.6033193746416275, 0.7049124617044611, 0.99, 0.01, 0.4226955042587988, 0.571667207395401, 0.4317182922704955, 0.8166083768519184, 0.99, 0.4022501141479854, 0.6382266595028482, 0.13098078971004062, 0.01, 0.4019944900970388, 0.7509872953959642, 0.10744549585806609, 0.11141881099397086, 0.13582694943570925, 0.42263822585794114, 0.7060801056256913, 0.5919192479316073, 0.3490408051516675, 0.01, 0.1474068984376523, 0.5068278072344523, 0.587667864816285, 0.27202408145422413, 0.3600024604533226, 0.5470220839396899, 0.24291271273767123, 0.01, 0.8262946501396632, 0.4607082434620983, 0.5164171798370287, 0.5461753834143539, 0.40004140807308897, 0.3149185418097739]
[0.35072764851650795, 0.9338635872736323, 0.6661116538548122, 0.22122407178079784, 0.9141833228931868, 0.26454309677589133, 0.08147019000482034, 0.7431768097712366, 0.779359970196542, 0.3674242569391465, 0.6812787958781966, 0.01, 0.5809945418023552, 0.36864128237691435, 0.4870070964979131, 0.3150183592559438, 0.3152561426253506, 0.2557270701650434, 0.6411261448893821, 0.08099058555980165, 0.01, 0.4077005383004977, 0.3515163842337565, 0.34192089639242, 0.4241941830280245, 0.5295961915468835, 0.5512975601314933, 0.01, 0.7284564086141284, 0.2562437655910898, 0.99, 0.4020711010579173, 0.01, 0.01, 0.9733059737639761, 0.8632191603411712, 0.01, 0.9816676796998494, 0.5936337168631086, 0.38642548251421627, 0.7375653512427975, 0.48444761576971657, 0.01, 0.48024066566013923, 0.09766994025227799, 0.8399134071011154, 0.24399780221732748, 0.15422605725272504, 0.99, 0.7070180803590025, 0.966902480574239, 0.4722642094037401, 0.3237688107226328, 0.22840565180992722, 0.195093680671687, 0.6033193746416275, 0.7049124617044611, 0.99, 0.01, 0.4226955042587988, 0.571667207395401, 0.4317182922704955, 0.8166083768519184, 0.99, 0.4022501141479854, 0.6382266595028482, 0.13098078971004062, 0.01, 0.4019944900970388, 0.7509872953959642, 0.10744549585806609, 0.11141881099397086, 0.13582694943570925, 0.42263822585794114, 0.7060801056256913, 0.5919192479316073, 0.3490408051516675, 0.01, 0.1474068984376523, 0.5068278072344523, 0.587667864816285, 0.27202408145422413, 0.3600024604533226, 0.5470220839396899, 0.24291271273767123, 0.01, 0.8262946501396632, 0.4607082434620983, 0.5164171798370287, 0.5461753834143539, 0.40004140807308897, 0.3149185418097739]
Training loss = 0.03235440194606781
step = 0, Training Accuracy: 0.49
Validation Accuracy: 0.61375
Training loss = 0.03127432107925415
step = 1, Training Accuracy: 0.52
Training loss = 0.03164353132247925
step = 2, Training Accuracy: 0.5366666666666666
Training loss = 0.031236298878987632
step = 3, Training Accuracy: 0.5
Training loss = 0.03215372363726298
step = 4, Training Accuracy: 0.5066666666666667
Training loss = 0.031732837557792666
step = 5, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.63
Training loss = 0.03198028385639191
step = 6, Training Accuracy: 0.51
Training loss = 0.03194026827812195
step = 7, Training Accuracy: 0.4866666666666667
Training loss = 0.03146655281384786
step = 8, Training Accuracy: 0.53
Training loss = 0.0304151060183843
step = 9, Training Accuracy: 0.58
Training loss = 0.0321800841887792
step = 10, Training Accuracy: 0.53
Validation Accuracy: 0.6275
Training loss = 0.03161867340405782
step = 11, Training Accuracy: 0.54
Training loss = 0.03137914141019185
step = 12, Training Accuracy: 0.5166666666666667
Training loss = 0.029840627908706664
step = 13, Training Accuracy: 0.5666666666666667
Training loss = 0.03274346947669983
step = 14, Training Accuracy: 0.45
Validation Accuracy: 0.62125
params:  [0.31552102438878094, 0.5899285609935816, 0.6142588538619482, 0.54415917460816, 0.8999868397680699, 0.10965205166656136, 0.017981733663600577, 0.99, 0.6885028219578901, 0.38368070336586346, 0.5155074874237544, 0.32754445436213353, 0.2693465845591983, 0.01, 0.7655033721693719, 0.7312943370057361, 0.24294169469554028, 0.10390538151555559, 0.5518437929513491, 0.648043377688718, 0.01, 0.99, 0.7851999538185818, 0.3623754074742262, 0.2429415022658448, 0.19951205588614698, 0.8116787248847821, 0.04395010082993356, 0.9355240753247126, 0.5204415636827275, 0.99, 0.5071268196424493, 0.01, 0.13012261369212383, 0.988743963910159, 0.7604286228727083, 0.11471884695271177, 0.8870266290894198, 0.8239144010326694, 0.32105960636251996, 0.3552717179737696, 0.9690190158937866, 0.011265935343695549, 0.6364282674356048, 0.3667545784789143, 0.6306001824728632, 0.21693542033080804, 0.1020973347774487, 0.99, 0.7161678373685465, 0.7205670277699538, 0.7879653148976533, 0.3976231659015002, 0.6046612626192123, 0.01, 0.6464083048743061, 0.7618311425441188, 0.99, 0.37171281540169887, 0.40247807388250334, 0.99, 0.9791653231799391, 0.2279561361890131, 0.6838631873915058, 0.8025370690123376, 0.47645181436075973, 0.12108051508243774, 0.01, 0.20220163964930093, 0.99, 0.01, 0.01, 0.01, 0.5987808746098786, 0.5262695824861747, 0.4309111076064528, 0.6534646379769267, 0.2186598371891479, 0.3863219742011373, 0.8255476872603892, 0.42786473910997536, 0.47298781416178953, 0.4274197883821841, 0.5734157708201363, 0.01, 0.049113018721510235, 0.727905017469354, 0.44697556307241043, 0.43274130318534565, 0.4795660445446647, 0.7327134384448087, 0.20757956404703443]
[0.31552102438878094, 0.5899285609935816, 0.6142588538619482, 0.54415917460816, 0.8999868397680699, 0.10965205166656136, 0.017981733663600577, 0.99, 0.6885028219578901, 0.38368070336586346, 0.5155074874237544, 0.32754445436213353, 0.2693465845591983, 0.01, 0.7655033721693719, 0.7312943370057361, 0.24294169469554028, 0.10390538151555559, 0.5518437929513491, 0.648043377688718, 0.01, 0.99, 0.7851999538185818, 0.3623754074742262, 0.2429415022658448, 0.19951205588614698, 0.8116787248847821, 0.04395010082993356, 0.9355240753247126, 0.5204415636827275, 0.99, 0.5071268196424493, 0.01, 0.13012261369212383, 0.988743963910159, 0.7604286228727083, 0.11471884695271177, 0.8870266290894198, 0.8239144010326694, 0.32105960636251996, 0.3552717179737696, 0.9690190158937866, 0.011265935343695549, 0.6364282674356048, 0.3667545784789143, 0.6306001824728632, 0.21693542033080804, 0.1020973347774487, 0.99, 0.7161678373685465, 0.7205670277699538, 0.7879653148976533, 0.3976231659015002, 0.6046612626192123, 0.01, 0.6464083048743061, 0.7618311425441188, 0.99, 0.37171281540169887, 0.40247807388250334, 0.99, 0.9791653231799391, 0.2279561361890131, 0.6838631873915058, 0.8025370690123376, 0.47645181436075973, 0.12108051508243774, 0.01, 0.20220163964930093, 0.99, 0.01, 0.01, 0.01, 0.5987808746098786, 0.5262695824861747, 0.4309111076064528, 0.6534646379769267, 0.2186598371891479, 0.3863219742011373, 0.8255476872603892, 0.42786473910997536, 0.47298781416178953, 0.4274197883821841, 0.5734157708201363, 0.01, 0.049113018721510235, 0.727905017469354, 0.44697556307241043, 0.43274130318534565, 0.4795660445446647, 0.7327134384448087, 0.20757956404703443]
Training loss = 0.034200890262921654
step = 0, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.6175
Training loss = 0.03367867469787598
step = 1, Training Accuracy: 0.5
Training loss = 0.03404152850310008
step = 2, Training Accuracy: 0.47333333333333333
Training loss = 0.03346149325370788
step = 3, Training Accuracy: 0.4766666666666667
Training loss = 0.0336869211991628
step = 4, Training Accuracy: 0.49666666666666665
Training loss = 0.03398690660794576
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.60375
Training loss = 0.03238995373249054
step = 6, Training Accuracy: 0.5
Training loss = 0.03329206645488739
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.03277909358342489
step = 8, Training Accuracy: 0.5066666666666667
Training loss = 0.0323323913415273
step = 9, Training Accuracy: 0.52
Training loss = 0.034330189029375714
step = 10, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.61
Training loss = 0.03475530604521433
step = 11, Training Accuracy: 0.5
Training loss = 0.03218728204568227
step = 12, Training Accuracy: 0.5
Training loss = 0.03280721306800842
step = 13, Training Accuracy: 0.51
Training loss = 0.033177016377449034
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.6125
params:  [0.01, 0.9274425139228664, 0.6806172892955351, 0.21970697339715864, 0.9009000628721112, 0.34848808094239236, 0.2826396398203194, 0.5646739132681462, 0.7087063494129772, 0.01, 0.4802546060144063, 0.27199576524245095, 0.01, 0.01, 0.8211350946589899, 0.01, 0.99, 0.01, 0.781002895524525, 0.4960911823735388, 0.2180231180396261, 0.12116490367641941, 0.4508593306142508, 0.7615632649430331, 0.06442026316885219, 0.5080885419679375, 0.600920980892141, 0.5377087692295872, 0.9263965269832224, 0.2986873836606281, 0.8774331606401728, 0.01, 0.2458986854797881, 0.05169641017431795, 0.74159800757319, 0.8851592110376335, 0.01, 0.99, 0.5164661523286378, 0.01, 0.8060567884881406, 0.594824561751044, 0.01, 0.01, 0.4320489427525395, 0.8376487281610513, 0.271492227565616, 0.7032317943942777, 0.99, 0.7672386598210451, 0.9367175415525772, 0.738867709904399, 0.33266685026647697, 0.46259605975084844, 0.2699606976629237, 0.9035406033189155, 0.99, 0.99, 0.4206928401807068, 0.038457517671653826, 0.8983823761859846, 0.23225224782794562, 0.2565549458413748, 0.8675664388428828, 0.99, 0.9672014764576684, 0.045149171134361274, 0.01, 0.01, 0.99, 0.44589280559976147, 0.07660624870714894, 0.22368639813194682, 0.7579146492564678, 0.5944787575584053, 0.20645783254492778, 0.6839373201295106, 0.728287867552178, 0.22019517447497516, 0.8219855191140356, 0.885236132317541, 0.6791775585662394, 0.5737688643341032, 0.17076437839420977, 0.3834676789383336, 0.4837332653304223, 0.012272532491337862, 0.034738223990857076, 0.031721526218012386, 0.2886408647312725, 0.2979264925042092, 0.23895328361713836]
[0.01, 0.9274425139228664, 0.6806172892955351, 0.21970697339715864, 0.9009000628721112, 0.34848808094239236, 0.2826396398203194, 0.5646739132681462, 0.7087063494129772, 0.01, 0.4802546060144063, 0.27199576524245095, 0.01, 0.01, 0.8211350946589899, 0.01, 0.99, 0.01, 0.781002895524525, 0.4960911823735388, 0.2180231180396261, 0.12116490367641941, 0.4508593306142508, 0.7615632649430331, 0.06442026316885219, 0.5080885419679375, 0.600920980892141, 0.5377087692295872, 0.9263965269832224, 0.2986873836606281, 0.8774331606401728, 0.01, 0.2458986854797881, 0.05169641017431795, 0.74159800757319, 0.8851592110376335, 0.01, 0.99, 0.5164661523286378, 0.01, 0.8060567884881406, 0.594824561751044, 0.01, 0.01, 0.4320489427525395, 0.8376487281610513, 0.271492227565616, 0.7032317943942777, 0.99, 0.7672386598210451, 0.9367175415525772, 0.738867709904399, 0.33266685026647697, 0.46259605975084844, 0.2699606976629237, 0.9035406033189155, 0.99, 0.99, 0.4206928401807068, 0.038457517671653826, 0.8983823761859846, 0.23225224782794562, 0.2565549458413748, 0.8675664388428828, 0.99, 0.9672014764576684, 0.045149171134361274, 0.01, 0.01, 0.99, 0.44589280559976147, 0.07660624870714894, 0.22368639813194682, 0.7579146492564678, 0.5944787575584053, 0.20645783254492778, 0.6839373201295106, 0.728287867552178, 0.22019517447497516, 0.8219855191140356, 0.885236132317541, 0.6791775585662394, 0.5737688643341032, 0.17076437839420977, 0.3834676789383336, 0.4837332653304223, 0.012272532491337862, 0.034738223990857076, 0.031721526218012386, 0.2886408647312725, 0.2979264925042092, 0.23895328361713836]
Training loss = 0.03493281582991282
step = 0, Training Accuracy: 0.44
Validation Accuracy: 0.61
Training loss = 0.0338821800549825
step = 1, Training Accuracy: 0.47
Training loss = 0.03377741734186808
step = 2, Training Accuracy: 0.48333333333333334
Training loss = 0.032849535544713336
step = 3, Training Accuracy: 0.5
Training loss = 0.033718610207239784
step = 4, Training Accuracy: 0.49666666666666665
Training loss = 0.03444074690341949
step = 5, Training Accuracy: 0.49
Validation Accuracy: 0.6225
Training loss = 0.03340151886145274
step = 6, Training Accuracy: 0.49
Training loss = 0.033847792148590086
step = 7, Training Accuracy: 0.47
Training loss = 0.03466028471787771
step = 8, Training Accuracy: 0.4166666666666667
Training loss = 0.03517099102338155
step = 9, Training Accuracy: 0.4666666666666667
Training loss = 0.033836646874745684
step = 10, Training Accuracy: 0.44
Validation Accuracy: 0.6325
Training loss = 0.03417224069436391
step = 11, Training Accuracy: 0.46
Training loss = 0.035121335585912065
step = 12, Training Accuracy: 0.43666666666666665
Training loss = 0.034391242861747745
step = 13, Training Accuracy: 0.4166666666666667
Training loss = 0.03384224077065786
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.63375
10 	8     	0.613437	0.0122912	0.59875	0.63375
params:  [0.027259587155085696, 0.7731986081458233, 0.99, 0.27824027931296497, 0.8740550088281878, 0.5792390323740211, 0.4471374450767956, 0.5419808457881531, 0.8693224139824546, 0.01, 0.3821639915605729, 0.01, 0.13505242022306055, 0.29338479758010516, 0.49576639227742075, 0.5098973694943961, 0.5678525825607801, 0.09844602354358453, 0.6301720497449036, 0.632517382543237, 0.19238814236042134, 0.01, 0.4513479985225144, 0.6795109545632896, 0.01, 0.01, 0.7482287732792916, 0.19144761544912942, 0.8001716472034475, 0.13052337216627705, 0.7166326403776198, 0.5155010064473418, 0.5005205632856186, 0.020098223780940228, 0.3995933486495533, 0.99, 0.12396077178328799, 0.99, 0.99, 0.03801183440302469, 0.99, 0.7967109758715807, 0.03413175146764033, 0.42421882843572034, 0.42141526464966383, 0.9791974620122276, 0.3552842410819867, 0.6228969138987227, 0.8935692762137358, 0.8090460796456813, 0.9646943589562289, 0.6702169053178341, 0.288530715747342, 0.3463928542968733, 0.01, 0.99, 0.89628190583693, 0.9871939987959386, 0.2326796628382038, 0.01, 0.99, 0.7830656191366079, 0.31528402865686395, 0.8936134362890873, 0.6572717718093106, 0.99, 0.3125671494454798, 0.16846128971662022, 0.01, 0.7801587431927327, 0.6157745530115502, 0.01, 0.3437459196631154, 0.7622994194657218, 0.9877301573380681, 0.24834222582941856, 0.8898415546115317, 0.7545641016288984, 0.4141358322667872, 0.7356312422188802, 0.6705037196526479, 0.5708956692995858, 0.41060783355353925, 0.0815359394683938, 0.7351209523028469, 0.21383488346475482, 0.5054831091229515, 0.44139258712577, 0.5193789607075083, 0.5285747531637391, 0.349354609654104, 0.17506834587455136]
[0.027259587155085696, 0.7731986081458233, 0.99, 0.27824027931296497, 0.8740550088281878, 0.5792390323740211, 0.4471374450767956, 0.5419808457881531, 0.8693224139824546, 0.01, 0.3821639915605729, 0.01, 0.13505242022306055, 0.29338479758010516, 0.49576639227742075, 0.5098973694943961, 0.5678525825607801, 0.09844602354358453, 0.6301720497449036, 0.632517382543237, 0.19238814236042134, 0.01, 0.4513479985225144, 0.6795109545632896, 0.01, 0.01, 0.7482287732792916, 0.19144761544912942, 0.8001716472034475, 0.13052337216627705, 0.7166326403776198, 0.5155010064473418, 0.5005205632856186, 0.020098223780940228, 0.3995933486495533, 0.99, 0.12396077178328799, 0.99, 0.99, 0.03801183440302469, 0.99, 0.7967109758715807, 0.03413175146764033, 0.42421882843572034, 0.42141526464966383, 0.9791974620122276, 0.3552842410819867, 0.6228969138987227, 0.8935692762137358, 0.8090460796456813, 0.9646943589562289, 0.6702169053178341, 0.288530715747342, 0.3463928542968733, 0.01, 0.99, 0.89628190583693, 0.9871939987959386, 0.2326796628382038, 0.01, 0.99, 0.7830656191366079, 0.31528402865686395, 0.8936134362890873, 0.6572717718093106, 0.99, 0.3125671494454798, 0.16846128971662022, 0.01, 0.7801587431927327, 0.6157745530115502, 0.01, 0.3437459196631154, 0.7622994194657218, 0.9877301573380681, 0.24834222582941856, 0.8898415546115317, 0.7545641016288984, 0.4141358322667872, 0.7356312422188802, 0.6705037196526479, 0.5708956692995858, 0.41060783355353925, 0.0815359394683938, 0.7351209523028469, 0.21383488346475482, 0.5054831091229515, 0.44139258712577, 0.5193789607075083, 0.5285747531637391, 0.349354609654104, 0.17506834587455136]
Training loss = 0.033805853128433226
step = 0, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.63875
Training loss = 0.03354548553625743
step = 1, Training Accuracy: 0.5033333333333333
Training loss = 0.03265956242879232
step = 2, Training Accuracy: 0.52
Training loss = 0.0328482186794281
step = 3, Training Accuracy: 0.4766666666666667
Training loss = 0.03187372366587321
step = 4, Training Accuracy: 0.52
Training loss = 0.03242570579051971
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.64125
Training loss = 0.033323284983634946
step = 6, Training Accuracy: 0.48
Training loss = 0.0323806627591451
step = 7, Training Accuracy: 0.4633333333333333
Training loss = 0.03227364242076874
step = 8, Training Accuracy: 0.53
Training loss = 0.032930835882822675
step = 9, Training Accuracy: 0.48333333333333334
Training loss = 0.03299325505892436
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.635
Training loss = 0.032605145970980326
step = 11, Training Accuracy: 0.4766666666666667
Training loss = 0.031848878264427186
step = 12, Training Accuracy: 0.5533333333333333
Training loss = 0.0327516637245814
step = 13, Training Accuracy: 0.4866666666666667
Training loss = 0.03187985599040985
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.63
params:  [0.01, 0.6535837758605535, 0.688728242297856, 0.2909850019880694, 0.32042650771535747, 0.01, 0.4571388055675052, 0.42520643087607674, 0.99, 0.35255604649298655, 0.3114316935754268, 0.24529303148004072, 0.23409957960599045, 0.2117657619898409, 0.7105675786685699, 0.1118256334154439, 0.7669271917480127, 0.013843156636805132, 0.9593733298535823, 0.3469806589981216, 0.6069493225409784, 0.10781878873111993, 0.4568686548978966, 0.4737449457227221, 0.01, 0.37632806260091073, 0.28790481999667367, 0.15444938302422448, 0.99, 0.08833358818709686, 0.8161249205824002, 0.01, 0.031061958670460438, 0.2804126743104147, 0.699561178194448, 0.940418399962102, 0.31349188450358756, 0.5848777127765601, 0.8266570095619091, 0.01, 0.99, 0.45421054153588514, 0.01, 0.23589946732403605, 0.6926661367226543, 0.99, 0.530934621399934, 0.99, 0.7955672451778731, 0.99, 0.9898832263563118, 0.8105590928873039, 0.29810547295004497, 0.7095274475616444, 0.01, 0.7959749674366529, 0.5348877799173298, 0.99, 0.453640103119331, 0.5109329124763672, 0.8571264555104386, 0.8597395507443384, 0.6173877677321535, 0.9279192970472405, 0.99, 0.9005665427501803, 0.04903387479148804, 0.5097557544769449, 0.11511023212984704, 0.99, 0.10234320553731785, 0.03417658842353256, 0.014590977288882923, 0.5533140658487065, 0.9516514571551137, 0.46775742493179884, 0.45880196708394566, 0.5193101123833593, 0.33078182620294, 0.99, 0.9244855103771072, 0.695439646495362, 0.7108361021874035, 0.135164278295098, 0.5699487500926363, 0.01, 0.3513544232609426, 0.09656060039519311, 0.28903214945065636, 0.21958027367385108, 0.34727517822795917, 0.12556796497107978]
[0.01, 0.6535837758605535, 0.688728242297856, 0.2909850019880694, 0.32042650771535747, 0.01, 0.4571388055675052, 0.42520643087607674, 0.99, 0.35255604649298655, 0.3114316935754268, 0.24529303148004072, 0.23409957960599045, 0.2117657619898409, 0.7105675786685699, 0.1118256334154439, 0.7669271917480127, 0.013843156636805132, 0.9593733298535823, 0.3469806589981216, 0.6069493225409784, 0.10781878873111993, 0.4568686548978966, 0.4737449457227221, 0.01, 0.37632806260091073, 0.28790481999667367, 0.15444938302422448, 0.99, 0.08833358818709686, 0.8161249205824002, 0.01, 0.031061958670460438, 0.2804126743104147, 0.699561178194448, 0.940418399962102, 0.31349188450358756, 0.5848777127765601, 0.8266570095619091, 0.01, 0.99, 0.45421054153588514, 0.01, 0.23589946732403605, 0.6926661367226543, 0.99, 0.530934621399934, 0.99, 0.7955672451778731, 0.99, 0.9898832263563118, 0.8105590928873039, 0.29810547295004497, 0.7095274475616444, 0.01, 0.7959749674366529, 0.5348877799173298, 0.99, 0.453640103119331, 0.5109329124763672, 0.8571264555104386, 0.8597395507443384, 0.6173877677321535, 0.9279192970472405, 0.99, 0.9005665427501803, 0.04903387479148804, 0.5097557544769449, 0.11511023212984704, 0.99, 0.10234320553731785, 0.03417658842353256, 0.014590977288882923, 0.5533140658487065, 0.9516514571551137, 0.46775742493179884, 0.45880196708394566, 0.5193101123833593, 0.33078182620294, 0.99, 0.9244855103771072, 0.695439646495362, 0.7108361021874035, 0.135164278295098, 0.5699487500926363, 0.01, 0.3513544232609426, 0.09656060039519311, 0.28903214945065636, 0.21958027367385108, 0.34727517822795917, 0.12556796497107978]
Training loss = 0.03310728152592977
step = 0, Training Accuracy: 0.5
Validation Accuracy: 0.62375
Training loss = 0.03244481146335602
step = 1, Training Accuracy: 0.53
Training loss = 0.033107826908429464
step = 2, Training Accuracy: 0.54
Training loss = 0.031576194167137146
step = 3, Training Accuracy: 0.5133333333333333
Training loss = 0.03263911028703054
step = 4, Training Accuracy: 0.48
Training loss = 0.03292597095171611
step = 5, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.6175
Training loss = 0.033073256810506185
step = 6, Training Accuracy: 0.4866666666666667
Training loss = 0.031226260860761006
step = 7, Training Accuracy: 0.54
Training loss = 0.030893526673316955
step = 8, Training Accuracy: 0.51
Training loss = 0.031219335993131002
step = 9, Training Accuracy: 0.5266666666666666
Training loss = 0.0315099694331487
step = 10, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.61125
Training loss = 0.03167616287867228
step = 11, Training Accuracy: 0.5333333333333333
Training loss = 0.03145151635011037
step = 12, Training Accuracy: 0.5366666666666666
Training loss = 0.03235574603080749
step = 13, Training Accuracy: 0.53
Training loss = 0.03099462846914927
step = 14, Training Accuracy: 0.5633333333333334
Validation Accuracy: 0.60875
params:  [0.01, 0.6556307180318114, 0.32272303671054686, 0.1665776344878948, 0.42417691620798104, 0.5225343206819747, 0.36271392849402023, 0.49471196539159634, 0.6088259470479581, 0.08526246057337529, 0.5581190029209876, 0.4547884923794627, 0.05252164275464108, 0.01, 0.99, 0.025876450840621394, 0.2543491694577519, 0.017695176201513813, 0.764679920255261, 0.37457603346098867, 0.01, 0.42642882969607865, 0.5808405326868822, 0.5294300891594412, 0.17438165227149868, 0.014695006998442228, 0.386038200841411, 0.6836307375040718, 0.6389415575251522, 0.44642385306163, 0.9235444042976072, 0.2556088627246985, 0.029364581848002252, 0.4872934135732946, 0.5611218684232304, 0.8718232666089802, 0.01, 0.5134033170769783, 0.4203865511876776, 0.03442900177322506, 0.6245081354558896, 0.6351665741431458, 0.3151684482121797, 0.28890424046409346, 0.4933558183929622, 0.99, 0.5212376644306782, 0.7675026168587379, 0.99, 0.99, 0.99, 0.5704429987722763, 0.46709254876165496, 0.1430150198138004, 0.27723358891391325, 0.8761655372495738, 0.8192033012153708, 0.764958263579066, 0.2445241650292242, 0.3125957951721291, 0.9821087785287226, 0.6040203305174217, 0.3923787349682961, 0.99, 0.99, 0.4606943636163234, 0.24774596227125426, 0.14839348128138177, 0.11755703943961843, 0.99, 0.35799972649282896, 0.17077864573353124, 0.5651592748973593, 0.43526726774816826, 0.99, 0.3063393823579892, 0.656238517461848, 0.03328109296243775, 0.3501651970282675, 0.9444626801878642, 0.5451828202573352, 0.8266180039507111, 0.99, 0.642194669827265, 0.1418705182232853, 0.06144306380104181, 0.18604545985455803, 0.01, 0.4622039923121256, 0.7156083711883949, 0.30802797065886456, 0.250968604298871]
[0.01, 0.6556307180318114, 0.32272303671054686, 0.1665776344878948, 0.42417691620798104, 0.5225343206819747, 0.36271392849402023, 0.49471196539159634, 0.6088259470479581, 0.08526246057337529, 0.5581190029209876, 0.4547884923794627, 0.05252164275464108, 0.01, 0.99, 0.025876450840621394, 0.2543491694577519, 0.017695176201513813, 0.764679920255261, 0.37457603346098867, 0.01, 0.42642882969607865, 0.5808405326868822, 0.5294300891594412, 0.17438165227149868, 0.014695006998442228, 0.386038200841411, 0.6836307375040718, 0.6389415575251522, 0.44642385306163, 0.9235444042976072, 0.2556088627246985, 0.029364581848002252, 0.4872934135732946, 0.5611218684232304, 0.8718232666089802, 0.01, 0.5134033170769783, 0.4203865511876776, 0.03442900177322506, 0.6245081354558896, 0.6351665741431458, 0.3151684482121797, 0.28890424046409346, 0.4933558183929622, 0.99, 0.5212376644306782, 0.7675026168587379, 0.99, 0.99, 0.99, 0.5704429987722763, 0.46709254876165496, 0.1430150198138004, 0.27723358891391325, 0.8761655372495738, 0.8192033012153708, 0.764958263579066, 0.2445241650292242, 0.3125957951721291, 0.9821087785287226, 0.6040203305174217, 0.3923787349682961, 0.99, 0.99, 0.4606943636163234, 0.24774596227125426, 0.14839348128138177, 0.11755703943961843, 0.99, 0.35799972649282896, 0.17077864573353124, 0.5651592748973593, 0.43526726774816826, 0.99, 0.3063393823579892, 0.656238517461848, 0.03328109296243775, 0.3501651970282675, 0.9444626801878642, 0.5451828202573352, 0.8266180039507111, 0.99, 0.642194669827265, 0.1418705182232853, 0.06144306380104181, 0.18604545985455803, 0.01, 0.4622039923121256, 0.7156083711883949, 0.30802797065886456, 0.250968604298871]
Training loss = 0.032824981609980264
step = 0, Training Accuracy: 0.51
Validation Accuracy: 0.61375
Training loss = 0.032862576444943746
step = 1, Training Accuracy: 0.5
Training loss = 0.03223745127518972
step = 2, Training Accuracy: 0.5033333333333333
Training loss = 0.03187253852685293
step = 3, Training Accuracy: 0.5266666666666666
Training loss = 0.0321369210879008
step = 4, Training Accuracy: 0.5166666666666667
Training loss = 0.03320184806982676
step = 5, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.635
Training loss = 0.03118402401606242
step = 6, Training Accuracy: 0.5233333333333333
Training loss = 0.032061927517255145
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.031556448737780254
step = 8, Training Accuracy: 0.5133333333333333
Training loss = 0.032201232314109804
step = 9, Training Accuracy: 0.53
Training loss = 0.03261087954044342
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.64125
Training loss = 0.0331053477525711
step = 11, Training Accuracy: 0.48333333333333334
Training loss = 0.03130909184614817
step = 12, Training Accuracy: 0.52
Training loss = 0.031627888878186544
step = 13, Training Accuracy: 0.5433333333333333
Training loss = 0.034139351646105445
step = 14, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.62625
params:  [0.01, 0.9003966901078583, 0.5122682115623471, 0.522066674140461, 0.99, 0.10315668589801397, 0.130190409702337, 0.6679990707812801, 0.57545953101596, 0.01, 0.7432199456944535, 0.14469796087430778, 0.22074543215753528, 0.01, 0.6760566444642353, 0.01594838021064906, 0.99, 0.1221045170619824, 0.8319222866472191, 0.3458334719067098, 0.01, 0.35357274925954585, 0.3629784933150392, 0.5266860704986985, 0.023446457940149504, 0.19976243807869182, 0.7616643897421824, 0.01, 0.8399857728017299, 0.01, 0.960289978077282, 0.01, 0.45774366820679174, 0.2612580139344853, 0.7748154744946716, 0.5537044375093187, 0.2305317697767474, 0.9012564520633616, 0.7366403430830384, 0.15060868168828268, 0.99, 0.713184967164753, 0.2804876219661387, 0.23427381073001208, 0.372349746764632, 0.9329761239569503, 0.2826864640584582, 0.5879213660076437, 0.99, 0.5355039191178642, 0.7653598977421264, 0.8325660984066032, 0.20253436110519732, 0.28798380817041286, 0.01, 0.766682107138502, 0.4648094584581808, 0.7115508437917919, 0.412389165445593, 0.01, 0.829087786174269, 0.5654400534056856, 0.3084301616821147, 0.8710903566871998, 0.8198335813854758, 0.99, 0.35088158349385323, 0.01, 0.01, 0.99, 0.3197727714314453, 0.3428860798078025, 0.20514835191606232, 0.982191088961617, 0.8852472051939015, 0.058034828583663406, 0.6089342774480262, 0.6872171838338841, 0.22198237699794812, 0.6650459947447518, 0.441048969639928, 0.5921487125933996, 0.8100310136685183, 0.21449799173911654, 0.35628929193953307, 0.10415532387835852, 0.02599433213591229, 0.47587535157610333, 0.3606841018570547, 0.16175369728307176, 0.37732833902900803, 0.01]
[0.01, 0.9003966901078583, 0.5122682115623471, 0.522066674140461, 0.99, 0.10315668589801397, 0.130190409702337, 0.6679990707812801, 0.57545953101596, 0.01, 0.7432199456944535, 0.14469796087430778, 0.22074543215753528, 0.01, 0.6760566444642353, 0.01594838021064906, 0.99, 0.1221045170619824, 0.8319222866472191, 0.3458334719067098, 0.01, 0.35357274925954585, 0.3629784933150392, 0.5266860704986985, 0.023446457940149504, 0.19976243807869182, 0.7616643897421824, 0.01, 0.8399857728017299, 0.01, 0.960289978077282, 0.01, 0.45774366820679174, 0.2612580139344853, 0.7748154744946716, 0.5537044375093187, 0.2305317697767474, 0.9012564520633616, 0.7366403430830384, 0.15060868168828268, 0.99, 0.713184967164753, 0.2804876219661387, 0.23427381073001208, 0.372349746764632, 0.9329761239569503, 0.2826864640584582, 0.5879213660076437, 0.99, 0.5355039191178642, 0.7653598977421264, 0.8325660984066032, 0.20253436110519732, 0.28798380817041286, 0.01, 0.766682107138502, 0.4648094584581808, 0.7115508437917919, 0.412389165445593, 0.01, 0.829087786174269, 0.5654400534056856, 0.3084301616821147, 0.8710903566871998, 0.8198335813854758, 0.99, 0.35088158349385323, 0.01, 0.01, 0.99, 0.3197727714314453, 0.3428860798078025, 0.20514835191606232, 0.982191088961617, 0.8852472051939015, 0.058034828583663406, 0.6089342774480262, 0.6872171838338841, 0.22198237699794812, 0.6650459947447518, 0.441048969639928, 0.5921487125933996, 0.8100310136685183, 0.21449799173911654, 0.35628929193953307, 0.10415532387835852, 0.02599433213591229, 0.47587535157610333, 0.3606841018570547, 0.16175369728307176, 0.37732833902900803, 0.01]
Training loss = 0.0310159969329834
step = 0, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.62
Training loss = 0.029015231132507324
step = 1, Training Accuracy: 0.5766666666666667
Training loss = 0.0314375501871109
step = 2, Training Accuracy: 0.5366666666666666
Training loss = 0.029832677642504375
step = 3, Training Accuracy: 0.5633333333333334
Training loss = 0.031149579286575316
step = 4, Training Accuracy: 0.5533333333333333
Training loss = 0.03107751687367757
step = 5, Training Accuracy: 0.52
Validation Accuracy: 0.62625
Training loss = 0.02894050459067027
step = 6, Training Accuracy: 0.58
Training loss = 0.029270029465357464
step = 7, Training Accuracy: 0.5566666666666666
Training loss = 0.029702815016110738
step = 8, Training Accuracy: 0.5666666666666667
Training loss = 0.02969556232293447
step = 9, Training Accuracy: 0.5733333333333334
Training loss = 0.02898843010266622
step = 10, Training Accuracy: 0.6
Validation Accuracy: 0.62625
Training loss = 0.030859706401824952
step = 11, Training Accuracy: 0.5466666666666666
Training loss = 0.028981701731681825
step = 12, Training Accuracy: 0.58
Training loss = 0.02767452855904897
step = 13, Training Accuracy: 0.5866666666666667
Training loss = 0.029269112547238667
step = 14, Training Accuracy: 0.5766666666666667
Validation Accuracy: 0.6275
params:  [0.01, 0.8872945411188634, 0.6369343304494823, 0.3886632066095894, 0.30368697924407867, 0.01, 0.08833620868373154, 0.409228472654301, 0.7934672564657971, 0.08289368529484933, 0.14480597850909227, 0.5379455064297329, 0.01, 0.01, 0.37979710596968247, 0.01, 0.99, 0.2410013141825475, 0.7598844855078452, 0.37758327492440347, 0.16813677572347677, 0.01, 0.5032321861152337, 0.6611860783160146, 0.4325815370974636, 0.30757025045724595, 0.4636714616714583, 0.817328933134762, 0.8847692534673606, 0.18165410489505948, 0.99, 0.01, 0.03361561723971798, 0.23766119241513028, 0.7065436206162067, 0.99, 0.01, 0.99, 0.5642237861528102, 0.01, 0.715999713145643, 0.5303977887541851, 0.28451346862366844, 0.31789961073956385, 0.4692639742579507, 0.8229202071926394, 0.543737951684014, 0.4807774714543007, 0.381212791093671, 0.9425711858979713, 0.9467682157058939, 0.8934070320494191, 0.5910347620655063, 0.4274986083774782, 0.01, 0.41688441705488244, 0.6145806800183171, 0.9589236598830503, 0.4231031814445732, 0.16781326892553255, 0.99, 0.4262633387436533, 0.7521136064930136, 0.70983544266195, 0.99, 0.873866329975975, 0.01, 0.28070328920554594, 0.01, 0.7763440010725481, 0.5177870324743928, 0.015456203822975065, 0.18838193594323638, 0.891736909017738, 0.8721455842251782, 0.01, 0.19762957728818875, 0.7858209355792878, 0.4796041727462052, 0.44321104765023694, 0.4072314313751333, 0.49411174728627805, 0.7802616447497632, 0.48461247896408577, 0.10135456316725827, 0.01, 0.43997777241493385, 0.3759525898234639, 0.17827088612940248, 0.4779651318009054, 0.03009275920033705, 0.012749265031964718]
[0.01, 0.8872945411188634, 0.6369343304494823, 0.3886632066095894, 0.30368697924407867, 0.01, 0.08833620868373154, 0.409228472654301, 0.7934672564657971, 0.08289368529484933, 0.14480597850909227, 0.5379455064297329, 0.01, 0.01, 0.37979710596968247, 0.01, 0.99, 0.2410013141825475, 0.7598844855078452, 0.37758327492440347, 0.16813677572347677, 0.01, 0.5032321861152337, 0.6611860783160146, 0.4325815370974636, 0.30757025045724595, 0.4636714616714583, 0.817328933134762, 0.8847692534673606, 0.18165410489505948, 0.99, 0.01, 0.03361561723971798, 0.23766119241513028, 0.7065436206162067, 0.99, 0.01, 0.99, 0.5642237861528102, 0.01, 0.715999713145643, 0.5303977887541851, 0.28451346862366844, 0.31789961073956385, 0.4692639742579507, 0.8229202071926394, 0.543737951684014, 0.4807774714543007, 0.381212791093671, 0.9425711858979713, 0.9467682157058939, 0.8934070320494191, 0.5910347620655063, 0.4274986083774782, 0.01, 0.41688441705488244, 0.6145806800183171, 0.9589236598830503, 0.4231031814445732, 0.16781326892553255, 0.99, 0.4262633387436533, 0.7521136064930136, 0.70983544266195, 0.99, 0.873866329975975, 0.01, 0.28070328920554594, 0.01, 0.7763440010725481, 0.5177870324743928, 0.015456203822975065, 0.18838193594323638, 0.891736909017738, 0.8721455842251782, 0.01, 0.19762957728818875, 0.7858209355792878, 0.4796041727462052, 0.44321104765023694, 0.4072314313751333, 0.49411174728627805, 0.7802616447497632, 0.48461247896408577, 0.10135456316725827, 0.01, 0.43997777241493385, 0.3759525898234639, 0.17827088612940248, 0.4779651318009054, 0.03009275920033705, 0.012749265031964718]
Training loss = 0.03118973215421041
step = 0, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.6225
Training loss = 0.03337585210800171
step = 1, Training Accuracy: 0.49666666666666665
Training loss = 0.032376376589139305
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.030983427762985228
step = 3, Training Accuracy: 0.5333333333333333
Training loss = 0.031908745964368185
step = 4, Training Accuracy: 0.5266666666666666
Training loss = 0.03245463748772939
step = 5, Training Accuracy: 0.55
Validation Accuracy: 0.63625
Training loss = 0.03284842848777771
step = 6, Training Accuracy: 0.5
Training loss = 0.03278471569220225
step = 7, Training Accuracy: 0.52
Training loss = 0.0336581289768219
step = 8, Training Accuracy: 0.48333333333333334
Training loss = 0.03220976372559865
step = 9, Training Accuracy: 0.5133333333333333
Training loss = 0.03154215395450592
step = 10, Training Accuracy: 0.53
Validation Accuracy: 0.64125
Training loss = 0.03075058082739512
step = 11, Training Accuracy: 0.49
Training loss = 0.02994513511657715
step = 12, Training Accuracy: 0.5466666666666666
Training loss = 0.03309126178423564
step = 13, Training Accuracy: 0.5
Training loss = 0.03170016805330912
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.61
params:  [0.01, 0.99, 0.180257817195626, 0.38945127500794696, 0.632577839235981, 0.24884884134046686, 0.24570552494622577, 0.6570925468254468, 0.5790863444124664, 0.0591460522730723, 0.28389829896454166, 0.3077322973489614, 0.12056430026175241, 0.04480872503282263, 0.5461496044470935, 0.01, 0.99, 0.01, 0.9007858767288682, 0.8017161598974758, 0.2617434011067247, 0.13983727381330124, 0.5484131666651743, 0.7947723866978766, 0.01, 0.5795094151550049, 0.5640456474275619, 0.6264735166058771, 0.6983536392309749, 0.01, 0.40035569298779183, 0.2231818628596201, 0.22015039942736514, 0.3843901919838635, 0.8467652506555452, 0.689119095362954, 0.01, 0.99, 0.7882769945171413, 0.01, 0.99, 0.6312325879224413, 0.5799972269496926, 0.4621497470289382, 0.34063347547913275, 0.7128843773079194, 0.4367179877302354, 0.99, 0.99, 0.99, 0.6389457906448883, 0.99, 0.1999886976005606, 0.3867445027488662, 0.5241666557251063, 0.8781258380678498, 0.48386040432153676, 0.799537045342188, 0.6205959265065583, 0.01, 0.5918125789733302, 0.5836860129695388, 0.23845850203468894, 0.6568700356505079, 0.6487304932137876, 0.9319323276395561, 0.01, 0.01, 0.01, 0.99, 0.19942476055673813, 0.11819481323866496, 0.1560674653854125, 0.5861080228777865, 0.8105490481237109, 0.33652536786896425, 0.6000457898708981, 0.530610962860862, 0.4657641977761078, 0.99, 0.6478619849661694, 0.6594922001363127, 0.2493526801148508, 0.22283046974274995, 0.5811371475651642, 0.6317649725022632, 0.42789586839536853, 0.5420079907490398, 0.16139840986807477, 0.7267282275951492, 0.3898468996273642, 0.06615227855886631]
[0.01, 0.99, 0.180257817195626, 0.38945127500794696, 0.632577839235981, 0.24884884134046686, 0.24570552494622577, 0.6570925468254468, 0.5790863444124664, 0.0591460522730723, 0.28389829896454166, 0.3077322973489614, 0.12056430026175241, 0.04480872503282263, 0.5461496044470935, 0.01, 0.99, 0.01, 0.9007858767288682, 0.8017161598974758, 0.2617434011067247, 0.13983727381330124, 0.5484131666651743, 0.7947723866978766, 0.01, 0.5795094151550049, 0.5640456474275619, 0.6264735166058771, 0.6983536392309749, 0.01, 0.40035569298779183, 0.2231818628596201, 0.22015039942736514, 0.3843901919838635, 0.8467652506555452, 0.689119095362954, 0.01, 0.99, 0.7882769945171413, 0.01, 0.99, 0.6312325879224413, 0.5799972269496926, 0.4621497470289382, 0.34063347547913275, 0.7128843773079194, 0.4367179877302354, 0.99, 0.99, 0.99, 0.6389457906448883, 0.99, 0.1999886976005606, 0.3867445027488662, 0.5241666557251063, 0.8781258380678498, 0.48386040432153676, 0.799537045342188, 0.6205959265065583, 0.01, 0.5918125789733302, 0.5836860129695388, 0.23845850203468894, 0.6568700356505079, 0.6487304932137876, 0.9319323276395561, 0.01, 0.01, 0.01, 0.99, 0.19942476055673813, 0.11819481323866496, 0.1560674653854125, 0.5861080228777865, 0.8105490481237109, 0.33652536786896425, 0.6000457898708981, 0.530610962860862, 0.4657641977761078, 0.99, 0.6478619849661694, 0.6594922001363127, 0.2493526801148508, 0.22283046974274995, 0.5811371475651642, 0.6317649725022632, 0.42789586839536853, 0.5420079907490398, 0.16139840986807477, 0.7267282275951492, 0.3898468996273642, 0.06615227855886631]
Training loss = 0.030853002866109213
step = 0, Training Accuracy: 0.5666666666666667
Validation Accuracy: 0.6075
Training loss = 0.031055822372436523
step = 1, Training Accuracy: 0.5233333333333333
Training loss = 0.031853689551353453
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.031677772800127665
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.0303838978211085
step = 4, Training Accuracy: 0.54
Training loss = 0.03247091035048167
step = 5, Training Accuracy: 0.51
Validation Accuracy: 0.60375
Training loss = 0.02954128404458364
step = 6, Training Accuracy: 0.5833333333333334
Training loss = 0.031199144721031188
step = 7, Training Accuracy: 0.56
Training loss = 0.03079211990038554
step = 8, Training Accuracy: 0.5433333333333333
Training loss = 0.030863032539685566
step = 9, Training Accuracy: 0.54
Training loss = 0.031663674712181095
step = 10, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.61125
Training loss = 0.029182143012682595
step = 11, Training Accuracy: 0.5466666666666666
Training loss = 0.03230677803357442
step = 12, Training Accuracy: 0.55
Training loss = 0.03162247975667318
step = 13, Training Accuracy: 0.5266666666666666
Training loss = 0.03113601823647817
step = 14, Training Accuracy: 0.5466666666666666
Validation Accuracy: 0.60625
params:  [0.33464587351936265, 0.99, 0.5086980252611744, 0.36549379831817846, 0.6784570696711084, 0.2163489799017222, 0.28431583287008355, 0.7259313339773495, 0.9360683125250021, 0.01, 0.7793280524783197, 0.1760461757685537, 0.2273373790823052, 0.2901213153932949, 0.99, 0.01, 0.99, 0.23291959295726783, 0.7849714273505729, 0.6952242169789457, 0.05499340900986001, 0.14030804267043523, 0.36441103803426456, 0.0608338346463938, 0.30036636752024537, 0.531637158483178, 0.4009609482962663, 0.4536270986325264, 0.99, 0.5052560002418087, 0.9552287853350075, 0.08268363028278121, 0.36731620825722033, 0.38390948080714515, 0.6728551472960185, 0.9421262045470011, 0.23891859876756916, 0.9624688158377194, 0.960587870029492, 0.3654861347884449, 0.99, 0.99, 0.03168295420053475, 0.1692063592436705, 0.643098024583465, 0.9797049787139331, 0.6878093531405377, 0.6659178157907687, 0.9895532015570764, 0.5866158572407878, 0.9490045106413939, 0.7862774184962538, 0.4355485561313652, 0.11370449248642034, 0.1474657546196217, 0.99, 0.4814587429032876, 0.99, 0.3396103556754227, 0.502269914568404, 0.99, 0.048363210121928124, 0.4274608529604028, 0.6528097493003343, 0.9847584479681321, 0.7003359260565714, 0.11192378150886165, 0.01, 0.07154566717833832, 0.99, 0.17830201755662037, 0.21731568692964182, 0.2682588949346156, 0.7261352352302604, 0.4455181211563796, 0.21375126393938002, 0.6414133489562055, 0.3457303324187512, 0.3468167857907284, 0.8655393994616386, 0.7070884841859215, 0.7734511639474966, 0.6087570989974325, 0.24777716823414883, 0.4098318797163749, 0.24085164574367623, 0.43765352237881616, 0.01, 0.3237931090524326, 0.35594966574949316, 0.23743613986754014, 0.01]
[0.33464587351936265, 0.99, 0.5086980252611744, 0.36549379831817846, 0.6784570696711084, 0.2163489799017222, 0.28431583287008355, 0.7259313339773495, 0.9360683125250021, 0.01, 0.7793280524783197, 0.1760461757685537, 0.2273373790823052, 0.2901213153932949, 0.99, 0.01, 0.99, 0.23291959295726783, 0.7849714273505729, 0.6952242169789457, 0.05499340900986001, 0.14030804267043523, 0.36441103803426456, 0.0608338346463938, 0.30036636752024537, 0.531637158483178, 0.4009609482962663, 0.4536270986325264, 0.99, 0.5052560002418087, 0.9552287853350075, 0.08268363028278121, 0.36731620825722033, 0.38390948080714515, 0.6728551472960185, 0.9421262045470011, 0.23891859876756916, 0.9624688158377194, 0.960587870029492, 0.3654861347884449, 0.99, 0.99, 0.03168295420053475, 0.1692063592436705, 0.643098024583465, 0.9797049787139331, 0.6878093531405377, 0.6659178157907687, 0.9895532015570764, 0.5866158572407878, 0.9490045106413939, 0.7862774184962538, 0.4355485561313652, 0.11370449248642034, 0.1474657546196217, 0.99, 0.4814587429032876, 0.99, 0.3396103556754227, 0.502269914568404, 0.99, 0.048363210121928124, 0.4274608529604028, 0.6528097493003343, 0.9847584479681321, 0.7003359260565714, 0.11192378150886165, 0.01, 0.07154566717833832, 0.99, 0.17830201755662037, 0.21731568692964182, 0.2682588949346156, 0.7261352352302604, 0.4455181211563796, 0.21375126393938002, 0.6414133489562055, 0.3457303324187512, 0.3468167857907284, 0.8655393994616386, 0.7070884841859215, 0.7734511639474966, 0.6087570989974325, 0.24777716823414883, 0.4098318797163749, 0.24085164574367623, 0.43765352237881616, 0.01, 0.3237931090524326, 0.35594966574949316, 0.23743613986754014, 0.01]
Training loss = 0.03437833289305369
step = 0, Training Accuracy: 0.45
Validation Accuracy: 0.635
Training loss = 0.0330164357026418
step = 1, Training Accuracy: 0.5
Training loss = 0.03372842808564504
step = 2, Training Accuracy: 0.45666666666666667
Training loss = 0.03390197217464447
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.0321510914961497
step = 4, Training Accuracy: 0.5333333333333333
Training loss = 0.03231647173563639
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.62375
Training loss = 0.03275791029135386
step = 6, Training Accuracy: 0.5033333333333333
Training loss = 0.03223541915416717
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.03316738228003184
step = 8, Training Accuracy: 0.47333333333333333
Training loss = 0.03280677159627279
step = 9, Training Accuracy: 0.47
Training loss = 0.034039652744929
step = 10, Training Accuracy: 0.44333333333333336
Validation Accuracy: 0.61375
Training loss = 0.03305403610070547
step = 11, Training Accuracy: 0.48333333333333334
Training loss = 0.032047784527142846
step = 12, Training Accuracy: 0.5033333333333333
Training loss = 0.032962751189867655
step = 13, Training Accuracy: 0.5
Training loss = 0.031261052886645
step = 14, Training Accuracy: 0.5466666666666666
Validation Accuracy: 0.6175
params:  [0.30032669475415585, 0.9405885295942185, 0.6458288607239416, 0.8895256505361335, 0.6143895244428769, 0.19885744709180886, 0.3485857836399533, 0.3770681957100762, 0.6495521474178181, 0.01, 0.2016613177314012, 0.01, 0.07438159482587718, 0.43145582887759304, 0.6333341723691828, 0.01, 0.7004715840992738, 0.2284046007110457, 0.56025111516625, 0.3642328006712443, 0.02250406422776957, 0.24745447000021317, 0.9781273603878102, 0.6134942921100502, 0.01, 0.46576564410746213, 0.7707811490842544, 0.40874915376026216, 0.99, 0.15564004718881358, 0.8056427771837321, 0.22548457770838437, 0.5157706539077298, 0.018713960901619336, 0.7343748609973424, 0.99, 0.01, 0.99, 0.7238551684046614, 0.01, 0.484296415188598, 0.704514557667608, 0.20749976127104564, 0.2665202874141893, 0.49681536321736597, 0.6143089865087041, 0.26691926423013734, 0.99, 0.99, 0.7665054810936365, 0.8286169455664824, 0.5850234595883582, 0.09440893425944652, 0.6669000951926163, 0.01, 0.99, 0.01, 0.99, 0.37383548128836386, 0.14445773664475364, 0.6171936568427857, 0.7407136696713996, 0.03867496309050622, 0.99, 0.99, 0.795814926005044, 0.01, 0.34585495788825443, 0.01, 0.99, 0.7677968299920348, 0.25002388722004226, 0.5086092986463421, 0.556191865689536, 0.8428672626877807, 0.45757144397996186, 0.623687073291474, 0.32474441191279635, 0.19932960236386982, 0.99, 0.99, 0.45207210589904123, 0.8859289671906869, 0.5362416943601799, 0.08459081391293247, 0.6452909489706034, 0.06749063633758032, 0.019432420736090583, 0.4467971719933357, 0.8055256225147756, 0.01, 0.01]
[0.30032669475415585, 0.9405885295942185, 0.6458288607239416, 0.8895256505361335, 0.6143895244428769, 0.19885744709180886, 0.3485857836399533, 0.3770681957100762, 0.6495521474178181, 0.01, 0.2016613177314012, 0.01, 0.07438159482587718, 0.43145582887759304, 0.6333341723691828, 0.01, 0.7004715840992738, 0.2284046007110457, 0.56025111516625, 0.3642328006712443, 0.02250406422776957, 0.24745447000021317, 0.9781273603878102, 0.6134942921100502, 0.01, 0.46576564410746213, 0.7707811490842544, 0.40874915376026216, 0.99, 0.15564004718881358, 0.8056427771837321, 0.22548457770838437, 0.5157706539077298, 0.018713960901619336, 0.7343748609973424, 0.99, 0.01, 0.99, 0.7238551684046614, 0.01, 0.484296415188598, 0.704514557667608, 0.20749976127104564, 0.2665202874141893, 0.49681536321736597, 0.6143089865087041, 0.26691926423013734, 0.99, 0.99, 0.7665054810936365, 0.8286169455664824, 0.5850234595883582, 0.09440893425944652, 0.6669000951926163, 0.01, 0.99, 0.01, 0.99, 0.37383548128836386, 0.14445773664475364, 0.6171936568427857, 0.7407136696713996, 0.03867496309050622, 0.99, 0.99, 0.795814926005044, 0.01, 0.34585495788825443, 0.01, 0.99, 0.7677968299920348, 0.25002388722004226, 0.5086092986463421, 0.556191865689536, 0.8428672626877807, 0.45757144397996186, 0.623687073291474, 0.32474441191279635, 0.19932960236386982, 0.99, 0.99, 0.45207210589904123, 0.8859289671906869, 0.5362416943601799, 0.08459081391293247, 0.6452909489706034, 0.06749063633758032, 0.019432420736090583, 0.4467971719933357, 0.8055256225147756, 0.01, 0.01]
Training loss = 0.032248958746592206
step = 0, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.61625
Training loss = 0.03145941237608592
step = 1, Training Accuracy: 0.5433333333333333
Training loss = 0.03130137383937836
step = 2, Training Accuracy: 0.51
Training loss = 0.032405768434206644
step = 3, Training Accuracy: 0.5
Training loss = 0.0315978197256724
step = 4, Training Accuracy: 0.51
Training loss = 0.03187727153301239
step = 5, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.6075
Training loss = 0.031637434562047324
step = 6, Training Accuracy: 0.4766666666666667
Training loss = 0.03233708262443542
step = 7, Training Accuracy: 0.5433333333333333
Training loss = 0.03162761350472768
step = 8, Training Accuracy: 0.49666666666666665
Training loss = 0.031775083541870114
step = 9, Training Accuracy: 0.54
Training loss = 0.031983590722084045
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.605
Training loss = 0.03195785164833069
step = 11, Training Accuracy: 0.52
Training loss = 0.031032428940137226
step = 12, Training Accuracy: 0.53
Training loss = 0.032096295952796935
step = 13, Training Accuracy: 0.5166666666666667
Training loss = 0.03244033614794413
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.6025
11 	8     	0.616094	0.0100085	0.6025 	0.63   
params:  [0.01, 0.8678465349002085, 0.9622902809687255, 0.01, 0.7695535842013261, 0.27400414231596815, 0.6656117778895835, 0.930448287560647, 0.6711426130743958, 0.3411491227958065, 0.20105697615083123, 0.01, 0.14390079920643645, 0.016761251940676514, 0.9827006595953669, 0.27135054850401014, 0.7217862242161706, 0.01, 0.99, 0.696722313139527, 0.1747051762089727, 0.28370951325544835, 0.36545490690962523, 0.7590801571814497, 0.01, 0.037917187352167925, 0.7589156124864442, 0.23001972278395574, 0.7584876926246329, 0.01, 0.5406435151273754, 0.010376473422793908, 0.49715033761576555, 0.2308971107150331, 0.6839545786528349, 0.8273514247660383, 0.13584071196815925, 0.7312874972291595, 0.958226961237972, 0.3784346894664713, 0.99, 0.36775614772797005, 0.13706020379504968, 0.30369538285739534, 0.3376363618698688, 0.8462209877883063, 0.3292726624433552, 0.8968961769214914, 0.8731632085139921, 0.9258181961281446, 0.8695364957147848, 0.9728050120850308, 0.11920564688985533, 0.6096271961561601, 0.11611732661571111, 0.9425625991748845, 0.6158865412309098, 0.99, 0.8011702860007862, 0.3806813341947799, 0.8314978043137341, 0.8418295876236078, 0.26249384840664136, 0.8867128417787821, 0.43780663728609875, 0.7770310636157188, 0.17604119792596287, 0.01, 0.034982256047368356, 0.99, 0.6908895541884562, 0.2785150627522561, 0.08621088351232242, 0.99, 0.9031484129299344, 0.5709758746840855, 0.8912798016111193, 0.3972421429168984, 0.02850781625523302, 0.3961690564659328, 0.4424858979408841, 0.4390813217250418, 0.22636104399310708, 0.10768492802667848, 0.50567057357294, 0.25437654583488956, 0.10213968022071745, 0.5582680432059315, 0.7710536244541961, 0.17219551883654288, 0.9848277153127549, 0.22707053150963663]
[0.01, 0.8678465349002085, 0.9622902809687255, 0.01, 0.7695535842013261, 0.27400414231596815, 0.6656117778895835, 0.930448287560647, 0.6711426130743958, 0.3411491227958065, 0.20105697615083123, 0.01, 0.14390079920643645, 0.016761251940676514, 0.9827006595953669, 0.27135054850401014, 0.7217862242161706, 0.01, 0.99, 0.696722313139527, 0.1747051762089727, 0.28370951325544835, 0.36545490690962523, 0.7590801571814497, 0.01, 0.037917187352167925, 0.7589156124864442, 0.23001972278395574, 0.7584876926246329, 0.01, 0.5406435151273754, 0.010376473422793908, 0.49715033761576555, 0.2308971107150331, 0.6839545786528349, 0.8273514247660383, 0.13584071196815925, 0.7312874972291595, 0.958226961237972, 0.3784346894664713, 0.99, 0.36775614772797005, 0.13706020379504968, 0.30369538285739534, 0.3376363618698688, 0.8462209877883063, 0.3292726624433552, 0.8968961769214914, 0.8731632085139921, 0.9258181961281446, 0.8695364957147848, 0.9728050120850308, 0.11920564688985533, 0.6096271961561601, 0.11611732661571111, 0.9425625991748845, 0.6158865412309098, 0.99, 0.8011702860007862, 0.3806813341947799, 0.8314978043137341, 0.8418295876236078, 0.26249384840664136, 0.8867128417787821, 0.43780663728609875, 0.7770310636157188, 0.17604119792596287, 0.01, 0.034982256047368356, 0.99, 0.6908895541884562, 0.2785150627522561, 0.08621088351232242, 0.99, 0.9031484129299344, 0.5709758746840855, 0.8912798016111193, 0.3972421429168984, 0.02850781625523302, 0.3961690564659328, 0.4424858979408841, 0.4390813217250418, 0.22636104399310708, 0.10768492802667848, 0.50567057357294, 0.25437654583488956, 0.10213968022071745, 0.5582680432059315, 0.7710536244541961, 0.17219551883654288, 0.9848277153127549, 0.22707053150963663]
Training loss = 0.03307539721330007
step = 0, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.5975
Training loss = 0.03263889650503794
step = 1, Training Accuracy: 0.5066666666666667
Training loss = 0.033693066636721294
step = 2, Training Accuracy: 0.5
Training loss = 0.031210304299990336
step = 3, Training Accuracy: 0.5066666666666667
Training loss = 0.032679508924484256
step = 4, Training Accuracy: 0.47
Training loss = 0.03146478652954102
step = 5, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.5925
Training loss = 0.0317499307791392
step = 6, Training Accuracy: 0.5133333333333333
Training loss = 0.033425374428431194
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.03125568072001139
step = 8, Training Accuracy: 0.5066666666666667
Training loss = 0.031848560571670535
step = 9, Training Accuracy: 0.5266666666666666
Training loss = 0.032813075780868534
step = 10, Training Accuracy: 0.5
Validation Accuracy: 0.59875
Training loss = 0.03303193767865499
step = 11, Training Accuracy: 0.44333333333333336
Training loss = 0.03216763476530711
step = 12, Training Accuracy: 0.4866666666666667
Training loss = 0.03332891404628754
step = 13, Training Accuracy: 0.47333333333333333
Training loss = 0.031545368830362956
step = 14, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.6
params:  [0.313567996774364, 0.7462289175242185, 0.99, 0.33031109051676427, 0.8183116538962093, 0.32361117051682625, 0.5555464791441034, 0.7546867310915463, 0.7758897379281567, 0.01, 0.40304000146249663, 0.15623683087100346, 0.13599129660019643, 0.03223543356713421, 0.8142857201670538, 0.22040974005980912, 0.6022124014082421, 0.13093254127040382, 0.3721288022694444, 0.45062257559173435, 0.2719083862100927, 0.01, 0.5243205258590797, 0.551785799679509, 0.0390937222686115, 0.01, 0.5725439359072734, 0.01, 0.5729272469572179, 0.08245283429814432, 0.786944813622521, 0.012355919623754541, 0.3488261036935766, 0.27679810736213817, 0.5567238876223203, 0.8182754282059157, 0.02392302143730614, 0.99, 0.9489509872080342, 0.01, 0.99, 0.9322834154293547, 0.47303554888356486, 0.01, 0.9843185917061341, 0.99, 0.38591055725274204, 0.6546751319993398, 0.6164975469870647, 0.5669942468383552, 0.8298613884958828, 0.8098636483649981, 0.01, 0.5099776072255273, 0.4405115375300994, 0.8799408108757307, 0.99, 0.9531405771900677, 0.31992889860831875, 0.01, 0.99, 0.7629291290072169, 0.6225725673460774, 0.8046478940453734, 0.4110180350011527, 0.99, 0.4892918010824754, 0.10892347378710383, 0.01, 0.777614162752186, 0.5376144095299017, 0.4859961027129748, 0.28231210774845, 0.307639102008676, 0.729038773802574, 0.1329202734778406, 0.7098560476905044, 0.8390151511188956, 0.01, 0.99, 0.7075751931132548, 0.99, 0.5021051829920283, 0.1055320104949433, 0.08480798047462212, 0.37251434851720716, 0.01, 0.5019844854429432, 0.44037783850795875, 0.2772805673886666, 0.4599343666410315, 0.40461403417605835]
[0.313567996774364, 0.7462289175242185, 0.99, 0.33031109051676427, 0.8183116538962093, 0.32361117051682625, 0.5555464791441034, 0.7546867310915463, 0.7758897379281567, 0.01, 0.40304000146249663, 0.15623683087100346, 0.13599129660019643, 0.03223543356713421, 0.8142857201670538, 0.22040974005980912, 0.6022124014082421, 0.13093254127040382, 0.3721288022694444, 0.45062257559173435, 0.2719083862100927, 0.01, 0.5243205258590797, 0.551785799679509, 0.0390937222686115, 0.01, 0.5725439359072734, 0.01, 0.5729272469572179, 0.08245283429814432, 0.786944813622521, 0.012355919623754541, 0.3488261036935766, 0.27679810736213817, 0.5567238876223203, 0.8182754282059157, 0.02392302143730614, 0.99, 0.9489509872080342, 0.01, 0.99, 0.9322834154293547, 0.47303554888356486, 0.01, 0.9843185917061341, 0.99, 0.38591055725274204, 0.6546751319993398, 0.6164975469870647, 0.5669942468383552, 0.8298613884958828, 0.8098636483649981, 0.01, 0.5099776072255273, 0.4405115375300994, 0.8799408108757307, 0.99, 0.9531405771900677, 0.31992889860831875, 0.01, 0.99, 0.7629291290072169, 0.6225725673460774, 0.8046478940453734, 0.4110180350011527, 0.99, 0.4892918010824754, 0.10892347378710383, 0.01, 0.777614162752186, 0.5376144095299017, 0.4859961027129748, 0.28231210774845, 0.307639102008676, 0.729038773802574, 0.1329202734778406, 0.7098560476905044, 0.8390151511188956, 0.01, 0.99, 0.7075751931132548, 0.99, 0.5021051829920283, 0.1055320104949433, 0.08480798047462212, 0.37251434851720716, 0.01, 0.5019844854429432, 0.44037783850795875, 0.2772805673886666, 0.4599343666410315, 0.40461403417605835]
Training loss = 0.030970910986264547
step = 0, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.6225
Training loss = 0.031888845761617025
step = 1, Training Accuracy: 0.5433333333333333
Training loss = 0.03051746924718221
step = 2, Training Accuracy: 0.5633333333333334
Training loss = 0.03036838153998057
step = 3, Training Accuracy: 0.5433333333333333
Training loss = 0.03153529445330302
step = 4, Training Accuracy: 0.5533333333333333
Training loss = 0.032173068324724836
step = 5, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.64125
Training loss = 0.03090766171614329
step = 6, Training Accuracy: 0.57
Training loss = 0.030344130396842958
step = 7, Training Accuracy: 0.5366666666666666
Training loss = 0.03214831590652466
step = 8, Training Accuracy: 0.52
Training loss = 0.031113666892051698
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.03026184916496277
step = 10, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.63
Training loss = 0.03115499416987101
step = 11, Training Accuracy: 0.5133333333333333
Training loss = 0.030938042004903157
step = 12, Training Accuracy: 0.5466666666666666
Training loss = 0.029863049785296122
step = 13, Training Accuracy: 0.5566666666666666
Training loss = 0.030288826823234558
step = 14, Training Accuracy: 0.5366666666666666
Validation Accuracy: 0.635
params:  [0.01, 0.9849874586598859, 0.6551474063501858, 0.4722680255961484, 0.831765212628587, 0.2226867684834411, 0.3333591569216615, 0.6793648845402989, 0.47569014086433525, 0.11992140237710143, 0.26761325254633755, 0.01, 0.19366460740394692, 0.15904524698679945, 0.42809904838746693, 0.23932132365423, 0.4183265318823547, 0.01, 0.5274674732298561, 0.2261333543001811, 0.22185236138007394, 0.47899029075681576, 0.235272163606618, 0.6469117127791518, 0.020981158725067135, 0.10565578005777543, 0.9067886882328946, 0.16833707212002533, 0.7217494705169104, 0.22700202373305517, 0.4224321975808705, 0.01, 0.20806325330986752, 0.12802493858394523, 0.6705359351829899, 0.8208229044114709, 0.01, 0.5646755715718956, 0.7717013608910785, 0.01, 0.8998209260647629, 0.6744154723145749, 0.18170968984854322, 0.3296845232591654, 0.47300084664947284, 0.7123327229878662, 0.40968216731877644, 0.99, 0.99, 0.99, 0.5169732987268896, 0.6231814563002186, 0.15255393662612887, 0.6670142236998172, 0.36693495362695827, 0.99, 0.6114234024678875, 0.8819337926695213, 0.01, 0.11239994728070482, 0.7697988277636816, 0.99, 0.2664865509536767, 0.99, 0.9656678592140091, 0.9727449023744613, 0.6706023820826195, 0.09609531143293569, 0.09167315954627334, 0.5598832551466557, 0.33417432772296063, 0.06707307362138136, 0.21021631351036255, 0.48290608482659714, 0.6641855598115766, 0.014865088131471, 0.8559766342631763, 0.4631429231737715, 0.6332691104332897, 0.8174647910665016, 0.4788166641066388, 0.8414663586948056, 0.49321536705951297, 0.09638101598347083, 0.5471958051124692, 0.23224022281128792, 0.4392171712900889, 0.5141728691654845, 0.3526956862597338, 0.30833401437731217, 0.34975642540466234, 0.2663072852654108]
[0.01, 0.9849874586598859, 0.6551474063501858, 0.4722680255961484, 0.831765212628587, 0.2226867684834411, 0.3333591569216615, 0.6793648845402989, 0.47569014086433525, 0.11992140237710143, 0.26761325254633755, 0.01, 0.19366460740394692, 0.15904524698679945, 0.42809904838746693, 0.23932132365423, 0.4183265318823547, 0.01, 0.5274674732298561, 0.2261333543001811, 0.22185236138007394, 0.47899029075681576, 0.235272163606618, 0.6469117127791518, 0.020981158725067135, 0.10565578005777543, 0.9067886882328946, 0.16833707212002533, 0.7217494705169104, 0.22700202373305517, 0.4224321975808705, 0.01, 0.20806325330986752, 0.12802493858394523, 0.6705359351829899, 0.8208229044114709, 0.01, 0.5646755715718956, 0.7717013608910785, 0.01, 0.8998209260647629, 0.6744154723145749, 0.18170968984854322, 0.3296845232591654, 0.47300084664947284, 0.7123327229878662, 0.40968216731877644, 0.99, 0.99, 0.99, 0.5169732987268896, 0.6231814563002186, 0.15255393662612887, 0.6670142236998172, 0.36693495362695827, 0.99, 0.6114234024678875, 0.8819337926695213, 0.01, 0.11239994728070482, 0.7697988277636816, 0.99, 0.2664865509536767, 0.99, 0.9656678592140091, 0.9727449023744613, 0.6706023820826195, 0.09609531143293569, 0.09167315954627334, 0.5598832551466557, 0.33417432772296063, 0.06707307362138136, 0.21021631351036255, 0.48290608482659714, 0.6641855598115766, 0.014865088131471, 0.8559766342631763, 0.4631429231737715, 0.6332691104332897, 0.8174647910665016, 0.4788166641066388, 0.8414663586948056, 0.49321536705951297, 0.09638101598347083, 0.5471958051124692, 0.23224022281128792, 0.4392171712900889, 0.5141728691654845, 0.3526956862597338, 0.30833401437731217, 0.34975642540466234, 0.2663072852654108]
Training loss = 0.03460526784261068
step = 0, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.625
Training loss = 0.03304276247819265
step = 1, Training Accuracy: 0.4666666666666667
Training loss = 0.03241112609704336
step = 2, Training Accuracy: 0.48
Training loss = 0.033486639658610026
step = 3, Training Accuracy: 0.5133333333333333
Training loss = 0.03246777097384135
step = 4, Training Accuracy: 0.4866666666666667
Training loss = 0.03278999626636505
step = 5, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.60375
Training loss = 0.03374608417352041
step = 6, Training Accuracy: 0.4866666666666667
Training loss = 0.03268570423126221
step = 7, Training Accuracy: 0.4866666666666667
Training loss = 0.031663233637809755
step = 8, Training Accuracy: 0.5133333333333333
Training loss = 0.033609016140302025
step = 9, Training Accuracy: 0.49666666666666665
Training loss = 0.03350229442119598
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.60375
Training loss = 0.03231439193089803
step = 11, Training Accuracy: 0.5233333333333333
Training loss = 0.032481389045715334
step = 12, Training Accuracy: 0.49666666666666665
Training loss = 0.032336637179056806
step = 13, Training Accuracy: 0.49
Training loss = 0.032013723452885945
step = 14, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.6075
params:  [0.01, 0.7335182604657073, 0.99, 0.12481193251621459, 0.8899060243013183, 0.19615274150723322, 0.5159956146498914, 0.28339527905186684, 0.9830577113792065, 0.01, 0.5780283084978065, 0.34919101066443914, 0.2562975116382683, 0.01, 0.3465100902010729, 0.14858818436138754, 0.6558058658855926, 0.49831336709670376, 0.547090347738994, 0.5982224359588636, 0.01232405951453451, 0.0145112453627384, 0.3194870123296282, 0.8798219999802819, 0.18152907124096432, 0.01, 0.728884732166312, 0.36024847431953383, 0.682900998208206, 0.3400845308404865, 0.99, 0.30207823292774566, 0.7711957841304853, 0.35574419097702636, 0.2818770356102131, 0.5883398967197027, 0.01, 0.8587490786788055, 0.99, 0.23899272261306037, 0.99, 0.7038663801348211, 0.14447011508103788, 0.26396878343470553, 0.4517110395468032, 0.99, 0.5320782977096397, 0.6687831616635719, 0.99, 0.9768309963103964, 0.8719578998562509, 0.762642002218025, 0.06977126379901136, 0.07725441153450235, 0.1356200409549294, 0.99, 0.9486405769851329, 0.99, 0.5598139962426283, 0.1056230253702827, 0.7892343772222746, 0.6789779153121632, 0.3854523384560672, 0.99, 0.3867646368028595, 0.9411346197046092, 0.33349687737091305, 0.01, 0.01, 0.99, 0.803627270034202, 0.19666125431635983, 0.21479714715820286, 0.99, 0.7928522271640124, 0.17827832577965091, 0.99, 0.6827764889027716, 0.24356888697061563, 0.99, 0.45979956424322044, 0.5787147693522874, 0.6942111562480999, 0.5040735100386109, 0.6323230620963493, 0.01, 0.4436077758040137, 0.6500176595044063, 0.16913098314995328, 0.18120594353279107, 0.09812863027220628, 0.01]
[0.01, 0.7335182604657073, 0.99, 0.12481193251621459, 0.8899060243013183, 0.19615274150723322, 0.5159956146498914, 0.28339527905186684, 0.9830577113792065, 0.01, 0.5780283084978065, 0.34919101066443914, 0.2562975116382683, 0.01, 0.3465100902010729, 0.14858818436138754, 0.6558058658855926, 0.49831336709670376, 0.547090347738994, 0.5982224359588636, 0.01232405951453451, 0.0145112453627384, 0.3194870123296282, 0.8798219999802819, 0.18152907124096432, 0.01, 0.728884732166312, 0.36024847431953383, 0.682900998208206, 0.3400845308404865, 0.99, 0.30207823292774566, 0.7711957841304853, 0.35574419097702636, 0.2818770356102131, 0.5883398967197027, 0.01, 0.8587490786788055, 0.99, 0.23899272261306037, 0.99, 0.7038663801348211, 0.14447011508103788, 0.26396878343470553, 0.4517110395468032, 0.99, 0.5320782977096397, 0.6687831616635719, 0.99, 0.9768309963103964, 0.8719578998562509, 0.762642002218025, 0.06977126379901136, 0.07725441153450235, 0.1356200409549294, 0.99, 0.9486405769851329, 0.99, 0.5598139962426283, 0.1056230253702827, 0.7892343772222746, 0.6789779153121632, 0.3854523384560672, 0.99, 0.3867646368028595, 0.9411346197046092, 0.33349687737091305, 0.01, 0.01, 0.99, 0.803627270034202, 0.19666125431635983, 0.21479714715820286, 0.99, 0.7928522271640124, 0.17827832577965091, 0.99, 0.6827764889027716, 0.24356888697061563, 0.99, 0.45979956424322044, 0.5787147693522874, 0.6942111562480999, 0.5040735100386109, 0.6323230620963493, 0.01, 0.4436077758040137, 0.6500176595044063, 0.16913098314995328, 0.18120594353279107, 0.09812863027220628, 0.01]
Training loss = 0.03485146721204122
step = 0, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.60375
Training loss = 0.033129682938257854
step = 1, Training Accuracy: 0.44333333333333336
Training loss = 0.03424658457438151
step = 2, Training Accuracy: 0.49333333333333335
Training loss = 0.03251806636651357
step = 3, Training Accuracy: 0.49
Training loss = 0.03296895960966746
step = 4, Training Accuracy: 0.4766666666666667
Training loss = 0.03242928524812062
step = 5, Training Accuracy: 0.49
Validation Accuracy: 0.60125
Training loss = 0.03318546573321025
step = 6, Training Accuracy: 0.45666666666666667
Training loss = 0.03324851671854655
step = 7, Training Accuracy: 0.48
Training loss = 0.03397137900193532
step = 8, Training Accuracy: 0.47333333333333333
Training loss = 0.032513572374979656
step = 9, Training Accuracy: 0.5233333333333333
Training loss = 0.03305919488271077
step = 10, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.6325
Training loss = 0.03281265179316203
step = 11, Training Accuracy: 0.52
Training loss = 0.033184074958165485
step = 12, Training Accuracy: 0.4766666666666667
Training loss = 0.033868966102600095
step = 13, Training Accuracy: 0.4866666666666667
Training loss = 0.03488169491291046
step = 14, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.63125
params:  [0.04949584606146999, 0.7455764269601992, 0.8020821730701404, 0.7538815551009468, 0.4978918920026552, 0.31396631041611683, 0.45736136738459554, 0.35695287788453234, 0.9415126106477612, 0.01, 0.22117224784430473, 0.06349033484945649, 0.03430783266956075, 0.087172449869324, 0.871868930543828, 0.2610648399784713, 0.42976131313417065, 0.01, 0.5755842122156116, 0.838367237199767, 0.01, 0.18213604815261325, 0.18332875846115887, 0.5446032967961373, 0.19915751759310174, 0.05374968681602011, 0.7993770546747514, 0.09643869567397394, 0.790829402559785, 0.4903405709986609, 0.795001061779615, 0.09830271157892367, 0.5040829307705754, 0.32039231507929994, 0.34837648131081445, 0.99, 0.3093332300773818, 0.8454606347308757, 0.8646273787831811, 0.13209139927511357, 0.99, 0.6078045215266278, 0.01, 0.16033377299760662, 0.1646777405895023, 0.8683352321483215, 0.09992304900395838, 0.7129751628554115, 0.9131246757864265, 0.7319281248869856, 0.9298383266804269, 0.735813066983692, 0.5112509254361572, 0.3008645676287258, 0.09915675610911502, 0.7477855075598376, 0.38499640030586385, 0.99, 0.31491880304336994, 0.21435089440043853, 0.99, 0.8973564724232233, 0.01, 0.742165215484375, 0.8776967836970008, 0.9104365472931084, 0.243867390354331, 0.5297230656443237, 0.2921227920522202, 0.9158156117268094, 0.1997117672566538, 0.10511855468830528, 0.44493533313328043, 0.620554131826356, 0.99, 0.6343071935531932, 0.8691527909761706, 0.2448786395206083, 0.3312876060366984, 0.3536908617494822, 0.6205312607606547, 0.7840506448882216, 0.9441372343113155, 0.45016557612050556, 0.743379583040006, 0.17753842950497853, 0.37377032687417255, 0.26824235279082814, 0.4689546284915169, 0.35166546058477344, 0.4857817127534792, 0.01]
[0.04949584606146999, 0.7455764269601992, 0.8020821730701404, 0.7538815551009468, 0.4978918920026552, 0.31396631041611683, 0.45736136738459554, 0.35695287788453234, 0.9415126106477612, 0.01, 0.22117224784430473, 0.06349033484945649, 0.03430783266956075, 0.087172449869324, 0.871868930543828, 0.2610648399784713, 0.42976131313417065, 0.01, 0.5755842122156116, 0.838367237199767, 0.01, 0.18213604815261325, 0.18332875846115887, 0.5446032967961373, 0.19915751759310174, 0.05374968681602011, 0.7993770546747514, 0.09643869567397394, 0.790829402559785, 0.4903405709986609, 0.795001061779615, 0.09830271157892367, 0.5040829307705754, 0.32039231507929994, 0.34837648131081445, 0.99, 0.3093332300773818, 0.8454606347308757, 0.8646273787831811, 0.13209139927511357, 0.99, 0.6078045215266278, 0.01, 0.16033377299760662, 0.1646777405895023, 0.8683352321483215, 0.09992304900395838, 0.7129751628554115, 0.9131246757864265, 0.7319281248869856, 0.9298383266804269, 0.735813066983692, 0.5112509254361572, 0.3008645676287258, 0.09915675610911502, 0.7477855075598376, 0.38499640030586385, 0.99, 0.31491880304336994, 0.21435089440043853, 0.99, 0.8973564724232233, 0.01, 0.742165215484375, 0.8776967836970008, 0.9104365472931084, 0.243867390354331, 0.5297230656443237, 0.2921227920522202, 0.9158156117268094, 0.1997117672566538, 0.10511855468830528, 0.44493533313328043, 0.620554131826356, 0.99, 0.6343071935531932, 0.8691527909761706, 0.2448786395206083, 0.3312876060366984, 0.3536908617494822, 0.6205312607606547, 0.7840506448882216, 0.9441372343113155, 0.45016557612050556, 0.743379583040006, 0.17753842950497853, 0.37377032687417255, 0.26824235279082814, 0.4689546284915169, 0.35166546058477344, 0.4857817127534792, 0.01]
Training loss = 0.03304040133953094
step = 0, Training Accuracy: 0.46
Validation Accuracy: 0.6275
Training loss = 0.03440732181072235
step = 1, Training Accuracy: 0.45666666666666667
Training loss = 0.03258548657099406
step = 2, Training Accuracy: 0.4866666666666667
Training loss = 0.03355396767457326
step = 3, Training Accuracy: 0.5133333333333333
Training loss = 0.03258540074030558
step = 4, Training Accuracy: 0.49333333333333335
Training loss = 0.03364024122556051
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.61375
Training loss = 0.033057933449745176
step = 6, Training Accuracy: 0.47333333333333333
Training loss = 0.03194889426231384
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.03233885705471039
step = 8, Training Accuracy: 0.49666666666666665
Training loss = 0.03338151653607686
step = 9, Training Accuracy: 0.4866666666666667
Training loss = 0.03218331058820089
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.62625
Training loss = 0.03226317564646403
step = 11, Training Accuracy: 0.5
Training loss = 0.03358597159385681
step = 12, Training Accuracy: 0.48333333333333334
Training loss = 0.03054906984170278
step = 13, Training Accuracy: 0.53
Training loss = 0.0318291429678599
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.62625
params:  [0.01, 0.7279131649089801, 0.7702909380479793, 0.4639829818976718, 0.4768479850401306, 0.32117352576586966, 0.06770867166342748, 0.6100021442409911, 0.8287676711158668, 0.3135378960579577, 0.09044101231661122, 0.01, 0.4038191909303232, 0.29400707108734964, 0.4621971788829752, 0.01, 0.8428128615772247, 0.01, 0.5439685922511699, 0.3453615698493513, 0.01, 0.6133247390063091, 0.15432071199137265, 0.8913542103604599, 0.27901468833839704, 0.14983771193701634, 0.99, 0.01, 0.6941103089171982, 0.01, 0.9061007545042914, 0.6649198973460775, 0.3191764762634882, 0.18955181758355685, 0.5232128697991031, 0.99, 0.07605316083438471, 0.9370954541798676, 0.7412908420712923, 0.13309835899709246, 0.9051502365113344, 0.9469256311511958, 0.01, 0.5690663659098659, 0.38968331169670156, 0.8688185878955694, 0.01, 0.5857354896305386, 0.99, 0.7875644229840513, 0.8654790843354929, 0.7260610928132915, 0.3075325117245334, 0.5115452917899689, 0.17216436141233502, 0.8925011846993751, 0.9506971474511039, 0.99, 0.39545724240875657, 0.08858555702162733, 0.99, 0.8740741871336685, 0.21829941635909814, 0.99, 0.6244109112470017, 0.9404756946200489, 0.4627680124174245, 0.5146289497054651, 0.01, 0.99, 0.329722663344712, 0.050730654221671834, 0.779553751999883, 0.5138888857990308, 0.9532395250846398, 0.029532129980808897, 0.6533973388373306, 0.8830055206950271, 0.4719236780647966, 0.756216895045011, 0.8828793630493497, 0.8667317845465251, 0.99, 0.01, 0.6053802086567621, 0.38835346375019075, 0.26472640480044296, 0.5915359195163237, 0.37458451622244016, 0.7355456816473713, 0.4107191477107196, 0.01]
[0.01, 0.7279131649089801, 0.7702909380479793, 0.4639829818976718, 0.4768479850401306, 0.32117352576586966, 0.06770867166342748, 0.6100021442409911, 0.8287676711158668, 0.3135378960579577, 0.09044101231661122, 0.01, 0.4038191909303232, 0.29400707108734964, 0.4621971788829752, 0.01, 0.8428128615772247, 0.01, 0.5439685922511699, 0.3453615698493513, 0.01, 0.6133247390063091, 0.15432071199137265, 0.8913542103604599, 0.27901468833839704, 0.14983771193701634, 0.99, 0.01, 0.6941103089171982, 0.01, 0.9061007545042914, 0.6649198973460775, 0.3191764762634882, 0.18955181758355685, 0.5232128697991031, 0.99, 0.07605316083438471, 0.9370954541798676, 0.7412908420712923, 0.13309835899709246, 0.9051502365113344, 0.9469256311511958, 0.01, 0.5690663659098659, 0.38968331169670156, 0.8688185878955694, 0.01, 0.5857354896305386, 0.99, 0.7875644229840513, 0.8654790843354929, 0.7260610928132915, 0.3075325117245334, 0.5115452917899689, 0.17216436141233502, 0.8925011846993751, 0.9506971474511039, 0.99, 0.39545724240875657, 0.08858555702162733, 0.99, 0.8740741871336685, 0.21829941635909814, 0.99, 0.6244109112470017, 0.9404756946200489, 0.4627680124174245, 0.5146289497054651, 0.01, 0.99, 0.329722663344712, 0.050730654221671834, 0.779553751999883, 0.5138888857990308, 0.9532395250846398, 0.029532129980808897, 0.6533973388373306, 0.8830055206950271, 0.4719236780647966, 0.756216895045011, 0.8828793630493497, 0.8667317845465251, 0.99, 0.01, 0.6053802086567621, 0.38835346375019075, 0.26472640480044296, 0.5915359195163237, 0.37458451622244016, 0.7355456816473713, 0.4107191477107196, 0.01]
Training loss = 0.030502395232518513
step = 0, Training Accuracy: 0.5433333333333333
Validation Accuracy: 0.625
Training loss = 0.030863699515660602
step = 1, Training Accuracy: 0.5633333333333334
Training loss = 0.029753602345784506
step = 2, Training Accuracy: 0.58
Training loss = 0.030086979866027833
step = 3, Training Accuracy: 0.5666666666666667
Training loss = 0.031062050660451253
step = 4, Training Accuracy: 0.5633333333333334
Training loss = 0.031642239888509116
step = 5, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.62625
Training loss = 0.02940270264943441
step = 6, Training Accuracy: 0.54
Training loss = 0.029927680095036824
step = 7, Training Accuracy: 0.5333333333333333
Training loss = 0.03204401612281799
step = 8, Training Accuracy: 0.55
Training loss = 0.029662559827168783
step = 9, Training Accuracy: 0.56
Training loss = 0.02979710102081299
step = 10, Training Accuracy: 0.5566666666666666
Validation Accuracy: 0.6275
Training loss = 0.030029632647832236
step = 11, Training Accuracy: 0.5933333333333334
Training loss = 0.029628849029541014
step = 12, Training Accuracy: 0.59
Training loss = 0.029665572841962178
step = 13, Training Accuracy: 0.5633333333333334
Training loss = 0.029651583830515544
step = 14, Training Accuracy: 0.5733333333333334
Validation Accuracy: 0.63125
params:  [0.01, 0.8218751065158756, 0.6819103915100246, 0.12638435678861293, 0.46892677370117825, 0.6758593786986045, 0.01, 0.44842325411615014, 0.480896907872276, 0.22005072923749672, 0.28645919240230655, 0.3850409995592785, 0.36589385270164965, 0.3709488098573982, 0.49318069789591346, 0.4050581979000614, 0.3517875304981387, 0.09424286502715641, 0.5795168451649634, 0.6089590815661903, 0.5208069326862377, 0.6819117497880327, 0.3382611420976786, 0.9106333760103629, 0.14574900163726795, 0.5551822312697695, 0.8691237263169416, 0.2870861465326034, 0.99, 0.4189670872643231, 0.8004927210536303, 0.594507084167358, 0.59736834638277, 0.01, 0.6543823803095078, 0.48466516775513896, 0.32191912947715845, 0.99, 0.99, 0.3693956816590991, 0.9003573060852776, 0.6626774581336308, 0.4890092267597857, 0.28213167142971995, 0.7537080328976606, 0.7162277664569091, 0.24807131663803786, 0.4079383116099255, 0.7829452466436652, 0.9119904059750639, 0.99, 0.6337582011455413, 0.11528759553689658, 0.6764594782997553, 0.30319584178314263, 0.6980776107216864, 0.6591992745311752, 0.8259654961805455, 0.6358715751302733, 0.01, 0.9572983930932528, 0.7694679448224336, 0.7000055642007811, 0.99, 0.3724772598015271, 0.6965313026653676, 0.7644609127388906, 0.12560504302338843, 0.2895116927279798, 0.8937794110513906, 0.7640193633735393, 0.22648605775143593, 0.48054193418871216, 0.4957369386161167, 0.7939225777013138, 0.6270379352901783, 0.29202542719113456, 0.6170943874831266, 0.5431234306320012, 0.6874068022400832, 0.5377391601069078, 0.7752529958565464, 0.765428795573398, 0.03800875179507737, 0.20854152656467745, 0.24505006480087915, 0.37811632473341855, 0.5563983575598463, 0.34881999011379217, 0.5854288153570546, 0.5101308702809682, 0.4746613537784822]
[0.01, 0.8218751065158756, 0.6819103915100246, 0.12638435678861293, 0.46892677370117825, 0.6758593786986045, 0.01, 0.44842325411615014, 0.480896907872276, 0.22005072923749672, 0.28645919240230655, 0.3850409995592785, 0.36589385270164965, 0.3709488098573982, 0.49318069789591346, 0.4050581979000614, 0.3517875304981387, 0.09424286502715641, 0.5795168451649634, 0.6089590815661903, 0.5208069326862377, 0.6819117497880327, 0.3382611420976786, 0.9106333760103629, 0.14574900163726795, 0.5551822312697695, 0.8691237263169416, 0.2870861465326034, 0.99, 0.4189670872643231, 0.8004927210536303, 0.594507084167358, 0.59736834638277, 0.01, 0.6543823803095078, 0.48466516775513896, 0.32191912947715845, 0.99, 0.99, 0.3693956816590991, 0.9003573060852776, 0.6626774581336308, 0.4890092267597857, 0.28213167142971995, 0.7537080328976606, 0.7162277664569091, 0.24807131663803786, 0.4079383116099255, 0.7829452466436652, 0.9119904059750639, 0.99, 0.6337582011455413, 0.11528759553689658, 0.6764594782997553, 0.30319584178314263, 0.6980776107216864, 0.6591992745311752, 0.8259654961805455, 0.6358715751302733, 0.01, 0.9572983930932528, 0.7694679448224336, 0.7000055642007811, 0.99, 0.3724772598015271, 0.6965313026653676, 0.7644609127388906, 0.12560504302338843, 0.2895116927279798, 0.8937794110513906, 0.7640193633735393, 0.22648605775143593, 0.48054193418871216, 0.4957369386161167, 0.7939225777013138, 0.6270379352901783, 0.29202542719113456, 0.6170943874831266, 0.5431234306320012, 0.6874068022400832, 0.5377391601069078, 0.7752529958565464, 0.765428795573398, 0.03800875179507737, 0.20854152656467745, 0.24505006480087915, 0.37811632473341855, 0.5563983575598463, 0.34881999011379217, 0.5854288153570546, 0.5101308702809682, 0.4746613537784822]
Training loss = 0.03577903111775716
step = 0, Training Accuracy: 0.43666666666666665
Validation Accuracy: 0.635
Training loss = 0.03486592411994934
step = 1, Training Accuracy: 0.4766666666666667
Training loss = 0.03451512455940246
step = 2, Training Accuracy: 0.43
Training loss = 0.03423923929532369
step = 3, Training Accuracy: 0.44666666666666666
Training loss = 0.03455714682737986
step = 4, Training Accuracy: 0.4533333333333333
Training loss = 0.0355678915977478
step = 5, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.62625
Training loss = 0.03512627641359965
step = 6, Training Accuracy: 0.41333333333333333
Training loss = 0.03529282867908478
step = 7, Training Accuracy: 0.45
Training loss = 0.032962703704833986
step = 8, Training Accuracy: 0.5
Training loss = 0.034797874490420024
step = 9, Training Accuracy: 0.45
Training loss = 0.03436634242534638
step = 10, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.6125
Training loss = 0.034575567444165546
step = 11, Training Accuracy: 0.44333333333333336
Training loss = 0.03394290586312612
step = 12, Training Accuracy: 0.4866666666666667
Training loss = 0.033404879570007324
step = 13, Training Accuracy: 0.47333333333333333
Training loss = 0.034955493609110516
step = 14, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.62375
params:  [0.45680410499125534, 0.99, 0.5957645849798543, 0.22926607804302912, 0.6898846600480968, 0.28507903014628666, 0.4221515628973258, 0.35592430215327836, 0.7776052254205165, 0.022694929466920605, 0.6005268591036028, 0.2384157191185002, 0.05323383115425573, 0.18812498594316224, 0.99, 0.01, 0.99, 0.38941614334354274, 0.2672306048685889, 0.20651978304005314, 0.11441157124397637, 0.01, 0.6557938438817562, 0.7328408035049919, 0.41072228982385506, 0.2800271325390684, 0.99, 0.3030731081101092, 0.99, 0.01, 0.99, 0.34287734260556646, 0.6438740061479782, 0.01, 0.6363063351172671, 0.5162349417206138, 0.022181180928802155, 0.7061607469970084, 0.99, 0.23262319574066043, 0.8998971209261817, 0.858877861466159, 0.01, 0.8414137041895675, 0.2676732399881502, 0.99, 0.36146751459363036, 0.5046203006112967, 0.9536884230249364, 0.8353856870797849, 0.99, 0.8457379762571802, 0.48769244800127187, 0.2547069368532827, 0.19125749885370683, 0.8054145322219518, 0.99, 0.6650413320895204, 0.5623356891757398, 0.26779774444484006, 0.99, 0.6090745577731758, 0.36764040147424587, 0.99, 0.8360280007319023, 0.99, 0.45377441313062605, 0.11938812855699169, 0.01, 0.5954594082242481, 0.8272726728743398, 0.01, 0.26981477268756265, 0.806595610760529, 0.99, 0.2491042305284809, 0.7340902843360535, 0.444979370900749, 0.2056329845920185, 0.99, 0.7376464689383782, 0.9032428416928058, 0.33210288521041653, 0.19211034085196854, 0.7093086843722543, 0.2098873119646392, 0.3092717007722853, 0.34969813090226654, 0.41587790089453003, 0.4320253381178559, 0.3799854023734131, 0.3710857908974583]
[0.45680410499125534, 0.99, 0.5957645849798543, 0.22926607804302912, 0.6898846600480968, 0.28507903014628666, 0.4221515628973258, 0.35592430215327836, 0.7776052254205165, 0.022694929466920605, 0.6005268591036028, 0.2384157191185002, 0.05323383115425573, 0.18812498594316224, 0.99, 0.01, 0.99, 0.38941614334354274, 0.2672306048685889, 0.20651978304005314, 0.11441157124397637, 0.01, 0.6557938438817562, 0.7328408035049919, 0.41072228982385506, 0.2800271325390684, 0.99, 0.3030731081101092, 0.99, 0.01, 0.99, 0.34287734260556646, 0.6438740061479782, 0.01, 0.6363063351172671, 0.5162349417206138, 0.022181180928802155, 0.7061607469970084, 0.99, 0.23262319574066043, 0.8998971209261817, 0.858877861466159, 0.01, 0.8414137041895675, 0.2676732399881502, 0.99, 0.36146751459363036, 0.5046203006112967, 0.9536884230249364, 0.8353856870797849, 0.99, 0.8457379762571802, 0.48769244800127187, 0.2547069368532827, 0.19125749885370683, 0.8054145322219518, 0.99, 0.6650413320895204, 0.5623356891757398, 0.26779774444484006, 0.99, 0.6090745577731758, 0.36764040147424587, 0.99, 0.8360280007319023, 0.99, 0.45377441313062605, 0.11938812855699169, 0.01, 0.5954594082242481, 0.8272726728743398, 0.01, 0.26981477268756265, 0.806595610760529, 0.99, 0.2491042305284809, 0.7340902843360535, 0.444979370900749, 0.2056329845920185, 0.99, 0.7376464689383782, 0.9032428416928058, 0.33210288521041653, 0.19211034085196854, 0.7093086843722543, 0.2098873119646392, 0.3092717007722853, 0.34969813090226654, 0.41587790089453003, 0.4320253381178559, 0.3799854023734131, 0.3710857908974583]
Training loss = 0.03511860072612762
step = 0, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.60875
Training loss = 0.03541081269582113
step = 1, Training Accuracy: 0.4266666666666667
Training loss = 0.03356756587823232
step = 2, Training Accuracy: 0.44
Training loss = 0.03472668031851451
step = 3, Training Accuracy: 0.4866666666666667
Training loss = 0.03467175881067912
step = 4, Training Accuracy: 0.44666666666666666
Training loss = 0.03641692062218984
step = 5, Training Accuracy: 0.4
Validation Accuracy: 0.615
Training loss = 0.03409471690654755
step = 6, Training Accuracy: 0.4866666666666667
Training loss = 0.03383623600006103
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.033477342923482256
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03466396749019623
step = 9, Training Accuracy: 0.47
Training loss = 0.03380980094273885
step = 10, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.605
Training loss = 0.034543142914772035
step = 11, Training Accuracy: 0.44666666666666666
Training loss = 0.03530737499396006
step = 12, Training Accuracy: 0.44
Training loss = 0.03336171527703603
step = 13, Training Accuracy: 0.4533333333333333
Training loss = 0.032904807726542154
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.59125
12 	8     	0.618281	0.0153722	0.59125	0.635  
params:  [0.01, 0.676725098898212, 0.99, 0.4565309168195915, 0.99, 0.6414196826159124, 0.9426717863577367, 0.7115458019447027, 0.795396649442834, 0.1550382309874112, 0.18548073528366013, 0.42509609281177546, 0.01, 0.01, 0.8155899753706759, 0.3157851811876107, 0.8197534536035125, 0.18819353533912445, 0.6901801951865604, 0.5510028585091, 0.01, 0.12530423912818134, 0.03767864980711333, 0.6041715434627624, 0.11227618516142017, 0.01, 0.48460487694938303, 0.01, 0.4431895878182552, 0.5787288510643341, 0.99, 0.11016010300477738, 0.3559876148861058, 0.5737913726176525, 0.3235348728818903, 0.7284618146492521, 0.13822423163863445, 0.9127330949192995, 0.99, 0.01, 0.6912048130075426, 0.9102288553342996, 0.06350971704881275, 0.23129936763261533, 0.5516374129242382, 0.7148745020135672, 0.20455038024304895, 0.18009658259163325, 0.560052909254031, 0.6633055826999542, 0.5329754154950139, 0.7141435527458131, 0.13165006345000987, 0.27012255704346355, 0.11292832428889166, 0.99, 0.99, 0.99, 0.45876260657603984, 0.1462532693772351, 0.99, 0.7006684506878588, 0.6082083006743525, 0.99, 0.17256939735158217, 0.9376437514753364, 0.2667263859979574, 0.42605881105182364, 0.01, 0.5797350097794323, 0.2731389816199019, 0.21608989741920598, 0.17083605095797877, 0.7095096511729045, 0.99, 0.01, 0.5806703759628854, 0.7639958942751753, 0.01, 0.99, 0.38497582339014164, 0.829809837069079, 0.509127144712553, 0.3393208895780955, 0.6727623772287079, 0.30290367755438774, 0.01, 0.475488361171909, 0.1699316282338355, 0.03314316879002133, 0.4577076937373112, 0.2476963092407286]
[0.01, 0.676725098898212, 0.99, 0.4565309168195915, 0.99, 0.6414196826159124, 0.9426717863577367, 0.7115458019447027, 0.795396649442834, 0.1550382309874112, 0.18548073528366013, 0.42509609281177546, 0.01, 0.01, 0.8155899753706759, 0.3157851811876107, 0.8197534536035125, 0.18819353533912445, 0.6901801951865604, 0.5510028585091, 0.01, 0.12530423912818134, 0.03767864980711333, 0.6041715434627624, 0.11227618516142017, 0.01, 0.48460487694938303, 0.01, 0.4431895878182552, 0.5787288510643341, 0.99, 0.11016010300477738, 0.3559876148861058, 0.5737913726176525, 0.3235348728818903, 0.7284618146492521, 0.13822423163863445, 0.9127330949192995, 0.99, 0.01, 0.6912048130075426, 0.9102288553342996, 0.06350971704881275, 0.23129936763261533, 0.5516374129242382, 0.7148745020135672, 0.20455038024304895, 0.18009658259163325, 0.560052909254031, 0.6633055826999542, 0.5329754154950139, 0.7141435527458131, 0.13165006345000987, 0.27012255704346355, 0.11292832428889166, 0.99, 0.99, 0.99, 0.45876260657603984, 0.1462532693772351, 0.99, 0.7006684506878588, 0.6082083006743525, 0.99, 0.17256939735158217, 0.9376437514753364, 0.2667263859979574, 0.42605881105182364, 0.01, 0.5797350097794323, 0.2731389816199019, 0.21608989741920598, 0.17083605095797877, 0.7095096511729045, 0.99, 0.01, 0.5806703759628854, 0.7639958942751753, 0.01, 0.99, 0.38497582339014164, 0.829809837069079, 0.509127144712553, 0.3393208895780955, 0.6727623772287079, 0.30290367755438774, 0.01, 0.475488361171909, 0.1699316282338355, 0.03314316879002133, 0.4577076937373112, 0.2476963092407286]
Training loss = 0.03194680472215017
step = 0, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.605
Training loss = 0.03268751839796702
step = 1, Training Accuracy: 0.49666666666666665
Training loss = 0.0325776880979538
step = 2, Training Accuracy: 0.5033333333333333
Training loss = 0.03404651979605357
step = 3, Training Accuracy: 0.47
Training loss = 0.03253803769747416
step = 4, Training Accuracy: 0.45666666666666667
Training loss = 0.032802974383036296
step = 5, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.62
Training loss = 0.03167377551396688
step = 6, Training Accuracy: 0.53
Training loss = 0.03274004817008972
step = 7, Training Accuracy: 0.5166666666666667
Training loss = 0.03156633496284485
step = 8, Training Accuracy: 0.5366666666666666
Training loss = 0.03247612694899241
step = 9, Training Accuracy: 0.5033333333333333
Training loss = 0.03263883352279663
step = 10, Training Accuracy: 0.48
Validation Accuracy: 0.635
Training loss = 0.03136088411013285
step = 11, Training Accuracy: 0.5666666666666667
Training loss = 0.03168505191802978
step = 12, Training Accuracy: 0.51
Training loss = 0.03158839643001556
step = 13, Training Accuracy: 0.5033333333333333
Training loss = 0.03135656932989756
step = 14, Training Accuracy: 0.54
Validation Accuracy: 0.63875
params:  [0.18333292935337867, 0.8469211549924933, 0.99, 0.23027602929189822, 0.6823803309782884, 0.08558274332725563, 0.4063976351752564, 0.2867513227381788, 0.99, 0.01, 0.4281333766341122, 0.4085796317080709, 0.21635812103698923, 0.01, 0.8513245147544559, 0.26893058583474344, 0.8861835980861281, 0.01, 0.35547446658645654, 0.8493450356300383, 0.01, 0.01, 0.3414208174772221, 0.6553052249080975, 0.4163704568312921, 0.01, 0.5383291812118295, 0.04620697904959713, 0.6528324749995028, 0.3352737631434214, 0.7461482319139111, 0.01, 0.40499972944894064, 0.07700461357832664, 0.4901340043695639, 0.7270707441384339, 0.01, 0.99, 0.896027827951223, 0.01, 0.99, 0.99, 0.15065133052566676, 0.39690397582448206, 0.9064376894393615, 0.99, 0.5529791948074325, 0.5515238595221296, 0.99, 0.8648875280516013, 0.99, 0.42406334250952143, 0.12134491662171082, 0.18895061615869857, 0.2547984809909852, 0.7870243314793014, 0.99, 0.99, 0.18535222254769104, 0.01, 0.9214554105044072, 0.7137881917656606, 0.5864989618283216, 0.7456449328117044, 0.3158734067825236, 0.8756833596385174, 0.6397091629363202, 0.16303202867836072, 0.017588079595097762, 0.8766226702299794, 0.9506299377490876, 0.19172880681981797, 0.1781926663902029, 0.7256706392251087, 0.25949094953697205, 0.26308806397197465, 0.99, 0.5634184939667494, 0.01, 0.8708221132942271, 0.912561079389727, 0.99, 0.5623954311167372, 0.3436106018200481, 0.2295316187209632, 0.5806356230318341, 0.3130898329209269, 0.4234301172753675, 0.5982416724926678, 0.376815443182175, 0.15241695736846325, 0.10383015928947949]
[0.18333292935337867, 0.8469211549924933, 0.99, 0.23027602929189822, 0.6823803309782884, 0.08558274332725563, 0.4063976351752564, 0.2867513227381788, 0.99, 0.01, 0.4281333766341122, 0.4085796317080709, 0.21635812103698923, 0.01, 0.8513245147544559, 0.26893058583474344, 0.8861835980861281, 0.01, 0.35547446658645654, 0.8493450356300383, 0.01, 0.01, 0.3414208174772221, 0.6553052249080975, 0.4163704568312921, 0.01, 0.5383291812118295, 0.04620697904959713, 0.6528324749995028, 0.3352737631434214, 0.7461482319139111, 0.01, 0.40499972944894064, 0.07700461357832664, 0.4901340043695639, 0.7270707441384339, 0.01, 0.99, 0.896027827951223, 0.01, 0.99, 0.99, 0.15065133052566676, 0.39690397582448206, 0.9064376894393615, 0.99, 0.5529791948074325, 0.5515238595221296, 0.99, 0.8648875280516013, 0.99, 0.42406334250952143, 0.12134491662171082, 0.18895061615869857, 0.2547984809909852, 0.7870243314793014, 0.99, 0.99, 0.18535222254769104, 0.01, 0.9214554105044072, 0.7137881917656606, 0.5864989618283216, 0.7456449328117044, 0.3158734067825236, 0.8756833596385174, 0.6397091629363202, 0.16303202867836072, 0.017588079595097762, 0.8766226702299794, 0.9506299377490876, 0.19172880681981797, 0.1781926663902029, 0.7256706392251087, 0.25949094953697205, 0.26308806397197465, 0.99, 0.5634184939667494, 0.01, 0.8708221132942271, 0.912561079389727, 0.99, 0.5623954311167372, 0.3436106018200481, 0.2295316187209632, 0.5806356230318341, 0.3130898329209269, 0.4234301172753675, 0.5982416724926678, 0.376815443182175, 0.15241695736846325, 0.10383015928947949]
Training loss = 0.033832380374272664
step = 0, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.6325
Training loss = 0.03489477912584941
step = 1, Training Accuracy: 0.4266666666666667
Training loss = 0.0339301190773646
step = 2, Training Accuracy: 0.45
Training loss = 0.034014021952946984
step = 3, Training Accuracy: 0.4866666666666667
Training loss = 0.033114106853803
step = 4, Training Accuracy: 0.45
Training loss = 0.03540485541025797
step = 5, Training Accuracy: 0.4066666666666667
Validation Accuracy: 0.63375
Training loss = 0.03380219976107279
step = 6, Training Accuracy: 0.4633333333333333
Training loss = 0.03242878397305807
step = 7, Training Accuracy: 0.5133333333333333
Training loss = 0.033628446062405906
step = 8, Training Accuracy: 0.5033333333333333
Training loss = 0.034056156873703
step = 9, Training Accuracy: 0.44666666666666666
Training loss = 0.033443947633107506
step = 10, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.64125
Training loss = 0.03428710957368215
step = 11, Training Accuracy: 0.51
Training loss = 0.03664415160814921
step = 12, Training Accuracy: 0.4633333333333333
Training loss = 0.03521310289700826
step = 13, Training Accuracy: 0.45
Training loss = 0.032950840791066485
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.63
params:  [0.2650019725091874, 0.5271434216873142, 0.9595743351701999, 0.23083445726267732, 0.4602075216605811, 0.4115458538181438, 0.32929234983036504, 0.7102865646764329, 0.7713234734824153, 0.01, 0.48120769280631503, 0.38220899239626416, 0.0407474426463538, 0.012850546270130915, 0.4854153751129858, 0.12127240746609247, 0.3732523664861445, 0.2343982682304487, 0.23016458034306073, 0.8499045486964693, 0.7068270307842365, 0.30456298025607365, 0.24648437537744364, 0.6387667485670353, 0.2024507305084995, 0.28660885393908614, 0.3778410505059104, 0.29789725952357704, 0.2714282533862204, 0.13826445964776618, 0.99, 0.12632377642898351, 0.5108046309246054, 0.187549817645668, 0.3673458011947287, 0.8983828705484109, 0.01, 0.99, 0.99, 0.14538516038162952, 0.9745789894119702, 0.940195616462725, 0.293667167317168, 0.01, 0.7667099417061786, 0.7489977305760593, 0.7077071746782698, 0.46305297778612975, 0.99, 0.4139501716348532, 0.7382367964249342, 0.6984847305845445, 0.23198304364714448, 0.41105803722102796, 0.557226963487363, 0.99, 0.99, 0.6555649727968722, 0.013010207635303528, 0.21728130951866836, 0.49430202818097324, 0.42097323308940043, 0.6446356423967342, 0.9275994661267922, 0.29353221648614525, 0.99, 0.7349143039275358, 0.5213278397043944, 0.01, 0.99, 0.47865933824197293, 0.05587412067132563, 0.20296948401372644, 0.5896195265945641, 0.758480735494169, 0.01, 0.7948818783850218, 0.99, 0.01, 0.99, 0.6733223817950945, 0.6298287876383141, 0.6263444372479791, 0.3087581644540622, 0.2667648200180674, 0.34894661667906923, 0.1088904650400281, 0.5260899114148361, 0.27035887572739037, 0.37017663504079157, 0.01, 0.01]
[0.2650019725091874, 0.5271434216873142, 0.9595743351701999, 0.23083445726267732, 0.4602075216605811, 0.4115458538181438, 0.32929234983036504, 0.7102865646764329, 0.7713234734824153, 0.01, 0.48120769280631503, 0.38220899239626416, 0.0407474426463538, 0.012850546270130915, 0.4854153751129858, 0.12127240746609247, 0.3732523664861445, 0.2343982682304487, 0.23016458034306073, 0.8499045486964693, 0.7068270307842365, 0.30456298025607365, 0.24648437537744364, 0.6387667485670353, 0.2024507305084995, 0.28660885393908614, 0.3778410505059104, 0.29789725952357704, 0.2714282533862204, 0.13826445964776618, 0.99, 0.12632377642898351, 0.5108046309246054, 0.187549817645668, 0.3673458011947287, 0.8983828705484109, 0.01, 0.99, 0.99, 0.14538516038162952, 0.9745789894119702, 0.940195616462725, 0.293667167317168, 0.01, 0.7667099417061786, 0.7489977305760593, 0.7077071746782698, 0.46305297778612975, 0.99, 0.4139501716348532, 0.7382367964249342, 0.6984847305845445, 0.23198304364714448, 0.41105803722102796, 0.557226963487363, 0.99, 0.99, 0.6555649727968722, 0.013010207635303528, 0.21728130951866836, 0.49430202818097324, 0.42097323308940043, 0.6446356423967342, 0.9275994661267922, 0.29353221648614525, 0.99, 0.7349143039275358, 0.5213278397043944, 0.01, 0.99, 0.47865933824197293, 0.05587412067132563, 0.20296948401372644, 0.5896195265945641, 0.758480735494169, 0.01, 0.7948818783850218, 0.99, 0.01, 0.99, 0.6733223817950945, 0.6298287876383141, 0.6263444372479791, 0.3087581644540622, 0.2667648200180674, 0.34894661667906923, 0.1088904650400281, 0.5260899114148361, 0.27035887572739037, 0.37017663504079157, 0.01, 0.01]
Training loss = 0.032384551366170244
step = 0, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.6475
Training loss = 0.0347211229801178
step = 1, Training Accuracy: 0.47
Training loss = 0.0339887930949529
step = 2, Training Accuracy: 0.44666666666666666
Training loss = 0.0338157461086909
step = 3, Training Accuracy: 0.5
Training loss = 0.03235535303751628
step = 4, Training Accuracy: 0.48
Training loss = 0.03360123674074809
step = 5, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.6475
Training loss = 0.03250803927580515
step = 6, Training Accuracy: 0.5266666666666666
Training loss = 0.03294517596562704
step = 7, Training Accuracy: 0.5233333333333333
Training loss = 0.03367558141549428
step = 8, Training Accuracy: 0.49
Training loss = 0.03204495052496592
step = 9, Training Accuracy: 0.55
Training loss = 0.033769907355308534
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.62875
Training loss = 0.03318109412988027
step = 11, Training Accuracy: 0.48
Training loss = 0.03239814082781474
step = 12, Training Accuracy: 0.5
Training loss = 0.033207005858421325
step = 13, Training Accuracy: 0.5333333333333333
Training loss = 0.03383544385433197
step = 14, Training Accuracy: 0.46
Validation Accuracy: 0.6275
params:  [0.37110898641468315, 0.9514286611921199, 0.99, 0.7963610747085256, 0.9868104441001071, 0.480437916719184, 0.6130485007893949, 0.6869300880356125, 0.5557170200528344, 0.08245552549701993, 0.7675053118708622, 0.01, 0.22628606014712022, 0.2610070567555888, 0.5513202361543558, 0.39867755144453, 0.39770961913057673, 0.17595359558643406, 0.5513374266218015, 0.36761601262267407, 0.28372189920639873, 0.41386185477754445, 0.4951923624623767, 0.5643788893479889, 0.454201561787538, 0.01, 0.7107109101292068, 0.20581460116670042, 0.3563203834597407, 0.24249216529491097, 0.914605070066818, 0.48999555795879285, 0.34273359269994014, 0.06624699461764755, 0.2901726218495525, 0.7768549772649485, 0.18452656903117456, 0.9033866772552217, 0.99, 0.2522846204869573, 0.8619720987998233, 0.7043049110220443, 0.11408063540141775, 0.13338241045589447, 0.9709037935715845, 0.99, 0.43068962541259814, 0.6415646353513089, 0.99, 0.5509975752939484, 0.99, 0.6621576362098377, 0.11143320727514519, 0.24849997424492143, 0.20535033745487258, 0.99, 0.99, 0.99, 0.37283473221032964, 0.01, 0.99, 0.99, 0.3694759248437446, 0.6440164709688716, 0.4845754713145522, 0.99, 0.6685717377601997, 0.23171674927619026, 0.18771194320372522, 0.9539109889690257, 0.8399206803599572, 0.6750436682245156, 0.6198669954486568, 0.7108332956032792, 0.9650098171969774, 0.07125674742930375, 0.44561518906822273, 0.6824675844299737, 0.4459371574719023, 0.5995008140920062, 0.7064112139986307, 0.77826041202415, 0.99, 0.2708002109286288, 0.07766720607164168, 0.20724938208862326, 0.4393894887138773, 0.49831491780563153, 0.6037230048304549, 0.2649950810349918, 0.4200336546956096, 0.3584634656832132]
[0.37110898641468315, 0.9514286611921199, 0.99, 0.7963610747085256, 0.9868104441001071, 0.480437916719184, 0.6130485007893949, 0.6869300880356125, 0.5557170200528344, 0.08245552549701993, 0.7675053118708622, 0.01, 0.22628606014712022, 0.2610070567555888, 0.5513202361543558, 0.39867755144453, 0.39770961913057673, 0.17595359558643406, 0.5513374266218015, 0.36761601262267407, 0.28372189920639873, 0.41386185477754445, 0.4951923624623767, 0.5643788893479889, 0.454201561787538, 0.01, 0.7107109101292068, 0.20581460116670042, 0.3563203834597407, 0.24249216529491097, 0.914605070066818, 0.48999555795879285, 0.34273359269994014, 0.06624699461764755, 0.2901726218495525, 0.7768549772649485, 0.18452656903117456, 0.9033866772552217, 0.99, 0.2522846204869573, 0.8619720987998233, 0.7043049110220443, 0.11408063540141775, 0.13338241045589447, 0.9709037935715845, 0.99, 0.43068962541259814, 0.6415646353513089, 0.99, 0.5509975752939484, 0.99, 0.6621576362098377, 0.11143320727514519, 0.24849997424492143, 0.20535033745487258, 0.99, 0.99, 0.99, 0.37283473221032964, 0.01, 0.99, 0.99, 0.3694759248437446, 0.6440164709688716, 0.4845754713145522, 0.99, 0.6685717377601997, 0.23171674927619026, 0.18771194320372522, 0.9539109889690257, 0.8399206803599572, 0.6750436682245156, 0.6198669954486568, 0.7108332956032792, 0.9650098171969774, 0.07125674742930375, 0.44561518906822273, 0.6824675844299737, 0.4459371574719023, 0.5995008140920062, 0.7064112139986307, 0.77826041202415, 0.99, 0.2708002109286288, 0.07766720607164168, 0.20724938208862326, 0.4393894887138773, 0.49831491780563153, 0.6037230048304549, 0.2649950810349918, 0.4200336546956096, 0.3584634656832132]
Training loss = 0.03274259924888611
step = 0, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.61625
Training loss = 0.03241970419883728
step = 1, Training Accuracy: 0.47
Training loss = 0.033241997559865316
step = 2, Training Accuracy: 0.4633333333333333
Training loss = 0.03393978675206502
step = 3, Training Accuracy: 0.47333333333333333
Training loss = 0.03439686894416809
step = 4, Training Accuracy: 0.4633333333333333
Training loss = 0.03240750273068746
step = 5, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.62875
Training loss = 0.035421904325485226
step = 6, Training Accuracy: 0.43333333333333335
Training loss = 0.03311124463876088
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.032723910212516784
step = 8, Training Accuracy: 0.5066666666666667
Training loss = 0.03367473522822062
step = 9, Training Accuracy: 0.46
Training loss = 0.03218851625919342
step = 10, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.63875
Training loss = 0.033322228988011675
step = 11, Training Accuracy: 0.51
Training loss = 0.03249565025170644
step = 12, Training Accuracy: 0.54
Training loss = 0.03426777720451355
step = 13, Training Accuracy: 0.4266666666666667
Training loss = 0.0330062601963679
step = 14, Training Accuracy: 0.53
Validation Accuracy: 0.6325
params:  [0.2877986908614576, 0.7278597090711871, 0.8581864056307827, 0.01, 0.7528607912349261, 0.390654196201459, 0.5022819363079154, 0.35650843165545243, 0.99, 0.04226944188899331, 0.28413185827551657, 0.36023785625482313, 0.025007239472963877, 0.4287663426919208, 0.839194373290571, 0.01, 0.6048447841643251, 0.17647965501551702, 0.8997163597440971, 0.019485053023964916, 0.05232126845204303, 0.2915382603137383, 0.2919104810017684, 0.6259208056837758, 0.18090694692557224, 0.01, 0.5710750062579567, 0.08888810978656843, 0.5290687304685872, 0.01, 0.99, 0.18969428650652875, 0.40595480287564745, 0.19130643055316757, 0.6299514446554896, 0.99, 0.01, 0.99, 0.99, 0.4492972676431455, 0.6504925690860687, 0.6353906504534533, 0.4215629746140742, 0.40679091614667634, 0.6729170172999243, 0.7855056284058799, 0.2918714848581685, 0.99, 0.6957201627300686, 0.8316617335023677, 0.7962550418926576, 0.8605043953571382, 0.22294498537685645, 0.01, 0.3518696199933528, 0.99, 0.7913801523276242, 0.631324293670944, 0.3468804278811478, 0.01, 0.7948281184623709, 0.99, 0.40423159990267643, 0.99, 0.5739632211917481, 0.99, 0.06680608033268487, 0.3988213851695061, 0.01, 0.99, 0.8779741189217811, 0.4317999280035276, 0.01, 0.3282372256378126, 0.8875981388233033, 0.01, 0.3973810321151684, 0.99, 0.6978546686476323, 0.8800059946947005, 0.7081058332814336, 0.8519265096224838, 0.04187860970050361, 0.4008260500432284, 0.5500696313123322, 0.20363483666248774, 0.17921262659951895, 0.6926046985410981, 0.41226394809400946, 0.01465812515637005, 0.3771965612446678, 0.20053574743886585]
[0.2877986908614576, 0.7278597090711871, 0.8581864056307827, 0.01, 0.7528607912349261, 0.390654196201459, 0.5022819363079154, 0.35650843165545243, 0.99, 0.04226944188899331, 0.28413185827551657, 0.36023785625482313, 0.025007239472963877, 0.4287663426919208, 0.839194373290571, 0.01, 0.6048447841643251, 0.17647965501551702, 0.8997163597440971, 0.019485053023964916, 0.05232126845204303, 0.2915382603137383, 0.2919104810017684, 0.6259208056837758, 0.18090694692557224, 0.01, 0.5710750062579567, 0.08888810978656843, 0.5290687304685872, 0.01, 0.99, 0.18969428650652875, 0.40595480287564745, 0.19130643055316757, 0.6299514446554896, 0.99, 0.01, 0.99, 0.99, 0.4492972676431455, 0.6504925690860687, 0.6353906504534533, 0.4215629746140742, 0.40679091614667634, 0.6729170172999243, 0.7855056284058799, 0.2918714848581685, 0.99, 0.6957201627300686, 0.8316617335023677, 0.7962550418926576, 0.8605043953571382, 0.22294498537685645, 0.01, 0.3518696199933528, 0.99, 0.7913801523276242, 0.631324293670944, 0.3468804278811478, 0.01, 0.7948281184623709, 0.99, 0.40423159990267643, 0.99, 0.5739632211917481, 0.99, 0.06680608033268487, 0.3988213851695061, 0.01, 0.99, 0.8779741189217811, 0.4317999280035276, 0.01, 0.3282372256378126, 0.8875981388233033, 0.01, 0.3973810321151684, 0.99, 0.6978546686476323, 0.8800059946947005, 0.7081058332814336, 0.8519265096224838, 0.04187860970050361, 0.4008260500432284, 0.5500696313123322, 0.20363483666248774, 0.17921262659951895, 0.6926046985410981, 0.41226394809400946, 0.01465812515637005, 0.3771965612446678, 0.20053574743886585]
Training loss = 0.03178804755210876
step = 0, Training Accuracy: 0.52
Validation Accuracy: 0.6375
Training loss = 0.033823879758516945
step = 1, Training Accuracy: 0.47333333333333333
Training loss = 0.03267673790454864
step = 2, Training Accuracy: 0.5066666666666667
Training loss = 0.03377496242523193
step = 3, Training Accuracy: 0.44333333333333336
Training loss = 0.03236975471178691
step = 4, Training Accuracy: 0.4866666666666667
Training loss = 0.03174267848332723
step = 5, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.6175
Training loss = 0.03209297279516856
step = 6, Training Accuracy: 0.53
Training loss = 0.03237895568211873
step = 7, Training Accuracy: 0.5133333333333333
Training loss = 0.03329629083474477
step = 8, Training Accuracy: 0.48333333333333334
Training loss = 0.03283977925777435
step = 9, Training Accuracy: 0.47333333333333333
Training loss = 0.03222062389055888
step = 10, Training Accuracy: 0.48
Validation Accuracy: 0.6225
Training loss = 0.03246889114379883
step = 11, Training Accuracy: 0.4866666666666667
Training loss = 0.03280276596546173
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03316467185815175
step = 13, Training Accuracy: 0.4766666666666667
Training loss = 0.033056838909784954
step = 14, Training Accuracy: 0.51
Validation Accuracy: 0.62875
params:  [0.15753295347109517, 0.6912083523226745, 0.7179033998604938, 0.4019633270757193, 0.8177401712257023, 0.4795304856739196, 0.8284428289781607, 0.36537075526600526, 0.7801623471300378, 0.2293093273119981, 0.24839779196099965, 0.01, 0.48117101624077585, 0.12343992907698764, 0.27957629788579824, 0.1292973594383672, 0.8204160993955202, 0.2531023381962694, 0.5950828426342337, 0.7129344238777336, 0.01, 0.13826565637905505, 0.01, 0.5776387196956407, 0.41010088918863363, 0.5165452487366236, 0.569711829511078, 0.2757220224880158, 0.7170615730774738, 0.5534363980223811, 0.9061732134363808, 0.5600101392395243, 0.4882678668628782, 0.12125291980734121, 0.46924186055568656, 0.6390223656284789, 0.01, 0.9787066846267221, 0.6616249944872536, 0.3614445963273608, 0.99, 0.99, 0.6115535354289214, 0.01, 0.8344871897512844, 0.99, 0.18669360622373632, 0.8218487430490418, 0.8930214251522742, 0.5836459820427028, 0.7396531723871153, 0.9292934332193219, 0.12632433710915036, 0.05154558167455203, 0.42092806623701157, 0.8828924710794765, 0.9825639086489724, 0.99, 0.6118425383005827, 0.01, 0.8461506233586003, 0.7621184328553342, 0.5914389129047704, 0.8387972930782774, 0.36071209042772984, 0.99, 0.6447648770423859, 0.01, 0.1766016069805713, 0.8529478748333189, 0.99, 0.013635869037316284, 0.5356371693551566, 0.5561902421937608, 0.99, 0.42145779498755004, 0.8021720600751081, 0.7203534041203379, 0.19971325381868021, 0.99, 0.6665250357489809, 0.8704188116391905, 0.5060748219857716, 0.2509571664374998, 0.4307127785302174, 0.17675527791624962, 0.01, 0.5705817986256996, 0.2674555593603162, 0.7482237153495145, 0.35938188669641147, 0.3977504308530794]
[0.15753295347109517, 0.6912083523226745, 0.7179033998604938, 0.4019633270757193, 0.8177401712257023, 0.4795304856739196, 0.8284428289781607, 0.36537075526600526, 0.7801623471300378, 0.2293093273119981, 0.24839779196099965, 0.01, 0.48117101624077585, 0.12343992907698764, 0.27957629788579824, 0.1292973594383672, 0.8204160993955202, 0.2531023381962694, 0.5950828426342337, 0.7129344238777336, 0.01, 0.13826565637905505, 0.01, 0.5776387196956407, 0.41010088918863363, 0.5165452487366236, 0.569711829511078, 0.2757220224880158, 0.7170615730774738, 0.5534363980223811, 0.9061732134363808, 0.5600101392395243, 0.4882678668628782, 0.12125291980734121, 0.46924186055568656, 0.6390223656284789, 0.01, 0.9787066846267221, 0.6616249944872536, 0.3614445963273608, 0.99, 0.99, 0.6115535354289214, 0.01, 0.8344871897512844, 0.99, 0.18669360622373632, 0.8218487430490418, 0.8930214251522742, 0.5836459820427028, 0.7396531723871153, 0.9292934332193219, 0.12632433710915036, 0.05154558167455203, 0.42092806623701157, 0.8828924710794765, 0.9825639086489724, 0.99, 0.6118425383005827, 0.01, 0.8461506233586003, 0.7621184328553342, 0.5914389129047704, 0.8387972930782774, 0.36071209042772984, 0.99, 0.6447648770423859, 0.01, 0.1766016069805713, 0.8529478748333189, 0.99, 0.013635869037316284, 0.5356371693551566, 0.5561902421937608, 0.99, 0.42145779498755004, 0.8021720600751081, 0.7203534041203379, 0.19971325381868021, 0.99, 0.6665250357489809, 0.8704188116391905, 0.5060748219857716, 0.2509571664374998, 0.4307127785302174, 0.17675527791624962, 0.01, 0.5705817986256996, 0.2674555593603162, 0.7482237153495145, 0.35938188669641147, 0.3977504308530794]
Training loss = 0.03155276914437612
step = 0, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.6375
Training loss = 0.03289226174354553
step = 1, Training Accuracy: 0.5033333333333333
Training loss = 0.03412486374378204
step = 2, Training Accuracy: 0.43666666666666665
Training loss = 0.03256517827510834
step = 3, Training Accuracy: 0.49333333333333335
Training loss = 0.034204069375991825
step = 4, Training Accuracy: 0.4533333333333333
Training loss = 0.03241172293821971
step = 5, Training Accuracy: 0.49
Validation Accuracy: 0.635
Training loss = 0.032587526639302575
step = 6, Training Accuracy: 0.49666666666666665
Training loss = 0.03230321725209554
step = 7, Training Accuracy: 0.4633333333333333
Training loss = 0.033261714577674864
step = 8, Training Accuracy: 0.47333333333333333
Training loss = 0.033087135752042134
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.03243401269117991
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.62
Training loss = 0.03431456704934438
step = 11, Training Accuracy: 0.44333333333333336
Training loss = 0.033735866943995156
step = 12, Training Accuracy: 0.5033333333333333
Training loss = 0.03495461285114288
step = 13, Training Accuracy: 0.4766666666666667
Training loss = 0.0330693115790685
step = 14, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.63125
params:  [0.0890878789720919, 0.99, 0.99, 0.26435853480663773, 0.9752287022111249, 0.333914401223725, 0.5084433456343688, 0.5901737679729394, 0.5343239415668811, 0.44742666907360645, 0.3212852490169672, 0.01, 0.40096554838387366, 0.04068932260309446, 0.4384939361552743, 0.18892060446902786, 0.43139366050231753, 0.13391975273011408, 0.7028298992502976, 0.5116610668095645, 0.01, 0.045415975636589216, 0.5248079071026417, 0.8136200838785579, 0.2923445224259017, 0.01, 0.7498671189007536, 0.2931927894784703, 0.7298213979325509, 0.01, 0.99, 0.33599268982118613, 0.18804695925861026, 0.29549134664372834, 0.545043034866066, 0.5228201041636561, 0.01, 0.8784593171697967, 0.99, 0.1690447415373897, 0.99, 0.7986617072300264, 0.3708469498432354, 0.16699333615865666, 0.4861590621809485, 0.7202337572673543, 0.1675652088306806, 0.6434166071280285, 0.5364827529517224, 0.2818036640806194, 0.8972972438897437, 0.878509756944826, 0.17004471736525634, 0.054667453349517836, 0.4454392723775887, 0.9744674447521141, 0.99, 0.8298256386357099, 0.4141806955975183, 0.034588274113911466, 0.8370711388715283, 0.4490425843549388, 0.3755163241392159, 0.99, 0.2273205148993045, 0.6174431742233215, 0.5932439220055845, 0.20465065256750414, 0.01, 0.8204738652569875, 0.7482425143652822, 0.6983497198627338, 0.5133949763065108, 0.6678682024869402, 0.8147897888174404, 0.13675338593431985, 0.7860488413913232, 0.5774507862443, 0.21565396248622512, 0.99, 0.4951062617662474, 0.9011385704134857, 0.5153237055279904, 0.01, 0.5831628749102591, 0.01, 0.27331457200367454, 0.5178198392146592, 0.702292738348795, 0.24612532004911836, 0.4402704080672831, 0.20999588208147382]
[0.0890878789720919, 0.99, 0.99, 0.26435853480663773, 0.9752287022111249, 0.333914401223725, 0.5084433456343688, 0.5901737679729394, 0.5343239415668811, 0.44742666907360645, 0.3212852490169672, 0.01, 0.40096554838387366, 0.04068932260309446, 0.4384939361552743, 0.18892060446902786, 0.43139366050231753, 0.13391975273011408, 0.7028298992502976, 0.5116610668095645, 0.01, 0.045415975636589216, 0.5248079071026417, 0.8136200838785579, 0.2923445224259017, 0.01, 0.7498671189007536, 0.2931927894784703, 0.7298213979325509, 0.01, 0.99, 0.33599268982118613, 0.18804695925861026, 0.29549134664372834, 0.545043034866066, 0.5228201041636561, 0.01, 0.8784593171697967, 0.99, 0.1690447415373897, 0.99, 0.7986617072300264, 0.3708469498432354, 0.16699333615865666, 0.4861590621809485, 0.7202337572673543, 0.1675652088306806, 0.6434166071280285, 0.5364827529517224, 0.2818036640806194, 0.8972972438897437, 0.878509756944826, 0.17004471736525634, 0.054667453349517836, 0.4454392723775887, 0.9744674447521141, 0.99, 0.8298256386357099, 0.4141806955975183, 0.034588274113911466, 0.8370711388715283, 0.4490425843549388, 0.3755163241392159, 0.99, 0.2273205148993045, 0.6174431742233215, 0.5932439220055845, 0.20465065256750414, 0.01, 0.8204738652569875, 0.7482425143652822, 0.6983497198627338, 0.5133949763065108, 0.6678682024869402, 0.8147897888174404, 0.13675338593431985, 0.7860488413913232, 0.5774507862443, 0.21565396248622512, 0.99, 0.4951062617662474, 0.9011385704134857, 0.5153237055279904, 0.01, 0.5831628749102591, 0.01, 0.27331457200367454, 0.5178198392146592, 0.702292738348795, 0.24612532004911836, 0.4402704080672831, 0.20999588208147382]
Training loss = 0.0322785617907842
step = 0, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.6375
Training loss = 0.03285943369070689
step = 1, Training Accuracy: 0.4633333333333333
Training loss = 0.03195120712121328
step = 2, Training Accuracy: 0.5633333333333334
Training loss = 0.0334284116824468
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03292279124259949
step = 4, Training Accuracy: 0.5
Training loss = 0.03380895137786865
step = 5, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.62625
Training loss = 0.03350594460964203
step = 6, Training Accuracy: 0.47
Training loss = 0.03193685909112295
step = 7, Training Accuracy: 0.55
Training loss = 0.03274565537770589
step = 8, Training Accuracy: 0.5233333333333333
Training loss = 0.03313596030076345
step = 9, Training Accuracy: 0.5166666666666667
Training loss = 0.033224279284477236
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.6225
Training loss = 0.03198884924252828
step = 11, Training Accuracy: 0.5266666666666666
Training loss = 0.03250136435031891
step = 12, Training Accuracy: 0.49666666666666665
Training loss = 0.032251424590746564
step = 13, Training Accuracy: 0.5366666666666666
Training loss = 0.03280834337075551
step = 14, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.61875
params:  [0.01, 0.47344583084406616, 0.99, 0.5092520685247908, 0.530284649242549, 0.01, 0.5087458883467035, 0.99, 0.6188889585142733, 0.03731244979909387, 0.4608466738981866, 0.18092456547562577, 0.40879936892116375, 0.12119787161907745, 0.6570769007290554, 0.01, 0.23231761993225075, 0.01, 0.22435156054462457, 0.8468354552591318, 0.061133284286570486, 0.01, 0.06874544075622213, 0.6795910440323392, 0.11093813630552242, 0.01, 0.6136127081207349, 0.01, 0.4056011510291722, 0.1847170776527618, 0.5458365920613669, 0.017032126961161936, 0.37763421200733516, 0.5977569729298895, 0.35292964028161217, 0.5511639881529885, 0.250802240880596, 0.99, 0.791334052859757, 0.1594378629678146, 0.8165639578422492, 0.99, 0.01, 0.18916302174805602, 0.6750933947108461, 0.8687436932135946, 0.0368849384576998, 0.9622058704118011, 0.9841838088556567, 0.9068629879439827, 0.99, 0.9239540645781671, 0.325020328424061, 0.3816696240752015, 0.2519632489799937, 0.99, 0.99, 0.9128556024645671, 0.44201857858264576, 0.09546955247205526, 0.8194723919889121, 0.9008984447937856, 0.5767098829910468, 0.8440743608041853, 0.518712331785763, 0.8101995146745735, 0.4698876189173532, 0.10900862596877242, 0.01, 0.7734675726187592, 0.3256547216666139, 0.2763783737364795, 0.47594912396630573, 0.5275309537484117, 0.45261212475029877, 0.01, 0.7497341912091695, 0.5410859744076149, 0.34691123703863563, 0.7618072536675136, 0.554383052564533, 0.8181585775400159, 0.3513253753558233, 0.15388187082456894, 0.18566345470213516, 0.2563905506597421, 0.13255003344510302, 0.5669633022112849, 0.09728466277409997, 0.040864696737842654, 0.4009052690845204, 0.24577547872272637]
[0.01, 0.47344583084406616, 0.99, 0.5092520685247908, 0.530284649242549, 0.01, 0.5087458883467035, 0.99, 0.6188889585142733, 0.03731244979909387, 0.4608466738981866, 0.18092456547562577, 0.40879936892116375, 0.12119787161907745, 0.6570769007290554, 0.01, 0.23231761993225075, 0.01, 0.22435156054462457, 0.8468354552591318, 0.061133284286570486, 0.01, 0.06874544075622213, 0.6795910440323392, 0.11093813630552242, 0.01, 0.6136127081207349, 0.01, 0.4056011510291722, 0.1847170776527618, 0.5458365920613669, 0.017032126961161936, 0.37763421200733516, 0.5977569729298895, 0.35292964028161217, 0.5511639881529885, 0.250802240880596, 0.99, 0.791334052859757, 0.1594378629678146, 0.8165639578422492, 0.99, 0.01, 0.18916302174805602, 0.6750933947108461, 0.8687436932135946, 0.0368849384576998, 0.9622058704118011, 0.9841838088556567, 0.9068629879439827, 0.99, 0.9239540645781671, 0.325020328424061, 0.3816696240752015, 0.2519632489799937, 0.99, 0.99, 0.9128556024645671, 0.44201857858264576, 0.09546955247205526, 0.8194723919889121, 0.9008984447937856, 0.5767098829910468, 0.8440743608041853, 0.518712331785763, 0.8101995146745735, 0.4698876189173532, 0.10900862596877242, 0.01, 0.7734675726187592, 0.3256547216666139, 0.2763783737364795, 0.47594912396630573, 0.5275309537484117, 0.45261212475029877, 0.01, 0.7497341912091695, 0.5410859744076149, 0.34691123703863563, 0.7618072536675136, 0.554383052564533, 0.8181585775400159, 0.3513253753558233, 0.15388187082456894, 0.18566345470213516, 0.2563905506597421, 0.13255003344510302, 0.5669633022112849, 0.09728466277409997, 0.040864696737842654, 0.4009052690845204, 0.24577547872272637]
Training loss = 0.0311667005221049
step = 0, Training Accuracy: 0.53
Validation Accuracy: 0.62875
Training loss = 0.030921507477760315
step = 1, Training Accuracy: 0.57
Training loss = 0.03291529913743337
step = 2, Training Accuracy: 0.54
Training loss = 0.033428683678309125
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03203087270259857
step = 4, Training Accuracy: 0.5233333333333333
Training loss = 0.031212820609410604
step = 5, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.6425
Training loss = 0.03077166199684143
step = 6, Training Accuracy: 0.54
Training loss = 0.03204233646392822
step = 7, Training Accuracy: 0.52
Training loss = 0.03150207459926605
step = 8, Training Accuracy: 0.5533333333333333
Training loss = 0.03278722623984019
step = 9, Training Accuracy: 0.5466666666666666
Training loss = 0.03212031622727712
step = 10, Training Accuracy: 0.5266666666666666
Validation Accuracy: 0.6425
Training loss = 0.030569098393122354
step = 11, Training Accuracy: 0.5733333333333334
Training loss = 0.03249210238456726
step = 12, Training Accuracy: 0.53
Training loss = 0.030460331042607626
step = 13, Training Accuracy: 0.56
Training loss = 0.031524487535158796
step = 14, Training Accuracy: 0.54
Validation Accuracy: 0.645
13 	8     	0.631563	0.00728199	0.61875	0.645  
params:  [0.2902811193029617, 0.4127788030080662, 0.99, 0.3901733608762481, 0.35151381562414175, 0.2879609620902324, 0.3056723661787827, 0.8068248429309169, 0.4347600804669285, 0.48673914114505745, 0.59281489966042, 0.35142290172904445, 0.38877283388704803, 0.01, 0.5721902108052326, 0.2914416343899885, 0.4659147769874858, 0.01, 0.2355200763557318, 0.99, 0.4512693421929693, 0.23292713629374012, 0.01, 0.5252660458003527, 0.18693769864135115, 0.06580436573168226, 0.42431326260133756, 0.01, 0.1702779432825015, 0.5671364585160341, 0.99, 0.3399801003109753, 0.3439246337555121, 0.24422696129894467, 0.35692386252877345, 0.4729962340724836, 0.01, 0.99, 0.6184340005984013, 0.2052628928598018, 0.14673870475954642, 0.99, 0.01, 0.02701360787037657, 0.6501623371655845, 0.658624157277146, 0.01, 0.9621891723776312, 0.9763880177972014, 0.6860347499225223, 0.6851172368377945, 0.2590750418376674, 0.4120514313373163, 0.2502095835463517, 0.48672697838062595, 0.99, 0.99, 0.6776688715838819, 0.6720021327112969, 0.5235031924286659, 0.99, 0.4261012399810667, 0.8091573578537534, 0.99, 0.22832854120622467, 0.99, 0.6588174217010944, 0.13058582335327146, 0.01, 0.4622554915241628, 0.7203995524161807, 0.226142396226328, 0.3429367349950535, 0.6040542582823404, 0.6573992548431148, 0.01, 0.7810540365855702, 0.5038677050079406, 0.3532446392741347, 0.99, 0.5217449644358828, 0.9096262686688272, 0.4202932101271079, 0.7367997970480962, 0.01, 0.01, 0.01, 0.7728407865464946, 0.5057436248050927, 0.01, 0.4430494275995369, 0.09861554238194961]
[0.2902811193029617, 0.4127788030080662, 0.99, 0.3901733608762481, 0.35151381562414175, 0.2879609620902324, 0.3056723661787827, 0.8068248429309169, 0.4347600804669285, 0.48673914114505745, 0.59281489966042, 0.35142290172904445, 0.38877283388704803, 0.01, 0.5721902108052326, 0.2914416343899885, 0.4659147769874858, 0.01, 0.2355200763557318, 0.99, 0.4512693421929693, 0.23292713629374012, 0.01, 0.5252660458003527, 0.18693769864135115, 0.06580436573168226, 0.42431326260133756, 0.01, 0.1702779432825015, 0.5671364585160341, 0.99, 0.3399801003109753, 0.3439246337555121, 0.24422696129894467, 0.35692386252877345, 0.4729962340724836, 0.01, 0.99, 0.6184340005984013, 0.2052628928598018, 0.14673870475954642, 0.99, 0.01, 0.02701360787037657, 0.6501623371655845, 0.658624157277146, 0.01, 0.9621891723776312, 0.9763880177972014, 0.6860347499225223, 0.6851172368377945, 0.2590750418376674, 0.4120514313373163, 0.2502095835463517, 0.48672697838062595, 0.99, 0.99, 0.6776688715838819, 0.6720021327112969, 0.5235031924286659, 0.99, 0.4261012399810667, 0.8091573578537534, 0.99, 0.22832854120622467, 0.99, 0.6588174217010944, 0.13058582335327146, 0.01, 0.4622554915241628, 0.7203995524161807, 0.226142396226328, 0.3429367349950535, 0.6040542582823404, 0.6573992548431148, 0.01, 0.7810540365855702, 0.5038677050079406, 0.3532446392741347, 0.99, 0.5217449644358828, 0.9096262686688272, 0.4202932101271079, 0.7367997970480962, 0.01, 0.01, 0.01, 0.7728407865464946, 0.5057436248050927, 0.01, 0.4430494275995369, 0.09861554238194961]
Training loss = 0.0327057675520579
step = 0, Training Accuracy: 0.5133333333333333
Validation Accuracy: 0.64875
Training loss = 0.033632585604985554
step = 1, Training Accuracy: 0.4866666666666667
Training loss = 0.0341743540763855
step = 2, Training Accuracy: 0.48333333333333334
Training loss = 0.03240498125553131
step = 3, Training Accuracy: 0.5033333333333333
Training loss = 0.03352479855219523
step = 4, Training Accuracy: 0.44666666666666666
Training loss = 0.03241748174031576
step = 5, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.6475
Training loss = 0.03221230566501618
step = 6, Training Accuracy: 0.5166666666666667
Training loss = 0.03226850310961405
step = 7, Training Accuracy: 0.52
Training loss = 0.03529318630695343
step = 8, Training Accuracy: 0.44666666666666666
Training loss = 0.032086734573046366
step = 9, Training Accuracy: 0.53
Training loss = 0.032651119629542036
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.65
Training loss = 0.03309418559074402
step = 11, Training Accuracy: 0.49666666666666665
Training loss = 0.03495249330997467
step = 12, Training Accuracy: 0.4533333333333333
Training loss = 0.033138537208239234
step = 13, Training Accuracy: 0.48
Training loss = 0.0339816798766454
step = 14, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.64
params:  [0.01, 0.922803340482865, 0.9868905811484058, 0.579113090624763, 0.8702207995857666, 0.4877727615434953, 0.6386939726887831, 0.99, 0.7307999712370216, 0.01, 0.1446201878843949, 0.49535600100587557, 0.40591987218139963, 0.01, 0.8701883002929249, 0.01, 0.4811106961994398, 0.02959174150886995, 0.576441945730658, 0.8843207285863118, 0.4310548028478875, 0.01, 0.19680085104382672, 0.5383359087521148, 0.1263782307537765, 0.25766925339289826, 0.5242354839717558, 0.10687431174077303, 0.5363368878789276, 0.6152561243563426, 0.9316852115281349, 0.43515363857767486, 0.5014715467442246, 0.6317079337933071, 0.3341876523290865, 0.5838388901195012, 0.2541003525333849, 0.99, 0.8677282449508413, 0.34605790059132935, 0.8088980310586682, 0.99, 0.047948947622497434, 0.7784883163713042, 0.6050236045771609, 0.291320890128799, 0.11120367244935536, 0.7420365093916945, 0.9511890680895267, 0.7671966032221891, 0.8889471181526261, 0.7761161852412026, 0.3714388575393614, 0.01, 0.33024062604793514, 0.965774473456305, 0.7780279552969811, 0.723056027250691, 0.6180869802361195, 0.09230851762663814, 0.8410966370540728, 0.7151783116194204, 0.2647030609622967, 0.9565364730535719, 0.6064543210940923, 0.8397949014587787, 0.01, 0.1997972182306769, 0.07668352514593313, 0.6462017492136463, 0.4887181388097873, 0.5015415917919218, 0.8628491792933793, 0.5063893641653029, 0.9086918575950769, 0.2635966672118567, 0.9328087693647662, 0.35685362259004094, 0.11305657703264618, 0.99, 0.7809907959602936, 0.8727960008199204, 0.5430698547675953, 0.11483504486475096, 0.5130822614982088, 0.5035784172002591, 0.28478458125786654, 0.37583740221213546, 0.25794662364714227, 0.01, 0.7124296429992534, 0.01]
[0.01, 0.922803340482865, 0.9868905811484058, 0.579113090624763, 0.8702207995857666, 0.4877727615434953, 0.6386939726887831, 0.99, 0.7307999712370216, 0.01, 0.1446201878843949, 0.49535600100587557, 0.40591987218139963, 0.01, 0.8701883002929249, 0.01, 0.4811106961994398, 0.02959174150886995, 0.576441945730658, 0.8843207285863118, 0.4310548028478875, 0.01, 0.19680085104382672, 0.5383359087521148, 0.1263782307537765, 0.25766925339289826, 0.5242354839717558, 0.10687431174077303, 0.5363368878789276, 0.6152561243563426, 0.9316852115281349, 0.43515363857767486, 0.5014715467442246, 0.6317079337933071, 0.3341876523290865, 0.5838388901195012, 0.2541003525333849, 0.99, 0.8677282449508413, 0.34605790059132935, 0.8088980310586682, 0.99, 0.047948947622497434, 0.7784883163713042, 0.6050236045771609, 0.291320890128799, 0.11120367244935536, 0.7420365093916945, 0.9511890680895267, 0.7671966032221891, 0.8889471181526261, 0.7761161852412026, 0.3714388575393614, 0.01, 0.33024062604793514, 0.965774473456305, 0.7780279552969811, 0.723056027250691, 0.6180869802361195, 0.09230851762663814, 0.8410966370540728, 0.7151783116194204, 0.2647030609622967, 0.9565364730535719, 0.6064543210940923, 0.8397949014587787, 0.01, 0.1997972182306769, 0.07668352514593313, 0.6462017492136463, 0.4887181388097873, 0.5015415917919218, 0.8628491792933793, 0.5063893641653029, 0.9086918575950769, 0.2635966672118567, 0.9328087693647662, 0.35685362259004094, 0.11305657703264618, 0.99, 0.7809907959602936, 0.8727960008199204, 0.5430698547675953, 0.11483504486475096, 0.5130822614982088, 0.5035784172002591, 0.28478458125786654, 0.37583740221213546, 0.25794662364714227, 0.01, 0.7124296429992534, 0.01]
Training loss = 0.0341412216424942
step = 0, Training Accuracy: 0.48
Validation Accuracy: 0.64
Training loss = 0.03365970512231191
step = 1, Training Accuracy: 0.48333333333333334
Training loss = 0.034451190233230594
step = 2, Training Accuracy: 0.42333333333333334
Training loss = 0.03391300141811371
step = 3, Training Accuracy: 0.4666666666666667
Training loss = 0.03296497821807862
step = 4, Training Accuracy: 0.5
Training loss = 0.03373348395029704
step = 5, Training Accuracy: 0.44333333333333336
Validation Accuracy: 0.63875
Training loss = 0.033565183281898496
step = 6, Training Accuracy: 0.49666666666666665
Training loss = 0.03403885344664256
step = 7, Training Accuracy: 0.51
Training loss = 0.03428657670815786
step = 8, Training Accuracy: 0.44666666666666666
Training loss = 0.032414989272753394
step = 9, Training Accuracy: 0.49333333333333335
Training loss = 0.03342856307824453
step = 10, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.6425
Training loss = 0.034121684829394025
step = 11, Training Accuracy: 0.45666666666666667
Training loss = 0.033408706386884056
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.03390795270601908
step = 13, Training Accuracy: 0.49
Training loss = 0.03303847889105479
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.62875
params:  [0.25646730069940094, 0.6548053305486761, 0.5992163958859793, 0.8467742580138655, 0.8645510344349597, 0.1533182468230257, 0.47948814569997356, 0.9806073786170679, 0.8314917427837785, 0.1120457193443169, 0.6741878215858476, 0.5738121477112781, 0.01, 0.01589194726737693, 0.9078863385289087, 0.2300076124322322, 0.2604328362598153, 0.6360796948575872, 0.5290024001820852, 0.4117534991576234, 0.0909578297633689, 0.16362770300540147, 0.2723525556233887, 0.6028002667079168, 0.18658452417811533, 0.2752899119934221, 0.47082207385263974, 0.1749353168193188, 0.17826795767484735, 0.32872004571079355, 0.8050657674932032, 0.01, 0.23911386684008146, 0.4701088601073018, 0.539556196311092, 0.7103284674759338, 0.25320785579079386, 0.99, 0.99, 0.04566140055123559, 0.92547740711765, 0.919042644884698, 0.626957206811323, 0.3795720691771482, 0.7559180061710038, 0.7679296621707115, 0.23534611488538815, 0.9300435311900914, 0.5153760745949103, 0.7760689557559807, 0.7475492005261397, 0.9123960165086586, 0.01, 0.5997803446668579, 0.2775426701519502, 0.99, 0.99, 0.9285468010954675, 0.12609991880345, 0.29036817393199277, 0.9494118420748657, 0.8274218664043285, 0.37045779148849384, 0.99, 0.44453440519760146, 0.99, 0.5542277269111711, 0.01, 0.01, 0.9821058631120645, 0.209533312418773, 0.26122794425547197, 0.2939219839558764, 0.4007993878462464, 0.5363677902092765, 0.01, 0.46494639765534773, 0.4581430368569797, 0.5273056143710433, 0.864869996139071, 0.49093132556056535, 0.7600992038896136, 0.44018693495019146, 0.01, 0.5869780699428211, 0.01, 0.2514243954000784, 0.4722453477975529, 0.09571561875478088, 0.1003197986088468, 0.6408849073286855, 0.2726493127064762]
[0.25646730069940094, 0.6548053305486761, 0.5992163958859793, 0.8467742580138655, 0.8645510344349597, 0.1533182468230257, 0.47948814569997356, 0.9806073786170679, 0.8314917427837785, 0.1120457193443169, 0.6741878215858476, 0.5738121477112781, 0.01, 0.01589194726737693, 0.9078863385289087, 0.2300076124322322, 0.2604328362598153, 0.6360796948575872, 0.5290024001820852, 0.4117534991576234, 0.0909578297633689, 0.16362770300540147, 0.2723525556233887, 0.6028002667079168, 0.18658452417811533, 0.2752899119934221, 0.47082207385263974, 0.1749353168193188, 0.17826795767484735, 0.32872004571079355, 0.8050657674932032, 0.01, 0.23911386684008146, 0.4701088601073018, 0.539556196311092, 0.7103284674759338, 0.25320785579079386, 0.99, 0.99, 0.04566140055123559, 0.92547740711765, 0.919042644884698, 0.626957206811323, 0.3795720691771482, 0.7559180061710038, 0.7679296621707115, 0.23534611488538815, 0.9300435311900914, 0.5153760745949103, 0.7760689557559807, 0.7475492005261397, 0.9123960165086586, 0.01, 0.5997803446668579, 0.2775426701519502, 0.99, 0.99, 0.9285468010954675, 0.12609991880345, 0.29036817393199277, 0.9494118420748657, 0.8274218664043285, 0.37045779148849384, 0.99, 0.44453440519760146, 0.99, 0.5542277269111711, 0.01, 0.01, 0.9821058631120645, 0.209533312418773, 0.26122794425547197, 0.2939219839558764, 0.4007993878462464, 0.5363677902092765, 0.01, 0.46494639765534773, 0.4581430368569797, 0.5273056143710433, 0.864869996139071, 0.49093132556056535, 0.7600992038896136, 0.44018693495019146, 0.01, 0.5869780699428211, 0.01, 0.2514243954000784, 0.4722453477975529, 0.09571561875478088, 0.1003197986088468, 0.6408849073286855, 0.2726493127064762]
Training loss = 0.032162702480951946
step = 0, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.6275
Training loss = 0.032621787389119465
step = 1, Training Accuracy: 0.5233333333333333
Training loss = 0.03266228636105855
step = 2, Training Accuracy: 0.5233333333333333
Training loss = 0.03353018661340078
step = 3, Training Accuracy: 0.48
Training loss = 0.032803011933962505
step = 4, Training Accuracy: 0.5166666666666667
Training loss = 0.03473627646764119
step = 5, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.6275
Training loss = 0.03274581690629323
step = 6, Training Accuracy: 0.49333333333333335
Training loss = 0.033100231687227887
step = 7, Training Accuracy: 0.48
Training loss = 0.033245447476704916
step = 8, Training Accuracy: 0.4866666666666667
Training loss = 0.03367538770039876
step = 9, Training Accuracy: 0.4533333333333333
Training loss = 0.033206770022710164
step = 10, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.64125
Training loss = 0.0323066121339798
step = 11, Training Accuracy: 0.48333333333333334
Training loss = 0.03407327890396118
step = 12, Training Accuracy: 0.47333333333333333
Training loss = 0.032361706693967186
step = 13, Training Accuracy: 0.4866666666666667
Training loss = 0.032577170530955
step = 14, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.6375
params:  [0.23630663279018624, 0.6399352042922649, 0.99, 0.5996129079623771, 0.6929714397703955, 0.28852868289580164, 0.8756384067073473, 0.6536370478425136, 0.8377506866929846, 0.10992261756904209, 0.5073732471964677, 0.4309007836698575, 0.7139023555467039, 0.2219740577473395, 0.7123243610702076, 0.27827403064547185, 0.99, 0.30772359834210045, 0.01, 0.40559762780226183, 0.06360778867869354, 0.01, 0.3131279357485781, 0.511468819427459, 0.010686942583950088, 0.21179055527027824, 0.4565517414925606, 0.01, 0.17036029668653302, 0.4598631994003318, 0.8281074512574774, 0.01, 0.29246501452530166, 0.2500864563976557, 0.01, 0.5068363288988149, 0.379019308963359, 0.9242076560739378, 0.6401969262308721, 0.14660548363076437, 0.8355016054742187, 0.99, 0.01, 0.3499867348573047, 0.5414961504560272, 0.7346187953646938, 0.01, 0.5877343248052724, 0.7569500738943536, 0.7181794124920954, 0.5388225875969224, 0.8480500162542414, 0.4465265994805294, 0.20961865414850872, 0.01, 0.99, 0.726991467502681, 0.7582565345756223, 0.455613982647988, 0.14742187186095201, 0.48780707883985885, 0.6486210405254332, 0.12548414909490335, 0.6425924272580682, 0.33281006227488497, 0.99, 0.34655321065761735, 0.24241063573340269, 0.10847880750814957, 0.99, 0.3491318341397198, 0.3088523085422743, 0.6635640143159345, 0.99, 0.99, 0.01, 0.7954736229575323, 0.6867087179558276, 0.21938646225561764, 0.7954390352751398, 0.6694307310696097, 0.8964917950658174, 0.655467937066512, 0.14260807599589723, 0.7620820679037277, 0.17004051177640248, 0.25119528642689576, 0.6710078619898042, 0.113186836485577, 0.01, 0.26998689674614645, 0.16760442712173906]
[0.23630663279018624, 0.6399352042922649, 0.99, 0.5996129079623771, 0.6929714397703955, 0.28852868289580164, 0.8756384067073473, 0.6536370478425136, 0.8377506866929846, 0.10992261756904209, 0.5073732471964677, 0.4309007836698575, 0.7139023555467039, 0.2219740577473395, 0.7123243610702076, 0.27827403064547185, 0.99, 0.30772359834210045, 0.01, 0.40559762780226183, 0.06360778867869354, 0.01, 0.3131279357485781, 0.511468819427459, 0.010686942583950088, 0.21179055527027824, 0.4565517414925606, 0.01, 0.17036029668653302, 0.4598631994003318, 0.8281074512574774, 0.01, 0.29246501452530166, 0.2500864563976557, 0.01, 0.5068363288988149, 0.379019308963359, 0.9242076560739378, 0.6401969262308721, 0.14660548363076437, 0.8355016054742187, 0.99, 0.01, 0.3499867348573047, 0.5414961504560272, 0.7346187953646938, 0.01, 0.5877343248052724, 0.7569500738943536, 0.7181794124920954, 0.5388225875969224, 0.8480500162542414, 0.4465265994805294, 0.20961865414850872, 0.01, 0.99, 0.726991467502681, 0.7582565345756223, 0.455613982647988, 0.14742187186095201, 0.48780707883985885, 0.6486210405254332, 0.12548414909490335, 0.6425924272580682, 0.33281006227488497, 0.99, 0.34655321065761735, 0.24241063573340269, 0.10847880750814957, 0.99, 0.3491318341397198, 0.3088523085422743, 0.6635640143159345, 0.99, 0.99, 0.01, 0.7954736229575323, 0.6867087179558276, 0.21938646225561764, 0.7954390352751398, 0.6694307310696097, 0.8964917950658174, 0.655467937066512, 0.14260807599589723, 0.7620820679037277, 0.17004051177640248, 0.25119528642689576, 0.6710078619898042, 0.113186836485577, 0.01, 0.26998689674614645, 0.16760442712173906]
Training loss = 0.0350367538134257
step = 0, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.63125
Training loss = 0.03441599448521932
step = 1, Training Accuracy: 0.4533333333333333
Training loss = 0.034055350621541344
step = 2, Training Accuracy: 0.45666666666666667
Training loss = 0.033168863654136654
step = 3, Training Accuracy: 0.4866666666666667
Training loss = 0.03315565685431163
step = 4, Training Accuracy: 0.49666666666666665
Training loss = 0.03310033818085988
step = 5, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.65
Training loss = 0.03127768874168396
step = 6, Training Accuracy: 0.5633333333333334
Training loss = 0.03361624638239542
step = 7, Training Accuracy: 0.49666666666666665
Training loss = 0.03326879680156708
step = 8, Training Accuracy: 0.49666666666666665
Training loss = 0.03182569781939189
step = 9, Training Accuracy: 0.5333333333333333
Training loss = 0.03347847282886505
step = 10, Training Accuracy: 0.46
Validation Accuracy: 0.63375
Training loss = 0.03270128726959229
step = 11, Training Accuracy: 0.4866666666666667
Training loss = 0.0335664967695872
step = 12, Training Accuracy: 0.4866666666666667
Training loss = 0.032296762863794966
step = 13, Training Accuracy: 0.5166666666666667
Training loss = 0.03237119952837626
step = 14, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.64
params:  [0.157250618292286, 0.4564232228961924, 0.726157274585633, 0.6481048174574567, 0.5992577350304076, 0.2077844548002204, 0.5434037846711879, 0.8444795839755743, 0.37860660745404917, 0.3986331698197053, 0.5461543165027638, 0.0988954452571532, 0.08606894939585119, 0.39514105044637293, 0.3672947610053007, 0.17440632034941578, 0.25321525039503223, 0.01, 0.7809988327229773, 0.7640602194450188, 0.0522388375330056, 0.12650177514952424, 0.4612183960821971, 0.6953749139440492, 0.2785564882342824, 0.01, 0.4105890417410662, 0.18779842527726337, 0.6510920233918396, 0.17117710392913818, 0.99, 0.01, 0.5011585462058785, 0.677158461608932, 0.42627988473038275, 0.6692191431128297, 0.2716167176239319, 0.5708796321132967, 0.6684114091706285, 0.18218970648175786, 0.8109536341727899, 0.99, 0.01, 0.4953040745857752, 0.99, 0.9083873642190304, 0.32467550758219965, 0.8495057336925035, 0.8650188276016507, 0.7558194063634734, 0.9381920088582615, 0.8721776361741004, 0.7391634968193993, 0.3591541898437653, 0.15493862358350788, 0.99, 0.99, 0.99, 0.8218330137714525, 0.2163057809883313, 0.99, 0.9229957810506274, 0.6154492550738028, 0.99, 0.7190312686407063, 0.99, 0.4965489317450831, 0.2825146842428739, 0.01, 0.99, 0.3173344169164088, 0.12793965922134942, 0.43284975027034633, 0.9434365498521191, 0.9504365534536797, 0.07144382044892811, 0.6559216546952724, 0.3279966100403731, 0.4122567617280693, 0.8091640163083589, 0.6019920822032494, 0.9479591895478512, 0.4408767718740518, 0.15411202539092383, 0.010053890801441367, 0.30268219604187807, 0.6315939049993718, 0.5641079707987315, 0.3310191269688113, 0.01, 0.5665934515011889, 0.33502691782851535]
[0.157250618292286, 0.4564232228961924, 0.726157274585633, 0.6481048174574567, 0.5992577350304076, 0.2077844548002204, 0.5434037846711879, 0.8444795839755743, 0.37860660745404917, 0.3986331698197053, 0.5461543165027638, 0.0988954452571532, 0.08606894939585119, 0.39514105044637293, 0.3672947610053007, 0.17440632034941578, 0.25321525039503223, 0.01, 0.7809988327229773, 0.7640602194450188, 0.0522388375330056, 0.12650177514952424, 0.4612183960821971, 0.6953749139440492, 0.2785564882342824, 0.01, 0.4105890417410662, 0.18779842527726337, 0.6510920233918396, 0.17117710392913818, 0.99, 0.01, 0.5011585462058785, 0.677158461608932, 0.42627988473038275, 0.6692191431128297, 0.2716167176239319, 0.5708796321132967, 0.6684114091706285, 0.18218970648175786, 0.8109536341727899, 0.99, 0.01, 0.4953040745857752, 0.99, 0.9083873642190304, 0.32467550758219965, 0.8495057336925035, 0.8650188276016507, 0.7558194063634734, 0.9381920088582615, 0.8721776361741004, 0.7391634968193993, 0.3591541898437653, 0.15493862358350788, 0.99, 0.99, 0.99, 0.8218330137714525, 0.2163057809883313, 0.99, 0.9229957810506274, 0.6154492550738028, 0.99, 0.7190312686407063, 0.99, 0.4965489317450831, 0.2825146842428739, 0.01, 0.99, 0.3173344169164088, 0.12793965922134942, 0.43284975027034633, 0.9434365498521191, 0.9504365534536797, 0.07144382044892811, 0.6559216546952724, 0.3279966100403731, 0.4122567617280693, 0.8091640163083589, 0.6019920822032494, 0.9479591895478512, 0.4408767718740518, 0.15411202539092383, 0.010053890801441367, 0.30268219604187807, 0.6315939049993718, 0.5641079707987315, 0.3310191269688113, 0.01, 0.5665934515011889, 0.33502691782851535]
Training loss = 0.03463398655255635
step = 0, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.6575
Training loss = 0.033840797543525696
step = 1, Training Accuracy: 0.48
Training loss = 0.03337774435679118
step = 2, Training Accuracy: 0.5
Training loss = 0.03154993236064911
step = 3, Training Accuracy: 0.5266666666666666
Training loss = 0.03292457103729248
step = 4, Training Accuracy: 0.4866666666666667
Training loss = 0.03266592264175415
step = 5, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.635
Training loss = 0.03349790255228678
step = 6, Training Accuracy: 0.5
Training loss = 0.033399512767791746
step = 7, Training Accuracy: 0.5033333333333333
Training loss = 0.03344327211380005
step = 8, Training Accuracy: 0.4766666666666667
Training loss = 0.034992496172587075
step = 9, Training Accuracy: 0.47333333333333333
Training loss = 0.03263054450352987
step = 10, Training Accuracy: 0.48
Validation Accuracy: 0.625
Training loss = 0.03228221416473389
step = 11, Training Accuracy: 0.51
Training loss = 0.03353565911451976
step = 12, Training Accuracy: 0.45
Training loss = 0.03313987930615743
step = 13, Training Accuracy: 0.4633333333333333
Training loss = 0.03307372073332469
step = 14, Training Accuracy: 0.5
Validation Accuracy: 0.6275
params:  [0.01, 0.7612870294754595, 0.9511487583856222, 0.3961078819138325, 0.99, 0.3162690214270517, 0.99, 0.99, 0.3261997274916805, 0.01, 0.2196846969530195, 0.01, 0.5506728456712595, 0.047562179424242, 0.665516164763956, 0.04762149555098841, 0.5970301191681893, 0.15048672407541688, 0.13757760196543062, 0.658301011377866, 0.16773862661294953, 0.38930491632192465, 0.24126673966069537, 0.6325936804776976, 0.11520729300674414, 0.01, 0.20411571080939273, 0.01, 0.2964404379995947, 0.4628680089630245, 0.8578087350864136, 0.04816627915088004, 0.28211683266906035, 0.48080054919675813, 0.5117119904605651, 0.49317844410952616, 0.01, 0.872743211618912, 0.7446217335039348, 0.06594223757741197, 0.6698331569691106, 0.99, 0.08066504330575591, 0.20097033935729777, 0.7906824343961593, 0.9032666401202119, 0.016666150688168957, 0.8966617061995135, 0.9606884400842122, 0.9276468839595691, 0.6862886604144386, 0.8770669276804599, 0.04915433760320406, 0.33394641500574734, 0.39336630788618465, 0.88665192093711, 0.8137279483047364, 0.99, 0.42825022376171124, 0.1422960416414892, 0.7950438404662656, 0.9871806139593059, 0.6093164751018835, 0.99, 0.23854934981019993, 0.7892797861889529, 0.4589655258328609, 0.22086442698573042, 0.01, 0.878061596561333, 0.8147834493330575, 0.20825694499054076, 0.01, 0.3875399353800966, 0.8031109341399941, 0.01, 0.7808324223290553, 0.4486810033181772, 0.26032717953562856, 0.644701908296539, 0.99, 0.9566445791040868, 0.34178209394740644, 0.01, 0.01, 0.4967804735399486, 0.5608378530361489, 0.5647794924640742, 0.24217006757269727, 0.02621447021899395, 0.3770173121482435, 0.05437793839466684]
[0.01, 0.7612870294754595, 0.9511487583856222, 0.3961078819138325, 0.99, 0.3162690214270517, 0.99, 0.99, 0.3261997274916805, 0.01, 0.2196846969530195, 0.01, 0.5506728456712595, 0.047562179424242, 0.665516164763956, 0.04762149555098841, 0.5970301191681893, 0.15048672407541688, 0.13757760196543062, 0.658301011377866, 0.16773862661294953, 0.38930491632192465, 0.24126673966069537, 0.6325936804776976, 0.11520729300674414, 0.01, 0.20411571080939273, 0.01, 0.2964404379995947, 0.4628680089630245, 0.8578087350864136, 0.04816627915088004, 0.28211683266906035, 0.48080054919675813, 0.5117119904605651, 0.49317844410952616, 0.01, 0.872743211618912, 0.7446217335039348, 0.06594223757741197, 0.6698331569691106, 0.99, 0.08066504330575591, 0.20097033935729777, 0.7906824343961593, 0.9032666401202119, 0.016666150688168957, 0.8966617061995135, 0.9606884400842122, 0.9276468839595691, 0.6862886604144386, 0.8770669276804599, 0.04915433760320406, 0.33394641500574734, 0.39336630788618465, 0.88665192093711, 0.8137279483047364, 0.99, 0.42825022376171124, 0.1422960416414892, 0.7950438404662656, 0.9871806139593059, 0.6093164751018835, 0.99, 0.23854934981019993, 0.7892797861889529, 0.4589655258328609, 0.22086442698573042, 0.01, 0.878061596561333, 0.8147834493330575, 0.20825694499054076, 0.01, 0.3875399353800966, 0.8031109341399941, 0.01, 0.7808324223290553, 0.4486810033181772, 0.26032717953562856, 0.644701908296539, 0.99, 0.9566445791040868, 0.34178209394740644, 0.01, 0.01, 0.4967804735399486, 0.5608378530361489, 0.5647794924640742, 0.24217006757269727, 0.02621447021899395, 0.3770173121482435, 0.05437793839466684]
Training loss = 0.033490368326505024
step = 0, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.63625
Training loss = 0.03202101091543833
step = 1, Training Accuracy: 0.5033333333333333
Training loss = 0.03229831457138062
step = 2, Training Accuracy: 0.5266666666666666
Training loss = 0.03225214898586273
step = 3, Training Accuracy: 0.4766666666666667
Training loss = 0.03282005548477173
step = 4, Training Accuracy: 0.5133333333333333
Training loss = 0.03203513026237488
step = 5, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.6375
Training loss = 0.03276011129220327
step = 6, Training Accuracy: 0.49333333333333335
Training loss = 0.033507005373636885
step = 7, Training Accuracy: 0.5066666666666667
Training loss = 0.0314967405796051
step = 8, Training Accuracy: 0.54
Training loss = 0.03129475792249044
step = 9, Training Accuracy: 0.5466666666666666
Training loss = 0.03107847770055135
step = 10, Training Accuracy: 0.54
Validation Accuracy: 0.62375
Training loss = 0.03178519546985626
step = 11, Training Accuracy: 0.5266666666666666
Training loss = 0.03316138029098511
step = 12, Training Accuracy: 0.47
Training loss = 0.03179206411043803
step = 13, Training Accuracy: 0.5466666666666666
Training loss = 0.03133757690588633
step = 14, Training Accuracy: 0.5233333333333333
Validation Accuracy: 0.64
params:  [0.14928467930506864, 0.6421640902107338, 0.8280800700072632, 0.3799084905720522, 0.9274092698320215, 0.1772018741717869, 0.8974049783586641, 0.9019190510965099, 0.2950335050654572, 0.01, 0.5402476528904829, 0.20538135123706006, 0.24282040296003002, 0.01, 0.3519773159614229, 0.01, 0.39643776958725435, 0.16668079450778117, 0.7473573910566187, 0.3835898318966646, 0.01, 0.015692459856153862, 0.13216232913648426, 0.7356376246335592, 0.3735360073666719, 0.01, 0.5472589166162254, 0.4021963725325174, 0.5002583537126255, 0.4768670112554304, 0.6412257196549462, 0.011049134935063834, 0.03425077846417485, 0.6030640228639779, 0.7885266056079128, 0.4322646036906631, 0.6427197435832062, 0.99, 0.7238325546559314, 0.01, 0.777803912312247, 0.9374551550378062, 0.15531552528736087, 0.037032713035246495, 0.6616139694261415, 0.7992302121701558, 0.23186956590331623, 0.4249189626007018, 0.6633301208063451, 0.8118508499319256, 0.747847578484115, 0.8261344211823138, 0.0690130194963278, 0.08751200129250755, 0.273829323172459, 0.7764930814359247, 0.9162709685742477, 0.6827373967577545, 0.17740857097989293, 0.3240108656963311, 0.717774225213751, 0.83054594369925, 0.4486905256145067, 0.99, 0.4092904120754547, 0.7789170389376434, 0.7067866926608609, 0.6048726480435722, 0.01, 0.9588704520341167, 0.5982316643557786, 0.1106985699175266, 0.46366151442343745, 0.6430519597643377, 0.99, 0.01, 0.6843893388119956, 0.99, 0.04973824834021412, 0.5045122345114093, 0.313854327805583, 0.99, 0.3597499889357628, 0.2629285391401791, 0.20653688817811894, 0.25931924397403006, 0.2764484165939838, 0.47607003508451984, 0.23852934314125307, 0.25276051106813957, 0.33603629494126075, 0.01]
[0.14928467930506864, 0.6421640902107338, 0.8280800700072632, 0.3799084905720522, 0.9274092698320215, 0.1772018741717869, 0.8974049783586641, 0.9019190510965099, 0.2950335050654572, 0.01, 0.5402476528904829, 0.20538135123706006, 0.24282040296003002, 0.01, 0.3519773159614229, 0.01, 0.39643776958725435, 0.16668079450778117, 0.7473573910566187, 0.3835898318966646, 0.01, 0.015692459856153862, 0.13216232913648426, 0.7356376246335592, 0.3735360073666719, 0.01, 0.5472589166162254, 0.4021963725325174, 0.5002583537126255, 0.4768670112554304, 0.6412257196549462, 0.011049134935063834, 0.03425077846417485, 0.6030640228639779, 0.7885266056079128, 0.4322646036906631, 0.6427197435832062, 0.99, 0.7238325546559314, 0.01, 0.777803912312247, 0.9374551550378062, 0.15531552528736087, 0.037032713035246495, 0.6616139694261415, 0.7992302121701558, 0.23186956590331623, 0.4249189626007018, 0.6633301208063451, 0.8118508499319256, 0.747847578484115, 0.8261344211823138, 0.0690130194963278, 0.08751200129250755, 0.273829323172459, 0.7764930814359247, 0.9162709685742477, 0.6827373967577545, 0.17740857097989293, 0.3240108656963311, 0.717774225213751, 0.83054594369925, 0.4486905256145067, 0.99, 0.4092904120754547, 0.7789170389376434, 0.7067866926608609, 0.6048726480435722, 0.01, 0.9588704520341167, 0.5982316643557786, 0.1106985699175266, 0.46366151442343745, 0.6430519597643377, 0.99, 0.01, 0.6843893388119956, 0.99, 0.04973824834021412, 0.5045122345114093, 0.313854327805583, 0.99, 0.3597499889357628, 0.2629285391401791, 0.20653688817811894, 0.25931924397403006, 0.2764484165939838, 0.47607003508451984, 0.23852934314125307, 0.25276051106813957, 0.33603629494126075, 0.01]
Training loss = 0.0344069375594457
step = 0, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.64375
Training loss = 0.036229327122370404
step = 1, Training Accuracy: 0.38
Training loss = 0.0344982906182607
step = 2, Training Accuracy: 0.44333333333333336
Training loss = 0.033418160676956174
step = 3, Training Accuracy: 0.48333333333333334
Training loss = 0.03459469735622406
step = 4, Training Accuracy: 0.4533333333333333
Training loss = 0.035096839865048725
step = 5, Training Accuracy: 0.38
Validation Accuracy: 0.645
Training loss = 0.03401324013868968
step = 6, Training Accuracy: 0.47333333333333333
Training loss = 0.035216605265935265
step = 7, Training Accuracy: 0.44666666666666666
Training loss = 0.03481424689292908
step = 8, Training Accuracy: 0.48
Training loss = 0.036580597956975304
step = 9, Training Accuracy: 0.44666666666666666
Training loss = 0.03484139720598856
step = 10, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.645
Training loss = 0.03468133668104807
step = 11, Training Accuracy: 0.44333333333333336
Training loss = 0.03505565981070201
step = 12, Training Accuracy: 0.47
Training loss = 0.03406950314839681
step = 13, Training Accuracy: 0.46
Training loss = 0.034701837102572124
step = 14, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.63125
params:  [0.27951100167840626, 0.6776107538880705, 0.99, 0.2132719280509564, 0.5937593522280138, 0.03206797958876495, 0.29260379591112373, 0.6656619334474188, 0.7825390221194102, 0.01, 0.08523971082044263, 0.5280110313063784, 0.19804753997699057, 0.25394861351100545, 0.45184861912981833, 0.14640718537944894, 0.519976049278647, 0.3141577403754612, 0.19719706110480673, 0.6545381429952889, 0.01, 0.281295979866991, 0.011387227409736217, 0.4490019136702577, 0.18573654790028823, 0.01, 0.1306736813512977, 0.2603273529279073, 0.1954311703188339, 0.23633947846729725, 0.6090662569164297, 0.01, 0.824507037636137, 0.7464284137225354, 0.565504593567444, 0.5798351807998203, 0.22644104450792296, 0.99, 0.99, 0.3874947128223375, 0.6181108181824597, 0.8618836394502003, 0.01, 0.28476294312922745, 0.6994281147705086, 0.99, 0.01, 0.5606546756412454, 0.6608699310867174, 0.543084538064817, 0.99, 0.761273461223236, 0.01, 0.10733221460946046, 0.15612874807131621, 0.6835363167551545, 0.9634798784811675, 0.8147903872138276, 0.8156897282648943, 0.18597655801401902, 0.5513627361019079, 0.8986253157526721, 0.35869199152491615, 0.8153488233153416, 0.7590849567299988, 0.8485157734708932, 0.99, 0.18858778402526766, 0.2816447901871158, 0.49856598735601354, 0.06743705315750076, 0.34814850139250736, 0.7037256337257815, 0.6516882013729665, 0.7838407916440899, 0.2020088590098067, 0.6797552287303723, 0.9405484068132605, 0.30304426337729473, 0.7651462796856142, 0.5725293888859833, 0.8128368532772762, 0.4049023316932447, 0.03814398352834669, 0.23615504750007865, 0.5470418589704702, 0.15330374834971125, 0.27154038508160466, 0.01, 0.01, 0.46595340087132525, 0.01]
[0.27951100167840626, 0.6776107538880705, 0.99, 0.2132719280509564, 0.5937593522280138, 0.03206797958876495, 0.29260379591112373, 0.6656619334474188, 0.7825390221194102, 0.01, 0.08523971082044263, 0.5280110313063784, 0.19804753997699057, 0.25394861351100545, 0.45184861912981833, 0.14640718537944894, 0.519976049278647, 0.3141577403754612, 0.19719706110480673, 0.6545381429952889, 0.01, 0.281295979866991, 0.011387227409736217, 0.4490019136702577, 0.18573654790028823, 0.01, 0.1306736813512977, 0.2603273529279073, 0.1954311703188339, 0.23633947846729725, 0.6090662569164297, 0.01, 0.824507037636137, 0.7464284137225354, 0.565504593567444, 0.5798351807998203, 0.22644104450792296, 0.99, 0.99, 0.3874947128223375, 0.6181108181824597, 0.8618836394502003, 0.01, 0.28476294312922745, 0.6994281147705086, 0.99, 0.01, 0.5606546756412454, 0.6608699310867174, 0.543084538064817, 0.99, 0.761273461223236, 0.01, 0.10733221460946046, 0.15612874807131621, 0.6835363167551545, 0.9634798784811675, 0.8147903872138276, 0.8156897282648943, 0.18597655801401902, 0.5513627361019079, 0.8986253157526721, 0.35869199152491615, 0.8153488233153416, 0.7590849567299988, 0.8485157734708932, 0.99, 0.18858778402526766, 0.2816447901871158, 0.49856598735601354, 0.06743705315750076, 0.34814850139250736, 0.7037256337257815, 0.6516882013729665, 0.7838407916440899, 0.2020088590098067, 0.6797552287303723, 0.9405484068132605, 0.30304426337729473, 0.7651462796856142, 0.5725293888859833, 0.8128368532772762, 0.4049023316932447, 0.03814398352834669, 0.23615504750007865, 0.5470418589704702, 0.15330374834971125, 0.27154038508160466, 0.01, 0.01, 0.46595340087132525, 0.01]
Training loss = 0.03435034394264221
step = 0, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.6375
Training loss = 0.03265277067820231
step = 1, Training Accuracy: 0.5133333333333333
Training loss = 0.03434013485908508
step = 2, Training Accuracy: 0.46
Training loss = 0.034170457124710084
step = 3, Training Accuracy: 0.4533333333333333
Training loss = 0.0351513155301412
step = 4, Training Accuracy: 0.46
Training loss = 0.033927756349245705
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.64625
Training loss = 0.03406523505846659
step = 6, Training Accuracy: 0.46
Training loss = 0.03340060532093048
step = 7, Training Accuracy: 0.5033333333333333
Training loss = 0.033190640409787496
step = 8, Training Accuracy: 0.5166666666666667
Training loss = 0.03238742093245189
step = 9, Training Accuracy: 0.49666666666666665
Training loss = 0.03376511832078298
step = 10, Training Accuracy: 0.47333333333333333
Validation Accuracy: 0.64625
Training loss = 0.03403444091478983
step = 11, Training Accuracy: 0.44666666666666666
Training loss = 0.03339164614677429
step = 12, Training Accuracy: 0.4666666666666667
Training loss = 0.032607195178667704
step = 13, Training Accuracy: 0.46
Training loss = 0.033135062654813134
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.64875
14 	8     	0.636719	0.00667134	0.6275 	0.64875
params:  [0.2911806798522911, 0.4456108122895299, 0.99, 0.1849405201256499, 0.6139129612449603, 0.2655862613681884, 0.47337387617714477, 0.6220593613339767, 0.4798173740219521, 0.38001170279289326, 0.34431742321377357, 0.24546704957806903, 0.8325333361374553, 0.20387829598175164, 0.8672618151379776, 0.28116119701185577, 0.49787856846901224, 0.01, 0.13522055108854855, 0.7370544379933571, 0.01, 0.35320062606882374, 0.3337198673066958, 0.4921705452893146, 0.21947364371904282, 0.14383193223907795, 0.9173935551083261, 0.06286739637211465, 0.41787147438588595, 0.5167086278102926, 0.7871463043555003, 0.06557587737405982, 0.05371419289261359, 0.3597936058355147, 0.6910310910987641, 0.5030564600708761, 0.3943632018455082, 0.99, 0.99, 0.43885943434592095, 0.44106104860306194, 0.99, 0.06272148696377028, 0.16919710385719539, 0.5875938095324922, 0.7918909800996928, 0.07699686239516376, 0.6572283337580191, 0.7421615144740409, 0.9424995411794446, 0.99, 0.6309836460546618, 0.01, 0.01, 0.01, 0.5104868349824225, 0.99, 0.7364059945421753, 0.7083489620294771, 0.25253150717963285, 0.9626102779417309, 0.6894698060939048, 0.2880711888445591, 0.8515561046434273, 0.43654231904404506, 0.6423028562174926, 0.7977543951865287, 0.01, 0.0226330547222105, 0.24296331621914258, 0.4583796998453276, 0.35304627608858513, 0.5428479420479637, 0.5852270888406672, 0.7345245059725839, 0.523481099511605, 0.99, 0.6194015161485529, 0.15588674223086252, 0.745451451143195, 0.5894228456011316, 0.8690995469245949, 0.5017023675708026, 0.01, 0.05361393040111445, 0.7676542591921414, 0.01, 0.5860938384428406, 0.3060706415157342, 0.01, 0.7830046067730723, 0.01]
[0.2911806798522911, 0.4456108122895299, 0.99, 0.1849405201256499, 0.6139129612449603, 0.2655862613681884, 0.47337387617714477, 0.6220593613339767, 0.4798173740219521, 0.38001170279289326, 0.34431742321377357, 0.24546704957806903, 0.8325333361374553, 0.20387829598175164, 0.8672618151379776, 0.28116119701185577, 0.49787856846901224, 0.01, 0.13522055108854855, 0.7370544379933571, 0.01, 0.35320062606882374, 0.3337198673066958, 0.4921705452893146, 0.21947364371904282, 0.14383193223907795, 0.9173935551083261, 0.06286739637211465, 0.41787147438588595, 0.5167086278102926, 0.7871463043555003, 0.06557587737405982, 0.05371419289261359, 0.3597936058355147, 0.6910310910987641, 0.5030564600708761, 0.3943632018455082, 0.99, 0.99, 0.43885943434592095, 0.44106104860306194, 0.99, 0.06272148696377028, 0.16919710385719539, 0.5875938095324922, 0.7918909800996928, 0.07699686239516376, 0.6572283337580191, 0.7421615144740409, 0.9424995411794446, 0.99, 0.6309836460546618, 0.01, 0.01, 0.01, 0.5104868349824225, 0.99, 0.7364059945421753, 0.7083489620294771, 0.25253150717963285, 0.9626102779417309, 0.6894698060939048, 0.2880711888445591, 0.8515561046434273, 0.43654231904404506, 0.6423028562174926, 0.7977543951865287, 0.01, 0.0226330547222105, 0.24296331621914258, 0.4583796998453276, 0.35304627608858513, 0.5428479420479637, 0.5852270888406672, 0.7345245059725839, 0.523481099511605, 0.99, 0.6194015161485529, 0.15588674223086252, 0.745451451143195, 0.5894228456011316, 0.8690995469245949, 0.5017023675708026, 0.01, 0.05361393040111445, 0.7676542591921414, 0.01, 0.5860938384428406, 0.3060706415157342, 0.01, 0.7830046067730723, 0.01]
Training loss = 0.035989003578821815
step = 0, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.6525
Training loss = 0.034897520542144775
step = 1, Training Accuracy: 0.44666666666666666
Training loss = 0.03524218142032623
step = 2, Training Accuracy: 0.42
Training loss = 0.03465294539928436
step = 3, Training Accuracy: 0.3933333333333333
Training loss = 0.03416114588578542
step = 4, Training Accuracy: 0.49
Training loss = 0.03582862854003906
step = 5, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.63625
Training loss = 0.0355212277173996
step = 6, Training Accuracy: 0.4033333333333333
Training loss = 0.03446629047393799
step = 7, Training Accuracy: 0.41333333333333333
Training loss = 0.03512165625890096
step = 8, Training Accuracy: 0.4266666666666667
Training loss = 0.03507004797458649
step = 9, Training Accuracy: 0.41333333333333333
Training loss = 0.035326766769091286
step = 10, Training Accuracy: 0.42333333333333334
Validation Accuracy: 0.62875
Training loss = 0.036483416557312014
step = 11, Training Accuracy: 0.36
Training loss = 0.03511476874351502
step = 12, Training Accuracy: 0.4033333333333333
Training loss = 0.03454758683840434
step = 13, Training Accuracy: 0.4
Training loss = 0.03488616387049357
step = 14, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.63375
params:  [0.01, 0.43541355995449216, 0.7642967030598475, 0.15952333672647467, 0.6175220113674827, 0.01, 0.2901464932024042, 0.9461092244743788, 0.7392830279954735, 0.3117989068999967, 0.19678412904917533, 0.7781865452937189, 0.40141270410537605, 0.2566304174774437, 0.40938459742034783, 0.3322947122489768, 0.7779450515751738, 0.31634189539613855, 0.01, 0.6255943831388447, 0.22769216844678247, 0.34337669927316683, 0.08895139093157517, 0.8061578120233326, 0.024155269288183345, 0.01, 0.4448032095230107, 0.3204641407024943, 0.3143467284240502, 0.21976513729006575, 0.6928242200823329, 0.3996549193407174, 0.5551542366759822, 0.46828642752452576, 0.20102137675388324, 0.6963434059672857, 0.24678440530157453, 0.9789916829315739, 0.7371898852457524, 0.2584604563780216, 0.5110632527787576, 0.7639850544780966, 0.01, 0.02442436605970419, 0.49120492066253807, 0.9435797269468756, 0.13745866737832854, 0.8042186183748627, 0.5234285885165816, 0.6461379805869158, 0.7436584988056365, 0.6099278137075025, 0.27677184543039457, 0.3378406344938406, 0.01, 0.7058153877255184, 0.8288075747107189, 0.8715629427651275, 0.5821530595027675, 0.01, 0.6232356113384784, 0.99, 0.5529747438913302, 0.8150638236162475, 0.365103853017967, 0.9552963519627636, 0.7808012707259679, 0.01, 0.01, 0.9202678313877635, 0.4530280067123419, 0.1871062517312439, 0.5661985310324275, 0.5249523016625808, 0.9271739767136485, 0.19083796120328397, 0.7447594197830264, 0.8594114967127332, 0.0820998469382089, 0.7353292426541636, 0.3589988042628357, 0.99, 0.3835815070469896, 0.45328957663413116, 0.01, 0.210347894799106, 0.160852230722277, 0.43016591095825996, 0.08388687451956323, 0.01, 0.28175640360552057, 0.04347029256239281]
[0.01, 0.43541355995449216, 0.7642967030598475, 0.15952333672647467, 0.6175220113674827, 0.01, 0.2901464932024042, 0.9461092244743788, 0.7392830279954735, 0.3117989068999967, 0.19678412904917533, 0.7781865452937189, 0.40141270410537605, 0.2566304174774437, 0.40938459742034783, 0.3322947122489768, 0.7779450515751738, 0.31634189539613855, 0.01, 0.6255943831388447, 0.22769216844678247, 0.34337669927316683, 0.08895139093157517, 0.8061578120233326, 0.024155269288183345, 0.01, 0.4448032095230107, 0.3204641407024943, 0.3143467284240502, 0.21976513729006575, 0.6928242200823329, 0.3996549193407174, 0.5551542366759822, 0.46828642752452576, 0.20102137675388324, 0.6963434059672857, 0.24678440530157453, 0.9789916829315739, 0.7371898852457524, 0.2584604563780216, 0.5110632527787576, 0.7639850544780966, 0.01, 0.02442436605970419, 0.49120492066253807, 0.9435797269468756, 0.13745866737832854, 0.8042186183748627, 0.5234285885165816, 0.6461379805869158, 0.7436584988056365, 0.6099278137075025, 0.27677184543039457, 0.3378406344938406, 0.01, 0.7058153877255184, 0.8288075747107189, 0.8715629427651275, 0.5821530595027675, 0.01, 0.6232356113384784, 0.99, 0.5529747438913302, 0.8150638236162475, 0.365103853017967, 0.9552963519627636, 0.7808012707259679, 0.01, 0.01, 0.9202678313877635, 0.4530280067123419, 0.1871062517312439, 0.5661985310324275, 0.5249523016625808, 0.9271739767136485, 0.19083796120328397, 0.7447594197830264, 0.8594114967127332, 0.0820998469382089, 0.7353292426541636, 0.3589988042628357, 0.99, 0.3835815070469896, 0.45328957663413116, 0.01, 0.210347894799106, 0.160852230722277, 0.43016591095825996, 0.08388687451956323, 0.01, 0.28175640360552057, 0.04347029256239281]
Training loss = 0.03400792539119721
step = 0, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.6325
Training loss = 0.03264660060405731
step = 1, Training Accuracy: 0.52
Training loss = 0.03250629425048828
step = 2, Training Accuracy: 0.5
Training loss = 0.031741435130437215
step = 3, Training Accuracy: 0.53
Training loss = 0.03325344642003377
step = 4, Training Accuracy: 0.5366666666666666
Training loss = 0.03373591621716817
step = 5, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.6325
Training loss = 0.03367404043674469
step = 6, Training Accuracy: 0.49
Training loss = 0.031987087925275166
step = 7, Training Accuracy: 0.5033333333333333
Training loss = 0.034424970944722494
step = 8, Training Accuracy: 0.44666666666666666
Training loss = 0.03242049773534139
step = 9, Training Accuracy: 0.48
Training loss = 0.033128357728322344
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.64
Training loss = 0.03376928448677063
step = 11, Training Accuracy: 0.4866666666666667
Training loss = 0.032687987287839254
step = 12, Training Accuracy: 0.48333333333333334
Training loss = 0.03329778532187144
step = 13, Training Accuracy: 0.47333333333333333
Training loss = 0.03354007542133331
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.6375
params:  [0.01, 0.7359791300525265, 0.99, 0.25609889573071787, 0.614925480053649, 0.3168998986796403, 0.34416766939351107, 0.6139542290360631, 0.8676435703736413, 0.15426205108533234, 0.519348845878287, 0.6518962012927625, 0.4123037974499598, 0.3025391505077014, 0.346906720684113, 0.44892109211449277, 0.7740190259132973, 0.3559634022313818, 0.01, 0.5075210660777919, 0.09233011223550708, 0.24093668346074676, 0.14798619124685342, 0.45529332887989427, 0.10118732952962498, 0.01, 0.3196892308050332, 0.3950007436747145, 0.01, 0.4404173553695907, 0.6811226103223441, 0.4632822884309123, 0.2890357383797171, 0.6311314851682424, 0.12271312804090656, 0.4331562120006777, 0.4193349713008808, 0.99, 0.99, 0.32882039654847106, 0.37833278431369477, 0.7078114027328737, 0.15852791421480897, 0.21370784011462743, 0.99, 0.5869706341468099, 0.01, 0.5854651539838682, 0.572581813830671, 0.5797519850720602, 0.7379096091934569, 0.43473910426442997, 0.5018402693570684, 0.27794660062533194, 0.03138545669319745, 0.8546444201127342, 0.7028552515330229, 0.5498542096359011, 0.7777788712740541, 0.01, 0.24311567051271743, 0.6426173813226705, 0.48756793964977924, 0.8739573622627126, 0.6058837910416408, 0.6571459937320459, 0.99, 0.058419119343336615, 0.01, 0.512730899826403, 0.4178562933081097, 0.01, 0.399191916569525, 0.603452177153435, 0.9513466340099103, 0.10207843575818829, 0.47800820999150784, 0.46988063266375685, 0.07960401698667441, 0.9756511676235228, 0.99, 0.9812640746348241, 0.15087450408503972, 0.3853759171134393, 0.45590396072016565, 0.04400766177343829, 0.047549167066938444, 0.46513083163508057, 0.3304570872604969, 0.01, 0.466170481790546, 0.17810133482530208]
[0.01, 0.7359791300525265, 0.99, 0.25609889573071787, 0.614925480053649, 0.3168998986796403, 0.34416766939351107, 0.6139542290360631, 0.8676435703736413, 0.15426205108533234, 0.519348845878287, 0.6518962012927625, 0.4123037974499598, 0.3025391505077014, 0.346906720684113, 0.44892109211449277, 0.7740190259132973, 0.3559634022313818, 0.01, 0.5075210660777919, 0.09233011223550708, 0.24093668346074676, 0.14798619124685342, 0.45529332887989427, 0.10118732952962498, 0.01, 0.3196892308050332, 0.3950007436747145, 0.01, 0.4404173553695907, 0.6811226103223441, 0.4632822884309123, 0.2890357383797171, 0.6311314851682424, 0.12271312804090656, 0.4331562120006777, 0.4193349713008808, 0.99, 0.99, 0.32882039654847106, 0.37833278431369477, 0.7078114027328737, 0.15852791421480897, 0.21370784011462743, 0.99, 0.5869706341468099, 0.01, 0.5854651539838682, 0.572581813830671, 0.5797519850720602, 0.7379096091934569, 0.43473910426442997, 0.5018402693570684, 0.27794660062533194, 0.03138545669319745, 0.8546444201127342, 0.7028552515330229, 0.5498542096359011, 0.7777788712740541, 0.01, 0.24311567051271743, 0.6426173813226705, 0.48756793964977924, 0.8739573622627126, 0.6058837910416408, 0.6571459937320459, 0.99, 0.058419119343336615, 0.01, 0.512730899826403, 0.4178562933081097, 0.01, 0.399191916569525, 0.603452177153435, 0.9513466340099103, 0.10207843575818829, 0.47800820999150784, 0.46988063266375685, 0.07960401698667441, 0.9756511676235228, 0.99, 0.9812640746348241, 0.15087450408503972, 0.3853759171134393, 0.45590396072016565, 0.04400766177343829, 0.047549167066938444, 0.46513083163508057, 0.3304570872604969, 0.01, 0.466170481790546, 0.17810133482530208]
Training loss = 0.0327016544342041
step = 0, Training Accuracy: 0.5
Validation Accuracy: 0.64375
Training loss = 0.03400073250134786
step = 1, Training Accuracy: 0.44
Training loss = 0.0332395335038503
step = 2, Training Accuracy: 0.52
Training loss = 0.03305530548095703
step = 3, Training Accuracy: 0.4666666666666667
Training loss = 0.0334006134668986
step = 4, Training Accuracy: 0.4766666666666667
Training loss = 0.03401465634504954
step = 5, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.63
Training loss = 0.03420725782712301
step = 6, Training Accuracy: 0.4633333333333333
Training loss = 0.03387109935283661
step = 7, Training Accuracy: 0.48333333333333334
Training loss = 0.033873154322306316
step = 8, Training Accuracy: 0.44333333333333336
Training loss = 0.03350882311662038
step = 9, Training Accuracy: 0.48333333333333334
Training loss = 0.03348866879940033
step = 10, Training Accuracy: 0.45666666666666667
Validation Accuracy: 0.62875
Training loss = 0.032591516574223836
step = 11, Training Accuracy: 0.5133333333333333
Training loss = 0.03315860092639923
step = 12, Training Accuracy: 0.5
Training loss = 0.03356471061706543
step = 13, Training Accuracy: 0.4666666666666667
Training loss = 0.03362853229045868
step = 14, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.63875
params:  [0.2644187358880342, 0.7958339303431321, 0.99, 0.35610716381860136, 0.6393936861976751, 0.2781830206667192, 0.13485838063176014, 0.4856324988175096, 0.7635622083423371, 0.31969118076951797, 0.44783927532354495, 0.5311128399086951, 0.25971005274590553, 0.01, 0.6737985469345149, 0.3131567087955645, 0.856283451905578, 0.4873357312667249, 0.01, 0.757909969933249, 0.557987595918234, 0.14438052294935855, 0.42789688557174066, 0.6110116850061738, 0.07117029791810854, 0.323934018092876, 0.17854217479936452, 0.2549823866714105, 0.3145465004033249, 0.418447076174241, 0.8456596097738802, 0.28734568352533346, 0.8099775601081557, 0.5917513423253484, 0.3894316220305616, 0.7590729478447726, 0.01, 0.99, 0.99, 0.53537905793885, 0.45489411099772714, 0.7675015172115973, 0.01, 0.21004326689053426, 0.7241542449334059, 0.7757704832414736, 0.01, 0.8901011741666501, 0.99, 0.8281656368777861, 0.99, 0.4350234562391624, 0.01, 0.01, 0.48094643195005693, 0.7171593449181181, 0.7425744439107413, 0.99, 0.8273309680818217, 0.11940639057928362, 0.4141126550121724, 0.589539298624016, 0.3118690508727687, 0.99, 0.3600287897989035, 0.6126003962804657, 0.5317668136407123, 0.5559111309568379, 0.2728357831501103, 0.6023249351055543, 0.33095325107365753, 0.01, 0.5044452179569878, 0.4383131030332853, 0.6372871841664159, 0.01, 0.6161320105939176, 0.7096348090739547, 0.29809562754026075, 0.818252679435172, 0.45232142857849034, 0.99, 0.8507299691065886, 0.44996447264251765, 0.22075188875094123, 0.2593714683815339, 0.33325864130267013, 0.7413576370690872, 0.01, 0.016688869881343153, 0.6342143070221145, 0.01]
[0.2644187358880342, 0.7958339303431321, 0.99, 0.35610716381860136, 0.6393936861976751, 0.2781830206667192, 0.13485838063176014, 0.4856324988175096, 0.7635622083423371, 0.31969118076951797, 0.44783927532354495, 0.5311128399086951, 0.25971005274590553, 0.01, 0.6737985469345149, 0.3131567087955645, 0.856283451905578, 0.4873357312667249, 0.01, 0.757909969933249, 0.557987595918234, 0.14438052294935855, 0.42789688557174066, 0.6110116850061738, 0.07117029791810854, 0.323934018092876, 0.17854217479936452, 0.2549823866714105, 0.3145465004033249, 0.418447076174241, 0.8456596097738802, 0.28734568352533346, 0.8099775601081557, 0.5917513423253484, 0.3894316220305616, 0.7590729478447726, 0.01, 0.99, 0.99, 0.53537905793885, 0.45489411099772714, 0.7675015172115973, 0.01, 0.21004326689053426, 0.7241542449334059, 0.7757704832414736, 0.01, 0.8901011741666501, 0.99, 0.8281656368777861, 0.99, 0.4350234562391624, 0.01, 0.01, 0.48094643195005693, 0.7171593449181181, 0.7425744439107413, 0.99, 0.8273309680818217, 0.11940639057928362, 0.4141126550121724, 0.589539298624016, 0.3118690508727687, 0.99, 0.3600287897989035, 0.6126003962804657, 0.5317668136407123, 0.5559111309568379, 0.2728357831501103, 0.6023249351055543, 0.33095325107365753, 0.01, 0.5044452179569878, 0.4383131030332853, 0.6372871841664159, 0.01, 0.6161320105939176, 0.7096348090739547, 0.29809562754026075, 0.818252679435172, 0.45232142857849034, 0.99, 0.8507299691065886, 0.44996447264251765, 0.22075188875094123, 0.2593714683815339, 0.33325864130267013, 0.7413576370690872, 0.01, 0.016688869881343153, 0.6342143070221145, 0.01]
Training loss = 0.032603599429130554
step = 0, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.61875
Training loss = 0.03287679811318715
step = 1, Training Accuracy: 0.47
Training loss = 0.03414217472076416
step = 2, Training Accuracy: 0.45666666666666667
Training loss = 0.03286695082982381
step = 3, Training Accuracy: 0.4766666666666667
Training loss = 0.03268553594748179
step = 4, Training Accuracy: 0.5133333333333333
Training loss = 0.033813902735710145
step = 5, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.625
Training loss = 0.033351693550745645
step = 6, Training Accuracy: 0.52
Training loss = 0.03283744613329569
step = 7, Training Accuracy: 0.5333333333333333
Training loss = 0.03377992709477742
step = 8, Training Accuracy: 0.5066666666666667
Training loss = 0.03358729561169942
step = 9, Training Accuracy: 0.48
Training loss = 0.032659919261932374
step = 10, Training Accuracy: 0.54
Validation Accuracy: 0.6425
Training loss = 0.03253019491831462
step = 11, Training Accuracy: 0.5166666666666667
Training loss = 0.031122670372327167
step = 12, Training Accuracy: 0.5333333333333333
Training loss = 0.03399514436721802
step = 13, Training Accuracy: 0.49666666666666665
Training loss = 0.03336090008417765
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.63375
params:  [0.5723961908057604, 0.5965602239778802, 0.9620506989452188, 0.5336064013900339, 0.37332167661340987, 0.027239861180942987, 0.3173991249070941, 0.6988213555670276, 0.8631466784280535, 0.01, 0.4807422166526695, 0.40918498511952117, 0.023292010380762673, 0.10816059386530699, 0.4187445328326803, 0.013079814293949027, 0.18473212194830807, 0.17752346455169649, 0.2943413471115788, 0.6645214735411528, 0.614822254290585, 0.281992068072275, 0.11804569165850194, 0.42557876458990107, 0.08543168630380601, 0.01, 0.32958045516744683, 0.2316370850884415, 0.11819489286077611, 0.36333805275522657, 0.6690153054889751, 0.44485981737676206, 0.7765799607411763, 0.29214680920281105, 0.41570129120205124, 0.5404820539023621, 0.08715441485081743, 0.9401330694017983, 0.35212984864789326, 0.7083719958485141, 0.5860426248260355, 0.99, 0.01, 0.0866759511830538, 0.779735928586841, 0.5729236305367638, 0.01, 0.6828474050181643, 0.99, 0.48280438364401296, 0.99, 0.9083551292208674, 0.1859119715030756, 0.01, 0.2999928627394598, 0.6830137577301065, 0.8603831869689523, 0.3919848568139435, 0.9432663158072334, 0.6837568087132608, 0.5663941280115328, 0.5507454566765774, 0.5417213518512038, 0.99, 0.6224306644353899, 0.99, 0.9634052287787375, 0.3005347423171385, 0.2777948416207737, 0.5592368543553776, 0.401981622138135, 0.4371622443538165, 0.6773557359798332, 0.41373235359576915, 0.9003661450540118, 0.19087116707731638, 0.99, 0.5871292384936275, 0.2132437963663174, 0.99, 0.5509208202554672, 0.748987899947805, 0.4809791451404992, 0.09532239305440862, 0.5169425161011928, 0.3938754494044445, 0.2469966456971044, 0.489727884873389, 0.26509318541272825, 0.5189051994178753, 0.5695946385691113, 0.16673317182606068]
[0.5723961908057604, 0.5965602239778802, 0.9620506989452188, 0.5336064013900339, 0.37332167661340987, 0.027239861180942987, 0.3173991249070941, 0.6988213555670276, 0.8631466784280535, 0.01, 0.4807422166526695, 0.40918498511952117, 0.023292010380762673, 0.10816059386530699, 0.4187445328326803, 0.013079814293949027, 0.18473212194830807, 0.17752346455169649, 0.2943413471115788, 0.6645214735411528, 0.614822254290585, 0.281992068072275, 0.11804569165850194, 0.42557876458990107, 0.08543168630380601, 0.01, 0.32958045516744683, 0.2316370850884415, 0.11819489286077611, 0.36333805275522657, 0.6690153054889751, 0.44485981737676206, 0.7765799607411763, 0.29214680920281105, 0.41570129120205124, 0.5404820539023621, 0.08715441485081743, 0.9401330694017983, 0.35212984864789326, 0.7083719958485141, 0.5860426248260355, 0.99, 0.01, 0.0866759511830538, 0.779735928586841, 0.5729236305367638, 0.01, 0.6828474050181643, 0.99, 0.48280438364401296, 0.99, 0.9083551292208674, 0.1859119715030756, 0.01, 0.2999928627394598, 0.6830137577301065, 0.8603831869689523, 0.3919848568139435, 0.9432663158072334, 0.6837568087132608, 0.5663941280115328, 0.5507454566765774, 0.5417213518512038, 0.99, 0.6224306644353899, 0.99, 0.9634052287787375, 0.3005347423171385, 0.2777948416207737, 0.5592368543553776, 0.401981622138135, 0.4371622443538165, 0.6773557359798332, 0.41373235359576915, 0.9003661450540118, 0.19087116707731638, 0.99, 0.5871292384936275, 0.2132437963663174, 0.99, 0.5509208202554672, 0.748987899947805, 0.4809791451404992, 0.09532239305440862, 0.5169425161011928, 0.3938754494044445, 0.2469966456971044, 0.489727884873389, 0.26509318541272825, 0.5189051994178753, 0.5695946385691113, 0.16673317182606068]
Training loss = 0.03467343012491862
step = 0, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.6475
Training loss = 0.0337174920241038
step = 1, Training Accuracy: 0.49666666666666665
Training loss = 0.03392523944377899
step = 2, Training Accuracy: 0.44666666666666666
Training loss = 0.03313945432504018
step = 3, Training Accuracy: 0.52
Training loss = 0.03490366220474243
step = 4, Training Accuracy: 0.46
Training loss = 0.0341361262400945
step = 5, Training Accuracy: 0.42
Validation Accuracy: 0.655
Training loss = 0.03348903179168701
step = 6, Training Accuracy: 0.4666666666666667
Training loss = 0.03358144998550415
step = 7, Training Accuracy: 0.48
Training loss = 0.03363392512003581
step = 8, Training Accuracy: 0.4266666666666667
Training loss = 0.033904667695363364
step = 9, Training Accuracy: 0.45666666666666667
Training loss = 0.033414103388786316
step = 10, Training Accuracy: 0.43666666666666665
Validation Accuracy: 0.64875
Training loss = 0.03354700446128845
step = 11, Training Accuracy: 0.46
Training loss = 0.033850240111351015
step = 12, Training Accuracy: 0.47333333333333333
Training loss = 0.03249085307121277
step = 13, Training Accuracy: 0.5233333333333333
Training loss = 0.032857948740323384
step = 14, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.64875
params:  [0.01, 0.99, 0.9382787206715528, 0.1619297114626256, 0.17935203407384864, 0.12301895687586265, 0.2271904079444373, 0.45416150812577527, 0.5150751557576657, 0.25309633049449604, 0.01, 0.5962201693530143, 0.5795503520204367, 0.37883616799145065, 0.19055738541958367, 0.25209698119038154, 0.6119075903905571, 0.01, 0.3467745766216053, 0.8249953330121598, 0.06521111327623061, 0.1395155456860001, 0.41101907890511247, 0.53862403477085, 0.01, 0.01, 0.3437396414750443, 0.12266932865098383, 0.2374655569083245, 0.5606973223040435, 0.8171003803860551, 0.13893162928385966, 0.6992714300001222, 0.5978902315310446, 0.5807957135688964, 0.4692088178868948, 0.4392928679216957, 0.99, 0.5388782943273851, 0.24302546732472508, 0.5662802196597742, 0.7109497357195557, 0.01, 0.2570214082443849, 0.4770908137692499, 0.99, 0.01, 0.47152399618957386, 0.6162030019554083, 0.4693595248302833, 0.6024260021458245, 0.49957784706587044, 0.5281515623841319, 0.14262343954297774, 0.35726982272125707, 0.3749755955649609, 0.99, 0.716852187375011, 0.5752829493551233, 0.6083590098349136, 0.32967687596859874, 0.7137247813122071, 0.29925832035910016, 0.6316819374171765, 0.01, 0.6727654238416411, 0.99, 0.01, 0.23682521533899592, 0.45254094996521493, 0.3200589087861424, 0.6924070403264222, 0.5128923180299504, 0.7509678102587092, 0.9388374491726498, 0.01, 0.6827631587347684, 0.99, 0.6100009873112688, 0.7277948703950221, 0.7838423407381285, 0.7493238177550697, 0.7082259876633097, 0.5223262460012325, 0.01, 0.2879877217263749, 0.34964971240602083, 0.01, 0.19366228325116241, 0.01, 0.35470773620927115, 0.12978084838264978]
[0.01, 0.99, 0.9382787206715528, 0.1619297114626256, 0.17935203407384864, 0.12301895687586265, 0.2271904079444373, 0.45416150812577527, 0.5150751557576657, 0.25309633049449604, 0.01, 0.5962201693530143, 0.5795503520204367, 0.37883616799145065, 0.19055738541958367, 0.25209698119038154, 0.6119075903905571, 0.01, 0.3467745766216053, 0.8249953330121598, 0.06521111327623061, 0.1395155456860001, 0.41101907890511247, 0.53862403477085, 0.01, 0.01, 0.3437396414750443, 0.12266932865098383, 0.2374655569083245, 0.5606973223040435, 0.8171003803860551, 0.13893162928385966, 0.6992714300001222, 0.5978902315310446, 0.5807957135688964, 0.4692088178868948, 0.4392928679216957, 0.99, 0.5388782943273851, 0.24302546732472508, 0.5662802196597742, 0.7109497357195557, 0.01, 0.2570214082443849, 0.4770908137692499, 0.99, 0.01, 0.47152399618957386, 0.6162030019554083, 0.4693595248302833, 0.6024260021458245, 0.49957784706587044, 0.5281515623841319, 0.14262343954297774, 0.35726982272125707, 0.3749755955649609, 0.99, 0.716852187375011, 0.5752829493551233, 0.6083590098349136, 0.32967687596859874, 0.7137247813122071, 0.29925832035910016, 0.6316819374171765, 0.01, 0.6727654238416411, 0.99, 0.01, 0.23682521533899592, 0.45254094996521493, 0.3200589087861424, 0.6924070403264222, 0.5128923180299504, 0.7509678102587092, 0.9388374491726498, 0.01, 0.6827631587347684, 0.99, 0.6100009873112688, 0.7277948703950221, 0.7838423407381285, 0.7493238177550697, 0.7082259876633097, 0.5223262460012325, 0.01, 0.2879877217263749, 0.34964971240602083, 0.01, 0.19366228325116241, 0.01, 0.35470773620927115, 0.12978084838264978]
Training loss = 0.03493875741958618
step = 0, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.65
Training loss = 0.03553450167179108
step = 1, Training Accuracy: 0.42333333333333334
Training loss = 0.034846711158752444
step = 2, Training Accuracy: 0.43333333333333335
Training loss = 0.03423903445402781
step = 3, Training Accuracy: 0.44666666666666666
Training loss = 0.03463924109935761
step = 4, Training Accuracy: 0.44
Training loss = 0.03440499424934387
step = 5, Training Accuracy: 0.44
Validation Accuracy: 0.65625
Training loss = 0.03332461794217428
step = 6, Training Accuracy: 0.45
Training loss = 0.03473327974478404
step = 7, Training Accuracy: 0.44666666666666666
Training loss = 0.03457983831564585
step = 8, Training Accuracy: 0.4533333333333333
Training loss = 0.034311126271883645
step = 9, Training Accuracy: 0.45
Training loss = 0.03426494022210439
step = 10, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.65
Training loss = 0.03387251257896423
step = 11, Training Accuracy: 0.4866666666666667
Training loss = 0.03471324821313222
step = 12, Training Accuracy: 0.5033333333333333
Training loss = 0.03562354544798533
step = 13, Training Accuracy: 0.43333333333333335
Training loss = 0.033817243774731956
step = 14, Training Accuracy: 0.49666666666666665
Validation Accuracy: 0.6425
params:  [0.13491764015195576, 0.8372846181285047, 0.9168427956293851, 0.1612952738695651, 0.6684937967823685, 0.1284665433074691, 0.3358698222336475, 0.8634865185117073, 0.723831416765982, 0.01, 0.2659208690818941, 0.40523968222330375, 0.45993454226980873, 0.17633767837175618, 0.6470268195423987, 0.20363477380209288, 0.99, 0.3113396735249424, 0.20751527400254063, 0.7522877761553948, 0.3846907736936796, 0.42945695163347963, 0.0588409241213709, 0.21013650412076906, 0.5012434509835775, 0.2654073601258013, 0.30679411596334033, 0.3964950072784996, 0.24032130074457797, 0.21281443181076753, 0.860934569429357, 0.137998765308598, 0.7433771539204723, 0.5501129474514286, 0.3681890700303885, 0.19124844010401854, 0.23946338177766455, 0.9188107274492643, 0.9579279705164323, 0.15829912222634496, 0.8836727830448015, 0.7314954612350325, 0.01, 0.05233557864966823, 0.723603807178268, 0.7557704821741708, 0.11712447952684982, 0.7347058554813817, 0.8235388067109602, 0.77728222807449, 0.8203885200789562, 0.6675372005095748, 0.01, 0.37017553771704376, 0.5506020529898745, 0.99, 0.8185622581407818, 0.6414182584745285, 0.6878820956022258, 0.3870033423501648, 0.8526208455151367, 0.9018808715413746, 0.33211619010133364, 0.6080025017548499, 0.6805949990640181, 0.974510248598809, 0.6567456701410178, 0.01, 0.30401248019866944, 0.634484359440384, 0.6704816102446626, 0.30439855942359884, 0.6566713452993197, 0.936839700597512, 0.8975703414576335, 0.09061015470259148, 0.39640630928039583, 0.5944408164167346, 0.5168888325235289, 0.7051589450647141, 0.24104445178009876, 0.99, 0.49704767556360085, 0.5771294576166035, 0.37945165594591, 0.30325371134893525, 0.01, 0.30572752838465544, 0.01, 0.0772129758971156, 0.5814647084309779, 0.01]
[0.13491764015195576, 0.8372846181285047, 0.9168427956293851, 0.1612952738695651, 0.6684937967823685, 0.1284665433074691, 0.3358698222336475, 0.8634865185117073, 0.723831416765982, 0.01, 0.2659208690818941, 0.40523968222330375, 0.45993454226980873, 0.17633767837175618, 0.6470268195423987, 0.20363477380209288, 0.99, 0.3113396735249424, 0.20751527400254063, 0.7522877761553948, 0.3846907736936796, 0.42945695163347963, 0.0588409241213709, 0.21013650412076906, 0.5012434509835775, 0.2654073601258013, 0.30679411596334033, 0.3964950072784996, 0.24032130074457797, 0.21281443181076753, 0.860934569429357, 0.137998765308598, 0.7433771539204723, 0.5501129474514286, 0.3681890700303885, 0.19124844010401854, 0.23946338177766455, 0.9188107274492643, 0.9579279705164323, 0.15829912222634496, 0.8836727830448015, 0.7314954612350325, 0.01, 0.05233557864966823, 0.723603807178268, 0.7557704821741708, 0.11712447952684982, 0.7347058554813817, 0.8235388067109602, 0.77728222807449, 0.8203885200789562, 0.6675372005095748, 0.01, 0.37017553771704376, 0.5506020529898745, 0.99, 0.8185622581407818, 0.6414182584745285, 0.6878820956022258, 0.3870033423501648, 0.8526208455151367, 0.9018808715413746, 0.33211619010133364, 0.6080025017548499, 0.6805949990640181, 0.974510248598809, 0.6567456701410178, 0.01, 0.30401248019866944, 0.634484359440384, 0.6704816102446626, 0.30439855942359884, 0.6566713452993197, 0.936839700597512, 0.8975703414576335, 0.09061015470259148, 0.39640630928039583, 0.5944408164167346, 0.5168888325235289, 0.7051589450647141, 0.24104445178009876, 0.99, 0.49704767556360085, 0.5771294576166035, 0.37945165594591, 0.30325371134893525, 0.01, 0.30572752838465544, 0.01, 0.0772129758971156, 0.5814647084309779, 0.01]
Training loss = 0.03210368772347768
step = 0, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.64875
Training loss = 0.033058553139368695
step = 1, Training Accuracy: 0.49
Training loss = 0.034095865488052365
step = 2, Training Accuracy: 0.4666666666666667
Training loss = 0.0337342894077301
step = 3, Training Accuracy: 0.46
Training loss = 0.033795902729034426
step = 4, Training Accuracy: 0.5333333333333333
Training loss = 0.0339352931578954
step = 5, Training Accuracy: 0.47
Validation Accuracy: 0.64
Training loss = 0.032503963112831116
step = 6, Training Accuracy: 0.4666666666666667
Training loss = 0.03225651462872823
step = 7, Training Accuracy: 0.5133333333333333
Training loss = 0.03327633559703827
step = 8, Training Accuracy: 0.53
Training loss = 0.034348770181337994
step = 9, Training Accuracy: 0.4633333333333333
Training loss = 0.032473552425702414
step = 10, Training Accuracy: 0.47
Validation Accuracy: 0.64625
Training loss = 0.032266042431195574
step = 11, Training Accuracy: 0.5
Training loss = 0.034010509649912514
step = 12, Training Accuracy: 0.49
Training loss = 0.03254055082798004
step = 13, Training Accuracy: 0.5066666666666667
Training loss = 0.03260834832986196
step = 14, Training Accuracy: 0.5333333333333333
Validation Accuracy: 0.6475
params:  [0.20116905519847922, 0.9641120173805806, 0.99, 0.3650769040287182, 0.47962541046812723, 0.01, 0.5007122983200685, 0.99, 0.8551563856530189, 0.07215779948044157, 0.2978962525497741, 0.5110038059256847, 0.4515266077631151, 0.3383879493273193, 0.8831526877827025, 0.01, 0.615728500037873, 0.2701377565986391, 0.3397929228430399, 0.8238095672478911, 0.01, 0.40504806109575453, 0.01, 0.2437792789538004, 0.051288564834609016, 0.01, 0.5486839760789426, 0.01, 0.04317667173356954, 0.8117180796546152, 0.9764480132540501, 0.18505417205717883, 0.848534210063226, 0.46901544453565724, 0.5912723567339885, 0.01, 0.28926876900877024, 0.810309724866008, 0.7826899053523444, 0.45241653330139975, 0.2600797352183686, 0.6602253928865907, 0.22863950394176794, 0.34616837555309743, 0.7115667378913257, 0.9406044850231127, 0.01, 0.4654576359955285, 0.99, 0.5748744813973836, 0.99, 0.5500544458037983, 0.5655474832401559, 0.46350838848807513, 0.4645436162206827, 0.8117797207112099, 0.7036042064637614, 0.8035264566860585, 0.5770751163650029, 0.5419634694260338, 0.9722873881436571, 0.6837331211909968, 0.4004762890448942, 0.99, 0.011306185450833062, 0.8337854574458292, 0.6560215666552109, 0.028708527462495775, 0.13842723448729743, 0.5913233760515111, 0.07908407528022943, 0.16454470511608976, 0.350695057491996, 0.726070598262925, 0.6466609512052554, 0.01, 0.99, 0.6329424845573309, 0.35025573442054897, 0.5788453131046591, 0.6167035001515979, 0.99, 0.49797929591006346, 0.5386147416967949, 0.4096657410274514, 0.26273889471672035, 0.05002641197277581, 0.7550747156856832, 0.24442520726997552, 0.01, 0.2826542840435303, 0.2175500698690479]
[0.20116905519847922, 0.9641120173805806, 0.99, 0.3650769040287182, 0.47962541046812723, 0.01, 0.5007122983200685, 0.99, 0.8551563856530189, 0.07215779948044157, 0.2978962525497741, 0.5110038059256847, 0.4515266077631151, 0.3383879493273193, 0.8831526877827025, 0.01, 0.615728500037873, 0.2701377565986391, 0.3397929228430399, 0.8238095672478911, 0.01, 0.40504806109575453, 0.01, 0.2437792789538004, 0.051288564834609016, 0.01, 0.5486839760789426, 0.01, 0.04317667173356954, 0.8117180796546152, 0.9764480132540501, 0.18505417205717883, 0.848534210063226, 0.46901544453565724, 0.5912723567339885, 0.01, 0.28926876900877024, 0.810309724866008, 0.7826899053523444, 0.45241653330139975, 0.2600797352183686, 0.6602253928865907, 0.22863950394176794, 0.34616837555309743, 0.7115667378913257, 0.9406044850231127, 0.01, 0.4654576359955285, 0.99, 0.5748744813973836, 0.99, 0.5500544458037983, 0.5655474832401559, 0.46350838848807513, 0.4645436162206827, 0.8117797207112099, 0.7036042064637614, 0.8035264566860585, 0.5770751163650029, 0.5419634694260338, 0.9722873881436571, 0.6837331211909968, 0.4004762890448942, 0.99, 0.011306185450833062, 0.8337854574458292, 0.6560215666552109, 0.028708527462495775, 0.13842723448729743, 0.5913233760515111, 0.07908407528022943, 0.16454470511608976, 0.350695057491996, 0.726070598262925, 0.6466609512052554, 0.01, 0.99, 0.6329424845573309, 0.35025573442054897, 0.5788453131046591, 0.6167035001515979, 0.99, 0.49797929591006346, 0.5386147416967949, 0.4096657410274514, 0.26273889471672035, 0.05002641197277581, 0.7550747156856832, 0.24442520726997552, 0.01, 0.2826542840435303, 0.2175500698690479]
Training loss = 0.03307286401589712
step = 0, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.65125
Training loss = 0.034207395911216736
step = 1, Training Accuracy: 0.4533333333333333
Training loss = 0.03395550787448883
step = 2, Training Accuracy: 0.43666666666666665
Training loss = 0.033574503660202024
step = 3, Training Accuracy: 0.4633333333333333
Training loss = 0.03306833247343699
step = 4, Training Accuracy: 0.4766666666666667
Training loss = 0.03390076140562693
step = 5, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.64125
Training loss = 0.032866647640864055
step = 6, Training Accuracy: 0.47333333333333333
Training loss = 0.03349244773387909
step = 7, Training Accuracy: 0.4866666666666667
Training loss = 0.03397698442141215
step = 8, Training Accuracy: 0.47
Training loss = 0.03344479064146678
step = 9, Training Accuracy: 0.4533333333333333
Training loss = 0.032506128946940105
step = 10, Training Accuracy: 0.5166666666666667
Validation Accuracy: 0.625
Training loss = 0.03367004195849101
step = 11, Training Accuracy: 0.43333333333333335
Training loss = 0.033374677499135336
step = 12, Training Accuracy: 0.48
Training loss = 0.03396579523881276
step = 13, Training Accuracy: 0.49
Training loss = 0.034485211372375486
step = 14, Training Accuracy: 0.45666666666666667
Validation Accuracy: 0.62625
15 	8     	0.638594	0.00705551	0.62625	0.64875
params:  [0.7294449639532967, 0.9805930632091312, 0.99, 0.22361417011154153, 0.19761467297436436, 0.01, 0.04160740061255608, 0.9012738026174362, 0.927688484343626, 0.01, 0.43170328814558323, 0.5768059180973258, 0.21307272537841693, 0.2591054864953645, 0.2107799295079024, 0.6395953583457964, 0.5154420278380792, 0.24496116272056412, 0.13995176234946766, 0.4666997168329301, 0.6083693957733918, 0.31185433085152525, 0.01, 0.5541373862484427, 0.5165400284208237, 0.01, 0.2176285864108971, 0.01, 0.05793035773162328, 0.37155147661651516, 0.627213496928654, 0.20541800757383372, 0.8320847551828651, 0.479468497718863, 0.5479084320326656, 0.01, 0.22389525540579214, 0.99, 0.5823524133221667, 0.5535152469984435, 0.8402853508836763, 0.99, 0.01, 0.3723723801954612, 0.5104829405410182, 0.6765340653868542, 0.01, 0.664718352795954, 0.99, 0.7989690077274152, 0.7147550509490523, 0.6431135853836528, 0.46354725118360596, 0.01, 0.7306953519875938, 0.7232689606765196, 0.9694729889589092, 0.6995812127321204, 0.99, 0.01, 0.7361236077596081, 0.6563430473187142, 0.3519324156488671, 0.8457447458565983, 0.8015357046481327, 0.8703421008326936, 0.7764705258732748, 0.01, 0.4684551927133118, 0.6869267519837913, 0.340940680416981, 0.822386236353791, 0.9089698799124462, 0.5538894721342249, 0.99, 0.01, 0.7842155120830537, 0.6788391644129803, 0.176273824941151, 0.99, 0.6427314725215856, 0.5652608024437539, 0.554301134903324, 0.5111075641084831, 0.5919881553221326, 0.47207003754209076, 0.13768335560466163, 0.1235977228490531, 0.28206216920924465, 0.5709427473421929, 0.7061875749916405, 0.35648558605995645]
[0.7294449639532967, 0.9805930632091312, 0.99, 0.22361417011154153, 0.19761467297436436, 0.01, 0.04160740061255608, 0.9012738026174362, 0.927688484343626, 0.01, 0.43170328814558323, 0.5768059180973258, 0.21307272537841693, 0.2591054864953645, 0.2107799295079024, 0.6395953583457964, 0.5154420278380792, 0.24496116272056412, 0.13995176234946766, 0.4666997168329301, 0.6083693957733918, 0.31185433085152525, 0.01, 0.5541373862484427, 0.5165400284208237, 0.01, 0.2176285864108971, 0.01, 0.05793035773162328, 0.37155147661651516, 0.627213496928654, 0.20541800757383372, 0.8320847551828651, 0.479468497718863, 0.5479084320326656, 0.01, 0.22389525540579214, 0.99, 0.5823524133221667, 0.5535152469984435, 0.8402853508836763, 0.99, 0.01, 0.3723723801954612, 0.5104829405410182, 0.6765340653868542, 0.01, 0.664718352795954, 0.99, 0.7989690077274152, 0.7147550509490523, 0.6431135853836528, 0.46354725118360596, 0.01, 0.7306953519875938, 0.7232689606765196, 0.9694729889589092, 0.6995812127321204, 0.99, 0.01, 0.7361236077596081, 0.6563430473187142, 0.3519324156488671, 0.8457447458565983, 0.8015357046481327, 0.8703421008326936, 0.7764705258732748, 0.01, 0.4684551927133118, 0.6869267519837913, 0.340940680416981, 0.822386236353791, 0.9089698799124462, 0.5538894721342249, 0.99, 0.01, 0.7842155120830537, 0.6788391644129803, 0.176273824941151, 0.99, 0.6427314725215856, 0.5652608024437539, 0.554301134903324, 0.5111075641084831, 0.5919881553221326, 0.47207003754209076, 0.13768335560466163, 0.1235977228490531, 0.28206216920924465, 0.5709427473421929, 0.7061875749916405, 0.35648558605995645]
Training loss = 0.034045781493186954
step = 0, Training Accuracy: 0.5
Validation Accuracy: 0.6075
Training loss = 0.034378199378649395
step = 1, Training Accuracy: 0.49
Training loss = 0.03488174001375834
step = 2, Training Accuracy: 0.4533333333333333
Training loss = 0.03576559563477834
step = 3, Training Accuracy: 0.4633333333333333
Training loss = 0.0335134889682134
step = 4, Training Accuracy: 0.4766666666666667
Training loss = 0.03558737655480703
step = 5, Training Accuracy: 0.42
Validation Accuracy: 0.59375
Training loss = 0.033490657210350036
step = 6, Training Accuracy: 0.49
Training loss = 0.03558390279610952
step = 7, Training Accuracy: 0.3933333333333333
Training loss = 0.035447737773259484
step = 8, Training Accuracy: 0.47
Training loss = 0.034257084528605146
step = 9, Training Accuracy: 0.4666666666666667
Training loss = 0.035820894837379456
step = 10, Training Accuracy: 0.42333333333333334
Validation Accuracy: 0.59875
Training loss = 0.033941487669944766
step = 11, Training Accuracy: 0.45666666666666667
Training loss = 0.034021265904108686
step = 12, Training Accuracy: 0.44666666666666666
Training loss = 0.03531921327114105
step = 13, Training Accuracy: 0.42
Training loss = 0.03283900837103526
step = 14, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.61375
params:  [0.3407073061324478, 0.5555286805404598, 0.9534110141471716, 0.43613314625586397, 0.541918357012633, 0.05003109391237352, 0.548171898028487, 0.99, 0.7957793594489295, 0.02710514769531641, 0.3506738116530796, 0.4883988083219329, 0.5509906017621085, 0.19783907425316344, 0.5128067942023466, 0.01, 0.2925278885360363, 0.07423686340524153, 0.41445464490527406, 0.7386523735622598, 0.28778984747168884, 0.060611928038359825, 0.05911848782357694, 0.5248832039289806, 0.32774472167537727, 0.14974877177629356, 0.06817048177804674, 0.08018740955132264, 0.11346644628999814, 0.5420049161129762, 0.4413935207631074, 0.35170673305793876, 0.97770701132279, 0.5930140653594365, 0.6846018490844064, 0.44259194587738865, 0.16382883603952625, 0.8555231825761251, 0.4702525388407194, 0.6022785745942603, 0.7277651489737194, 0.7273332106979196, 0.01, 0.08854777336502515, 0.5926752673524722, 0.8025029272237286, 0.4187790233149723, 0.7927957542747818, 0.7481297439427439, 0.4789971722003971, 0.8203693431050232, 0.7472325186966204, 0.06003753521234284, 0.01, 0.6602784142512625, 0.7085993979524863, 0.5927417894400007, 0.5646073800225166, 0.580496125624289, 0.574258287127895, 0.5109058985373751, 0.6385239107762988, 0.529052471314263, 0.8875998107981095, 0.7444448519840055, 0.8143131173299494, 0.689710043795376, 0.15996464567209137, 0.37738070618560016, 0.5216821370893445, 0.6094889652853137, 0.6112822353715803, 0.7318542027399341, 0.6514372086542407, 0.7736444568348089, 0.01, 0.99, 0.8753277104390009, 0.20610339111333387, 0.5273412236701996, 0.48898339271674623, 0.7802598601579748, 0.5060720016882445, 0.1817295262098035, 0.19100281537222671, 0.5295822990600039, 0.23202941386089387, 0.6001416522560752, 0.3641975617564336, 0.2865049427283715, 0.3974146796159588, 0.35111038813781803]
[0.3407073061324478, 0.5555286805404598, 0.9534110141471716, 0.43613314625586397, 0.541918357012633, 0.05003109391237352, 0.548171898028487, 0.99, 0.7957793594489295, 0.02710514769531641, 0.3506738116530796, 0.4883988083219329, 0.5509906017621085, 0.19783907425316344, 0.5128067942023466, 0.01, 0.2925278885360363, 0.07423686340524153, 0.41445464490527406, 0.7386523735622598, 0.28778984747168884, 0.060611928038359825, 0.05911848782357694, 0.5248832039289806, 0.32774472167537727, 0.14974877177629356, 0.06817048177804674, 0.08018740955132264, 0.11346644628999814, 0.5420049161129762, 0.4413935207631074, 0.35170673305793876, 0.97770701132279, 0.5930140653594365, 0.6846018490844064, 0.44259194587738865, 0.16382883603952625, 0.8555231825761251, 0.4702525388407194, 0.6022785745942603, 0.7277651489737194, 0.7273332106979196, 0.01, 0.08854777336502515, 0.5926752673524722, 0.8025029272237286, 0.4187790233149723, 0.7927957542747818, 0.7481297439427439, 0.4789971722003971, 0.8203693431050232, 0.7472325186966204, 0.06003753521234284, 0.01, 0.6602784142512625, 0.7085993979524863, 0.5927417894400007, 0.5646073800225166, 0.580496125624289, 0.574258287127895, 0.5109058985373751, 0.6385239107762988, 0.529052471314263, 0.8875998107981095, 0.7444448519840055, 0.8143131173299494, 0.689710043795376, 0.15996464567209137, 0.37738070618560016, 0.5216821370893445, 0.6094889652853137, 0.6112822353715803, 0.7318542027399341, 0.6514372086542407, 0.7736444568348089, 0.01, 0.99, 0.8753277104390009, 0.20610339111333387, 0.5273412236701996, 0.48898339271674623, 0.7802598601579748, 0.5060720016882445, 0.1817295262098035, 0.19100281537222671, 0.5295822990600039, 0.23202941386089387, 0.6001416522560752, 0.3641975617564336, 0.2865049427283715, 0.3974146796159588, 0.35111038813781803]
Training loss = 0.03420953651269277
step = 0, Training Accuracy: 0.47
Validation Accuracy: 0.61125
Training loss = 0.03463625431060791
step = 1, Training Accuracy: 0.47
Training loss = 0.03399765233198802
step = 2, Training Accuracy: 0.46
Training loss = 0.03571975807348887
step = 3, Training Accuracy: 0.45666666666666667
Training loss = 0.03425303300221761
step = 4, Training Accuracy: 0.4633333333333333
Training loss = 0.033793494900067646
step = 5, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.61
Training loss = 0.03482195556163788
step = 6, Training Accuracy: 0.41
Training loss = 0.03365627070267995
step = 7, Training Accuracy: 0.4766666666666667
Training loss = 0.03394705732663472
step = 8, Training Accuracy: 0.4266666666666667
Training loss = 0.03389796555042267
step = 9, Training Accuracy: 0.44666666666666666
Training loss = 0.03412766019503276
step = 10, Training Accuracy: 0.52
Validation Accuracy: 0.61375
Training loss = 0.0333461465438207
step = 11, Training Accuracy: 0.4533333333333333
Training loss = 0.033769699533780416
step = 12, Training Accuracy: 0.49333333333333335
Training loss = 0.033779405156771344
step = 13, Training Accuracy: 0.5
Training loss = 0.03474453449249268
step = 14, Training Accuracy: 0.4633333333333333
Validation Accuracy: 0.605
params:  [0.01, 0.937744949964462, 0.7067529638801722, 0.5318568749667447, 0.3785238505851378, 0.01, 0.12532340842714562, 0.5246648375901516, 0.99, 0.08421648207256019, 0.3199985240073142, 0.24298554378936638, 0.5256719632927824, 0.3298038905436693, 0.5311229805673255, 0.01, 0.4379511179613229, 0.21966437486365625, 0.2657897010775086, 0.6975329157526861, 0.27149602972395614, 0.34055674179058804, 0.01, 0.19089488806182978, 0.27506746767373047, 0.01, 0.01, 0.15221217978662455, 0.4015507264366187, 0.5033555796595177, 0.6455178512694248, 0.23899223767364225, 0.6631602058608458, 0.1133833372017149, 0.5772246595840722, 0.438078216200849, 0.12536687968988636, 0.99, 0.5241516650741579, 0.2331093468138321, 0.6230194084691121, 0.8223871147968963, 0.01, 0.01, 0.9005874403444127, 0.7594289844769592, 0.01, 0.6282794770080731, 0.8930627545655022, 0.7385810769912903, 0.8547193476587338, 0.6865349986265877, 0.01529300316045451, 0.07696420052089002, 0.29758840162734707, 0.8700141000748137, 0.7836696109797501, 0.3901020672953995, 0.6712514797923947, 0.4738528407095667, 0.45165764618615334, 0.99, 0.6430892642616104, 0.9623407676463114, 0.6552920746505257, 0.99, 0.99, 0.13257999737457, 0.45053934198365153, 0.4852668654589482, 0.8320239415015287, 0.5426874476213568, 0.48248905120156016, 0.46308947505812537, 0.45148310875368053, 0.01, 0.34719024729401954, 0.835904219130627, 0.01, 0.789567108368401, 0.5109673721208865, 0.7727462849144348, 0.4726518941365168, 0.01, 0.17901845359044144, 0.527278781514122, 0.06929323063570075, 0.011859202174505479, 0.01, 0.01, 0.64032237479822, 0.10369519582755837]
[0.01, 0.937744949964462, 0.7067529638801722, 0.5318568749667447, 0.3785238505851378, 0.01, 0.12532340842714562, 0.5246648375901516, 0.99, 0.08421648207256019, 0.3199985240073142, 0.24298554378936638, 0.5256719632927824, 0.3298038905436693, 0.5311229805673255, 0.01, 0.4379511179613229, 0.21966437486365625, 0.2657897010775086, 0.6975329157526861, 0.27149602972395614, 0.34055674179058804, 0.01, 0.19089488806182978, 0.27506746767373047, 0.01, 0.01, 0.15221217978662455, 0.4015507264366187, 0.5033555796595177, 0.6455178512694248, 0.23899223767364225, 0.6631602058608458, 0.1133833372017149, 0.5772246595840722, 0.438078216200849, 0.12536687968988636, 0.99, 0.5241516650741579, 0.2331093468138321, 0.6230194084691121, 0.8223871147968963, 0.01, 0.01, 0.9005874403444127, 0.7594289844769592, 0.01, 0.6282794770080731, 0.8930627545655022, 0.7385810769912903, 0.8547193476587338, 0.6865349986265877, 0.01529300316045451, 0.07696420052089002, 0.29758840162734707, 0.8700141000748137, 0.7836696109797501, 0.3901020672953995, 0.6712514797923947, 0.4738528407095667, 0.45165764618615334, 0.99, 0.6430892642616104, 0.9623407676463114, 0.6552920746505257, 0.99, 0.99, 0.13257999737457, 0.45053934198365153, 0.4852668654589482, 0.8320239415015287, 0.5426874476213568, 0.48248905120156016, 0.46308947505812537, 0.45148310875368053, 0.01, 0.34719024729401954, 0.835904219130627, 0.01, 0.789567108368401, 0.5109673721208865, 0.7727462849144348, 0.4726518941365168, 0.01, 0.17901845359044144, 0.527278781514122, 0.06929323063570075, 0.011859202174505479, 0.01, 0.01, 0.64032237479822, 0.10369519582755837]
Training loss = 0.034429186781247456
step = 0, Training Accuracy: 0.46
Validation Accuracy: 0.6175
Training loss = 0.033013362089792886
step = 1, Training Accuracy: 0.44666666666666666
Training loss = 0.03391706387201945
step = 2, Training Accuracy: 0.45
Training loss = 0.03397348344326019
step = 3, Training Accuracy: 0.49333333333333335
Training loss = 0.03349792798360189
step = 4, Training Accuracy: 0.49666666666666665
Training loss = 0.03289129058519999
step = 5, Training Accuracy: 0.5066666666666667
Validation Accuracy: 0.6375
Training loss = 0.03470172921816508
step = 6, Training Accuracy: 0.45
Training loss = 0.0343969064950943
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.03514904856681824
step = 8, Training Accuracy: 0.43666666666666665
Training loss = 0.03380867679913839
step = 9, Training Accuracy: 0.51
Training loss = 0.03436946491400401
step = 10, Training Accuracy: 0.4866666666666667
Validation Accuracy: 0.63625
Training loss = 0.03349169413248698
step = 11, Training Accuracy: 0.49666666666666665
Training loss = 0.03462825854619344
step = 12, Training Accuracy: 0.47
Training loss = 0.03311408678690592
step = 13, Training Accuracy: 0.49
Training loss = 0.03356566071510315
step = 14, Training Accuracy: 0.47
Validation Accuracy: 0.6375
params:  [0.20157530460518414, 0.6804748972379908, 0.9531806111745138, 0.728000163142285, 0.4226610336184449, 0.17790497839876074, 0.37862357663752133, 0.6539132156074685, 0.772972129899715, 0.01, 0.5599536615120548, 0.2808857746905461, 0.1337206745606956, 0.2526527668918933, 0.40161978456725095, 0.01, 0.463297244592467, 0.01, 0.7718498892916685, 0.541444982030905, 0.66605600482433, 0.0909833292580994, 0.3224303857821059, 0.7065692289591272, 0.010297403338760891, 0.010275250164694313, 0.4410339383646878, 0.424393344882413, 0.28596712489441234, 0.3246087381576716, 0.733230913118295, 0.46120382486054023, 0.7080768696913542, 0.3723909683611769, 0.23565536574787876, 0.5264522184963633, 0.13582047607785408, 0.99, 0.7912498434835507, 0.5665767937210036, 0.7243741142919821, 0.9343566948656383, 0.01, 0.23791686751881355, 0.3799723981787443, 0.528074714927043, 0.17067156598650016, 0.8183809703070382, 0.665724675034783, 0.7991382730250097, 0.8881628775351837, 0.7176213771468565, 0.4038708950310338, 0.1364945281853035, 0.22061602967974767, 0.713736846876851, 0.7242102294037372, 0.41526705791082935, 0.556283123751043, 0.6670288767548045, 0.9112326347903469, 0.6256257970972374, 0.7097335000154235, 0.8630077734408641, 0.6187339132463212, 0.932615548602982, 0.9339852274790509, 0.14068985396481443, 0.20314938054045673, 0.44261483890154096, 0.46489626919489757, 0.42877286858186897, 0.5839903488345609, 0.99, 0.99, 0.01, 0.8924054978682849, 0.7871120480171456, 0.01, 0.7703331330850179, 0.5284148880027986, 0.99, 0.3989957859241917, 0.42046536947162194, 0.8571150501794161, 0.06944723631007038, 0.12777198726434597, 0.370947678634163, 0.1872746497093455, 0.01, 0.35928999631375297, 0.522864537347677]
[0.20157530460518414, 0.6804748972379908, 0.9531806111745138, 0.728000163142285, 0.4226610336184449, 0.17790497839876074, 0.37862357663752133, 0.6539132156074685, 0.772972129899715, 0.01, 0.5599536615120548, 0.2808857746905461, 0.1337206745606956, 0.2526527668918933, 0.40161978456725095, 0.01, 0.463297244592467, 0.01, 0.7718498892916685, 0.541444982030905, 0.66605600482433, 0.0909833292580994, 0.3224303857821059, 0.7065692289591272, 0.010297403338760891, 0.010275250164694313, 0.4410339383646878, 0.424393344882413, 0.28596712489441234, 0.3246087381576716, 0.733230913118295, 0.46120382486054023, 0.7080768696913542, 0.3723909683611769, 0.23565536574787876, 0.5264522184963633, 0.13582047607785408, 0.99, 0.7912498434835507, 0.5665767937210036, 0.7243741142919821, 0.9343566948656383, 0.01, 0.23791686751881355, 0.3799723981787443, 0.528074714927043, 0.17067156598650016, 0.8183809703070382, 0.665724675034783, 0.7991382730250097, 0.8881628775351837, 0.7176213771468565, 0.4038708950310338, 0.1364945281853035, 0.22061602967974767, 0.713736846876851, 0.7242102294037372, 0.41526705791082935, 0.556283123751043, 0.6670288767548045, 0.9112326347903469, 0.6256257970972374, 0.7097335000154235, 0.8630077734408641, 0.6187339132463212, 0.932615548602982, 0.9339852274790509, 0.14068985396481443, 0.20314938054045673, 0.44261483890154096, 0.46489626919489757, 0.42877286858186897, 0.5839903488345609, 0.99, 0.99, 0.01, 0.8924054978682849, 0.7871120480171456, 0.01, 0.7703331330850179, 0.5284148880027986, 0.99, 0.3989957859241917, 0.42046536947162194, 0.8571150501794161, 0.06944723631007038, 0.12777198726434597, 0.370947678634163, 0.1872746497093455, 0.01, 0.35928999631375297, 0.522864537347677]
Training loss = 0.034073266784350076
step = 0, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.63875
Training loss = 0.03382022321224212
step = 1, Training Accuracy: 0.4766666666666667
Training loss = 0.033129223585128785
step = 2, Training Accuracy: 0.5066666666666667
Training loss = 0.035138543446858725
step = 3, Training Accuracy: 0.43333333333333335
Training loss = 0.0336955585082372
step = 4, Training Accuracy: 0.49333333333333335
Training loss = 0.034404691060384116
step = 5, Training Accuracy: 0.4666666666666667
Validation Accuracy: 0.63375
Training loss = 0.03321268121401469
step = 6, Training Accuracy: 0.4533333333333333
Training loss = 0.03348736862341563
step = 7, Training Accuracy: 0.4533333333333333
Training loss = 0.03377514580885569
step = 8, Training Accuracy: 0.45
Training loss = 0.03403562366962433
step = 9, Training Accuracy: 0.4633333333333333
Training loss = 0.03401220500469208
step = 10, Training Accuracy: 0.47
Validation Accuracy: 0.63625
Training loss = 0.03443734308083852
step = 11, Training Accuracy: 0.45
Training loss = 0.033523541092872616
step = 12, Training Accuracy: 0.45666666666666667
Training loss = 0.03373241464296977
step = 13, Training Accuracy: 0.48
Training loss = 0.03449134329954783
step = 14, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.63375
params:  [0.6462934464715413, 0.99, 0.6759763675999709, 0.49390108144063816, 0.6145074612790777, 0.15003102224535753, 0.48141740469012606, 0.33646961970959033, 0.5092737489845975, 0.12551775475476845, 0.19556487024208713, 0.2582146829439479, 0.1947494692825979, 0.0145478524300231, 0.5060386759837391, 0.21083549814024538, 0.45232809957704245, 0.01, 0.3153376326573981, 0.617691140588825, 0.38864607694925246, 0.5051884967120228, 0.2141317174391166, 0.3939443887763096, 0.2721707781434983, 0.18095084988631144, 0.4022441173235755, 0.3079961578302706, 0.17679663734944523, 0.36602437962746304, 0.7536468873544837, 0.01, 0.7370343257198696, 0.0659293561940944, 0.6222958399946623, 0.40123754385253685, 0.4688876042176989, 0.9643195179849885, 0.5248515944562762, 0.573420866523993, 0.766923122644479, 0.99, 0.01, 0.4819097229888623, 0.6703828904940778, 0.8694867537846791, 0.01, 0.5509716277033263, 0.8033355540845655, 0.7899591009423281, 0.8419230894640987, 0.99, 0.17991840432627826, 0.18840710428599436, 0.04878551674845666, 0.41851520933207687, 0.99, 0.605962689293799, 0.7259463150560075, 0.7594285050611405, 0.3479949082132943, 0.6702575227148696, 0.41989022074357474, 0.99, 0.5557580413762856, 0.926828677124929, 0.8857114479385891, 0.03653537898461051, 0.3906928808738667, 0.6219979554626003, 0.19238004717376173, 0.627326346715676, 0.49058264614498975, 0.12665382781409434, 0.6359245086811366, 0.42670010296710126, 0.9596126120130151, 0.4960929877159499, 0.19150784641483634, 0.6839989378412463, 0.6293622165602115, 0.5746143692153372, 0.49419988006698984, 0.07870351539675224, 0.5887125172667743, 0.3929216366704021, 0.01, 0.4528237315437366, 0.01, 0.42320707914822925, 0.5063006286974724, 0.32474704824884304]
[0.6462934464715413, 0.99, 0.6759763675999709, 0.49390108144063816, 0.6145074612790777, 0.15003102224535753, 0.48141740469012606, 0.33646961970959033, 0.5092737489845975, 0.12551775475476845, 0.19556487024208713, 0.2582146829439479, 0.1947494692825979, 0.0145478524300231, 0.5060386759837391, 0.21083549814024538, 0.45232809957704245, 0.01, 0.3153376326573981, 0.617691140588825, 0.38864607694925246, 0.5051884967120228, 0.2141317174391166, 0.3939443887763096, 0.2721707781434983, 0.18095084988631144, 0.4022441173235755, 0.3079961578302706, 0.17679663734944523, 0.36602437962746304, 0.7536468873544837, 0.01, 0.7370343257198696, 0.0659293561940944, 0.6222958399946623, 0.40123754385253685, 0.4688876042176989, 0.9643195179849885, 0.5248515944562762, 0.573420866523993, 0.766923122644479, 0.99, 0.01, 0.4819097229888623, 0.6703828904940778, 0.8694867537846791, 0.01, 0.5509716277033263, 0.8033355540845655, 0.7899591009423281, 0.8419230894640987, 0.99, 0.17991840432627826, 0.18840710428599436, 0.04878551674845666, 0.41851520933207687, 0.99, 0.605962689293799, 0.7259463150560075, 0.7594285050611405, 0.3479949082132943, 0.6702575227148696, 0.41989022074357474, 0.99, 0.5557580413762856, 0.926828677124929, 0.8857114479385891, 0.03653537898461051, 0.3906928808738667, 0.6219979554626003, 0.19238004717376173, 0.627326346715676, 0.49058264614498975, 0.12665382781409434, 0.6359245086811366, 0.42670010296710126, 0.9596126120130151, 0.4960929877159499, 0.19150784641483634, 0.6839989378412463, 0.6293622165602115, 0.5746143692153372, 0.49419988006698984, 0.07870351539675224, 0.5887125172667743, 0.3929216366704021, 0.01, 0.4528237315437366, 0.01, 0.42320707914822925, 0.5063006286974724, 0.32474704824884304]
Training loss = 0.033104898730913795
step = 0, Training Accuracy: 0.45666666666666667
Validation Accuracy: 0.62
Training loss = 0.03319796144962311
step = 1, Training Accuracy: 0.5166666666666667
Training loss = 0.034335930744806925
step = 2, Training Accuracy: 0.45
Training loss = 0.03429338753223419
step = 3, Training Accuracy: 0.45666666666666667
Training loss = 0.03379694561163584
step = 4, Training Accuracy: 0.49333333333333335
Training loss = 0.03452177504698435
step = 5, Training Accuracy: 0.44666666666666666
Validation Accuracy: 0.61625
Training loss = 0.03368807832400004
step = 6, Training Accuracy: 0.51
Training loss = 0.0342558894554774
step = 7, Training Accuracy: 0.4866666666666667
Training loss = 0.03305301547050476
step = 8, Training Accuracy: 0.4666666666666667
Training loss = 0.0344338991244634
step = 9, Training Accuracy: 0.4533333333333333
Training loss = 0.03503742615381877
step = 10, Training Accuracy: 0.42
Validation Accuracy: 0.61875
Training loss = 0.03409754455089569
step = 11, Training Accuracy: 0.4766666666666667
Training loss = 0.03421743889649709
step = 12, Training Accuracy: 0.44
Training loss = 0.03385715126991272
step = 13, Training Accuracy: 0.4533333333333333
Training loss = 0.03412155290444692
step = 14, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.6125
params:  [0.4996130606598323, 0.99, 0.99, 0.39187663087553226, 0.47990562630396943, 0.021667287525687563, 0.01, 0.3655057153413796, 0.6176889329812518, 0.5032899503228907, 0.6475422444996886, 0.5078083173534838, 0.2104066811632837, 0.3968961517111036, 0.692042678772355, 0.18405280422495174, 0.2344301514702522, 0.41225297657620696, 0.2708107759899044, 0.3219733295019735, 0.2844503354339455, 0.5375129281245075, 0.01, 0.6531740741111356, 0.6059329691806196, 0.01, 0.3744375846610953, 0.33558525679651147, 0.03284741375393346, 0.30242310156845875, 0.5896160814015318, 0.17058111416814364, 0.99, 0.3011901017323112, 0.7069152055392712, 0.12214012044751277, 0.43356867560328716, 0.5906312070718835, 0.8722761081797668, 0.22188862463957093, 0.8133770845352211, 0.9181270770920251, 0.17832559937088163, 0.12483461586593578, 0.47980486445560516, 0.542561788412876, 0.01, 0.4621423528291728, 0.9473307806103611, 0.3180466332693545, 0.8923657275046553, 0.5210875853304077, 0.05396396565960865, 0.18220927672134601, 0.12086916833708916, 0.99, 0.99, 0.7886944540721244, 0.8130524323511983, 0.8690650649680249, 0.5066828416654781, 0.8741466718323995, 0.01, 0.46965469441652247, 0.700462245565036, 0.99, 0.828928614623208, 0.07892017980298323, 0.24278611611995038, 0.37206242888813906, 0.6845504592311628, 0.5504143421762422, 0.5562049277961553, 0.4774813943127095, 0.9316352089469471, 0.01, 0.6918615786480016, 0.4883283692617678, 0.02996326165020058, 0.9749273490607647, 0.18394219840183995, 0.7574408796822615, 0.6455435060042538, 0.07832159715803438, 0.5814823819780064, 0.16999968821072314, 0.3025121352380274, 0.34263837981428324, 0.01, 0.025356626219473377, 0.8883190837237334, 0.4460293266809121]
[0.4996130606598323, 0.99, 0.99, 0.39187663087553226, 0.47990562630396943, 0.021667287525687563, 0.01, 0.3655057153413796, 0.6176889329812518, 0.5032899503228907, 0.6475422444996886, 0.5078083173534838, 0.2104066811632837, 0.3968961517111036, 0.692042678772355, 0.18405280422495174, 0.2344301514702522, 0.41225297657620696, 0.2708107759899044, 0.3219733295019735, 0.2844503354339455, 0.5375129281245075, 0.01, 0.6531740741111356, 0.6059329691806196, 0.01, 0.3744375846610953, 0.33558525679651147, 0.03284741375393346, 0.30242310156845875, 0.5896160814015318, 0.17058111416814364, 0.99, 0.3011901017323112, 0.7069152055392712, 0.12214012044751277, 0.43356867560328716, 0.5906312070718835, 0.8722761081797668, 0.22188862463957093, 0.8133770845352211, 0.9181270770920251, 0.17832559937088163, 0.12483461586593578, 0.47980486445560516, 0.542561788412876, 0.01, 0.4621423528291728, 0.9473307806103611, 0.3180466332693545, 0.8923657275046553, 0.5210875853304077, 0.05396396565960865, 0.18220927672134601, 0.12086916833708916, 0.99, 0.99, 0.7886944540721244, 0.8130524323511983, 0.8690650649680249, 0.5066828416654781, 0.8741466718323995, 0.01, 0.46965469441652247, 0.700462245565036, 0.99, 0.828928614623208, 0.07892017980298323, 0.24278611611995038, 0.37206242888813906, 0.6845504592311628, 0.5504143421762422, 0.5562049277961553, 0.4774813943127095, 0.9316352089469471, 0.01, 0.6918615786480016, 0.4883283692617678, 0.02996326165020058, 0.9749273490607647, 0.18394219840183995, 0.7574408796822615, 0.6455435060042538, 0.07832159715803438, 0.5814823819780064, 0.16999968821072314, 0.3025121352380274, 0.34263837981428324, 0.01, 0.025356626219473377, 0.8883190837237334, 0.4460293266809121]
Training loss = 0.03326597511768341
step = 0, Training Accuracy: 0.46
Validation Accuracy: 0.61875
Training loss = 0.03540442188580831
step = 1, Training Accuracy: 0.4166666666666667
Training loss = 0.03409758786360423
step = 2, Training Accuracy: 0.4866666666666667
Training loss = 0.03489329814910889
step = 3, Training Accuracy: 0.43666666666666665
Training loss = 0.03506245950857798
step = 4, Training Accuracy: 0.45
Training loss = 0.034844740827878314
step = 5, Training Accuracy: 0.4266666666666667
Validation Accuracy: 0.635
Training loss = 0.034707969824473064
step = 6, Training Accuracy: 0.4633333333333333
Training loss = 0.03407675405343374
step = 7, Training Accuracy: 0.48
Training loss = 0.035243576566378276
step = 8, Training Accuracy: 0.44
Training loss = 0.033883341749509174
step = 9, Training Accuracy: 0.45
Training loss = 0.03391435364882151
step = 10, Training Accuracy: 0.43333333333333335
Validation Accuracy: 0.63
Training loss = 0.0354876176516215
step = 11, Training Accuracy: 0.4633333333333333
Training loss = 0.033719271421432495
step = 12, Training Accuracy: 0.44
Training loss = 0.034203446706136065
step = 13, Training Accuracy: 0.44333333333333336
Training loss = 0.035164835850397744
step = 14, Training Accuracy: 0.44
Validation Accuracy: 0.62625
params:  [0.6389626800821399, 0.621578514644024, 0.7637435122723595, 0.3410529645411017, 0.2509156419670167, 0.14523281438931848, 0.1608776302137138, 0.5186296461458156, 0.5298084357663857, 0.5449920716601151, 0.44340651838030476, 0.20312051229817243, 0.3510408475020613, 0.16760834891496096, 0.43608252822303367, 0.01, 0.6428446310915643, 0.32895682427490897, 0.13729326192782842, 0.7333400735723656, 0.2796823856646687, 0.8873642715309389, 0.22880121346124938, 0.3519247619280157, 0.5384712203302922, 0.14326751337441734, 0.22340680246465194, 0.317548252799452, 0.01, 0.7749125525765663, 0.7633471356858427, 0.16529615183726817, 0.8221114132326902, 0.19975863077076825, 0.2970983609302457, 0.43261867260035514, 0.05365935823673848, 0.8748134241735569, 0.5040969410212751, 0.42116794697437115, 0.737022856385008, 0.6284991723616197, 0.01, 0.22971627538947492, 0.8213355930032716, 0.22937987045559177, 0.19212389553077736, 0.6902190672320075, 0.8408959381881753, 0.3951530257306778, 0.99, 0.763147213526428, 0.05549324709530745, 0.011304862247293546, 0.1423152876295061, 0.4186786082357765, 0.7371089696907298, 0.6604103975283366, 0.842083234054615, 0.49561433077884437, 0.9075019951354782, 0.8084977747563714, 0.5463913699828491, 0.7945741987668508, 0.7923739999566091, 0.99, 0.99, 0.01, 0.3402822328042309, 0.667473212547203, 0.6211934419771065, 0.5971555332884526, 0.6362661661985005, 0.22347115369259662, 0.99, 0.01, 0.8647543896987837, 0.9355914436321734, 0.357749000364432, 0.9849923202115756, 0.5498950967721258, 0.99, 0.8654956672443819, 0.0829436439565896, 0.6014935653544773, 0.5143567819680388, 0.1082965527750876, 0.33032942108903973, 0.03657250665932835, 0.5703776807082863, 0.626514879442226, 0.20357071945781152]
[0.6389626800821399, 0.621578514644024, 0.7637435122723595, 0.3410529645411017, 0.2509156419670167, 0.14523281438931848, 0.1608776302137138, 0.5186296461458156, 0.5298084357663857, 0.5449920716601151, 0.44340651838030476, 0.20312051229817243, 0.3510408475020613, 0.16760834891496096, 0.43608252822303367, 0.01, 0.6428446310915643, 0.32895682427490897, 0.13729326192782842, 0.7333400735723656, 0.2796823856646687, 0.8873642715309389, 0.22880121346124938, 0.3519247619280157, 0.5384712203302922, 0.14326751337441734, 0.22340680246465194, 0.317548252799452, 0.01, 0.7749125525765663, 0.7633471356858427, 0.16529615183726817, 0.8221114132326902, 0.19975863077076825, 0.2970983609302457, 0.43261867260035514, 0.05365935823673848, 0.8748134241735569, 0.5040969410212751, 0.42116794697437115, 0.737022856385008, 0.6284991723616197, 0.01, 0.22971627538947492, 0.8213355930032716, 0.22937987045559177, 0.19212389553077736, 0.6902190672320075, 0.8408959381881753, 0.3951530257306778, 0.99, 0.763147213526428, 0.05549324709530745, 0.011304862247293546, 0.1423152876295061, 0.4186786082357765, 0.7371089696907298, 0.6604103975283366, 0.842083234054615, 0.49561433077884437, 0.9075019951354782, 0.8084977747563714, 0.5463913699828491, 0.7945741987668508, 0.7923739999566091, 0.99, 0.99, 0.01, 0.3402822328042309, 0.667473212547203, 0.6211934419771065, 0.5971555332884526, 0.6362661661985005, 0.22347115369259662, 0.99, 0.01, 0.8647543896987837, 0.9355914436321734, 0.357749000364432, 0.9849923202115756, 0.5498950967721258, 0.99, 0.8654956672443819, 0.0829436439565896, 0.6014935653544773, 0.5143567819680388, 0.1082965527750876, 0.33032942108903973, 0.03657250665932835, 0.5703776807082863, 0.626514879442226, 0.20357071945781152]
Training loss = 0.03431895732879639
step = 0, Training Accuracy: 0.43666666666666665
Validation Accuracy: 0.61875
Training loss = 0.03454764386018117
step = 1, Training Accuracy: 0.45
Training loss = 0.035341829260190326
step = 2, Training Accuracy: 0.42
Training loss = 0.035446353753407794
step = 3, Training Accuracy: 0.43
Training loss = 0.034812243382136024
step = 4, Training Accuracy: 0.47333333333333333
Training loss = 0.03487690448760986
step = 5, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.6025
Training loss = 0.03482748667399089
step = 6, Training Accuracy: 0.42
Training loss = 0.0335179611047109
step = 7, Training Accuracy: 0.5133333333333333
Training loss = 0.03490642825762431
step = 8, Training Accuracy: 0.4066666666666667
Training loss = 0.034290363788604734
step = 9, Training Accuracy: 0.45
Training loss = 0.03466513911883036
step = 10, Training Accuracy: 0.44
Validation Accuracy: 0.62
Training loss = 0.03466170390446981
step = 11, Training Accuracy: 0.44
Training loss = 0.03538896679878235
step = 12, Training Accuracy: 0.4533333333333333
Training loss = 0.03457466801007589
step = 13, Training Accuracy: 0.45
Training loss = 0.03553744912147522
step = 14, Training Accuracy: 0.39666666666666667
Validation Accuracy: 0.6175
params:  [0.5134282545357718, 0.99, 0.9462822756065002, 0.6494816632532752, 0.3987186341929324, 0.23840613819364392, 0.2264076901506562, 0.773536079926234, 0.5173938167975203, 0.01, 0.0835527293962745, 0.33197378519032955, 0.23805877025904731, 0.3320385802079924, 0.20508087643860023, 0.01, 0.6411139728153419, 0.026000950183246524, 0.19484119078566922, 0.7542111468864753, 0.47412777752350704, 0.36450110733582936, 0.08253829344989087, 0.4115628330355829, 0.31983853761713, 0.40250517750459175, 0.17286513075617296, 0.517023040777064, 0.01, 0.13264559028116743, 0.7628833234798655, 0.6014938491365869, 0.5222880633522626, 0.44684151684373574, 0.3058320711192223, 0.1730651074762234, 0.20194655393302383, 0.7196072037642273, 0.9391971498024558, 0.5778552877994735, 0.6368197747076723, 0.7305578770035078, 0.01, 0.20798254052389037, 0.7697235797541087, 0.8016577393453286, 0.0568920216334579, 0.2707464200716867, 0.6159521393990017, 0.8850955883104928, 0.99, 0.8948930135676172, 0.2557743438774116, 0.01, 0.43236287368254617, 0.6661084878928374, 0.9131564804907585, 0.5055264045390154, 0.99, 0.31615708312580804, 0.43126573368144006, 0.861986733508864, 0.6440828078428371, 0.971561582965079, 0.6168684876639021, 0.99, 0.7528969045364955, 0.01, 0.021277085352548242, 0.2709866710386748, 0.6587656228796279, 0.4786270499858496, 0.7726747823565724, 0.4782112939749136, 0.6351604136587623, 0.07373137487401585, 0.8031281810680447, 0.5653381656506183, 0.18513729626611886, 0.99, 0.2687035101015207, 0.5944365017827329, 0.19316289757737826, 0.4758425639948175, 0.4436721986252676, 0.36002047109551283, 0.34670524336816094, 0.23701303870838955, 0.01, 0.40806092085331874, 0.8452579949131527, 0.08362572843039263]
[0.5134282545357718, 0.99, 0.9462822756065002, 0.6494816632532752, 0.3987186341929324, 0.23840613819364392, 0.2264076901506562, 0.773536079926234, 0.5173938167975203, 0.01, 0.0835527293962745, 0.33197378519032955, 0.23805877025904731, 0.3320385802079924, 0.20508087643860023, 0.01, 0.6411139728153419, 0.026000950183246524, 0.19484119078566922, 0.7542111468864753, 0.47412777752350704, 0.36450110733582936, 0.08253829344989087, 0.4115628330355829, 0.31983853761713, 0.40250517750459175, 0.17286513075617296, 0.517023040777064, 0.01, 0.13264559028116743, 0.7628833234798655, 0.6014938491365869, 0.5222880633522626, 0.44684151684373574, 0.3058320711192223, 0.1730651074762234, 0.20194655393302383, 0.7196072037642273, 0.9391971498024558, 0.5778552877994735, 0.6368197747076723, 0.7305578770035078, 0.01, 0.20798254052389037, 0.7697235797541087, 0.8016577393453286, 0.0568920216334579, 0.2707464200716867, 0.6159521393990017, 0.8850955883104928, 0.99, 0.8948930135676172, 0.2557743438774116, 0.01, 0.43236287368254617, 0.6661084878928374, 0.9131564804907585, 0.5055264045390154, 0.99, 0.31615708312580804, 0.43126573368144006, 0.861986733508864, 0.6440828078428371, 0.971561582965079, 0.6168684876639021, 0.99, 0.7528969045364955, 0.01, 0.021277085352548242, 0.2709866710386748, 0.6587656228796279, 0.4786270499858496, 0.7726747823565724, 0.4782112939749136, 0.6351604136587623, 0.07373137487401585, 0.8031281810680447, 0.5653381656506183, 0.18513729626611886, 0.99, 0.2687035101015207, 0.5944365017827329, 0.19316289757737826, 0.4758425639948175, 0.4436721986252676, 0.36002047109551283, 0.34670524336816094, 0.23701303870838955, 0.01, 0.40806092085331874, 0.8452579949131527, 0.08362572843039263]
Training loss = 0.03440441012382507
step = 0, Training Accuracy: 0.45
Validation Accuracy: 0.635
Training loss = 0.033208709756533304
step = 1, Training Accuracy: 0.5266666666666666
Training loss = 0.03429417272408803
step = 2, Training Accuracy: 0.46
Training loss = 0.034585778713226316
step = 3, Training Accuracy: 0.44
Training loss = 0.03347532014052073
step = 4, Training Accuracy: 0.49333333333333335
Training loss = 0.03381383339564006
step = 5, Training Accuracy: 0.4766666666666667
Validation Accuracy: 0.64
Training loss = 0.0341169277826945
step = 6, Training Accuracy: 0.48
Training loss = 0.03316900591055552
step = 7, Training Accuracy: 0.5
Training loss = 0.03489439050356547
step = 8, Training Accuracy: 0.5
Training loss = 0.032243515054384865
step = 9, Training Accuracy: 0.5033333333333333
Training loss = 0.03382726569970449
step = 10, Training Accuracy: 0.48333333333333334
Validation Accuracy: 0.64
Training loss = 0.03362602750460307
step = 11, Training Accuracy: 0.49666666666666665
Training loss = 0.03361959795157115
step = 12, Training Accuracy: 0.5
Training loss = 0.03398728092511495
step = 13, Training Accuracy: 0.47
Training loss = 0.03340506772200266
step = 14, Training Accuracy: 0.4533333333333333
Validation Accuracy: 0.63
16 	8     	0.622031	0.0107699 	0.605  	0.6375 
params:  [0.32509688012876536, 0.9717156537714791, 0.9009672470674718, 0.6977475165314774, 0.5915154020592336, 0.01, 0.1657134259131473, 0.39896383315133443, 0.7607782785915802, 0.01, 0.14271671557536533, 0.2847573039924158, 0.07450509799995819, 0.4333637781009801, 0.7147226366478743, 0.09262078882898313, 0.4777137930479515, 0.01, 0.13407106796103452, 0.4553396782353383, 0.4818121194209724, 0.4603461770674405, 0.3392256706838121, 0.16005749248495688, 0.19993307325948514, 0.1261611292390617, 0.01, 0.4315989932373515, 0.1159324416269058, 0.6122856434844864, 0.6248655771103204, 0.26508266687855375, 0.5867450811267296, 0.11561806111775577, 0.2678111608326016, 0.49557669241970354, 0.20137873334856735, 0.8996475162971621, 0.44289780881893426, 0.3375121212956019, 0.3344299407324546, 0.62659903843797, 0.04645240349106734, 0.10554907969058573, 0.8192950558612526, 0.7765531333289187, 0.30268459602421216, 0.6962420520153499, 0.7236713002650286, 0.713384240028612, 0.7943757987533755, 0.5471724111919103, 0.14804995932590506, 0.14751189975857004, 0.46470216341736614, 0.3659592982097808, 0.9402684844038116, 0.6623620279023663, 0.99, 0.5795321252597673, 0.882208555320591, 0.99, 0.7312116616260018, 0.99, 0.7300316104576487, 0.8559243890084746, 0.48193590902461747, 0.01, 0.17506906010211387, 0.31686415080670355, 0.6364108974979832, 0.7538419304285386, 0.5822534544011667, 0.6185263797629664, 0.6001714393631234, 0.05152564234437307, 0.13475055732501895, 0.9586290342552852, 0.09211327932253624, 0.7915760082846557, 0.49268098420634493, 0.942458140079192, 0.39547845468061926, 0.18527772473297716, 0.4794639513339496, 0.2609666449896356, 0.14625503898918776, 0.024386755266275068, 0.05265584574699121, 0.3168030182609623, 0.5467033538305475, 0.39026845167028873]
[0.32509688012876536, 0.9717156537714791, 0.9009672470674718, 0.6977475165314774, 0.5915154020592336, 0.01, 0.1657134259131473, 0.39896383315133443, 0.7607782785915802, 0.01, 0.14271671557536533, 0.2847573039924158, 0.07450509799995819, 0.4333637781009801, 0.7147226366478743, 0.09262078882898313, 0.4777137930479515, 0.01, 0.13407106796103452, 0.4553396782353383, 0.4818121194209724, 0.4603461770674405, 0.3392256706838121, 0.16005749248495688, 0.19993307325948514, 0.1261611292390617, 0.01, 0.4315989932373515, 0.1159324416269058, 0.6122856434844864, 0.6248655771103204, 0.26508266687855375, 0.5867450811267296, 0.11561806111775577, 0.2678111608326016, 0.49557669241970354, 0.20137873334856735, 0.8996475162971621, 0.44289780881893426, 0.3375121212956019, 0.3344299407324546, 0.62659903843797, 0.04645240349106734, 0.10554907969058573, 0.8192950558612526, 0.7765531333289187, 0.30268459602421216, 0.6962420520153499, 0.7236713002650286, 0.713384240028612, 0.7943757987533755, 0.5471724111919103, 0.14804995932590506, 0.14751189975857004, 0.46470216341736614, 0.3659592982097808, 0.9402684844038116, 0.6623620279023663, 0.99, 0.5795321252597673, 0.882208555320591, 0.99, 0.7312116616260018, 0.99, 0.7300316104576487, 0.8559243890084746, 0.48193590902461747, 0.01, 0.17506906010211387, 0.31686415080670355, 0.6364108974979832, 0.7538419304285386, 0.5822534544011667, 0.6185263797629664, 0.6001714393631234, 0.05152564234437307, 0.13475055732501895, 0.9586290342552852, 0.09211327932253624, 0.7915760082846557, 0.49268098420634493, 0.942458140079192, 0.39547845468061926, 0.18527772473297716, 0.4794639513339496, 0.2609666449896356, 0.14625503898918776, 0.024386755266275068, 0.05265584574699121, 0.3168030182609623, 0.5467033538305475, 0.39026845167028873]
Training loss = 0.03325660208861033
step = 0, Training Accuracy: 0.49333333333333335
Validation Accuracy: 0.63625
Training loss = 0.033950628439585365
step = 1, Training Accuracy: 0.45
Training loss = 0.03343339463075002
step = 2, Training Accuracy: 0.4666666666666667
Training loss = 0.03473057190577189
step = 3, Training Accuracy: 0.47333333333333333
Training loss = 0.03356398006280263
step = 4, Training Accuracy: 0.47
Training loss = 0.03456983864307404
step = 5, Training Accuracy: 0.46
Validation Accuracy: 0.645
Training loss = 0.034435187379519144
step = 6, Training Accuracy: 0.41
Training loss = 0.03473289012908935
step = 7, Training Accuracy: 0.45666666666666667
Training loss = 0.03451491832733154
step = 8, Training Accuracy: 0.4533333333333333
Training loss = 0.03329551617304484
step = 9, Training Accuracy: 0.5066666666666667
Training loss = 0.03359137574831645
step = 10, Training Accuracy: 0.5033333333333333
Validation Accuracy: 0.63625
Training loss = 0.03596217115720113
step = 11, Training Accuracy: 0.4166666666666667
Training loss = 0.03482982794443766
step = 12, Training Accuracy: 0.4766666666666667
Training loss = 0.03446947435537974
step = 13, Training Accuracy: 0.4633333333333333
