parameter = [0.4914, 0.4822, 0.4465, 0.2023, 0.1994, 0.201]
Training loss = 0.033883764637368065
step = 0, Training Accuracy: 0.4451785714285714
Validation Accuracy: 0.51625
Training loss = 0.030913701451250487
step = 1, Training Accuracy: 0.4825
Training loss = 0.030110790463430542
step = 2, Training Accuracy: 0.5041071428571429
Training loss = 0.0280938906116145
step = 3, Training Accuracy: 0.5635714285714286
Training loss = 0.024592964415039335
step = 4, Training Accuracy: 0.6375
Training loss = 0.023469209910503455
step = 5, Training Accuracy: 0.66375
Validation Accuracy: 0.5975
Training loss = 0.02312719065696001
step = 6, Training Accuracy: 0.6698214285714286
Training loss = 0.022626389882394245
step = 7, Training Accuracy: 0.6728571428571428
Training loss = 0.021978578194975854
step = 8, Training Accuracy: 0.6832142857142857
Training loss = 0.021756204888224603
step = 9, Training Accuracy: 0.6928571428571428
Training loss = 0.02192016310989857
step = 10, Training Accuracy: 0.6857142857142857
Validation Accuracy: 0.76875
Training loss = 0.021285093937601363
step = 11, Training Accuracy: 0.6967857142857142
Training loss = 0.021609325206705502
step = 12, Training Accuracy: 0.6939285714285715
Training loss = 0.021216677469866618
step = 13, Training Accuracy: 0.6907142857142857
Training loss = 0.020936995473291194
step = 14, Training Accuracy: 0.6992857142857143
Training loss = 0.020881952244256225
step = 15, Training Accuracy: 0.7005357142857143
Validation Accuracy: 0.75
Training loss = 0.020675528954182353
step = 16, Training Accuracy: 0.7092857142857143
Training loss = 0.020727244386715547
step = 17, Training Accuracy: 0.7082142857142857
Training loss = 0.020540866223829134
step = 18, Training Accuracy: 0.70625
Training loss = 0.020758226662874222
step = 19, Training Accuracy: 0.7091071428571428
Training loss = 0.020209761347089496
step = 20, Training Accuracy: 0.7107142857142857
Validation Accuracy: 0.76625
Training loss = 0.020186992617590088
step = 21, Training Accuracy: 0.71875
Training loss = 0.019895376084106308
step = 22, Training Accuracy: 0.7096428571428571
Training loss = 0.020245988416884627
step = 23, Training Accuracy: 0.7082142857142857
Training loss = 0.020233363338879175
step = 24, Training Accuracy: 0.7210714285714286
Training loss = 0.019573864197092398
step = 25, Training Accuracy: 0.7232142857142857
Validation Accuracy: 0.77125
Training loss = 0.01970114493476493
step = 26, Training Accuracy: 0.7175
Training loss = 0.01970417319663933
step = 27, Training Accuracy: 0.7121428571428572
Training loss = 0.019690494973744664
step = 28, Training Accuracy: 0.7176785714285714
Training loss = 0.019761139713227748
step = 29, Training Accuracy: 0.7157142857142857
Training loss = 0.019547979235649108
step = 30, Training Accuracy: 0.7273214285714286
Validation Accuracy: 0.775
Training loss = 0.019447801639991148
step = 31, Training Accuracy: 0.7219642857142857
Training loss = 0.01937369054449456
step = 32, Training Accuracy: 0.7325
Training loss = 0.01903018535780055
step = 33, Training Accuracy: 0.7307142857142858
Training loss = 0.018932414815894194
step = 34, Training Accuracy: 0.7335714285714285
Training loss = 0.01891756469649928
step = 35, Training Accuracy: 0.7396428571428572
Validation Accuracy: 0.775
Training loss = 0.019076522402465344
step = 36, Training Accuracy: 0.7351785714285715
Training loss = 0.018506176684583937
step = 37, Training Accuracy: 0.7417857142857143
Training loss = 0.018674284054764678
step = 38, Training Accuracy: 0.7373214285714286
Training loss = 0.019018950664571353
step = 39, Training Accuracy: 0.7316071428571429
Training loss = 0.018892584262149674
step = 40, Training Accuracy: 0.7333928571428572
Validation Accuracy: 0.79
Training loss = 0.01875850836081164
step = 41, Training Accuracy: 0.7366071428571429
Training loss = 0.018792557955852576
step = 42, Training Accuracy: 0.7346428571428572
Training loss = 0.018518209973616258
step = 43, Training Accuracy: 0.7335714285714285
Training loss = 0.018483308729316507
step = 44, Training Accuracy: 0.7432142857142857
Training loss = 0.018848185863878045
step = 45, Training Accuracy: 0.73625
Validation Accuracy: 0.77875
Training loss = 0.018455091656318732
step = 46, Training Accuracy: 0.7394642857142857
Training loss = 0.01878936448267528
step = 47, Training Accuracy: 0.7314285714285714
Training loss = 0.01848086617354836
step = 48, Training Accuracy: 0.7428571428571429
Training loss = 0.018280563604618823
step = 49, Training Accuracy: 0.7398214285714285
Training loss = 0.018591231006596768
step = 50, Training Accuracy: 0.7405357142857143
Validation Accuracy: 0.7775
Training loss = 0.018155087711555617
step = 51, Training Accuracy: 0.7408928571428571
Training loss = 0.018110051761780467
step = 52, Training Accuracy: 0.7433928571428572
Training loss = 0.017808463711823735
step = 53, Training Accuracy: 0.7492857142857143
Training loss = 0.01830785676304783
step = 54, Training Accuracy: 0.74125
Training loss = 0.01805424800408738
step = 55, Training Accuracy: 0.74375
Validation Accuracy: 0.7975
Training loss = 0.018304257717515742
step = 56, Training Accuracy: 0.7391071428571429
Training loss = 0.0179044243480478
step = 57, Training Accuracy: 0.7482142857142857
Training loss = 0.01805710145937545
step = 58, Training Accuracy: 0.7517857142857143
Training loss = 0.017820476926863192
step = 59, Training Accuracy: 0.7491071428571429
Training loss = 0.017513335049152375
step = 60, Training Accuracy: 0.7455357142857143
Validation Accuracy: 0.80125
Training loss = 0.01747692528047732
step = 61, Training Accuracy: 0.7507142857142857
Training loss = 0.017894537491457804
step = 62, Training Accuracy: 0.7489285714285714
Training loss = 0.017770934935126985
step = 63, Training Accuracy: 0.7467857142857143
Training loss = 0.018267469917024885
step = 64, Training Accuracy: 0.7458928571428571
Training loss = 0.017433771139809064
step = 65, Training Accuracy: 0.75375
Validation Accuracy: 0.79375
Training loss = 0.017454126253724098
step = 66, Training Accuracy: 0.7558928571428571
Training loss = 0.01747986494430474
step = 67, Training Accuracy: 0.7528571428571429
Training loss = 0.017431429640523025
step = 68, Training Accuracy: 0.7532142857142857
Training loss = 0.017707192056945393
step = 69, Training Accuracy: 0.7525
Training loss = 0.017660786685134683
step = 70, Training Accuracy: 0.7553571428571428
Validation Accuracy: 0.8125
Training loss = 0.017573415557188648
step = 71, Training Accuracy: 0.7476785714285714
Training loss = 0.017824588300926345
step = 72, Training Accuracy: 0.7480357142857142
Training loss = 0.017184239546103135
step = 73, Training Accuracy: 0.7558928571428571
Training loss = 0.01751771830022335
step = 74, Training Accuracy: 0.7551785714285715
Training loss = 0.017424450388976505
step = 75, Training Accuracy: 0.7516071428571428
Validation Accuracy: 0.79875
Training loss = 0.01732491905667952
step = 76, Training Accuracy: 0.7578571428571429
Training loss = 0.01708582542836666
step = 77, Training Accuracy: 0.7596428571428572
Training loss = 0.01752595663602863
step = 78, Training Accuracy: 0.7517857142857143
Training loss = 0.017439597781215396
step = 79, Training Accuracy: 0.75375
Training loss = 0.0170903791859746
step = 80, Training Accuracy: 0.7680357142857143
Validation Accuracy: 0.81125
Training loss = 0.017260545428310122
step = 81, Training Accuracy: 0.7623214285714286
Training loss = 0.01729547694325447
step = 82, Training Accuracy: 0.7569642857142858
Training loss = 0.017102529709892615
step = 83, Training Accuracy: 0.76375
Training loss = 0.01727015428777252
step = 84, Training Accuracy: 0.7573214285714286
Training loss = 0.017309413589537144
step = 85, Training Accuracy: 0.75625
Validation Accuracy: 0.81
Training loss = 0.01701619760266372
step = 86, Training Accuracy: 0.7641071428571429
Training loss = 0.017393724934331008
step = 87, Training Accuracy: 0.7496428571428572
Training loss = 0.01700465067955
step = 88, Training Accuracy: 0.7641071428571429
Training loss = 0.017120114415884017
step = 89, Training Accuracy: 0.7571428571428571
Training loss = 0.016997948975435325
step = 90, Training Accuracy: 0.7623214285714286
Validation Accuracy: 0.8075
Training loss = 0.017038866377302578
step = 91, Training Accuracy: 0.7551785714285715
Training loss = 0.01761523703911475
step = 92, Training Accuracy: 0.7510714285714286
Training loss = 0.017357369219618186
step = 93, Training Accuracy: 0.7571428571428571
Training loss = 0.017320183824215615
step = 94, Training Accuracy: 0.7594642857142857
Training loss = 0.01698872211788382
step = 95, Training Accuracy: 0.7596428571428572
Validation Accuracy: 0.81375
Training loss = 0.017027695870825223
step = 96, Training Accuracy: 0.7566071428571428
Training loss = 0.01720881908067635
step = 97, Training Accuracy: 0.7619642857142858
Training loss = 0.017061791941523553
step = 98, Training Accuracy: 0.7619642857142858
Training loss = 0.017146550613854613
step = 99, Training Accuracy: 0.7583928571428571
Validation Accuracy: 0.81
