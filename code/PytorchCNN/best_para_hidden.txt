params:  [0.4546697027176039, 0.686768414501576, 0.9204193933550783, 0.2179701676469351, 0.745324316140274, 0.1048188233508859, 0.99, 0.7815456771647684, 0.5141275004897095, 0.01, 0.7030585412151354, 0.6010050009290273, 0.9232729239222149, 0.22283673116023392, 0.01, 0.7843266009278341, 0.13323349436411253, 0.01, 0.18908445647472388, 0.8208260937274724, 0.4242244345592337, 0.3905102105198264, 0.5607986532858978, 0.01]
[0.4546697027176039, 0.686768414501576, 0.9204193933550783, 0.2179701676469351, 0.745324316140274, 0.1048188233508859, 0.99, 0.7815456771647684, 0.5141275004897095, 0.01, 0.7030585412151354, 0.6010050009290273, 0.9232729239222149, 0.22283673116023392, 0.01, 0.7843266009278341, 0.13323349436411253, 0.01, 0.18908445647472388, 0.8208260937274724, 0.4242244345592337, 0.3905102105198264, 0.5607986532858978, 0.01]
Training loss = 0.03442081652581692
step = 0, Training Accuracy: 0.3982142857142857
Validation Accuracy: 0.50125
Training loss = 0.03276557690330914
step = 1, Training Accuracy: 0.4476785714285714
Training loss = 0.031679899809615955
step = 2, Training Accuracy: 0.4783928571428571
Training loss = 0.03130269038890089
step = 3, Training Accuracy: 0.48125
Training loss = 0.031057033836841583
step = 4, Training Accuracy: 0.49
Training loss = 0.030615990938884872
step = 5, Training Accuracy: 0.5026785714285714
Validation Accuracy: 0.565
Training loss = 0.030315636854086603
step = 6, Training Accuracy: 0.5105357142857143
Training loss = 0.029469983567084586
step = 7, Training Accuracy: 0.5357142857142857
Training loss = 0.029222889893821307
step = 8, Training Accuracy: 0.5430357142857143
Training loss = 0.028712904921599797
step = 9, Training Accuracy: 0.5566071428571429
Training loss = 0.027466040541018758
step = 10, Training Accuracy: 0.5741071428571428
Validation Accuracy: 0.62875
Training loss = 0.025624393203428814
step = 11, Training Accuracy: 0.6066071428571429
Training loss = 0.02366678802030427
step = 12, Training Accuracy: 0.6464285714285715
Training loss = 0.022667006371276718
step = 13, Training Accuracy: 0.6551785714285714
Training loss = 0.022320910543203353
step = 14, Training Accuracy: 0.6598214285714286
Training loss = 0.02136637721210718
step = 15, Training Accuracy: 0.6842857142857143
Validation Accuracy: 0.74125
Training loss = 0.021689967113946166
step = 16, Training Accuracy: 0.6771428571428572
Training loss = 0.020798718498221465
step = 17, Training Accuracy: 0.695
Training loss = 0.020420351273247175
step = 18, Training Accuracy: 0.6996428571428571
Training loss = 0.020374018092240605
step = 19, Training Accuracy: 0.6948214285714286
Training loss = 0.01974132063133376
step = 20, Training Accuracy: 0.7130357142857143
Validation Accuracy: 0.7625
Training loss = 0.019819943649428233
step = 21, Training Accuracy: 0.7076785714285714
Training loss = 0.01950719069157328
step = 22, Training Accuracy: 0.7114285714285714
Training loss = 0.019525841266981193
step = 23, Training Accuracy: 0.7175
Training loss = 0.019478479214012624
step = 24, Training Accuracy: 0.7114285714285714
Training loss = 0.018879504624222006
step = 25, Training Accuracy: 0.7157142857142857
Validation Accuracy: 0.76
Training loss = 0.01868464719504118
step = 26, Training Accuracy: 0.7180357142857143
Training loss = 0.018805286485169614
step = 27, Training Accuracy: 0.7226785714285714
Training loss = 0.018635680436023642
step = 28, Training Accuracy: 0.7260714285714286
Training loss = 0.018444451189466884
step = 29, Training Accuracy: 0.7341071428571428
Training loss = 0.018351289816200732
step = 30, Training Accuracy: 0.7321428571428571
Validation Accuracy: 0.7825
Training loss = 0.01839219098112413
step = 31, Training Accuracy: 0.7317857142857143
Training loss = 0.01840764348528215
step = 32, Training Accuracy: 0.7328571428571429
Training loss = 0.01815278263496501
step = 33, Training Accuracy: 0.7305357142857143
Training loss = 0.018085203394293786
step = 34, Training Accuracy: 0.7383928571428572
Training loss = 0.018027716167271137
step = 35, Training Accuracy: 0.73125
Validation Accuracy: 0.78125
Training loss = 0.018059118991451604
step = 36, Training Accuracy: 0.7326785714285714
Training loss = 0.01802771153194564
step = 37, Training Accuracy: 0.7439285714285714
Training loss = 0.01786711839692933
step = 38, Training Accuracy: 0.7396428571428572
Training loss = 0.017393695749342443
step = 39, Training Accuracy: 0.7467857142857143
Training loss = 0.01749964584197317
step = 40, Training Accuracy: 0.75
Validation Accuracy: 0.8
Training loss = 0.017346802369824478
step = 41, Training Accuracy: 0.75125
Training loss = 0.01731764772108623
step = 42, Training Accuracy: 0.7451785714285715
Training loss = 0.017242534000958716
step = 43, Training Accuracy: 0.7503571428571428
Training loss = 0.017236071079969405
step = 44, Training Accuracy: 0.7473214285714286
Training loss = 0.01709885803184339
step = 45, Training Accuracy: 0.7508928571428571
Validation Accuracy: 0.7875
Training loss = 0.017097210671220508
step = 46, Training Accuracy: 0.7542857142857143
Training loss = 0.017187153159507685
step = 47, Training Accuracy: 0.7555357142857143
Training loss = 0.016823563144675324
step = 48, Training Accuracy: 0.7594642857142857
Training loss = 0.0168280462707792
step = 49, Training Accuracy: 0.7571428571428571
Training loss = 0.01667223724935736
step = 50, Training Accuracy: 0.7566071428571428
Validation Accuracy: 0.79875
Training loss = 0.01685503260365554
step = 51, Training Accuracy: 0.7526785714285714
Training loss = 0.016824651126350676
step = 52, Training Accuracy: 0.7598214285714285
Training loss = 0.01644161313240017
step = 53, Training Accuracy: 0.7625
Training loss = 0.01648090950612511
step = 54, Training Accuracy: 0.7578571428571429
Training loss = 0.016720624108399664
step = 55, Training Accuracy: 0.7567857142857143
Validation Accuracy: 0.7975
Training loss = 0.016060638943953175
step = 56, Training Accuracy: 0.7658928571428572
Training loss = 0.0161077704546707
step = 57, Training Accuracy: 0.7698214285714285
Training loss = 0.01644736922745194
step = 58, Training Accuracy: 0.7651785714285714
Training loss = 0.016218305001301427
step = 59, Training Accuracy: 0.7707142857142857
Training loss = 0.01641011546765055
step = 60, Training Accuracy: 0.7639285714285714
Validation Accuracy: 0.7925
Training loss = 0.016305606971893993
step = 61, Training Accuracy: 0.765
Training loss = 0.016398141314940794
step = 62, Training Accuracy: 0.75875
Training loss = 0.016258551882846015
step = 63, Training Accuracy: 0.7742857142857142
Training loss = 0.01598045422562531
step = 64, Training Accuracy: 0.7723214285714286
Training loss = 0.016175437239663942
step = 65, Training Accuracy: 0.7655357142857143
Validation Accuracy: 0.80625
Training loss = 0.015772042950349195
step = 66, Training Accuracy: 0.7744642857142857
Training loss = 0.016081786903419666
step = 67, Training Accuracy: 0.7707142857142857
Training loss = 0.016081185388777938
step = 68, Training Accuracy: 0.7675
Training loss = 0.01582065378448793
step = 69, Training Accuracy: 0.7694642857142857
Training loss = 0.016001362752701555
step = 70, Training Accuracy: 0.7676785714285714
Validation Accuracy: 0.78625
Training loss = 0.015876141829150064
step = 71, Training Accuracy: 0.7641071428571429
Training loss = 0.015776659489742346
step = 72, Training Accuracy: 0.7685714285714286
Training loss = 0.01578430028366191
step = 73, Training Accuracy: 0.77375
Training loss = 0.015592569299042226
step = 74, Training Accuracy: 0.7739285714285714
Training loss = 0.015588611508054392
step = 75, Training Accuracy: 0.77625
Validation Accuracy: 0.805
Training loss = 0.015691673843456166
step = 76, Training Accuracy: 0.77875
Training loss = 0.015332647711038589
step = 77, Training Accuracy: 0.7755357142857143
Training loss = 0.0154698521271348
step = 78, Training Accuracy: 0.7782142857142857
Training loss = 0.01570532421448401
step = 79, Training Accuracy: 0.7757142857142857
Training loss = 0.0154870628831642
step = 80, Training Accuracy: 0.7796428571428572
Validation Accuracy: 0.79
Training loss = 0.015052007937005589
step = 81, Training Accuracy: 0.7842857142857143
Training loss = 0.015397074398185526
step = 82, Training Accuracy: 0.7851785714285714
Training loss = 0.015532816057758672
step = 83, Training Accuracy: 0.7825
Training loss = 0.015490197432892663
step = 84, Training Accuracy: 0.7767857142857143
Training loss = 0.01530984705047948
step = 85, Training Accuracy: 0.7826785714285714
Validation Accuracy: 0.7875
Training loss = 0.01522283451365573
step = 86, Training Accuracy: 0.7835714285714286
Training loss = 0.01508948094610657
step = 87, Training Accuracy: 0.7851785714285714
Training loss = 0.015366949630635125
step = 88, Training Accuracy: 0.7767857142857143
Training loss = 0.015264280619365828
step = 89, Training Accuracy: 0.7819642857142857
Training loss = 0.01548928608319589
step = 90, Training Accuracy: 0.7794642857142857
Validation Accuracy: 0.79875
Training loss = 0.015313476574208056
step = 91, Training Accuracy: 0.7866071428571428
Training loss = 0.015120725706219673
step = 92, Training Accuracy: 0.7803571428571429
Training loss = 0.015276651448969331
step = 93, Training Accuracy: 0.78375
Training loss = 0.015069530145930392
step = 94, Training Accuracy: 0.7857142857142857
Training loss = 0.015043484925159386
step = 95, Training Accuracy: 0.7864285714285715
Validation Accuracy: 0.795
Training loss = 0.015038430509822709
step = 96, Training Accuracy: 0.7864285714285715
Training loss = 0.01505178182785
step = 97, Training Accuracy: 0.78
Training loss = 0.01514496193134359
step = 98, Training Accuracy: 0.7885714285714286
Training loss = 0.014844308995774814
step = 99, Training Accuracy: 0.7866071428571428
Validation Accuracy: 0.7925
