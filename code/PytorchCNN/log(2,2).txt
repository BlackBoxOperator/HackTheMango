individual:  Individual('d', [64.0, 128.0, 256.0, 512.0, 1024.0, 1024.0])
Training loss = 0.06776327168302877
step = 0, Training Accuracy: 0.44625
Training loss = 0.06229153610765934
step = 1, Training Accuracy: 0.4805357142857143
Training loss = 0.06147895256323474
step = 2, Training Accuracy: 0.4832142857142857
Training loss = 0.060021439492702486
step = 3, Training Accuracy: 0.5167857142857143
Training loss = 0.056811903757708414
step = 4, Training Accuracy: 0.5544642857142857
Training loss = 0.051342602973537786
step = 5, Training Accuracy: 0.6130357142857142
Training loss = 0.048035049880189556
step = 6, Training Accuracy: 0.6485714285714286
Training loss = 0.048576497568615845
step = 7, Training Accuracy: 0.6433928571428571
Training loss = 0.04653993195188897
step = 8, Training Accuracy: 0.6614285714285715
Training loss = 0.045376893494810375
step = 9, Training Accuracy: 0.6828571428571428
Validation Accuracy: 0.7325
individual:  Individual('d', [64.0, 128.0, 256.0, 512.0, 1024.0, 1024.0])
Training loss = 0.06774563957537924
step = 0, Training Accuracy: 0.4475
Training loss = 0.06194040947726795
step = 1, Training Accuracy: 0.47732142857142856
Training loss = 0.06154904241008418
step = 2, Training Accuracy: 0.47946428571428573
Training loss = 0.05953815763550145
step = 3, Training Accuracy: 0.5073214285714286
Training loss = 0.05726407497056893
step = 4, Training Accuracy: 0.5457142857142857
Training loss = 0.05146676665438073
step = 5, Training Accuracy: 0.6282142857142857
Training loss = 0.04873291951205049
step = 6, Training Accuracy: 0.6467857142857143
Training loss = 0.04735005411186389
step = 7, Training Accuracy: 0.6658928571428572
Training loss = 0.0468992256373167
step = 8, Training Accuracy: 0.6603571428571429
Training loss = 0.04575770520206009
step = 9, Training Accuracy: 0.6721428571428572
Validation Accuracy: 0.74125
gen	nevals	avg     	std     	min   	max    
0  	2     	0.736875	0.004375	0.7325	0.74125
individual:  Individual('d', [64.0, 105.0, 135.0, 512.0, 272.0, 962.0])
Training loss = 0.06677716520215783
step = 0, Training Accuracy: 0.44571428571428573
Training loss = 0.06304956456380231
step = 1, Training Accuracy: 0.4607142857142857
Training loss = 0.06253218099474907
step = 2, Training Accuracy: 0.4680357142857143
Training loss = 0.06114609052027975
step = 3, Training Accuracy: 0.49160714285714285
Training loss = 0.059224116919296126
step = 4, Training Accuracy: 0.5151785714285714
Training loss = 0.05478296695011003
step = 5, Training Accuracy: 0.5641071428571428
Training loss = 0.05156555154493877
step = 6, Training Accuracy: 0.6166071428571429
Training loss = 0.0500685449849282
step = 7, Training Accuracy: 0.6355357142857143
Training loss = 0.0495248619094491
step = 8, Training Accuracy: 0.6330357142857143
Training loss = 0.04829808947763273
step = 9, Training Accuracy: 0.6516071428571428
Validation Accuracy: 0.75125
individual:  Individual('d', [64.0, 128.0, 256.0, 512.0, 1024.0, 1024.0])
Training loss = 0.06759275747197015
step = 0, Training Accuracy: 0.4328571428571429
Training loss = 0.06193944578724248
step = 1, Training Accuracy: 0.4833928571428571
Training loss = 0.06076011433133057
step = 2, Training Accuracy: 0.5042857142857143
Training loss = 0.05804702649159091
step = 3, Training Accuracy: 0.5344642857142857
Training loss = 0.0529107559791633
step = 4, Training Accuracy: 0.61125
Training loss = 0.04984760353607791
step = 5, Training Accuracy: 0.6310714285714286
Training loss = 0.047789456583559514
step = 6, Training Accuracy: 0.6526785714285714
Training loss = 0.046821813647236143
step = 7, Training Accuracy: 0.6626785714285715
Training loss = 0.04631292124411889
step = 8, Training Accuracy: 0.6673214285714286
Training loss = 0.04503014178680522
step = 9, Training Accuracy: 0.6766071428571429
Validation Accuracy: 0.74875
1  	2     	0.75125 	0       	0.75125	0.75125
individual:  Individual('d', [111.0, 105.0, 135.0, 275.0, 366.0, 1049.0])
Training loss = 0.06553354475115027
step = 0, Training Accuracy: 0.4373214285714286
Training loss = 0.06276283273739475
step = 1, Training Accuracy: 0.4742857142857143
Training loss = 0.06236001530928271
step = 2, Training Accuracy: 0.47517857142857145
Training loss = 0.06095853306353092
step = 3, Training Accuracy: 0.4907142857142857
Training loss = 0.06046479103820664
step = 4, Training Accuracy: 0.5067857142857143
Training loss = 0.058958495312503405
step = 5, Training Accuracy: 0.5303571428571429
Training loss = 0.05507456504872867
step = 6, Training Accuracy: 0.5735714285714286
Training loss = 0.05167444827301162
step = 7, Training Accuracy: 0.6207142857142857
Training loss = 0.04988718315958977
step = 8, Training Accuracy: 0.6339285714285714
Training loss = 0.04843963238277606
step = 9, Training Accuracy: 0.6514285714285715
Validation Accuracy: 0.715
individual:  Individual('d', [64.0, 105.0, 135.0, 512.0, 272.0, 962.0])
Training loss = 0.06702312455645629
step = 0, Training Accuracy: 0.42875
Training loss = 0.06450533832822528
step = 1, Training Accuracy: 0.4514285714285714
Training loss = 0.0636639813865934
step = 2, Training Accuracy: 0.4539285714285714
Training loss = 0.06300263276057584
step = 3, Training Accuracy: 0.4591071428571429
Training loss = 0.06180698533143316
step = 4, Training Accuracy: 0.4657142857142857
Training loss = 0.06182533983673368
step = 5, Training Accuracy: 0.4858928571428571
Training loss = 0.0613243045019252
step = 6, Training Accuracy: 0.4717857142857143
Training loss = 0.059888210743665696
step = 7, Training Accuracy: 0.5025
Training loss = 0.05913702678467546
step = 8, Training Accuracy: 0.5214285714285715
Training loss = 0.05523629048040935
step = 9, Training Accuracy: 0.5633928571428571
Validation Accuracy: 0.69125
2  	2     	0.715   	0       	0.715  	0.715  
individual:  Individual('d', [90.0, 74.0, 212.0, 382.0, 250.0, 1563.0])
Training loss = 0.0659326158463955
step = 0, Training Accuracy: 0.4367857142857143
Training loss = 0.06316719326589788
step = 1, Training Accuracy: 0.46089285714285716
Training loss = 0.06271519937685557
step = 2, Training Accuracy: 0.4685714285714286
Training loss = 0.06183139130473137
step = 3, Training Accuracy: 0.4807142857142857
Training loss = 0.06071362399629184
step = 4, Training Accuracy: 0.48642857142857143
Training loss = 0.060147626123258045
step = 5, Training Accuracy: 0.49464285714285716
Training loss = 0.05824663129236017
step = 6, Training Accuracy: 0.51875
Training loss = 0.052757233647363524
step = 7, Training Accuracy: 0.5903571428571428
Training loss = 0.050287516761038986
step = 8, Training Accuracy: 0.6228571428571429
Training loss = 0.04954793932182448
step = 9, Training Accuracy: 0.6378571428571429
Validation Accuracy: 0.7075
individual:  Individual('d', [157.0, 139.0, 271.0, 93.0, 438.0, 908.0])
Training loss = 0.06419975649033274
step = 0, Training Accuracy: 0.45571428571428574
Training loss = 0.06215215320033687
step = 1, Training Accuracy: 0.4733928571428571
Training loss = 0.061112582364252634
step = 2, Training Accuracy: 0.49107142857142855
Training loss = 0.059718424965228355
step = 3, Training Accuracy: 0.51
Training loss = 0.058894826450518196
step = 4, Training Accuracy: 0.5185714285714286
Training loss = 0.05587362004177911
step = 5, Training Accuracy: 0.5705357142857143
Training loss = 0.05063653460570744
step = 6, Training Accuracy: 0.6248214285714285
Training loss = 0.048177028511251725
step = 7, Training Accuracy: 0.6476785714285714
Training loss = 0.04777712516486645
step = 8, Training Accuracy: 0.6642857142857143
Training loss = 0.046480579716818675
step = 9, Training Accuracy: 0.66375
Validation Accuracy: 0.72125
3  	2     	0.714375	0.006875	0.7075 	0.72125
individual:  Individual('d', [360.0, 142.0, 271.0, 372.0, 1467.0, 957.0])
Training loss = 0.06722092971205712
step = 0, Training Accuracy: 0.44660714285714287
Training loss = 0.061796692333051136
step = 1, Training Accuracy: 0.4789285714285714
Training loss = 0.060686073441590584
step = 2, Training Accuracy: 0.49464285714285716
Training loss = 0.05985561589045184
step = 3, Training Accuracy: 0.5042857142857143
Training loss = 0.05974290759435722
step = 4, Training Accuracy: 0.5157142857142857
Training loss = 0.055331055862563
step = 5, Training Accuracy: 0.5742857142857143
Training loss = 0.051266093738377094
step = 6, Training Accuracy: 0.6166071428571429
Training loss = 0.04904651960091932
step = 7, Training Accuracy: 0.6433928571428571
Training loss = 0.04765370512115104
step = 8, Training Accuracy: 0.6596428571428572
Training loss = 0.046252424674374716
step = 9, Training Accuracy: 0.67
Validation Accuracy: 0.71875
individual:  Individual('d', [368.0, 488.0, 99.0, 138.0, 250.0, 1666.0])
Training loss = 0.06466056257486344
step = 0, Training Accuracy: 0.45714285714285713
Training loss = 0.06260391001190459
step = 1, Training Accuracy: 0.46839285714285717
Training loss = 0.06205184410725321
step = 2, Training Accuracy: 0.47767857142857145
Training loss = 0.06135772570967674
step = 3, Training Accuracy: 0.4928571428571429
Training loss = 0.06071318811603955
step = 4, Training Accuracy: 0.4955357142857143
Training loss = 0.05930580639413425
step = 5, Training Accuracy: 0.5142857142857142
Training loss = 0.057382865973881314
step = 6, Training Accuracy: 0.5426785714285715
Training loss = 0.053531161216752866
step = 7, Training Accuracy: 0.5910714285714286
Training loss = 0.050335041289883004
step = 8, Training Accuracy: 0.6219642857142857
Training loss = 0.04970549842076642
step = 9, Training Accuracy: 0.6432142857142857
Validation Accuracy: 0.71125
4  	2     	0.715   	0.00375 	0.71125	0.71875
individual:  Individual('d', [299.0, 503.0, 410.0, 60.0, 292.0, 1325.0])
Training loss = 0.06446736465607371
step = 0, Training Accuracy: 0.44803571428571426
Training loss = 0.06273471063801221
step = 1, Training Accuracy: 0.4758928571428571
Training loss = 0.06121389608298029
step = 2, Training Accuracy: 0.4923214285714286
Training loss = 0.06045015381915229
step = 3, Training Accuracy: 0.5032142857142857
Training loss = 0.05977260550217969
step = 4, Training Accuracy: 0.5171428571428571
Training loss = 0.05896800597863538
step = 5, Training Accuracy: 0.5276785714285714
Training loss = 0.05822490283421108
step = 6, Training Accuracy: 0.5358928571428572
Training loss = 0.05689233601093292
step = 7, Training Accuracy: 0.55
Training loss = 0.05117385237344674
step = 8, Training Accuracy: 0.6221428571428571
Training loss = 0.049012800481702604
step = 9, Training Accuracy: 0.6498214285714285
Validation Accuracy: 0.70625
individual:  Individual('d', [262.0, 142.0, 271.0, 254.0, 150.0, 956.0])
Training loss = 0.06623168339686734
step = 0, Training Accuracy: 0.4342857142857143
Training loss = 0.06352089192186083
step = 1, Training Accuracy: 0.45964285714285713
Training loss = 0.06293618174535888
step = 2, Training Accuracy: 0.46482142857142855
Training loss = 0.06230182538075107
step = 3, Training Accuracy: 0.4719642857142857
Training loss = 0.060843443955693924
step = 4, Training Accuracy: 0.4948214285714286
Training loss = 0.061002641724688667
step = 5, Training Accuracy: 0.50125
Training loss = 0.059511395767331124
step = 6, Training Accuracy: 0.5146428571428572
Training loss = 0.05991145263825144
step = 7, Training Accuracy: 0.5089285714285714
Training loss = 0.05618726965572153
step = 8, Training Accuracy: 0.5425
Training loss = 0.05242151758500508
step = 9, Training Accuracy: 0.6039285714285715
Validation Accuracy: 0.63875
5  	2     	0.70625 	0       	0.70625	0.70625
individual:  Individual('d', [484.0, 462.0, 286.0, 60.0, 234.0, 1404.0])
Training loss = 0.06455493566180978
step = 0, Training Accuracy: 0.4455357142857143
Training loss = 0.062267484398824825
step = 1, Training Accuracy: 0.47410714285714284
Training loss = 0.061591344901493615
step = 2, Training Accuracy: 0.4898214285714286
Training loss = 0.06062474640352385
step = 3, Training Accuracy: 0.5023214285714286
Training loss = 0.06051637602703912
step = 4, Training Accuracy: 0.5073214285714286
Training loss = 0.059639668549810135
step = 5, Training Accuracy: 0.5135714285714286
Training loss = 0.05858480388564723
step = 6, Training Accuracy: 0.5407142857142857
Training loss = 0.05659964575299195
step = 7, Training Accuracy: 0.5532142857142858
Training loss = 0.05350676277918475
step = 8, Training Accuracy: 0.5914285714285714
Training loss = 0.050722266696393487
step = 9, Training Accuracy: 0.6358928571428571
Validation Accuracy: 0.71
individual:  Individual('d', [299.0, 503.0, 410.0, 60.0, 292.0, 1325.0])
Training loss = 0.06370502665638923
step = 0, Training Accuracy: 0.4675
Training loss = 0.06216414558035987
step = 1, Training Accuracy: 0.4807142857142857
Training loss = 0.06087704234889575
step = 2, Training Accuracy: 0.5023214285714286
Training loss = 0.06017913501177515
step = 3, Training Accuracy: 0.5094642857142857
Training loss = 0.05879537185387952
step = 4, Training Accuracy: 0.5233928571428571
Training loss = 0.05766430482268334
step = 5, Training Accuracy: 0.5389285714285714
Training loss = 0.05407568501574653
step = 6, Training Accuracy: 0.5866071428571429
Training loss = 0.050395935694021836
step = 7, Training Accuracy: 0.61875
Training loss = 0.048685543068817685
step = 8, Training Accuracy: 0.6421428571428571
Training loss = 0.047312612687902794
step = 9, Training Accuracy: 0.6560714285714285
Validation Accuracy: 0.7225
6  	2     	0.7225  	0       	0.7225 	0.7225 
individual:  Individual('d', [334.0, 37.0, 410.0, 17.0, 383.0, 1326.0])
Training loss = 0.06371361671813897
step = 0, Training Accuracy: 0.45714285714285713
Training loss = 0.06082078691039767
step = 1, Training Accuracy: 0.4992857142857143
Training loss = 0.06044092660503728
step = 2, Training Accuracy: 0.4976785714285714
Training loss = 0.05872297517955303
step = 3, Training Accuracy: 0.5225
Training loss = 0.055654220048870356
step = 4, Training Accuracy: 0.5583928571428571
Training loss = 0.0509083926943796
step = 5, Training Accuracy: 0.6226785714285714
Training loss = 0.04908697443349021
step = 6, Training Accuracy: 0.6375
Training loss = 0.04688083421971117
step = 7, Training Accuracy: 0.6578571428571428
Training loss = 0.04579428836171116
step = 8, Training Accuracy: 0.6678571428571428
Training loss = 0.045424806475639345
step = 9, Training Accuracy: 0.6708928571428572
Validation Accuracy: 0.73875
individual:  Individual('d', [299.0, 21.0, 307.0, 282.0, 761.0, 1126.0])
Training loss = 0.06631527594157628
step = 0, Training Accuracy: 0.4348214285714286
Training loss = 0.062347025030425614
step = 1, Training Accuracy: 0.4780357142857143
Training loss = 0.06096566931477615
step = 2, Training Accuracy: 0.49214285714285716
Training loss = 0.060296639086944714
step = 3, Training Accuracy: 0.48875
Training loss = 0.05916016078421048
step = 4, Training Accuracy: 0.5208928571428572
Training loss = 0.05558224649301597
step = 5, Training Accuracy: 0.5701785714285714
Training loss = 0.0513810734929783
step = 6, Training Accuracy: 0.6275
Training loss = 0.048723507449030874
step = 7, Training Accuracy: 0.645
Training loss = 0.04698998283062662
step = 8, Training Accuracy: 0.66125
Training loss = 0.04589438529951232
step = 9, Training Accuracy: 0.6725
Validation Accuracy: 0.7475
7  	2     	0.7475  	0       	0.7475 	0.7475 
individual:  Individual('d', [258.0, 95.0, 484.0, 133.0, 761.0, 229.0])
Training loss = 0.06495120599865914
step = 0, Training Accuracy: 0.44375
Training loss = 0.06151295573583671
step = 1, Training Accuracy: 0.48428571428571426
Training loss = 0.061052079498767856
step = 2, Training Accuracy: 0.49392857142857144
Training loss = 0.06016047633119992
step = 3, Training Accuracy: 0.5016071428571428
Training loss = 0.059421720589910236
step = 4, Training Accuracy: 0.5219642857142858
Training loss = 0.05805472343095711
step = 5, Training Accuracy: 0.5417857142857143
Training loss = 0.05553225043628897
step = 6, Training Accuracy: 0.5766071428571429
Training loss = 0.05082538195486579
step = 7, Training Accuracy: 0.6228571428571429
Training loss = 0.04835301465221814
step = 8, Training Accuracy: 0.6478571428571429
Training loss = 0.047436065572713106
step = 9, Training Accuracy: 0.6575
Validation Accuracy: 0.72875
individual:  Individual('d', [178.0, 22.0, 374.0, 440.0, 61.0, 1206.0])
Training loss = 0.06891729134534086
step = 0, Training Accuracy: 0.36660714285714285
Training loss = 0.06781549909285137
step = 1, Training Accuracy: 0.3701785714285714
Training loss = 0.06758124487740653
step = 2, Training Accuracy: 0.3607142857142857
Training loss = 0.06701879157551698
step = 3, Training Accuracy: 0.36464285714285716
Training loss = 0.06646948873996734
step = 4, Training Accuracy: 0.39035714285714285
Training loss = 0.06667183004319668
step = 5, Training Accuracy: 0.38839285714285715
Training loss = 0.06647751662347998
step = 6, Training Accuracy: 0.3775
Training loss = 0.06591713152825833
step = 7, Training Accuracy: 0.40089285714285716
Training loss = 0.0663011559844017
step = 8, Training Accuracy: 0.39839285714285716
Training loss = 0.06608435608446599
step = 9, Training Accuracy: 0.40482142857142855
Validation Accuracy: 0.4675
8  	2     	0.72875 	0       	0.72875	0.72875
individual:  Individual('d', [258.0, 95.0, 484.0, 133.0, 761.0, 229.0])
Training loss = 0.0649957704011883
step = 0, Training Accuracy: 0.44857142857142857
Training loss = 0.061867987236806324
step = 1, Training Accuracy: 0.4783928571428571
Training loss = 0.061018173141138894
step = 2, Training Accuracy: 0.4969642857142857
Training loss = 0.06025504007935524
step = 3, Training Accuracy: 0.51375
Training loss = 0.05873083869261401
step = 4, Training Accuracy: 0.5289285714285714
Training loss = 0.05423494780170066
step = 5, Training Accuracy: 0.5921428571428572
Training loss = 0.04971287145146302
step = 6, Training Accuracy: 0.6421428571428571
Training loss = 0.04800010037741491
step = 7, Training Accuracy: 0.6507142857142857
Training loss = 0.04660009667277336
step = 8, Training Accuracy: 0.665
Training loss = 0.04612707855978183
step = 9, Training Accuracy: 0.6701785714285714
Validation Accuracy: 0.7175
individual:  Individual('d', [363.0, 51.0, 388.0, 58.0, 761.0, 1184.0])
Training loss = 0.06426111380968776
step = 0, Training Accuracy: 0.45017857142857143
Training loss = 0.06132259243300983
step = 1, Training Accuracy: 0.4928571428571429
Training loss = 0.06124463002596583
step = 2, Training Accuracy: 0.4951785714285714
Training loss = 0.05967016591557435
step = 3, Training Accuracy: 0.5166071428571428
Training loss = 0.05851532923323768
step = 4, Training Accuracy: 0.5358928571428572
Training loss = 0.05738246400441442
step = 5, Training Accuracy: 0.5428571428571428
Training loss = 0.05280841133956398
step = 6, Training Accuracy: 0.60375
Training loss = 0.049764925709792546
step = 7, Training Accuracy: 0.6342857142857142
Training loss = 0.04771392314029591
step = 8, Training Accuracy: 0.6532142857142857
Training loss = 0.0463207080002342
step = 9, Training Accuracy: 0.6646428571428571
Validation Accuracy: 0.715
9  	2     	0.7175  	0       	0.7175 	0.7175 
individual:  Individual('d', [156.0, 95.0, 484.0, 133.0, 792.0, 933.0])
Training loss = 0.06446585319936275
step = 0, Training Accuracy: 0.46
Training loss = 0.06169403517884867
step = 1, Training Accuracy: 0.4905357142857143
Training loss = 0.06062277550143855
step = 2, Training Accuracy: 0.5101785714285715
Training loss = 0.059669451436826164
step = 3, Training Accuracy: 0.5228571428571429
Training loss = 0.05904638406421457
step = 4, Training Accuracy: 0.5335714285714286
Training loss = 0.056911842237625805
step = 5, Training Accuracy: 0.5580357142857143
Training loss = 0.05225246600274529
step = 6, Training Accuracy: 0.6123214285714286
Training loss = 0.049272743271929875
step = 7, Training Accuracy: 0.6383928571428571
Training loss = 0.04742470803537539
step = 8, Training Accuracy: 0.6555357142857143
Training loss = 0.046857882530561515
step = 9, Training Accuracy: 0.6653571428571429
Validation Accuracy: 0.73
individual:  Individual('d', [148.0, 77.0, 484.0, 319.0, 527.0, 229.0])
Training loss = 0.06605461620858738
step = 0, Training Accuracy: 0.44589285714285715
Training loss = 0.0628050478228501
step = 1, Training Accuracy: 0.47232142857142856
Training loss = 0.061545426196285655
step = 2, Training Accuracy: 0.47696428571428573
Training loss = 0.0604845622501203
step = 3, Training Accuracy: 0.49857142857142855
Training loss = 0.05990834816225937
step = 4, Training Accuracy: 0.5083928571428571
Training loss = 0.05850564546883106
step = 5, Training Accuracy: 0.5271428571428571
Training loss = 0.05336047114006111
step = 6, Training Accuracy: 0.5933928571428572
Training loss = 0.049847459766481604
step = 7, Training Accuracy: 0.63125
Training loss = 0.04825856261487518
step = 8, Training Accuracy: 0.6417857142857143
Training loss = 0.04791590907743999
step = 9, Training Accuracy: 0.6571428571428571
Validation Accuracy: 0.68625
10 	2     	0.73    	0       	0.73   	0.73   
individual:  Individual('d', [156.0, 95.0, 484.0, 133.0, 792.0, 933.0])
Training loss = 0.06419608904847077
step = 0, Training Accuracy: 0.4630357142857143
Training loss = 0.06180329695343971
step = 1, Training Accuracy: 0.48839285714285713
Training loss = 0.060880814652357784
step = 2, Training Accuracy: 0.5053571428571428
Training loss = 0.05933361258889948
step = 3, Training Accuracy: 0.5269642857142857
Training loss = 0.05587673901447228
step = 4, Training Accuracy: 0.5646428571428571
Training loss = 0.050798588395118714
step = 5, Training Accuracy: 0.62625
Training loss = 0.048517779824989185
step = 6, Training Accuracy: 0.6407142857142857
Training loss = 0.047051814826471465
step = 7, Training Accuracy: 0.65875
Training loss = 0.04649005955351251
step = 8, Training Accuracy: 0.6617857142857143
Training loss = 0.04574773050312485
step = 9, Training Accuracy: 0.6719642857142857
Validation Accuracy: 0.73
individual:  Individual('d', [310.0, 48.0, 60.0, 425.0, 792.0, 933.0])
Training loss = 0.06750054717063904
step = 0, Training Accuracy: 0.44839285714285715
Training loss = 0.0625370585599116
step = 1, Training Accuracy: 0.46517857142857144
Training loss = 0.061740929526942115
step = 2, Training Accuracy: 0.4875
Training loss = 0.06106886431574821
step = 3, Training Accuracy: 0.4930357142857143
Training loss = 0.05952888637781143
step = 4, Training Accuracy: 0.5110714285714286
Training loss = 0.05576024129986763
step = 5, Training Accuracy: 0.5689285714285715
Training loss = 0.051369502272989066
step = 6, Training Accuracy: 0.6180357142857142
Training loss = 0.049076350310019085
step = 7, Training Accuracy: 0.6439285714285714
Training loss = 0.047756288977605955
step = 8, Training Accuracy: 0.6585714285714286
Training loss = 0.04683455905744008
step = 9, Training Accuracy: 0.6671428571428571
Validation Accuracy: 0.73625
11 	2     	0.73625 	0       	0.73625	0.73625
individual:  Individual('d', [131.0, 219.0, 253.0, 108.0, 1476.0, 321.0])
Training loss = 0.06408584511705807
step = 0, Training Accuracy: 0.45571428571428574
Training loss = 0.06211393945983478
step = 1, Training Accuracy: 0.4876785714285714
Training loss = 0.06115183297012534
step = 2, Training Accuracy: 0.49142857142857144
Training loss = 0.05936764296676431
step = 3, Training Accuracy: 0.5210714285714285
Training loss = 0.058761452713183
step = 4, Training Accuracy: 0.53875
Training loss = 0.05426683518503393
step = 5, Training Accuracy: 0.5910714285714286
Training loss = 0.0496626991885049
step = 6, Training Accuracy: 0.63875
Training loss = 0.04793622102056231
step = 7, Training Accuracy: 0.6517857142857143
Training loss = 0.045649792067706585
step = 8, Training Accuracy: 0.67125
Training loss = 0.046349323301443035
step = 9, Training Accuracy: 0.6626785714285715
Validation Accuracy: 0.73875
individual:  Individual('d', [204.0, 370.0, 60.0, 349.0, 473.0, 545.0])
Training loss = 0.065937966927886
step = 0, Training Accuracy: 0.4519642857142857
Training loss = 0.06283202748213496
step = 1, Training Accuracy: 0.4692857142857143
Training loss = 0.06188390366733074
step = 2, Training Accuracy: 0.4767857142857143
Training loss = 0.06057452610560826
step = 3, Training Accuracy: 0.5
Training loss = 0.060060810020991735
step = 4, Training Accuracy: 0.5082142857142857
Training loss = 0.057901548040764673
step = 5, Training Accuracy: 0.5335714285714286
Training loss = 0.05355755784681865
step = 6, Training Accuracy: 0.6071428571428571
Training loss = 0.05004168502454247
step = 7, Training Accuracy: 0.635
Training loss = 0.049055812694132325
step = 8, Training Accuracy: 0.6426785714285714
Training loss = 0.047218570043998105
step = 9, Training Accuracy: 0.6533928571428571
Validation Accuracy: 0.7
12 	2     	0.73875 	0       	0.73875	0.73875
individual:  Individual('d', [49.0, 219.0, 253.0, 131.0, 1532.0, 1491.0])
Training loss = 0.0647269112084593
step = 0, Training Accuracy: 0.46839285714285717
Training loss = 0.061152826451829505
step = 1, Training Accuracy: 0.4953571428571429
Training loss = 0.059712167595114024
step = 2, Training Accuracy: 0.51125
Training loss = 0.05894770822354725
step = 3, Training Accuracy: 0.52625
Training loss = 0.05513059628329107
step = 4, Training Accuracy: 0.5873214285714285
Training loss = 0.05019881296902895
step = 5, Training Accuracy: 0.6391071428571429
Training loss = 0.04839679434363331
step = 6, Training Accuracy: 0.6542857142857142
Training loss = 0.04669502780373607
step = 7, Training Accuracy: 0.6623214285714286
Training loss = 0.045347388024841034
step = 8, Training Accuracy: 0.6746428571428571
Training loss = 0.04460699687046664
step = 9, Training Accuracy: 0.6792857142857143
Validation Accuracy: 0.74125
individual:  Individual('d', [217.0, 192.0, 386.0, 275.0, 1684.0, 321.0])
Training loss = 0.0652827473623412
step = 0, Training Accuracy: 0.4548214285714286
Training loss = 0.062087796458176206
step = 1, Training Accuracy: 0.46875
Training loss = 0.06111917784171445
step = 2, Training Accuracy: 0.4825
Training loss = 0.060278625062533786
step = 3, Training Accuracy: 0.49892857142857144
Training loss = 0.05909579395183495
step = 4, Training Accuracy: 0.5096428571428572
Training loss = 0.05983817203768662
step = 5, Training Accuracy: 0.5098214285714285
Training loss = 0.05715426217232432
step = 6, Training Accuracy: 0.5423214285714286
Training loss = 0.05324667127536876
step = 7, Training Accuracy: 0.5998214285714286
Training loss = 0.049391104749270845
step = 8, Training Accuracy: 0.6407142857142857
Training loss = 0.04674029371568135
step = 9, Training Accuracy: 0.6569642857142857
Validation Accuracy: 0.7325
13 	2     	0.74125 	0       	0.74125	0.74125
individual:  Individual('d', [437.0, 272.0, 495.0, 131.0, 1532.0, 1491.0])
Training loss = 0.06523474393146379
step = 0, Training Accuracy: 0.45339285714285715
Training loss = 0.06219480757202421
step = 1, Training Accuracy: 0.47928571428571426
Training loss = 0.06151199351463999
step = 2, Training Accuracy: 0.48232142857142857
Training loss = 0.059839086213282176
step = 3, Training Accuracy: 0.5001785714285715
Training loss = 0.059306203265275276
step = 4, Training Accuracy: 0.5244642857142857
Training loss = 0.0563570581057242
step = 5, Training Accuracy: 0.5623214285714285
Training loss = 0.05317793090960809
step = 6, Training Accuracy: 0.5942857142857143
Training loss = 0.04867737617343664
step = 7, Training Accuracy: 0.6508928571428572
Training loss = 0.04728684981486627
step = 8, Training Accuracy: 0.6541071428571429
Training loss = 0.04659560964575836
step = 9, Training Accuracy: 0.6648214285714286
Validation Accuracy: 0.72375
individual:  Individual('d', [368.0, 498.0, 39.0, 400.0, 1479.0, 606.0])
Training loss = 0.067000300266913
step = 0, Training Accuracy: 0.4519642857142857
Training loss = 0.0625736115766423
step = 1, Training Accuracy: 0.47089285714285717
Training loss = 0.061147866312946594
step = 2, Training Accuracy: 0.4807142857142857
Training loss = 0.06025495401450566
step = 3, Training Accuracy: 0.4907142857142857
Training loss = 0.059402876357947075
step = 4, Training Accuracy: 0.5028571428571429
Training loss = 0.05808144249022007
step = 5, Training Accuracy: 0.5232142857142857
Training loss = 0.053416667021811005
step = 6, Training Accuracy: 0.5953571428571428
Training loss = 0.04937862048191684
step = 7, Training Accuracy: 0.6419642857142858
Training loss = 0.048358464501798155
step = 8, Training Accuracy: 0.6528571428571428
Training loss = 0.04739901894437415
step = 9, Training Accuracy: 0.6591071428571429
Validation Accuracy: 0.745
14 	2     	0.745   	0       	0.745  	0.745  
individual:  Individual('d', [493.0, 441.0, 425.0, 163.0, 351.0, 606.0])
Training loss = 0.06469960640583719
step = 0, Training Accuracy: 0.4591071428571429
Training loss = 0.06302824672843729
step = 1, Training Accuracy: 0.4692857142857143
Training loss = 0.06207210492874895
step = 2, Training Accuracy: 0.47535714285714287
Training loss = 0.060916158642087666
step = 3, Training Accuracy: 0.49410714285714286
Training loss = 0.059960821430597985
step = 4, Training Accuracy: 0.5014285714285714
Training loss = 0.05958353434290205
step = 5, Training Accuracy: 0.5241071428571429
Training loss = 0.058201096462351935
step = 6, Training Accuracy: 0.5294642857142857
Training loss = 0.0545014488697052
step = 7, Training Accuracy: 0.5844642857142858
Training loss = 0.05024382976016828
step = 8, Training Accuracy: 0.6371428571428571
Training loss = 0.04944336116846119
step = 9, Training Accuracy: 0.6432142857142857
Validation Accuracy: 0.72375
individual:  Individual('d', [368.0, 497.0, 39.0, 400.0, 1479.0, 606.0])
Training loss = 0.06710510889334338
step = 0, Training Accuracy: 0.44392857142857145
Training loss = 0.062385808868067605
step = 1, Training Accuracy: 0.4694642857142857
Training loss = 0.06246025818799223
step = 2, Training Accuracy: 0.46339285714285716
Training loss = 0.06160966414426054
step = 3, Training Accuracy: 0.4832142857142857
Training loss = 0.06018779844045639
step = 4, Training Accuracy: 0.50125
Training loss = 0.060121602628912245
step = 5, Training Accuracy: 0.5078571428571429
Training loss = 0.058549104971545085
step = 6, Training Accuracy: 0.53625
Training loss = 0.05566556672964777
step = 7, Training Accuracy: 0.5744642857142858
Training loss = 0.05221613709415708
step = 8, Training Accuracy: 0.61625
Training loss = 0.049342731035181456
step = 9, Training Accuracy: 0.6339285714285714
Validation Accuracy: 0.69125
15 	2     	0.72375 	0       	0.72375	0.72375
individual:  Individual('d', [507.0, 413.0, 425.0, 346.0, 571.0, 2035.0])
Training loss = 0.06581444895693234
step = 0, Training Accuracy: 0.445
Training loss = 0.06301973385470254
step = 1, Training Accuracy: 0.46714285714285714
Training loss = 0.062222892131124224
step = 2, Training Accuracy: 0.47910714285714284
Training loss = 0.0612017808003085
step = 3, Training Accuracy: 0.4876785714285714
Training loss = 0.060863622788872036
step = 4, Training Accuracy: 0.4919642857142857
Training loss = 0.0605677767843008
step = 5, Training Accuracy: 0.48839285714285713
Training loss = 0.06008993188185351
step = 6, Training Accuracy: 0.5005357142857143
Training loss = 0.05944903623844896
step = 7, Training Accuracy: 0.5005357142857143
Training loss = 0.057355432382651735
step = 8, Training Accuracy: 0.5385714285714286
Training loss = 0.05310634536402566
step = 9, Training Accuracy: 0.5967857142857143
Validation Accuracy: 0.66
individual:  Individual('d', [406.0, 441.0, 72.0, 317.0, 1690.0, 1007.0])
Training loss = 0.06633547281580313
step = 0, Training Accuracy: 0.4539285714285714
Training loss = 0.062143562233873774
step = 1, Training Accuracy: 0.485
Training loss = 0.0610585484866585
step = 2, Training Accuracy: 0.49660714285714286
Training loss = 0.06166611264858927
step = 3, Training Accuracy: 0.47089285714285717
Training loss = 0.05972005722778184
step = 4, Training Accuracy: 0.5008928571428571
Training loss = 0.05954078517854214
step = 5, Training Accuracy: 0.5189285714285714
Training loss = 0.05767510161868163
step = 6, Training Accuracy: 0.5494642857142857
Training loss = 0.05274024095918451
step = 7, Training Accuracy: 0.6121428571428571
Training loss = 0.049846202885465964
step = 8, Training Accuracy: 0.6285714285714286
Training loss = 0.04793056910591466
step = 9, Training Accuracy: 0.6521428571428571
Validation Accuracy: 0.74875
16 	2     	0.74875 	0       	0.74875	0.74875
individual:  Individual('d', [126.0, 375.0, 457.0, 163.0, 577.0, 693.0])
Training loss = 0.06441332194421973
step = 0, Training Accuracy: 0.4539285714285714
Training loss = 0.06230576425790787
step = 1, Training Accuracy: 0.47625
Training loss = 0.060815739908388684
step = 2, Training Accuracy: 0.48892857142857143
Training loss = 0.06011310602937426
step = 3, Training Accuracy: 0.5028571428571429
Training loss = 0.05920890396194799
step = 4, Training Accuracy: 0.5382142857142858
Training loss = 0.05564954189317567
step = 5, Training Accuracy: 0.5757142857142857
Training loss = 0.05159154678561858
step = 6, Training Accuracy: 0.6251785714285715
Training loss = 0.047977924506579124
step = 7, Training Accuracy: 0.6578571428571428
Training loss = 0.0472383739054203
step = 8, Training Accuracy: 0.6614285714285715
Training loss = 0.04623891491975103
step = 9, Training Accuracy: 0.6696428571428571
Validation Accuracy: 0.75
individual:  Individual('d', [159.0, 368.0, 416.0, 48.0, 1690.0, 1007.0])
Training loss = 0.06376685111650399
step = 0, Training Accuracy: 0.46517857142857144
Training loss = 0.0610246211716107
step = 1, Training Accuracy: 0.49589285714285714
Training loss = 0.05971498717154775
step = 2, Training Accuracy: 0.5183928571428571
Training loss = 0.05844281928879874
step = 3, Training Accuracy: 0.5355357142857143
Training loss = 0.05459698863327503
step = 4, Training Accuracy: 0.5767857142857142
Training loss = 0.05019716440034764
step = 5, Training Accuracy: 0.6266071428571428
Training loss = 0.047805833529148786
step = 6, Training Accuracy: 0.6482142857142857
Training loss = 0.04634712760469743
step = 7, Training Accuracy: 0.6707142857142857
Training loss = 0.04504441425204277
step = 8, Training Accuracy: 0.67875
Training loss = 0.0447032049245068
step = 9, Training Accuracy: 0.6828571428571428
Validation Accuracy: 0.7225
17 	2     	0.75    	0       	0.75   	0.75   
individual:  Individual('d', [149.0, 293.0, 22.0, 435.0, 464.0, 1377.0])
Training loss = 0.0663970997184515
step = 0, Training Accuracy: 0.4566071428571429
Training loss = 0.06294088690408639
step = 1, Training Accuracy: 0.465
Training loss = 0.06228218809834549
step = 2, Training Accuracy: 0.46732142857142855
Training loss = 0.060084694496222904
step = 3, Training Accuracy: 0.49839285714285714
Training loss = 0.0565041783452034
step = 4, Training Accuracy: 0.5494642857142857
Training loss = 0.05230072704276868
step = 5, Training Accuracy: 0.6110714285714286
Training loss = 0.05026427086974893
step = 6, Training Accuracy: 0.6296428571428572
Training loss = 0.04934412891843489
step = 7, Training Accuracy: 0.6414285714285715
Training loss = 0.048696779273450376
step = 8, Training Accuracy: 0.6498214285714285
Training loss = 0.047220189278679235
step = 9, Training Accuracy: 0.6607142857142857
Validation Accuracy: 0.74875
individual:  Individual('d', [401.0, 398.0, 429.0, 324.0, 1081.0, 958.0])
Training loss = 0.06595556211258684
step = 0, Training Accuracy: 0.4607142857142857
Training loss = 0.06264311625489166
step = 1, Training Accuracy: 0.4639285714285714
Training loss = 0.06178743425224509
step = 2, Training Accuracy: 0.47464285714285714
Training loss = 0.06126013446067061
step = 3, Training Accuracy: 0.4858928571428571
Training loss = 0.059996429298605235
step = 4, Training Accuracy: 0.5035714285714286
Training loss = 0.05874321572482586
step = 5, Training Accuracy: 0.5148214285714285
Training loss = 0.056943837574550085
step = 6, Training Accuracy: 0.5614285714285714
Training loss = 0.05149562404091869
step = 7, Training Accuracy: 0.6216071428571428
Training loss = 0.050832137667707035
step = 8, Training Accuracy: 0.6298214285714285
Training loss = 0.04844211566661085
step = 9, Training Accuracy: 0.6557142857142857
Validation Accuracy: 0.74125
18 	2     	0.74875 	0       	0.74875	0.74875
individual:  Individual('d', [149.0, 297.0, 499.0, 435.0, 741.0, 1377.0])
Training loss = 0.06620704000549657
step = 0, Training Accuracy: 0.4548214285714286
Training loss = 0.062212937431676045
step = 1, Training Accuracy: 0.4760714285714286
Training loss = 0.06185234258217471
step = 2, Training Accuracy: 0.48
Training loss = 0.06141634102378573
step = 3, Training Accuracy: 0.49464285714285716
Training loss = 0.06039824531546661
step = 4, Training Accuracy: 0.49660714285714286
Training loss = 0.05912874413388116
step = 5, Training Accuracy: 0.5180357142857143
Training loss = 0.05739834249019623
step = 6, Training Accuracy: 0.5539285714285714
Training loss = 0.05191168803189482
step = 7, Training Accuracy: 0.6141071428571429
Training loss = 0.05034991828990834
step = 8, Training Accuracy: 0.63
Training loss = 0.04857153403971876
step = 9, Training Accuracy: 0.6428571428571429
Validation Accuracy: 0.70625
individual:  Individual('d', [289.0, 125.0, 438.0, 435.0, 1452.0, 1377.0])
Training loss = 0.06812408009810107
step = 0, Training Accuracy: 0.43910714285714286
Training loss = 0.062134466767311096
step = 1, Training Accuracy: 0.48160714285714284
Training loss = 0.061255287868635995
step = 2, Training Accuracy: 0.4826785714285714
Training loss = 0.060240540355443954
step = 3, Training Accuracy: 0.5067857142857143
Training loss = 0.060435082582490786
step = 4, Training Accuracy: 0.49357142857142855
Training loss = 0.06015657916665077
step = 5, Training Accuracy: 0.49839285714285714
Training loss = 0.05887804270855018
step = 6, Training Accuracy: 0.5201785714285714
Training loss = 0.05723166166671685
step = 7, Training Accuracy: 0.5594642857142857
Training loss = 0.05483289348227637
step = 8, Training Accuracy: 0.5878571428571429
Training loss = 0.04969239427575043
step = 9, Training Accuracy: 0.6314285714285715
Validation Accuracy: 0.72375
19 	2     	0.72375 	0       	0.72375	0.72375
individual:  Individual('d', [289.0, 125.0, 148.0, 177.0, 16.0, 218.0])
Training loss = 0.06813105951462473
step = 0, Training Accuracy: 0.3557142857142857
Training loss = 0.0674570774606296
step = 1, Training Accuracy: 0.37107142857142855
Training loss = 0.06715044410101005
step = 2, Training Accuracy: 0.36678571428571427
Training loss = 0.0670165751022952
step = 3, Training Accuracy: 0.37892857142857145
Training loss = 0.06659332997032574
step = 4, Training Accuracy: 0.38553571428571426
Training loss = 0.06636482877390726
step = 5, Training Accuracy: 0.39071428571428574
Training loss = 0.0664529340820653
step = 6, Training Accuracy: 0.3844642857142857
Training loss = 0.06616247530494418
step = 7, Training Accuracy: 0.38857142857142857
Training loss = 0.06602438422186034
step = 8, Training Accuracy: 0.38875
Training loss = 0.06609084822237492
step = 9, Training Accuracy: 0.3964285714285714
Validation Accuracy: 0.4425
individual:  Individual('d', [289.0, 125.0, 438.0, 435.0, 1452.0, 1377.0])
Training loss = 0.06690704803381647
step = 0, Training Accuracy: 0.4417857142857143
Training loss = 0.06209158768611295
step = 1, Training Accuracy: 0.46767857142857144
Training loss = 0.06132814189153058
step = 2, Training Accuracy: 0.48428571428571426
Training loss = 0.06036835309650217
step = 3, Training Accuracy: 0.4953571428571429
Training loss = 0.05985594698360988
step = 4, Training Accuracy: 0.5032142857142857
Training loss = 0.058270376707826345
step = 5, Training Accuracy: 0.5355357142857143
Training loss = 0.0550989913727556
step = 6, Training Accuracy: 0.5819642857142857
Training loss = 0.05025709509317364
step = 7, Training Accuracy: 0.6308928571428571
Training loss = 0.04873350002935954
step = 8, Training Accuracy: 0.6466071428571428
Training loss = 0.04812394814299686
step = 9, Training Accuracy: 0.6578571428571428
Validation Accuracy: 0.695
20 	2     	0.56875 	0.12625 	0.4425 	0.695  
individual:  Individual('d', [289.0, 70.0, 16.0, 119.0, 1377.0, 16.0])
Training loss = 0.06724362130675997
step = 0, Training Accuracy: 0.38089285714285714
Training loss = 0.06629020585545471
step = 1, Training Accuracy: 0.39785714285714285
Training loss = 0.06561200674091067
step = 2, Training Accuracy: 0.40910714285714284
Training loss = 0.06522800887269634
step = 3, Training Accuracy: 0.4325
Training loss = 0.06451573193073273
step = 4, Training Accuracy: 0.44375
Training loss = 0.06327438503503799
step = 5, Training Accuracy: 0.4344642857142857
Training loss = 0.06291843963520867
step = 6, Training Accuracy: 0.4541071428571429
Training loss = 0.062427115089126996
step = 7, Training Accuracy: 0.4575
Training loss = 0.06253610823835645
step = 8, Training Accuracy: 0.4541071428571429
Training loss = 0.061414891396250046
step = 9, Training Accuracy: 0.4569642857142857
Validation Accuracy: 0.53125
individual:  Individual('d', [123.0, 75.0, 119.0, 178.0, 459.0, 1377.0])
Training loss = 0.06491718611546925
step = 0, Training Accuracy: 0.445
Training loss = 0.06211894160934857
step = 1, Training Accuracy: 0.48625
Training loss = 0.06103797993489674
step = 2, Training Accuracy: 0.4951785714285714
Training loss = 0.059823871361357826
step = 3, Training Accuracy: 0.5058928571428571
Training loss = 0.057609406411647794
step = 4, Training Accuracy: 0.5423214285714286
Training loss = 0.05232620377093553
step = 5, Training Accuracy: 0.6239285714285714
Training loss = 0.04842403205377715
step = 6, Training Accuracy: 0.6569642857142857
Training loss = 0.04801318846642971
step = 7, Training Accuracy: 0.6521428571428571
Training loss = 0.04633129071444273
step = 8, Training Accuracy: 0.6721428571428572
Training loss = 0.04543837990079607
step = 9, Training Accuracy: 0.6678571428571428
Validation Accuracy: 0.7225
21 	2     	0.7225  	0       	0.7225 	0.7225 
individual:  Individual('d', [167.0, 75.0, 257.0, 178.0, 1702.0, 1888.0])
Training loss = 0.06551907347781318
step = 0, Training Accuracy: 0.45803571428571427
Training loss = 0.06127875660146986
step = 1, Training Accuracy: 0.48910714285714285
Training loss = 0.06056941901998861
step = 2, Training Accuracy: 0.5057142857142857
Training loss = 0.05916304296680859
step = 3, Training Accuracy: 0.5269642857142857
Training loss = 0.057500282536659925
step = 4, Training Accuracy: 0.5546428571428571
Training loss = 0.05493175760975906
step = 5, Training Accuracy: 0.5821428571428572
Training loss = 0.05000089502760342
step = 6, Training Accuracy: 0.62625
Training loss = 0.04758014732173511
step = 7, Training Accuracy: 0.6505357142857143
Training loss = 0.04643848472407886
step = 8, Training Accuracy: 0.6644642857142857
Training loss = 0.046024398425860064
step = 9, Training Accuracy: 0.6701785714285714
Validation Accuracy: 0.71625
individual:  Individual('d', [123.0, 75.0, 119.0, 178.0, 459.0, 1377.0])
Training loss = 0.06464623437396118
step = 0, Training Accuracy: 0.4575
Training loss = 0.06220278720770563
step = 1, Training Accuracy: 0.4744642857142857
Training loss = 0.0617201031850917
step = 2, Training Accuracy: 0.48160714285714284
Training loss = 0.0607831258220332
step = 3, Training Accuracy: 0.4853571428571429
Training loss = 0.060031732895544594
step = 4, Training Accuracy: 0.5001785714285715
Training loss = 0.055885424688458446
step = 5, Training Accuracy: 0.5619642857142857
Training loss = 0.05143568663192647
step = 6, Training Accuracy: 0.6225
Training loss = 0.04878336917608976
step = 7, Training Accuracy: 0.64625
Training loss = 0.04696814007524933
step = 8, Training Accuracy: 0.6614285714285715
Training loss = 0.046714405976235863
step = 9, Training Accuracy: 0.6753571428571429
Validation Accuracy: 0.7475
22 	2     	0.731875	0.015625	0.71625	0.7475 
individual:  Individual('d', [123.0, 16.0, 92.0, 464.0, 217.0, 169.0])
Training loss = 0.06777776754328182
step = 0, Training Accuracy: 0.40517857142857144
Training loss = 0.06406809769570827
step = 1, Training Accuracy: 0.43839285714285714
Training loss = 0.063117876883064
step = 2, Training Accuracy: 0.45517857142857143
Training loss = 0.06240077820207392
step = 3, Training Accuracy: 0.47017857142857145
Training loss = 0.06142760924994946
step = 4, Training Accuracy: 0.4757142857142857
Training loss = 0.05782197101839951
step = 5, Training Accuracy: 0.5219642857142858
Training loss = 0.05457372781421457
step = 6, Training Accuracy: 0.5585714285714286
Training loss = 0.05301357450229781
step = 7, Training Accuracy: 0.5760714285714286
Training loss = 0.05119198278657028
step = 8, Training Accuracy: 0.60375
Training loss = 0.05022175057125943
step = 9, Training Accuracy: 0.6255357142857143
Validation Accuracy: 0.725
individual:  Individual('d', [44.0, 142.0, 257.0, 410.0, 1586.0, 1888.0])
Training loss = 0.06620431933019842
step = 0, Training Accuracy: 0.4523214285714286
Training loss = 0.061096219633306775
step = 1, Training Accuracy: 0.49
Training loss = 0.05902334454868521
step = 2, Training Accuracy: 0.51375
Training loss = 0.052159467084067206
step = 3, Training Accuracy: 0.6075
Training loss = 0.049337414162499565
step = 4, Training Accuracy: 0.6419642857142858
Training loss = 0.04783151156135968
step = 5, Training Accuracy: 0.66125
Training loss = 0.04845573266702039
step = 6, Training Accuracy: 0.6489285714285714
Training loss = 0.04666733410741602
step = 7, Training Accuracy: 0.6639285714285714
Training loss = 0.04492357569081443
step = 8, Training Accuracy: 0.6735714285714286
Training loss = 0.04466330731021506
step = 9, Training Accuracy: 0.6814285714285714
Validation Accuracy: 0.73125
23 	2     	0.73125 	0       	0.73125	0.73125
individual:  Individual('d', [117.0, 251.0, 329.0, 236.0, 1586.0, 1358.0])
Training loss = 0.06593789670084203
step = 0, Training Accuracy: 0.44821428571428573
Training loss = 0.06192205618534769
step = 1, Training Accuracy: 0.4853571428571429
Training loss = 0.060570193986807554
step = 2, Training Accuracy: 0.5
Training loss = 0.05864847417388643
step = 3, Training Accuracy: 0.5371428571428571
Training loss = 0.05506489779267992
step = 4, Training Accuracy: 0.5791071428571428
Training loss = 0.049279496589941636
step = 5, Training Accuracy: 0.6419642857142858
Training loss = 0.04752502777214561
step = 6, Training Accuracy: 0.6582142857142858
Training loss = 0.046385466472378796
step = 7, Training Accuracy: 0.6692857142857143
Training loss = 0.04609699963458947
step = 8, Training Accuracy: 0.6685714285714286
Training loss = 0.04539209275373391
step = 9, Training Accuracy: 0.6767857142857143
Validation Accuracy: 0.72375
individual:  Individual('d', [17.0, 142.0, 458.0, 368.0, 1586.0, 1939.0])
Training loss = 0.06747212172618934
step = 0, Training Accuracy: 0.44625
Training loss = 0.06107983286891665
step = 1, Training Accuracy: 0.5035714285714286
Training loss = 0.06012773292405265
step = 2, Training Accuracy: 0.5258928571428572
Training loss = 0.05803930936115129
step = 3, Training Accuracy: 0.5660714285714286
Training loss = 0.054709355288318225
step = 4, Training Accuracy: 0.5944642857142857
Training loss = 0.050610189091946395
step = 5, Training Accuracy: 0.6339285714285714
Training loss = 0.04903004224811282
step = 6, Training Accuracy: 0.6508928571428572
Training loss = 0.04797200041690043
step = 7, Training Accuracy: 0.6555357142857143
Training loss = 0.04706334035311426
step = 8, Training Accuracy: 0.6626785714285715
Training loss = 0.04592616770948683
step = 9, Training Accuracy: 0.6755357142857142
Validation Accuracy: 0.72375
24 	2     	0.72375 	0       	0.72375	0.72375
individual:  Individual('d', [17.0, 75.0, 196.0, 131.0, 1713.0, 974.0])
Training loss = 0.06427685634366104
step = 0, Training Accuracy: 0.45035714285714284
Training loss = 0.059124993873494014
step = 1, Training Accuracy: 0.5267857142857143
Training loss = 0.05536377023373331
step = 2, Training Accuracy: 0.5755357142857143
Training loss = 0.05016937927475997
step = 3, Training Accuracy: 0.6323214285714286
Training loss = 0.04798134994826146
step = 4, Training Accuracy: 0.6521428571428571
Training loss = 0.04623105078403439
step = 5, Training Accuracy: 0.6644642857142857
Training loss = 0.045391696744731494
step = 6, Training Accuracy: 0.6732142857142858
Training loss = 0.045236276084823265
step = 7, Training Accuracy: 0.6769642857142857
Training loss = 0.04491302885115147
step = 8, Training Accuracy: 0.67625
Training loss = 0.043407308863742014
step = 9, Training Accuracy: 0.6798214285714286
Validation Accuracy: 0.75125
individual:  Individual('d', [140.0, 125.0, 323.0, 143.0, 1317.0, 609.0])
Training loss = 0.0648720603116921
step = 0, Training Accuracy: 0.4514285714285714
Training loss = 0.06148460623409067
step = 1, Training Accuracy: 0.4907142857142857
Training loss = 0.06070578116391386
step = 2, Training Accuracy: 0.49892857142857144
Training loss = 0.05898292616009712
step = 3, Training Accuracy: 0.5196428571428572
Training loss = 0.05715640783309937
step = 4, Training Accuracy: 0.5573214285714285
Training loss = 0.05171487004097019
step = 5, Training Accuracy: 0.6214285714285714
Training loss = 0.048147578191544325
step = 6, Training Accuracy: 0.6532142857142857
Training loss = 0.04701491954071181
step = 7, Training Accuracy: 0.665
Training loss = 0.04599822012973683
step = 8, Training Accuracy: 0.6673214285714286
Training loss = 0.04525277541684253
step = 9, Training Accuracy: 0.6760714285714285
Validation Accuracy: 0.74375
25 	2     	0.75125 	0       	0.75125	0.75125
individual:  Individual('d', [278.0, 75.0, 37.0, 70.0, 780.0, 1388.0])
Training loss = 0.06427735245653561
step = 0, Training Accuracy: 0.45
Training loss = 0.0611712883412838
step = 1, Training Accuracy: 0.48714285714285716
Training loss = 0.06080559687955039
step = 2, Training Accuracy: 0.5057142857142857
Training loss = 0.05969252985502992
step = 3, Training Accuracy: 0.52
Training loss = 0.059313595635550366
step = 4, Training Accuracy: 0.5317857142857143
Training loss = 0.056753852452550616
step = 5, Training Accuracy: 0.5575
Training loss = 0.053415000310965945
step = 6, Training Accuracy: 0.6066071428571429
Training loss = 0.04888029574815716
step = 7, Training Accuracy: 0.6326785714285714
Training loss = 0.047163656279444695
step = 8, Training Accuracy: 0.6560714285714285
Training loss = 0.047207474995936666
step = 9, Training Accuracy: 0.6619642857142857
Validation Accuracy: 0.72125
individual:  Individual('d', [472.0, 55.0, 508.0, 51.0, 1687.0, 974.0])
Training loss = 0.0633643386300121
step = 0, Training Accuracy: 0.47285714285714286
Training loss = 0.061719084924885204
step = 1, Training Accuracy: 0.4923214285714286
Training loss = 0.06023770720830986
step = 2, Training Accuracy: 0.5105357142857143
Training loss = 0.05929528280028275
step = 3, Training Accuracy: 0.5233928571428571
Training loss = 0.05914443763239043
step = 4, Training Accuracy: 0.5285714285714286
Training loss = 0.057967192009091374
step = 5, Training Accuracy: 0.5503571428571429
Training loss = 0.05493886822036335
step = 6, Training Accuracy: 0.5805357142857143
Training loss = 0.05079287439584732
step = 7, Training Accuracy: 0.6191071428571429
Training loss = 0.048253358687673296
step = 8, Training Accuracy: 0.6410714285714286
Training loss = 0.047045815006962845
step = 9, Training Accuracy: 0.6594642857142857
Validation Accuracy: 0.73875
26 	2     	0.73875 	0       	0.73875	0.73875
individual:  Individual('d', [65.0, 504.0, 50.0, 32.0, 1122.0, 74.0])
Training loss = 0.06327233912689345
step = 0, Training Accuracy: 0.4644642857142857
Training loss = 0.0606018390506506
step = 1, Training Accuracy: 0.4982142857142857
Training loss = 0.05941194286303861
step = 2, Training Accuracy: 0.5201785714285714
Training loss = 0.0568929100143058
step = 3, Training Accuracy: 0.56125
Training loss = 0.05044415895960161
step = 4, Training Accuracy: 0.63375
Training loss = 0.04857654371431896
step = 5, Training Accuracy: 0.6558928571428572
Training loss = 0.047313219686704024
step = 6, Training Accuracy: 0.6651785714285714
Training loss = 0.04680149144892182
step = 7, Training Accuracy: 0.6753571428571429
Training loss = 0.045787389384848734
step = 8, Training Accuracy: 0.6741071428571429
Training loss = 0.04456086489771094
step = 9, Training Accuracy: 0.6828571428571428
Validation Accuracy: 0.75625
individual:  Individual('d', [208.0, 104.0, 25.0, 69.0, 1817.0, 1473.0])
Training loss = 0.06445745646953582
step = 0, Training Accuracy: 0.46910714285714283
Training loss = 0.061370851578457015
step = 1, Training Accuracy: 0.48625
Training loss = 0.060415949715035305
step = 2, Training Accuracy: 0.4992857142857143
Training loss = 0.059368143528699874
step = 3, Training Accuracy: 0.5239285714285714
Training loss = 0.05783723787537643
step = 4, Training Accuracy: 0.5510714285714285
Training loss = 0.054635846550975524
step = 5, Training Accuracy: 0.585
Training loss = 0.05070196775453431
step = 6, Training Accuracy: 0.6173214285714286
Training loss = 0.04766824010227408
step = 7, Training Accuracy: 0.6503571428571429
Training loss = 0.047130572061453546
step = 8, Training Accuracy: 0.6589285714285714
Training loss = 0.04498310804367065
step = 9, Training Accuracy: 0.6819642857142857
Validation Accuracy: 0.74125
27 	2     	0.75625 	0       	0.75625	0.75625
individual:  Individual('d', [65.0, 504.0, 50.0, 32.0, 1122.0, 74.0])
Training loss = 0.06311282580452306
step = 0, Training Accuracy: 0.4639285714285714
Training loss = 0.060808725580573084
step = 1, Training Accuracy: 0.4994642857142857
Training loss = 0.06004243647413594
step = 2, Training Accuracy: 0.50625
Training loss = 0.05868603880916323
step = 3, Training Accuracy: 0.5298214285714286
Training loss = 0.05768010689743928
step = 4, Training Accuracy: 0.5392857142857143
Training loss = 0.055500390582851
step = 5, Training Accuracy: 0.5819642857142857
Training loss = 0.050419780212853635
step = 6, Training Accuracy: 0.6310714285714286
Training loss = 0.04816646375294242
step = 7, Training Accuracy: 0.64625
Training loss = 0.047620406166783404
step = 8, Training Accuracy: 0.66125
Training loss = 0.04611385936183589
step = 9, Training Accuracy: 0.6658928571428572
Validation Accuracy: 0.745
individual:  Individual('d', [65.0, 419.0, 101.0, 32.0, 980.0, 1520.0])
Training loss = 0.06348634010979108
step = 0, Training Accuracy: 0.46035714285714285
Training loss = 0.06147960772471769
step = 1, Training Accuracy: 0.4880357142857143
Training loss = 0.060203693828412466
step = 2, Training Accuracy: 0.5064285714285715
Training loss = 0.059339061081409454
step = 3, Training Accuracy: 0.5282142857142857
Training loss = 0.058492737944637024
step = 4, Training Accuracy: 0.5403571428571429
Training loss = 0.05776367177920682
step = 5, Training Accuracy: 0.5553571428571429
Training loss = 0.054828383390392574
step = 6, Training Accuracy: 0.5851785714285714
Training loss = 0.05092888474996601
step = 7, Training Accuracy: 0.6219642857142857
Training loss = 0.048491516592247146
step = 8, Training Accuracy: 0.6492857142857142
Training loss = 0.04676635086536408
step = 9, Training Accuracy: 0.6632142857142858
Validation Accuracy: 0.71875
28 	2     	0.745   	0       	0.745  	0.745  
individual:  Individual('d', [16.0, 413.0, 16.0, 200.0, 1270.0, 136.0])
Training loss = 0.06563430200730051
step = 0, Training Accuracy: 0.44035714285714284
Training loss = 0.0615051267934697
step = 1, Training Accuracy: 0.48642857142857143
Training loss = 0.060240378060511184
step = 2, Training Accuracy: 0.5053571428571428
Training loss = 0.06009669763701302
step = 3, Training Accuracy: 0.5183928571428571
Training loss = 0.0571747343561479
step = 4, Training Accuracy: 0.56875
Training loss = 0.05411443030195577
step = 5, Training Accuracy: 0.5980357142857143
Training loss = 0.051174379885196686
step = 6, Training Accuracy: 0.6296428571428572
Training loss = 0.0488472675212792
step = 7, Training Accuracy: 0.64875
Training loss = 0.04853018191776105
step = 8, Training Accuracy: 0.6571428571428571
Training loss = 0.04794726084917784
step = 9, Training Accuracy: 0.6576785714285714
Validation Accuracy: 0.75
individual:  Individual('d', [315.0, 504.0, 77.0, 91.0, 1122.0, 74.0])
Training loss = 0.0639755619530167
step = 0, Training Accuracy: 0.46285714285714286
Training loss = 0.06157321789434978
step = 1, Training Accuracy: 0.4928571428571429
Training loss = 0.06130045735410282
step = 2, Training Accuracy: 0.49625
Training loss = 0.060663684053080424
step = 3, Training Accuracy: 0.49607142857142855
Training loss = 0.060477798698203904
step = 4, Training Accuracy: 0.5066071428571428
Training loss = 0.05949360179049628
step = 5, Training Accuracy: 0.5283928571428571
Training loss = 0.058280383603913445
step = 6, Training Accuracy: 0.5467857142857143
Training loss = 0.055966632036226135
step = 7, Training Accuracy: 0.5730357142857143
Training loss = 0.05196161643735
step = 8, Training Accuracy: 0.61125
Training loss = 0.04933947838842869
step = 9, Training Accuracy: 0.6396428571428572
Validation Accuracy: 0.7275
29 	2     	0.75    	0       	0.75   	0.75   
individual:  Individual('d', [234.0, 413.0, 16.0, 401.0, 1204.0, 795.0])
Training loss = 0.06650711587497166
step = 0, Training Accuracy: 0.4467857142857143
Training loss = 0.06171572008303233
step = 1, Training Accuracy: 0.4858928571428571
Training loss = 0.06127994241459029
step = 2, Training Accuracy: 0.4975
Training loss = 0.06011566650654589
step = 3, Training Accuracy: 0.5073214285714286
Training loss = 0.057418100237846374
step = 4, Training Accuracy: 0.5471428571428572
Training loss = 0.05286438047885895
step = 5, Training Accuracy: 0.5998214285714286
Training loss = 0.04922140189579555
step = 6, Training Accuracy: 0.6421428571428571
Training loss = 0.04878161495285375
step = 7, Training Accuracy: 0.6446428571428572
Training loss = 0.047593552768230435
step = 8, Training Accuracy: 0.6591071428571429
Training loss = 0.046752396587814604
step = 9, Training Accuracy: 0.6644642857142857
Validation Accuracy: 0.74
individual:  Individual('d', [57.0, 500.0, 46.0, 109.0, 1270.0, 67.0])
Training loss = 0.06541932312505586
step = 0, Training Accuracy: 0.44125
Training loss = 0.06260348681892668
step = 1, Training Accuracy: 0.48410714285714285
Training loss = 0.06135144533855574
step = 2, Training Accuracy: 0.48142857142857143
Training loss = 0.06038340827184064
step = 3, Training Accuracy: 0.5026785714285714
Training loss = 0.05636658045862402
step = 4, Training Accuracy: 0.5719642857142857
Training loss = 0.05160566466727427
step = 5, Training Accuracy: 0.6192857142857143
Training loss = 0.050542624784367426
step = 6, Training Accuracy: 0.6408928571428572
Training loss = 0.047375865961824144
step = 7, Training Accuracy: 0.6601785714285714
Training loss = 0.04700352186071021
step = 8, Training Accuracy: 0.66625
Training loss = 0.04717057108879089
step = 9, Training Accuracy: 0.6639285714285714
Validation Accuracy: 0.7325
30 	2     	0.74    	0       	0.74   	0.74   
individual:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  value:  (0.75625,)
gen	nevals	avg     	std     	min    	max    
0  	2     	0.736875	0.004375	0.7325 	0.74125
1  	2     	0.75125 	0       	0.75125	0.75125
2  	2     	0.715   	0       	0.715  	0.715  
3  	2     	0.714375	0.006875	0.7075 	0.72125
4  	2     	0.715   	0.00375 	0.71125	0.71875
5  	2     	0.70625 	0       	0.70625	0.70625
6  	2     	0.7225  	0       	0.7225 	0.7225 
7  	2     	0.7475  	0       	0.7475 	0.7475 
8  	2     	0.72875 	0       	0.72875	0.72875
9  	2     	0.7175  	0       	0.7175 	0.7175 
10 	2     	0.73    	0       	0.73   	0.73   
11 	2     	0.73625 	0       	0.73625	0.73625
12 	2     	0.73875 	0       	0.73875	0.73875
13 	2     	0.74125 	0       	0.74125	0.74125
14 	2     	0.745   	0       	0.745  	0.745  
15 	2     	0.72375 	0       	0.72375	0.72375
16 	2     	0.74875 	0       	0.74875	0.74875
17 	2     	0.75    	0       	0.75   	0.75   
18 	2     	0.74875 	0       	0.74875	0.74875
19 	2     	0.72375 	0       	0.72375	0.72375
20 	2     	0.56875 	0.12625 	0.4425 	0.695  
21 	2     	0.7225  	0       	0.7225 	0.7225 
22 	2     	0.731875	0.015625	0.71625	0.7475 
23 	2     	0.73125 	0       	0.73125	0.73125
24 	2     	0.72375 	0       	0.72375	0.72375
25 	2     	0.75125 	0       	0.75125	0.75125
26 	2     	0.73875 	0       	0.73875	0.73875
27 	2     	0.75625 	0       	0.75625	0.75625
28 	2     	0.745   	0       	0.745  	0.745  
29 	2     	0.75    	0       	0.75   	0.75   
30 	2     	0.74    	0       	0.74   	0.74 
